{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-17 12:57:38.518160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Review_Results'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import sqlalchemy\n",
    "import json\n",
    "config=json.load(open(\"/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Scripts/config.json\",\"r\"))\n",
    "username=config['username']\n",
    "password=config['password']\n",
    "database=config['database']\n",
    "\n",
    "BL_engine=sqlalchemy.create_engine(\n",
    "            \"mysql+pymysql://%s:%s@localhost/%s\" % (username, password, database))\n",
    "print(datetime.datetime.now())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-08-29_2020-10-28/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-09-05_2020-10-19/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-09-19_2020-11-26/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-09-26_2020-11-28/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-10-03_2020-11-29/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-10-10_2020-12-03/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-10-17_2020-12-07/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-10-24_2020-12-08/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-10-31_2020-12-09/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-11-07_2020-12-11/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-11-14_2020-12-13/',\n",
       " '/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/output_No_DCM_2020-11-21_2020-12-16/']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_output='/mnt/clients/juba/hqjubaapp02/jliang/Projects/Big_Lots/Predictive_Model/Model_Outputs/'\n",
    "list_folder_output_by_week=os.listdir(folder_output)\n",
    "list_folder_output_by_week=[folder_output+x+\"/\" for x in list_folder_output_by_week if \"output_No_DCM_\" in x]\n",
    "list_folder_output_by_week.sort()\n",
    "list_folder_output_by_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in list_folder_output_by_week:\n",
    "    if len(os.listdir(folder))!=6:\n",
    "        print(\"check the folder that the writing files were not generated in the same folder by day: \\n%s\"%folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/clients/juba/hqjubaapp02/sharefolder/biglots_data/Email_Subscription_Files/Unsubs/BL_Email_UnSubscriber_File_Refresh__20200525040444.csv',\n",
       " '/mnt/clients/juba/hqjubaapp02/sharefolder/biglots_data/Email_Subscription_Files/Unsubs/BL_Email_UnSubscriber_File_Refresh__20200625040341.csv',\n",
       " '/mnt/clients/juba/hqjubaapp02/sharefolder/biglots_data/Email_Subscription_Files/Unsubs/BL_Email_UnSubscriber_File_Refresh__20200725040404.csv',\n",
       " '/mnt/clients/juba/hqjubaapp02/sharefolder/biglots_data/Email_Subscription_Files/Unsubs/BL_Email_UnSubscriber_File_Refresh__20200825040414.csv',\n",
       " '/mnt/clients/juba/hqjubaapp02/sharefolder/biglots_data/Email_Subscription_Files/Unsubs/BL_Email_UnSubscriber_File_Refresh__20200925040406.csv',\n",
       " '/mnt/clients/juba/hqjubaapp02/sharefolder/biglots_data/Email_Subscription_Files/Unsubs/BL_Email_UnSubscriber_File_Refresh__20201025040442.csv',\n",
       " '/mnt/clients/juba/hqjubaapp02/sharefolder/biglots_data/Email_Subscription_Files/Unsubs/BL_Email_UnSubscriber_File_Refresh__20201125050434.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_unsubsription=\"/mnt/clients/juba/hqjubaapp02/sharefolder/biglots_data/Email_Subscription_Files/Unsubs/\"\n",
    "list_unsubsription_files=glob.glob(folder_unsubsription+\"*.csv\")\n",
    "list_unsubsription_files=[x for x in list_unsubsription_files if \"iber_File_Refresh__\" in x]\n",
    "list_unsubsription_files.sort()\n",
    "list_unsubsription_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-29 trans_1_only_DV3_2020-08-29 2020-12-17 13:00:20.847542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-29 trans_2_plus_DV2_2020-08-29 2020-12-17 13:01:03.629354\n",
      "2020-09-05 trans_1_only_DV3_2020-09-05 2020-12-17 13:05:17.295424\n",
      "2020-09-05 trans_2_plus_DV2_2020-09-05 2020-12-17 13:05:37.386311\n",
      "2020-09-19 trans_1_only_DV3_2020-09-19 2020-12-17 13:08:52.668953\n"
     ]
    }
   ],
   "source": [
    "df_output_train_summary=pd.DataFrame()\n",
    "df_output_test_summary=pd.DataFrame()\n",
    "df_output_both_summary=pd.DataFrame()\n",
    "\n",
    "for weekly_folder in list_folder_output_by_week:\n",
    "    files=os.listdir(weekly_folder)\n",
    "    \n",
    "    file_trans_1_only_DV3=[weekly_folder+x for x in files if \"BL_LRModeling_NoDCM_trans_1_only_DV3\" in x][0]\n",
    "    file_trans_2_plus_DV2=[weekly_folder+x for x in files if \"BL_LRModeling_NoDCM_trans_2_plus_DV2\" in x][0]\n",
    "    week_end_dt=file_trans_1_only_DV3.split(\"_JL_\")[0][-10:]\n",
    "    week_end_dt=datetime.datetime.strptime(week_end_dt,\"%Y-%m-%d\").date()\n",
    "    \n",
    "    df_unsub_files=pd.DataFrame({\"file_path\":list_unsubsription_files})\n",
    "    df_unsub_files['date']=df_unsub_files['file_path'].apply(lambda x: x.split(\"ile_Refresh__\")[1][:8])\n",
    "    df_unsub_files['date']=pd.to_datetime(df_unsub_files['date']).dt.date\n",
    "    df_unsub_files['day_diff']=abs(df_unsub_files['date']-week_end_dt)\n",
    "    path_unsub=df_unsub_files[df_unsub_files['day_diff']==df_unsub_files['day_diff'].min()]['file_path'].values.tolist()[0]\n",
    "    list_unsunsribe_ids=pd.read_csv(path_unsub,\n",
    "                             dtype=str,usecols=['customersummary_c_primaryscnhash'])['customersummary_c_primaryscnhash'].unique().tolist()\n",
    "    \n",
    "    sql_str_start=\"'\"+str(week_end_dt-datetime.timedelta(days=13))+\"'\"\n",
    "    sql_str_end=\"'\"+str(week_end_dt)+\"'\"\n",
    "    df_ids_shoppers_past_2_weeks=pd.read_sql(\"select distinct customer_id_hashed as customer_id_hashed from Pred_POS_Department where transaction_dt between %s and %s and customer_id_hashed is not null;\"%(sql_str_start,sql_str_end),con=BL_engine)\n",
    "    df_ids_shoppers_past_2_weeks['past_shoppers']=\"shopper_in_past_2_weeks\"\n",
    "    df_week_train=pd.DataFrame()\n",
    "    df_week_test=pd.DataFrame()\n",
    "    df_week_both=pd.DataFrame()\n",
    "    \n",
    "    # train\n",
    "    for file in [file_trans_1_only_DV3,file_trans_2_plus_DV2]:\n",
    "        print(week_end_dt,file.split(\"BL_LRModeling_NoDCM_\")[1][:27],datetime.datetime.now())\n",
    "        type_model=file.split(\"BL_LRModeling_NoDCM_\")[1][:12]\n",
    "        DV_n=file.split(type_model)[1][1:4]\n",
    "        excel_file=pd.ExcelFile(file)\n",
    "        file_ids_train=[weekly_folder+x for x in files if \"df_train\" in x and type_model in x][0]\n",
    "        file_ids_test=[weekly_folder+x for x in files if \"df_test\" in x and type_model in x][0]\n",
    "        ### train\n",
    "        df_ids_train=pd.read_csv(file_ids_train)\n",
    "        df_ids_train['subscription_lables']=np.where(df_ids_train['customer_id_hashed'].isin(list_unsunsribe_ids),\"unsub\",\"default_subs\")\n",
    "\n",
    "        df_ids_train=pd.merge(df_ids_train,df_ids_shoppers_past_2_weeks,on=\"customer_id_hashed\",how=\"left\")\n",
    "        count_target_ids_shoppered_past2weeks_train=df_ids_train[(df_ids_train['selection_label']==\"target\") & (df_ids_train['past_shoppers']==\"shopper_in_past_2_weeks\")]\n",
    "        count_target_ids_shoppered_past2weeks_train=len(count_target_ids_shoppered_past2weeks_train)\n",
    "        count_nonselect_ids_shoppered_past2weeks_train=df_ids_train[(df_ids_train['selection_label']==\"nonselect\") & (df_ids_train['past_shoppers']==\"shopper_in_past_2_weeks\")]\n",
    "        count_nonselect_ids_shoppered_past2weeks_train=len(count_nonselect_ids_shoppered_past2weeks_train)\n",
    "        ### test\n",
    "        df_ids_test=pd.read_csv(file_ids_test)\n",
    "        df_ids_test['subscription_lables']=np.where(df_ids_test['customer_id_hashed'].isin(list_unsunsribe_ids),\"unsub\",\"default_subs\")\n",
    "\n",
    "        df_ids_test=pd.merge(df_ids_test,df_ids_shoppers_past_2_weeks,on=\"customer_id_hashed\",how=\"left\")\n",
    "        count_target_ids_shoppered_past2weeks_test=df_ids_test[(df_ids_test['selection_label']==\"target\") & (df_ids_test['past_shoppers']==\"shopper_in_past_2_weeks\")]\n",
    "        count_target_ids_shoppered_past2weeks_test=len(count_target_ids_shoppered_past2weeks_test)\n",
    "        count_nonselect_ids_shoppered_past2weeks_test=df_ids_test[(df_ids_test['selection_label']==\"nonselect\") & (df_ids_test['past_shoppers']==\"shopper_in_past_2_weeks\")]\n",
    "        count_nonselect_ids_shoppered_past2weeks_test=len(count_nonselect_ids_shoppered_past2weeks_test)\n",
    "        \n",
    "        # new to file past 4 weeks count\n",
    "        count_id_train_new_signs_past4weeks=df_ids_train[(df_ids_train['sign_up_label']==\"new_signs\")].shape[0]\n",
    "        count_id_train_new_signs_past4weeks_sub=df_ids_train[(df_ids_train['sign_up_label']==\"new_signs\") & (df_ids_train['subscription_lables']==\"default_subs\")].shape[0]\n",
    "        count_id_train_new_signs_past4weeks_unsub=df_ids_train[(df_ids_train['sign_up_label']==\"new_signs\") & (df_ids_train['subscription_lables']==\"unsub\")].shape[0]\n",
    "        \n",
    "        count_id_test_new_signs_past4weeks=df_ids_test[(df_ids_test['sign_up_label']==\"new_signs\")].shape[0]\n",
    "        count_id_test_new_signs_past4weeks_sub=df_ids_test[(df_ids_test['sign_up_label']==\"new_signs\") & (df_ids_test['subscription_lables']==\"default_subs\")].shape[0]\n",
    "        count_id_test_new_signs_past4weeks_unsub=df_ids_test[(df_ids_test['sign_up_label']==\"new_signs\") & (df_ids_test['subscription_lables']==\"unsub\")].shape[0]\n",
    "        \n",
    "        \n",
    "        # count\n",
    "        df=excel_file.parse(\"df_dataset_shape\")\n",
    "        train_records=df.loc[df['Unnamed: 0']==\"X_train\",\"records\"].values[0]\n",
    "        test_records=df.loc[df['Unnamed: 0']==\"X_test\",\"records\"].values[0]\n",
    "\n",
    "        # cutoff\n",
    "        df=excel_file.parse(\"select_score_matrix\")\n",
    "        cutoff=df.iloc[0,0]\n",
    "        # Media selection\n",
    "        # Train\n",
    "        df_train=excel_file.parse(\"train_id_summary\")\n",
    "        target_count_train=df_train[df_train['selection_label']==\"target\"]['customer_id_hashed'].sum()\n",
    "        nonselect_count_train=df_train[df_train['selection_label']==\"nonselect\"]['customer_id_hashed'].sum()\n",
    "        \n",
    "        target_count_train_new=df_train[(df_train['selection_label']==\"target\") & (df_train['sign_up_label']==\"new_signs\")]['customer_id_hashed'].sum()\n",
    "        target_count_train_existing=df_train[(df_train['selection_label']==\"target\") & (df_train['sign_up_label']==\"existing\")]['customer_id_hashed'].sum()\n",
    "        target_count_train_existing_sub=df_ids_train[(df_ids_train['selection_label']==\"target\") & (df_ids_train['sign_up_label']==\"existing\") & (df_ids_train['subscription_lables']==\"default_subs\")].shape[0]\n",
    "        target_count_train_existing_unsub=df_ids_train[(df_ids_train['selection_label']==\"target\") & (df_ids_train['sign_up_label']==\"existing\") & (df_ids_train['subscription_lables']==\"unsub\")].shape[0]\n",
    "        nonselect_count_train_existing_sub=df_ids_train[(df_ids_train['selection_label']==\"nonselect\") & (df_ids_train['sign_up_label']==\"existing\") & (df_ids_train['subscription_lables']==\"default_subs\")].shape[0]\n",
    "        nonselect_count_train_existing_unsub=df_ids_train[(df_ids_train['selection_label']==\"nonselect\") & (df_ids_train['sign_up_label']==\"existing\") & (df_ids_train['subscription_lables']==\"unsub\")].shape[0]        \n",
    "        \n",
    "        shoper_count_train_target=df_train[(df_train['selection_label']==\"target\") & (df_train['actual_shopping_label']==\"shopper\")]['customer_id_hashed'].sum()\n",
    "        shoper_count_train_nonselect=df_train[(df_train['selection_label']==\"nonselect\") & (df_train['actual_shopping_label']==\"shopper\")]['customer_id_hashed'].sum()\n",
    "\n",
    "        target_shop_rate_train=np.round(shoper_count_train_target/target_count_train,4)\n",
    "        nonselect_shop_rate_train=np.round(shoper_count_train_nonselect/nonselect_count_train,4)\n",
    "        target_shop_rate_P2W_train=np.round(count_target_ids_shoppered_past2weeks_train/target_count_train,4)\n",
    "        nonselect_shop_rate_P2W_train=np.round(count_nonselect_ids_shoppered_past2weeks_train/nonselect_count_train,4)\n",
    "        \n",
    "        # Test\n",
    "        df_test=excel_file.parse(\"test_id_summary\")\n",
    "        target_count_test=df_test[df_test['selection_label']==\"target\"]['customer_id_hashed'].sum()\n",
    "        nonselect_count_test=df_test[df_test['selection_label']==\"nonselect\"]['customer_id_hashed'].sum()\n",
    "        total_count_test=target_count_test+nonselect_count_test\n",
    "\n",
    "        target_count_test_new=df_test[(df_test['selection_label']==\"target\") & (df_test['sign_up_label']==\"new_signs\")]['customer_id_hashed'].sum()\n",
    "        target_count_test_existing=df_test[(df_test['selection_label']==\"target\") & (df_test['sign_up_label']==\"existing\")]['customer_id_hashed'].sum()\n",
    "        target_count_test_existing_sub=df_ids_test[(df_ids_test['selection_label']==\"target\") & (df_ids_test['sign_up_label']==\"existing\") &(df_ids_test['subscription_lables']==\"default_subs\")].shape[0]\n",
    "        target_count_test_existing_unsub=df_ids_test[(df_ids_test['selection_label']==\"target\") & (df_ids_test['sign_up_label']==\"existing\") & (df_ids_test['subscription_lables']==\"unsub\")].shape[0]\n",
    "        nonselect_count_test_existing_sub=df_ids_test[(df_ids_test['selection_label']==\"nonselect\") & (df_ids_test['sign_up_label']==\"existing\") & (df_ids_test['subscription_lables']==\"default_subs\")].shape[0]\n",
    "        nonselect_count_test_existing_unsub=df_ids_test[(df_ids_test['selection_label']==\"nonselect\") & (df_ids_test['sign_up_label']==\"existing\") & (df_ids_test['subscription_lables']==\"unsub\")].shape[0]        \n",
    "        \n",
    "        \n",
    "        shoper_count_test_target=df_test[(df_test['selection_label']==\"target\") & (df_test['actual_shopping_label']==\"shopper\")]['customer_id_hashed'].sum()\n",
    "        shoper_count_test_nonselect=df_test[(df_test['selection_label']==\"nonselect\") & (df_test['actual_shopping_label']==\"shopper\")]['customer_id_hashed'].sum()\n",
    "        \n",
    "        target_shop_rate_test=np.round(shoper_count_test_target/target_count_test,4)\n",
    "        nonselect_shop_rate_test=np.round(shoper_count_test_nonselect/nonselect_count_test,4)\n",
    "        target_shop_rate_P2W_test=np.round(count_target_ids_shoppered_past2weeks_test/target_count_test,4)\n",
    "        nonselect_shop_rate_P2W_test=np.round(count_nonselect_ids_shoppered_past2weeks_test/nonselect_count_test,4)\n",
    "        \n",
    "        # Both\n",
    "        target_shop_rate_DV_both=np.round(sum([shoper_count_train_target,shoper_count_test_target])/sum([target_count_train,target_count_test]),4)\n",
    "        nonselect_shop_rate_DV_both=np.round(sum([shoper_count_train_nonselect,shoper_count_test_nonselect])/sum([nonselect_count_train,nonselect_count_test]),4)\n",
    "        target_shop_rate_P2W_both=np.round(sum([count_target_ids_shoppered_past2weeks_train,count_target_ids_shoppered_past2weeks_test])/sum([target_count_train,target_count_test]),4)\n",
    "        nonselect_shop_rate_P2W_both=np.round(sum([count_nonselect_ids_shoppered_past2weeks_train,count_nonselect_ids_shoppered_past2weeks_test])/sum([target_count_train,nonselect_count_test]),4)\n",
    "        \n",
    "        df_output_train=pd.DataFrame({\n",
    "            \"Total_Counts\":train_records,\n",
    "            \"cutoffs\":cutoff,\n",
    "            \"target_count\":target_count_train,\n",
    "            \"target_new_ids\":target_count_train_new,\n",
    "            \"past4W_new_ids_subset\":count_id_train_new_signs_past4weeks,\n",
    "            \"past4W_new_ids_subset_sub\":count_id_train_new_signs_past4weeks_sub,\n",
    "            \"past4W_new_ids_subset_unsub\":count_id_train_new_signs_past4weeks_unsub,\n",
    "            \"target_existing_ids\":target_count_train_existing,\n",
    "            \"target_existing_ids_sub\":target_count_train_existing_sub,\n",
    "            \"target_existing_ids_unsub\":target_count_train_existing_unsub,\n",
    "            \"target_shop_rate_DV\":target_shop_rate_train,\n",
    "            \"nonselect_shop_rate_DV\":nonselect_shop_rate_train,\n",
    "            \"target_shop_rate_Past2W\":target_shop_rate_P2W_train,\n",
    "            \"nonselect_shop_rate_Past2W\":nonselect_shop_rate_P2W_train,\n",
    "            'nonselect_count_existing_sub':nonselect_count_train_existing_sub,\n",
    "            'nonselect_count_existing_unsub':nonselect_count_train_existing_unsub\n",
    "        },index=[type_model]).T.rename(columns={type_model:week_end_dt}).reset_index()\n",
    "        \n",
    "        df_output_test=pd.DataFrame({\n",
    "            \"Total_Counts\":test_records,\n",
    "            \"cutoffs\":cutoff,\n",
    "            \"target_count\":target_count_test,\n",
    "            \"target_new_ids\":target_count_test_new,\n",
    "            \"past4W_new_ids_subset\":count_id_test_new_signs_past4weeks,\n",
    "            \"past4W_new_ids_subset_sub\":count_id_test_new_signs_past4weeks_sub,\n",
    "            \"past4W_new_ids_subset_unsub\":count_id_test_new_signs_past4weeks_unsub,\n",
    "            \"target_existing_ids\":target_count_test_existing,\n",
    "            \"target_existing_ids_sub\":target_count_test_existing_sub,\n",
    "            \"target_existing_ids_unsub\":target_count_test_existing_unsub,\n",
    "            \"target_shop_rate_DV\":target_shop_rate_test,\n",
    "            \"nonselect_shop_rate_DV\":nonselect_shop_rate_test,\n",
    "            \"target_shop_rate_Past2W\":target_shop_rate_P2W_test,\n",
    "            \"nonselect_shop_rate_Past2W\":nonselect_shop_rate_P2W_test,\n",
    "            'nonselect_count_existing_sub':nonselect_count_test_existing_sub,\n",
    "            'nonselect_count_existing_unsub':nonselect_count_test_existing_unsub\n",
    "        },index=[type_model]).T.rename(columns={type_model:week_end_dt}).reset_index()\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "        # iterrate the cutoff of 1 trans\n",
    "        if type_model==\"trans_1_only\":\n",
    "            df_train_id_new=df_ids_train[df_ids_train['sign_up_label']==\"new_signs\"]\n",
    "            df_new_cutoff_train=pd.DataFrame()        \n",
    "            for i in range(1,6):\n",
    "                new_cutoff=np.round(cutoff/(1+i/10),4)\n",
    "                df_train_id_new['selection_label']=np.where(df_train_id_new['y_hat']>=new_cutoff,\"target\",\"nonselect\")\n",
    "                df=pd.DataFrame({week_end_dt:df_train_id_new['selection_label'].tolist().count(\"target\")},index=[\"count_new_target_at_%d0pctg_diminishing\"%i])\n",
    "                df_new_cutoff_train=df_new_cutoff_train.append(df)\n",
    "                \n",
    "            df_test_id_new=df_ids_test[df_ids_test['sign_up_label']==\"new_signs\"]\n",
    "            df_new_cutoff_test=pd.DataFrame()        \n",
    "            for i in range(1,6):\n",
    "                new_cutoff=np.round(cutoff/(1+i/10),4)\n",
    "                df_test_id_new['selection_label']=np.where(df_test_id_new['y_hat']>=new_cutoff,\"target\",\"nonselect\")\n",
    "                df=pd.DataFrame({week_end_dt:df_test_id_new['selection_label'].tolist().count(\"target\")},index=[\"count_new_target_at_%d0pctg_diminishing\"%i])\n",
    "                df_new_cutoff_test=df_new_cutoff_test.append(df)  \n",
    "            df_new_cutoff_train=df_new_cutoff_train.reset_index()\n",
    "            df_new_cutoff_test=df_new_cutoff_test.reset_index()\n",
    "            df_output_train=df_output_train.append(df_new_cutoff_train)\n",
    "            df_output_test=df_output_test.append(df_new_cutoff_test)\n",
    "            \n",
    "                \n",
    "        elif type_model==\"trans_2_plus\":\n",
    "            df_train_id_all=df_ids_train.copy()\n",
    "            df_update_cutoff_train=pd.DataFrame()        \n",
    "            for i in range(1,6):\n",
    "                updated_cutoff=np.round(cutoff/(1+i/10),4)\n",
    "                df_train_id_all['selection_label']=np.where(df_train_id_all['y_hat']>=updated_cutoff,\"target\",\"nonselect\")\n",
    "                df=pd.DataFrame({week_end_dt:df_train_id_all['selection_label'].tolist().count(\"target\")},index=[\"count_updated_target_at_%d0pctg_diminishing\"%i])\n",
    "                df_update_cutoff_train=df_update_cutoff_train.append(df)\n",
    "                \n",
    "            df_test_id_all=df_ids_test.copy()\n",
    "            df_update_cutoff_test=pd.DataFrame()        \n",
    "            for i in range(1,6):\n",
    "                updated_cutoff=np.round(cutoff/(1+i/10),4)\n",
    "                df_test_id_all['selection_label']=np.where(df_test_id_all['y_hat']>=updated_cutoff,\"target\",\"nonselect\")\n",
    "                df=pd.DataFrame({week_end_dt:df_test_id_all['selection_label'].tolist().count(\"target\")},index=[\"count_updated_target_at_%d0pctg_diminishing\"%i])\n",
    "                df_update_cutoff_test=df_update_cutoff_test.append(df)  \n",
    "            \n",
    "            df_update_cutoff_train=df_update_cutoff_train.reset_index()\n",
    "            df_update_cutoff_test=df_update_cutoff_test.reset_index()\n",
    "            \n",
    "            df_output_train=df_output_train.append(df_update_cutoff_train)\n",
    "            df_output_test=df_output_test.append(df_update_cutoff_test)\n",
    "            \n",
    "            \n",
    "        df_output_train['type_model']=type_model\n",
    "        df_output_train['DV_type']=DV_n\n",
    "        df_output_test['type_model']=type_model\n",
    "        df_output_test['DV_type']=DV_n\n",
    "        \n",
    "        df_output_train=df_output_train.set_index(['index','DV_type','type_model'])\n",
    "        df_output_test=df_output_test.set_index(['index','DV_type','type_model'])\n",
    "        \n",
    "        df_week_train=df_week_train.append(df_output_train)\n",
    "        df_week_test=df_week_test.append(df_output_test)\n",
    "        \n",
    "\n",
    "        df_output_total=pd.DataFrame({\n",
    "            \"Total_Counts\":train_records+test_records,\n",
    "            \"cutoffs\":cutoff,\n",
    "            \"target_count\":target_count_train+target_count_test,\n",
    "            \"target_new_ids\":target_count_train_new+target_count_test_new,\n",
    "            \"past4W_new_ids_subset\":count_id_train_new_signs_past4weeks+count_id_test_new_signs_past4weeks,\n",
    "            \"past4W_new_ids_subset_sub\":count_id_train_new_signs_past4weeks_sub+count_id_test_new_signs_past4weeks_sub,\n",
    "            \"past4W_new_ids_subset_unsub\":count_id_train_new_signs_past4weeks_unsub+count_id_test_new_signs_past4weeks_unsub,\n",
    "            \"target_existing_ids\":target_count_train_existing+target_count_test_existing,\n",
    "            \"target_existing_ids_sub\":target_count_train_existing_sub+target_count_test_existing_sub,\n",
    "            \"target_existing_ids_unsub\":target_count_train_existing_unsub+target_count_test_existing_unsub,\n",
    "            \"target_shop_rate_DV\":target_shop_rate_DV_both,\n",
    "            \"nonselect_shop_rate_DV\":nonselect_shop_rate_DV_both,\n",
    "            \"target_shop_rate_Past2W\":target_shop_rate_P2W_both,\n",
    "            \"nonselect_shop_rate_Past2W\":nonselect_shop_rate_P2W_both,\n",
    "            'nonselect_count_existing_sub':nonselect_count_train_existing_sub+nonselect_count_test_existing_sub,\n",
    "            'nonselect_count_existing_unsub':nonselect_count_train_existing_unsub+nonselect_count_test_existing_unsub\n",
    "        },index=[type_model]).T.rename(columns={type_model:week_end_dt}).reset_index()\n",
    "        df_output_total['type_model']=type_model\n",
    "        df_output_total['DV_type']=DV_n\n",
    "        df_output_total=df_output_total.set_index(['index','DV_type','type_model'])\n",
    "        df_week_both=df_week_both.append(df_output_total)\n",
    "        \n",
    "    \n",
    "    if len(df_output_train_summary)==0:\n",
    "        df_output_train_summary=df_week_train\n",
    "    else:\n",
    "        df_output_train_summary=pd.concat([df_output_train_summary,df_week_train],axis=1)\n",
    "        \n",
    "    if len(df_output_test_summary)==0:\n",
    "        df_output_test_summary=df_week_test\n",
    "    else:\n",
    "        df_output_test_summary=pd.concat([df_output_test_summary,df_week_test],axis=1)\n",
    "        \n",
    "    if len(df_output_both_summary)==0:\n",
    "        df_output_both_summary=df_week_both\n",
    "    else:\n",
    "        df_output_both_summary=pd.concat([df_output_both_summary,df_week_both],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_train_summary=df_output_train_summary.reset_index()\n",
    "df_output_test_summary=df_output_test_summary.reset_index()\n",
    "df_output_both_summary=df_output_both_summary.reset_index()\n",
    "\n",
    "df_train_new_update=df_output_train_summary[~df_output_train_summary['index'].isin(df_output_both_summary['index'].tolist())]\n",
    "df_test_new_update=df_output_test_summary[~df_output_test_summary['index'].isin(df_output_both_summary['index'].tolist())]\n",
    "df_train_new_update=df_train_new_update.set_index(['index','DV_type','type_model'])\n",
    "df_test_new_update=df_test_new_update.set_index(['index','DV_type','type_model'])\n",
    "\n",
    "df_both_new_update=df_train_new_update+df_test_new_update\n",
    "df_both_new_update=df_both_new_update.reset_index()\n",
    "df_output_both_summary=df_output_both_summary.append(df_both_new_update)\n",
    "df_order=df_output_train_summary[['index','DV_type','type_model']]\n",
    "df_order['order']=range(df_order.shape[0])\n",
    "\n",
    "df_output_both_summary=pd.merge(df_order,df_output_both_summary,on=['index','DV_type','type_model'],how=\"outer\")\n",
    "df_output_both_summary=df_output_both_summary.sort_values(\"order\")\n",
    "del df_output_both_summary['order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_both_summary.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_an_empty_row(df):\n",
    "    df_1=df[df['DV_type']==\"DV3\"]\n",
    "    df_2=df[df['DV_type']==\"DV2\"]\n",
    "    df_empty=pd.DataFrame(columns=df_1.columns.tolist())\n",
    "    df_empty[df_empty.columns.tolist()[0]]=[np.nan]\n",
    "    \n",
    "    return df_1.append(df_empty).append(df_2)\n",
    "\n",
    "\n",
    "df_output_both_summary=insert_an_empty_row(df_output_both_summary)\n",
    "df_output_train_summary=insert_an_empty_row(df_output_train_summary)\n",
    "df_output_test_summary=insert_an_empty_row(df_output_test_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"./BL_RL_modeling_summary_JL_%s.xlsx\"%str(datetime.datetime.now().date()),engine=\"xlsxwriter\")\n",
    "df_output_both_summary.to_excel(writer,\"overall\",index=False)\n",
    "df_output_train_summary.to_excel(writer,\"train\",index=False)\n",
    "df_output_test_summary.to_excel(writer,\"test\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
