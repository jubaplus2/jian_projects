{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/celery/Google_LiveRamp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90 days back up to 2019-04-06\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import gc\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thismonday 2019-04-08\n",
      "last_week_end_saturday:  2019-04-06\n",
      "start_90_days:  2019-01-07\n"
     ]
    }
   ],
   "source": [
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "            \n",
    "\n",
    "\n",
    "thismonday=datetime.datetime.now().date()-datetime.timedelta(days=datetime.datetime.now().date().weekday())\n",
    "thismonday=datetime.date(2019,4,8)\n",
    "print(\"thismonday\", thismonday)\n",
    "\n",
    "last_week_end_saturday=thismonday-datetime.timedelta(days=2)\n",
    "\n",
    "print(\"last_week_end_saturday: \",last_week_end_saturday)\n",
    "\n",
    "start_90_days=last_week_end_saturday-datetime.timedelta(days=89)\n",
    "print(\"start_90_days: \",start_90_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer_pather=\"/home/jian/celery/Google_LiveRamp/output/\"\n",
    "data_root_2019=\"/home/jian/BigLots/2019_by_weeks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_daily_list=[x for x in list(recursive_file_gen(data_root_2019)) if \"Daily\" in x]\n",
    "\n",
    "sub_class_level_daily_df=pd.DataFrame({\"file_path\":files_daily_list})\n",
    "sub_class_level_daily_df['week_end_dt']=sub_class_level_daily_df['file_path'].apply(lambda x: x.split(\"_weeks/MediaStorm_\")[1][:10])\n",
    "sub_class_level_daily_df=sub_class_level_daily_df[(sub_class_level_daily_df['week_end_dt']>=str(start_90_days)) & (sub_class_level_daily_df['week_end_dt']<=\"2019-02-09\")]\n",
    "sub_class_level_daily_df=sub_class_level_daily_df.sort_values(\"week_end_dt\")\n",
    "\n",
    "\n",
    "item_level_daily_df=pd.DataFrame({\"file_path\":files_daily_list})\n",
    "item_level_daily_df['week_end_dt']=item_level_daily_df['file_path'].apply(lambda x: x.split(\"_weeks/MediaStorm_\")[1][:10])\n",
    "item_level_daily_df=item_level_daily_df[(item_level_daily_df['week_end_dt']>=\"2019-02-16\") & (item_level_daily_df['week_end_dt']<=\"2019-04-06\")]\n",
    "item_level_daily_df=item_level_daily_df.sort_values(\"week_end_dt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2019-04-15 15:38:21.834860\n",
      "2 2019-04-15 15:39:10.185455\n",
      "3 2019-04-15 15:39:55.961365\n",
      "4 2019-04-15 15:40:34.520565\n",
      "5 2019-04-15 15:41:14.435255\n"
     ]
    }
   ],
   "source": [
    "i_counter=0\n",
    "data_last_90_days=pd.DataFrame()\n",
    "for file_sub_class in sub_class_level_daily_df['file_path'].tolist():\n",
    "    df=pd.read_table(file_sub_class,sep=\"|\",dtype=str,usecols=['location_id','customer_id_hashed','transaction_dt','subclass_transaction_amt'])\n",
    "    df=df[~pd.isnull(df['customer_id_hashed'])]    \n",
    "    df=df[df['location_id']!=\"6990\"]\n",
    "    df['subclass_transaction_amt']=df['subclass_transaction_amt'].astype(float)\n",
    "    df=df.groupby(['customer_id_hashed','transaction_dt'])['subclass_transaction_amt'].sum().to_frame().reset_index()\n",
    "    df=df.rename(columns={\"transaction_dt\":\"transaction_timestamp\",\"subclass_transaction_amt\":\"Conversion_Amount\"})\n",
    "    df['transaction_timestamp']=df['transaction_timestamp'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "    data_last_90_days=data_last_90_days.append(df)\n",
    "    i_counter+=1\n",
    "    print(i_counter,datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2019-04-15 15:42:01.069579\n",
      "7 2019-04-15 15:42:47.735543\n",
      "8 2019-04-15 15:43:40.081591\n",
      "9 2019-04-15 15:44:32.096346\n",
      "10 2019-04-15 15:45:22.816569\n",
      "11 2019-04-15 15:46:14.011225\n",
      "12 2019-04-15 15:47:05.124093\n",
      "13 2019-04-15 15:48:10.756140\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file_item_level in item_level_daily_df['file_path'].tolist():\n",
    "    df=pd.read_table(file_item_level,sep=\"|\",dtype=str,usecols=['location_id','customer_id_hashed','transaction_dt','item_transaction_amt'])\n",
    "    df=df[~pd.isnull(df['customer_id_hashed'])]\n",
    "    df=df[df['location_id']!=\"6990\"]\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    df=df.groupby(['customer_id_hashed','transaction_dt'])['item_transaction_amt'].sum().to_frame().reset_index()\n",
    "    df=df.rename(columns={\"transaction_dt\":\"transaction_timestamp\",\"item_transaction_amt\":\"Conversion_Amount\"})\n",
    "    df['transaction_timestamp']=df['transaction_timestamp'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "    data_last_90_days=data_last_90_days.append(df)\n",
    "    i_counter+=1\n",
    "    print(i_counter,datetime.datetime.now())\n",
    "data_last_90_days=data_last_90_days[data_last_90_days['transaction_timestamp']>=datetime.date(int(str(start_90_days).split(\"-\")[0]),int(str(start_90_days).split(\"-\")[1]),int(str(start_90_days).split(\"-\")[2]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path        date\n",
       "0  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-04-06\n",
       "1  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-30\n",
       "2  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-23\n",
       "3  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-16\n",
       "4  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-09"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_2019_weekly=[x for x in list(recursive_file_gen(\"/home/jian/BigLots/2019_by_weeks/\")) if (\"aster\" in x) & (\".txt\" in x) ]\n",
    "Master_2018_weekly=[x for x in list(recursive_file_gen(\"/home/jian/BigLots/2018_by_weeks/\")) if (\"aster\" in x) & (\".txt\" in x) ]\n",
    "\n",
    "\n",
    "weekly_df=pd.DataFrame({\"file_path\":Master_2019_weekly+Master_2018_weekly})\n",
    "weekly_df['date']=weekly_df['file_path'].apply(lambda x: x.split(\"_by_weeks/MediaStorm_\")[1][:10])\n",
    "weekly_df['date']=weekly_df['date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "weekly_df=weekly_df.sort_values(\"date\",ascending=False).reset_index()\n",
    "del weekly_df['index']\n",
    "weekly_df.head(5)\n",
    "\n",
    "# No need for the recent posibble file foloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1873409, 3)\n"
     ]
    }
   ],
   "source": [
    "data_0=pd.read_table(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/MediaStorm_Lapsed_Reward_Member_Master_from2014-08-26to2017-02-26.zip\",\n",
    "                     dtype=str,sep=\"|\",usecols=['customer_id_hashed','email_address_hash','customer_zip_code']).drop_duplicates()\n",
    "print(data_0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19337597, 3)\n"
     ]
    }
   ],
   "source": [
    "data_1=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/MediaStormCustTot-hashed-email.txt\",\n",
    "                     dtype=str,header=None,usecols=[0,1,5])\n",
    "data_1.columns=['customer_id_hashed','email_address_hash','customer_zip_code']\n",
    "data_1['customer_id_hashed']=data_1['customer_id_hashed'].apply(lambda x: hashlib.sha256(x.encode('utf-8')).hexdigest())\n",
    "print(data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7255226, 3)\n",
      "(5759051, 3)\n",
      "(659127, 3)\n"
     ]
    }
   ],
   "source": [
    "data_2 = pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/'+'MediaStormCustomerTransactionTotals_2018-01-09_2018-03-31.txt',\n",
    "                     sep = ',',dtype = str,usecols=['customer_id_hashed','email_address_hash','customer_zip_code'])\n",
    "print(data_2.shape)\n",
    "data_3 = pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/'+'Existing Reward Member Master as of 2018-06-05.txt',\n",
    "                     dtype = str,sep = '|',usecols=['customer_id_hashed','email_address_hash','customer_zip_code'])\n",
    "print(data_3.shape)\n",
    "data_4 = pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/'+'New Reward Member Master as of 2018-06-05.txt',\n",
    "                     dtype = str,sep = '|',usecols=['customer_id_hashed','email_address_hash','customer_zip_code'])\n",
    "print(data_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_old=data_4.append(data_3).append(data_2).append(data_1).append(data_0).drop_duplicates()\n",
    "del data_4\n",
    "del data_3\n",
    "del data_2\n",
    "del data_1\n",
    "del data_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25122556, 3)\n",
      "25087795\n",
      "(25087795, 3)\n"
     ]
    }
   ],
   "source": [
    "all_weekly_biweekly_master_file=pd.DataFrame()\n",
    "for file_path in weekly_df['file_path'].tolist():\n",
    "    df=pd.read_table(file_path,dtype=str,usecols=['customer_id_hashed','email_address_hash','customer_zip_code'],sep=\"|\")\n",
    "    all_weekly_biweekly_master_file=all_weekly_biweekly_master_file.append(df)\n",
    "\n",
    "all_weekly_biweekly_master_file=all_weekly_biweekly_master_file.append(master_old)\n",
    "print(all_weekly_biweekly_master_file.shape)\n",
    "print(len(all_weekly_biweekly_master_file['customer_id_hashed'].unique()))\n",
    "\n",
    "all_weekly_biweekly_master_file=all_weekly_biweekly_master_file.drop_duplicates('customer_id_hashed')\n",
    "print(all_weekly_biweekly_master_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16463959, 3)\n",
      "(16463959, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>transaction_timestamp</th>\n",
       "      <th>Conversion_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001ed4962579d15869b5ec21ee8ecfa136d13b07c3f8...</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002227290330cf6112d04470e512057ba4b50ab64c9f...</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>27.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed transaction_timestamp  \\\n",
       "0  00001ed4962579d15869b5ec21ee8ecfa136d13b07c3f8...            2019-01-10   \n",
       "1  00002227290330cf6112d04470e512057ba4b50ab64c9f...            2019-01-10   \n",
       "\n",
       "   Conversion_Amount  \n",
       "0               7.95  \n",
       "1              27.23  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_last_90_days.shape)\n",
    "print(data_last_90_days[['customer_id_hashed','transaction_timestamp']].drop_duplicates().shape)\n",
    "\n",
    "data_last_90_days.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_Raws: 16463959\n",
      "Null Email rows excluded: 1017500\n",
      "Na_Email_Rows_Pctg:  0.06180166022036376\n"
     ]
    }
   ],
   "source": [
    "data_last_90_days=pd.merge(data_last_90_days,all_weekly_biweekly_master_file,on=\"customer_id_hashed\",how=\"left\").rename(columns={\"email_address_hash\":\"Email_1\",\"customer_zip_code\":\"Zip_Code\"})\n",
    "data_last_90_days.head(2)\n",
    "\n",
    "total_rows_with_na_str=str(data_last_90_days.shape[0])\n",
    "print(\"Total_Raws: \"+total_rows_with_na_str)\n",
    "na_emails_rows_count_str=str(data_last_90_days[pd.isnull(data_last_90_days['Email_1'])].shape[0])\n",
    "print(\"Null Email rows excluded: \"+na_emails_rows_count_str)\n",
    "data_last_90_days=data_last_90_days[~pd.isnull(data_last_90_days['Email_1'])]\n",
    "del data_last_90_days['customer_id_hashed']\n",
    "\n",
    "print(\"Na_Email_Rows_Pctg: \",int(na_emails_rows_count_str)/int(total_rows_with_na_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_timestamp</th>\n",
       "      <th>Conversion_Amount</th>\n",
       "      <th>Email_1</th>\n",
       "      <th>Zip_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>7.95</td>\n",
       "      <td>787ae23b29bbc6fe721c28c14d0227575c534dca7470e9...</td>\n",
       "      <td>43612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>27.23</td>\n",
       "      <td>216b81a8a9eee53938c376a96eaace39016f7787626786...</td>\n",
       "      <td>77840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_timestamp  Conversion_Amount  \\\n",
       "0            2019-01-10               7.95   \n",
       "1            2019-01-10              27.23   \n",
       "\n",
       "                                             Email_1 Zip_Code  \n",
       "0  787ae23b29bbc6fe721c28c14d0227575c534dca7470e9...    43612  \n",
       "1  216b81a8a9eee53938c376a96eaace39016f7787626786...    77840  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_last_90_days.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_last_90_days=data_last_90_days[[\"Email_1\",\"Zip_Code\",\"transaction_timestamp\", \"Conversion_Amount\"]].rename(columns={\"Conversion_Amount\":\"transaction_amount\"})\n",
    "data_last_90_days['transaction_amount']=data_last_90_days['transaction_amount'].apply(lambda x: np.round(x,2)).astype(str)\n",
    "data_last_90_days['transaction_amount']=data_last_90_days['transaction_amount'].apply(lambda x: x.split(\".\")[0]+\".\"+x.split(\".\")[1].ljust(2,\"0\"))\n",
    "data_last_90_days['transaction_category']=\"In_Store\"\n",
    "\n",
    "data_last_90_days['Zip_Code']=\"00000\"\n",
    "\n",
    "data_last_90_days=data_last_90_days[['Zip_Code','Email_1','transaction_category','transaction_timestamp','transaction_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 4, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_max_date=data_last_90_days['transaction_timestamp'].max()\n",
    "data_max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 1, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_min_date=data_last_90_days['transaction_timestamp'].min()\n",
    "data_min_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15446459, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_last_90_days.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(89)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_max_date-data_min_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_last_90_days['transaction_timestamp'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/celery/Google_LiveRamp/output/'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer_pather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_path=writer_pather+\"BL_LR_GoogleStoreSales_90days_\"+str(data_min_date)+\"_\"+str(data_max_date)+\"_JL_\"+str(datetime.datetime.now().date())+\".txt\"\n",
    "\n",
    "data_last_90_days.to_csv(local_path,index=False,sep=\"|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "697681124.07000029"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_last_90_days['transaction_amount'].astype(float).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip_Code</th>\n",
       "      <th>Email_1</th>\n",
       "      <th>transaction_category</th>\n",
       "      <th>transaction_timestamp</th>\n",
       "      <th>transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000</td>\n",
       "      <td>787ae23b29bbc6fe721c28c14d0227575c534dca7470e9...</td>\n",
       "      <td>In_Store</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>7.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000</td>\n",
       "      <td>216b81a8a9eee53938c376a96eaace39016f7787626786...</td>\n",
       "      <td>In_Store</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>27.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000</td>\n",
       "      <td>884c7d27f0df2fdd99383fbe9ca4515281160dd08fb351...</td>\n",
       "      <td>In_Store</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000</td>\n",
       "      <td>3f029ca17f7d6d7c711c18b63ebd245798a8efd2b386d8...</td>\n",
       "      <td>In_Store</td>\n",
       "      <td>2019-01-12</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000</td>\n",
       "      <td>4b86884f30bce7a304559a5acd1a1bbdba1daaa151267f...</td>\n",
       "      <td>In_Store</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>26.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Zip_Code                                            Email_1  \\\n",
       "0    00000  787ae23b29bbc6fe721c28c14d0227575c534dca7470e9...   \n",
       "1    00000  216b81a8a9eee53938c376a96eaace39016f7787626786...   \n",
       "2    00000  884c7d27f0df2fdd99383fbe9ca4515281160dd08fb351...   \n",
       "3    00000  3f029ca17f7d6d7c711c18b63ebd245798a8efd2b386d8...   \n",
       "4    00000  4b86884f30bce7a304559a5acd1a1bbdba1daaa151267f...   \n",
       "\n",
       "  transaction_category transaction_timestamp transaction_amount  \n",
       "0             In_Store            2019-01-10               7.95  \n",
       "1             In_Store            2019-01-10              27.23  \n",
       "2             In_Store            2019-01-07               9.90  \n",
       "3             In_Store            2019-01-12               3.00  \n",
       "4             In_Store            2019-01-10              26.50  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_last_90_days.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_path==\"/home/jian/celery/Google_LiveRamp/output/BL_LR_GoogleStoreSales_90days_2019-01-07_2019-04-06_JL_2019-04-15.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58140093672500026"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_last_90_days['transaction_amount'].astype(float).sum()/1200000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_last_90_days.columns.tolist()==['Zip_Code','Email_1','transaction_category','transaction_timestamp','transaction_amount']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import paramiko\n",
    "\n",
    "host = \"sftp.liveramp.com\" #hard-coded\n",
    "port = 22\n",
    "transport = paramiko.Transport((host, port))\n",
    "\n",
    "password = \"Jubaplus2019!\" #hard-coded\n",
    "username = \"big-lots-ga-aw\" #hard-coded\n",
    "transport.connect(username = username, password = password)\n",
    "sftp = paramiko.SFTPClient.from_transport(transport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# local_path defined above before saving the local txt\n",
    "remote_path=\"/uploads/\"+os.path.basename(local_path)\n",
    "sftp.put(local_path,remote_path)\n",
    "sftp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
