{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "week_end_saturday=datetime.date(year=2018,month=11,day=3)\n",
    "\n",
    "# Added Google SOTF account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google PLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shopping']\n"
     ]
    }
   ],
   "source": [
    "Google_PLA_1=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Google_Adwords/Shopping/MetroArea_Shopping_Google_Oct2016-Sep2017_CSV.csv\",skiprows=2,dtype=str)\n",
    "Google_PLA_2=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Google_Adwords/Shopping/MetroArea_Shopping_Google_Oct2017-20181213_CSV.csv\",skiprows=2,dtype=str)\n",
    "\n",
    "del Google_PLA_1['Currency']\n",
    "del Google_PLA_2['Currency']\n",
    "\n",
    "Google_PLA_1['Day']=Google_PLA_1['Day'].apply(lambda x: datetime.datetime.strptime(x, '%b %d, %Y').date())\n",
    "Google_PLA_2['Day']=Google_PLA_2['Day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d').date())\n",
    "\n",
    "\n",
    "Google_PLA_2.columns=Google_PLA_1.columns\n",
    "Google_PLA=Google_PLA_1.append(Google_PLA_2)\n",
    "# Keep US Only\n",
    "# print(Google_PLA['Country/Territory'].unique())\n",
    "\n",
    "Google_PLA=Google_PLA[Google_PLA['Country/Territory']=='United States']\n",
    "Google_PLA.reset_index(inplace=True)\n",
    "del Google_PLA['index']\n",
    "print(Google_PLA['Campaign type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_Google_num(df):\n",
    "    if 'Impressions' in df.columns:\n",
    "        df['Impressions']=df['Impressions'].apply(lambda x: x.replace(\",\",\"\"))\n",
    "        df['Impressions']=df['Impressions'].astype(int)\n",
    "    if 'Clicks' in df.columns:\n",
    "        df['Clicks']=df['Clicks'].apply(lambda x: x.replace(\",\",\"\"))\n",
    "        df['Clicks']=df['Clicks'].astype(int)\n",
    "    if 'Cost' in df.columns:\n",
    "        df['Cost']=df['Cost'].apply(lambda x: x.replace(\",\",\"\"))\n",
    "        df['Cost']=df['Cost'].apply(lambda x: x.replace(\"$\",\"\"))\n",
    "        df['Cost']=df['Cost'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Google_PLA=Google_PLA[['Day','Metro area','Impressions','Clicks','Cost']]\n",
    "Google_PLA=clean_Google_num(Google_PLA)\n",
    "\n",
    "Google_PLA['weekday']=Google_PLA['Day'].apply(lambda x: x.weekday())\n",
    "Google_PLA=Google_PLA[(Google_PLA['Day']>=datetime.date(year=2016,month=10,day=2)) & (Google_PLA['Day']<=week_end_saturday)]\n",
    "Google_PLA.reset_index(inplace=True)\n",
    "del Google_PLA['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Google_PLA['week_start_date']=np.where(Google_PLA['weekday']==6,\n",
    "                                          Google_PLA['Day'],\n",
    "                                          Google_PLA['Day'].apply(lambda x: x-datetime.timedelta(days=(x.weekday()+1))))\n",
    "Google_PLA['week_end_date']=Google_PLA['week_start_date']+datetime.timedelta(days=6)\n",
    "Google_PLA=Google_PLA.groupby(['week_start_date','week_end_date','Metro area'])['Impressions','Clicks','Cost'].sum()\n",
    "Google_PLA.reset_index(inplace=True)\n",
    "Google_PLA['media']=\"Digital\"\n",
    "Google_PLA['submedia']=\"PLA\"\n",
    "Google_PLA['placement']=\"Google\"\n",
    "Google_PLA=Google_PLA[['week_start_date','week_end_date','Metro area','media','submedia','placement','Impressions','Clicks','Cost']]\n",
    "Google_PLA.columns=['week_start_date','week_end_date','DMA','media','submedia','placement','Impressions','Clicks','Cost']\n",
    "\n",
    "Google_PLA.to_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Aggregated_PLA_Google_Till_\"+str(week_end_saturday)+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Search Only' 'Display Only']\n",
      "['Search Only' 'Display Only']\n",
      "['Search Only']\n"
     ]
    }
   ],
   "source": [
    "Google_SEM_GDN_1=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Google_Adwords/Text_Ads/MetroArea_CampaignType_SEM_Oct2016-Sep2017_CSV.csv\",skiprows=2,dtype=str)\n",
    "del Google_SEM_GDN_1['Currency']\n",
    "Google_SEM_GDN_2=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Google_Adwords/Text_Ads/MetroArea_CampaignType_SEM_Oct2017-20181201_CSV.csv\",skiprows=2,dtype=str)\n",
    "del Google_SEM_GDN_2['Currency']\n",
    "\n",
    "Google_SEM_GDN_1['Day']=Google_SEM_GDN_1['Day'].apply(lambda x: datetime.datetime.strptime(x, '%b %d, %Y').date())\n",
    "Google_SEM_GDN_2['Day']=Google_SEM_GDN_2['Day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d').date())\n",
    "Google_SEM_GDN_2.columns=Google_SEM_GDN_1.columns.tolist()\n",
    "print(Google_SEM_GDN_1['Campaign type'].unique())\n",
    "print(Google_SEM_GDN_2['Campaign type'].unique())\n",
    "\n",
    "Google_SOTF_account=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Google_Adwords/SOTF/MetroArea_CampaignType_SOTF_Jan2018-20181201_CSV.csv\",skiprows=2,dtype=str)\n",
    "del Google_SOTF_account['Currency']\n",
    "Google_SOTF_account['Day']=Google_SOTF_account['Day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d').date())\n",
    "Google_SOTF_account=Google_SOTF_account[['Day', 'Metro area (Geographic)', 'Country/Territory (Geographic)', 'Campaign type', 'Clicks', 'Impressions','Cost']]\n",
    "\n",
    "Google_SOTF_account.columns=Google_SEM_GDN_1.columns\n",
    "print(Google_SOTF_account['Campaign type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338225648.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Google_SEM_GDN=Google_SEM_GDN_1.append(Google_SEM_GDN_2).append(Google_SOTF_account)\n",
    "\n",
    "# Keep US only, no missing found\n",
    "# print(Google_SEM_GDN['Country/Territory'].unique())\n",
    "Google_SEM_GDN=Google_SEM_GDN[Google_SEM_GDN['Country/Territory']=='United States']\n",
    "Google_SEM_GDN.reset_index(inplace=True)\n",
    "del Google_SEM_GDN['index']\n",
    "Google_SEM_GDN['Impressions'].apply(lambda x: x.replace(\",\",\"\")).astype(float).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "Google_SEM=Google_SEM_GDN[Google_SEM_GDN['Campaign type']=='Search Only']\n",
    "del Google_SEM['Campaign type']\n",
    "Google_SEM=clean_Google_num(Google_SEM)\n",
    "\n",
    "Google_SEM['weekday']=Google_SEM['Day'].apply(lambda x: x.weekday())\n",
    "Google_SEM=Google_SEM[(Google_SEM['Day']>=datetime.date(year=2016,month=10,day=2)) & (Google_SEM['Day']<=week_end_saturday)]\n",
    "Google_SEM.reset_index(inplace=True)\n",
    "del Google_SEM['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Google_SEM['week_start_date']=np.where(Google_SEM['weekday']==6,\n",
    "                                          Google_SEM['Day'],\n",
    "                                          Google_SEM['Day'].apply(lambda x: x-datetime.timedelta(days=(x.weekday()+1))))\n",
    "Google_SEM['week_end_date']=Google_SEM['week_start_date']+datetime.timedelta(days=6)\n",
    "Google_SEM=Google_SEM.groupby(['week_start_date','week_end_date','Metro area'])['Impressions','Clicks','Cost'].sum()\n",
    "Google_SEM.reset_index(inplace=True)\n",
    "Google_SEM['media']=\"Digital\"\n",
    "Google_SEM['submedia']=\"SEM\"\n",
    "Google_SEM['placement']=\"Google\"\n",
    "Google_SEM=Google_SEM[['week_start_date','week_end_date','Metro area','media','submedia','placement','Impressions','Clicks','Cost']]\n",
    "Google_SEM.columns=['week_start_date','week_end_date','DMA','media','submedia','placement','Impressions','Clicks','Cost']\n",
    "\n",
    "Google_SEM.to_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Aggregated_SEM_Google_Till_\"+str(week_end_saturday)+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2018, 11, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Google_SEM['week_end_date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google GDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "Google_GDN=Google_SEM_GDN[Google_SEM_GDN['Campaign type']=='Display Only']\n",
    "del Google_GDN['Campaign type']\n",
    "Google_GDN=clean_Google_num(Google_GDN)\n",
    "\n",
    "Google_GDN['weekday']=Google_GDN['Day'].apply(lambda x: x.weekday())\n",
    "Google_GDN=Google_GDN[(Google_GDN['Day']>=datetime.date(year=2016,month=10,day=2)) & (Google_GDN['Day']<=week_end_saturday)]\n",
    "Google_GDN.reset_index(inplace=True)\n",
    "del Google_GDN['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Google_GDN['week_start_date']=np.where(Google_GDN['weekday']==6,\n",
    "                                          Google_GDN['Day'],\n",
    "                                          Google_GDN['Day'].apply(lambda x: x-datetime.timedelta(days=(x.weekday()+1))))\n",
    "Google_GDN['week_end_date']=Google_GDN['week_start_date']+datetime.timedelta(days=6)\n",
    "Google_GDN=Google_GDN.groupby(['week_start_date','week_end_date','Metro area'])['Impressions','Clicks','Cost'].sum()\n",
    "Google_GDN.reset_index(inplace=True)\n",
    "Google_GDN['media']=\"Digital\"\n",
    "Google_GDN['submedia']=\"Programmatic\"\n",
    "Google_GDN['placement']=\"GDN\"\n",
    "Google_GDN=Google_GDN[['week_start_date','week_end_date','Metro area','media','submedia','placement','Impressions','Clicks','Cost']]\n",
    "Google_GDN.columns=['week_start_date','week_end_date','DMA','media','submedia','placement','Impressions','Clicks','Cost']\n",
    "\n",
    "Google_GDN.to_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Aggregated_GDN_Google_Till_\"+str(week_end_saturday)+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bing PLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "Bing_PLA=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Bing_Ads/Using_MetroArea_Shopping_Bing_20161001_20181031.csv\",skiprows=9,skipfooter=2)\n",
    "Bing_PLA=Bing_PLA[['Gregorian date','Country/region','Metro area','Impressions','Clicks','Spend']]\n",
    "Bing_PLA.columns=['Day','Country','DMA','Impressions','Clicks','Cost']\n",
    "Bing_PLA['DMA']=Bing_PLA['DMA'].fillna(\"xx\")\n",
    "# US only in Bing Shopping\n",
    "Bing_PLA['Day']=Bing_PLA['Day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d').date())\n",
    "Bing_PLA['weekday']=Bing_PLA['Day'].apply(lambda x: x.weekday())\n",
    "Bing_PLA=Bing_PLA[(Bing_PLA['Day']>=datetime.date(year=2016,month=10,day=2)) & (Bing_PLA['Day']<=week_end_saturday)]\n",
    "Bing_PLA.reset_index(inplace=True)\n",
    "del Bing_PLA['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Bing_PLA['week_start_date']=np.where(Bing_PLA['weekday']==6,\n",
    "                                          Bing_PLA['Day'],\n",
    "                                          Bing_PLA['Day'].apply(lambda x: x-datetime.timedelta(days=(x.weekday()+1))))\n",
    "Bing_PLA['week_end_date']=Bing_PLA['week_start_date']+datetime.timedelta(days=6)\n",
    "Bing_PLA=Bing_PLA.groupby(['week_start_date','week_end_date','DMA'])['Impressions','Clicks','Cost'].sum()\n",
    "Bing_PLA.reset_index(inplace=True)\n",
    "Bing_PLA['media']=\"Digital\"\n",
    "Bing_PLA['submedia']=\"PLA\"\n",
    "Bing_PLA['placement']=\"Bing\"\n",
    "Bing_PLA=Bing_PLA[['week_start_date','week_end_date','DMA','media','submedia','placement','Impressions','Clicks','Cost']]\n",
    "\n",
    "Bing_PLA.to_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Aggregated_PLA_Bing_Till_\"+str(week_end_saturday)+\".csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bing SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "Bing_SEM=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Bing_Ads/Using_MetroArea_SEM_Bing_20161001_20181031.csv\",skiprows=9,skipfooter=2)\n",
    "Bing_SEM=Bing_SEM[['Gregorian date','Country/region','Metro area','Impressions','Clicks','Spend']]\n",
    "Bing_SEM.columns=['Day','Country','DMA','Impressions','Clicks','Cost']\n",
    "Bing_SEM=Bing_SEM[Bing_SEM['Country'].isin(['United States',np.nan])]\n",
    "\n",
    "Bing_SEM['Country'].fillna(\"xx\",inplace=True)\n",
    "Bing_SEM['DMA'].fillna(\"xx\",inplace=True)\n",
    "\n",
    "Bing_SEM['Day']=Bing_SEM['Day'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d').date())\n",
    "Bing_SEM['weekday']=Bing_SEM['Day'].apply(lambda x: x.weekday())\n",
    "Bing_SEM=Bing_SEM[(Bing_SEM['Day']>=datetime.date(year=2016,month=10,day=2)) & (Bing_SEM['Day']<=week_end_saturday)]\n",
    "Bing_SEM.reset_index(inplace=True)\n",
    "del Bing_SEM['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Bing_SEM['week_start_date']=np.where(Bing_SEM['weekday']==6,\n",
    "                                          Bing_SEM['Day'],\n",
    "                                          Bing_SEM['Day'].apply(lambda x: x-datetime.timedelta(days=(x.weekday()+1))))\n",
    "Bing_SEM['week_end_date']=Bing_SEM['week_start_date']+datetime.timedelta(days=6)\n",
    "Bing_SEM=Bing_SEM.groupby(['week_start_date','week_end_date','DMA'])['Impressions','Clicks','Cost'].sum()\n",
    "Bing_SEM.reset_index(inplace=True)\n",
    "Bing_SEM['media']=\"Digital\"\n",
    "Bing_SEM['submedia']=\"SEM\"\n",
    "Bing_SEM['placement']=\"Bing\"\n",
    "Bing_SEM=Bing_SEM[['week_start_date','week_end_date','DMA','media','submedia','placement','Impressions','Clicks','Cost']]\n",
    "\n",
    "Bing_SEM.to_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/Aggregated_SEM_Bing_Till_\"+str(week_end_saturday)+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCriteo_by_Day=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull March 23/Criteo/Extract_20161001_20180228.csv\",sep=\";\")\\nCriteo_by_Day[\\'Day\\']=Criteo_by_Day[\\'Day\\'].apply(lambda x: datetime.datetime.strptime(x,\"%a %m/%d/%Y\").date())\\nCriteo_by_Day=Criteo_by_Day[(Criteo_by_Day[\\'Day\\']>=datetime.datetime.strptime(\\'2016-10-02\\',\"%Y-%m-%d\").date()) & (Criteo_by_Day[\\'Day\\']<=datetime.datetime.strptime(\\'2018-02-27\\',\"%Y-%m-%d\").date())]\\nCriteo_by_Day[\\'weekday\\']=Criteo_by_Day[\\'Day\\'].apply(lambda x:x.weekday())\\nCriteo_by_Day=Criteo_by_Day.reset_index()\\ndel Criteo_by_Day[\\'index\\']\\nCriteo_by_Day[\\'week_start_date\\']=np.where(Criteo_by_Day[\\'weekday\\']==6,\\n                                          Criteo_by_Day[\\'Day\\'],\\n                                         Criteo_by_Day[\\'Day\\'].apply(lambda x:x-datetime.timedelta(days=(x.weekday()+1))))\\nCriteo_by_Day[\\'week_end_date\\']=Criteo_by_Day[\\'week_start_date\\']+datetime.timedelta(days=6)\\nCriteo_by_Day[\\'media\\']=\"Digital\"\\nCriteo_by_Day[\\'submedia\\']=\"Programmatic\"\\nCriteo_by_Day[\\'placement\\']=\"Display Retargeting\"\\nCriteo_by_Day[\\'cleaned dma\\']=\"National\"\\nCriteo_by_Day=Criteo_by_Day[[\\'week_start_date\\',\\'week_end_date\\',\\'cleaned dma\\',\\'media\\',\\'submedia\\',\\'placement\\',\\'Impressions\\',\\'Clicks\\',\\'Cost\\']]\\nCriteo_by_Day=Criteo_by_Day.groupby([\\'week_start_date\\',\\'week_end_date\\',\\'cleaned dma\\',\\'media\\',\\'submedia\\',\\'placement\\'])[\\'Impressions\\',\\'Clicks\\',\\'Cost\\'].sum()\\nCriteo_by_Day.rename(columns={\\'Impressions\\':\\'impression\\',\\'Clicks\\':\\'click\\',\\'Cost\\':\\'cost\\'}, inplace=True)\\nCriteo_by_Day.reset_index(inplace=True)\\n\\nCriteo_by_Day.to_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Aug_4/Criteo_Till_20180227.csv\",index=False)\\n\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No need any more since it's already in datorama\n",
    "\n",
    "'''\n",
    "Criteo_by_Day=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull March 23/Criteo/Extract_20161001_20180228.csv\",sep=\";\")\n",
    "Criteo_by_Day['Day']=Criteo_by_Day['Day'].apply(lambda x: datetime.datetime.strptime(x,\"%a %m/%d/%Y\").date())\n",
    "Criteo_by_Day=Criteo_by_Day[(Criteo_by_Day['Day']>=datetime.datetime.strptime('2016-10-02',\"%Y-%m-%d\").date()) & (Criteo_by_Day['Day']<=datetime.datetime.strptime('2018-02-27',\"%Y-%m-%d\").date())]\n",
    "Criteo_by_Day['weekday']=Criteo_by_Day['Day'].apply(lambda x:x.weekday())\n",
    "Criteo_by_Day=Criteo_by_Day.reset_index()\n",
    "del Criteo_by_Day['index']\n",
    "Criteo_by_Day['week_start_date']=np.where(Criteo_by_Day['weekday']==6,\n",
    "                                          Criteo_by_Day['Day'],\n",
    "                                         Criteo_by_Day['Day'].apply(lambda x:x-datetime.timedelta(days=(x.weekday()+1))))\n",
    "Criteo_by_Day['week_end_date']=Criteo_by_Day['week_start_date']+datetime.timedelta(days=6)\n",
    "Criteo_by_Day['media']=\"Digital\"\n",
    "Criteo_by_Day['submedia']=\"Programmatic\"\n",
    "Criteo_by_Day['placement']=\"Display Retargeting\"\n",
    "Criteo_by_Day['cleaned dma']=\"National\"\n",
    "Criteo_by_Day=Criteo_by_Day[['week_start_date','week_end_date','cleaned dma','media','submedia','placement','Impressions','Clicks','Cost']]\n",
    "Criteo_by_Day=Criteo_by_Day.groupby(['week_start_date','week_end_date','cleaned dma','media','submedia','placement'])['Impressions','Clicks','Cost'].sum()\n",
    "Criteo_by_Day.rename(columns={'Impressions':'impression','Clicks':'click','Cost':'cost'}, inplace=True)\n",
    "Criteo_by_Day.reset_index(inplace=True)\n",
    "\n",
    "Criteo_by_Day.to_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Aug_4/Criteo_Till_20180227.csv\",index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jian_Overall_TMR_Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output=Google_PLA.append(Google_SEM).append(Google_GDN).append(Bing_SEM).append(Bing_PLA)\n",
    "output=output.rename(columns={\"DMA\":\"dma\",\"Impressions\":\"impression\",\"Clicks\":\"click\",\"Cost\":\"cost\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>week_end_date</th>\n",
       "      <th>dma</th>\n",
       "      <th>media</th>\n",
       "      <th>submedia</th>\n",
       "      <th>placement</th>\n",
       "      <th>impression</th>\n",
       "      <th>click</th>\n",
       "      <th>cost</th>\n",
       "      <th>cleaned dma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79873</th>\n",
       "      <td>2018-04-29</td>\n",
       "      <td>2018-05-05</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>Digital</td>\n",
       "      <td>PLA</td>\n",
       "      <td>Bing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80052</th>\n",
       "      <td>2018-05-06</td>\n",
       "      <td>2018-05-12</td>\n",
       "      <td>London</td>\n",
       "      <td>Digital</td>\n",
       "      <td>PLA</td>\n",
       "      <td>Bing</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80081</th>\n",
       "      <td>2018-05-06</td>\n",
       "      <td>2018-05-12</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>Digital</td>\n",
       "      <td>PLA</td>\n",
       "      <td>Bing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80490</th>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Newcastle upon Tyne</td>\n",
       "      <td>Digital</td>\n",
       "      <td>PLA</td>\n",
       "      <td>Bing</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      week_start_date week_end_date                  dma    media submedia  \\\n",
       "79873      2018-04-29    2018-05-05               Ottawa  Digital      PLA   \n",
       "80052      2018-05-06    2018-05-12               London  Digital      PLA   \n",
       "80081      2018-05-06    2018-05-12               Ottawa  Digital      PLA   \n",
       "80490      2018-05-20    2018-05-26  Newcastle upon Tyne  Digital      PLA   \n",
       "\n",
       "      placement  impression  click  cost cleaned dma  \n",
       "79873      Bing           1      0   0.0         NaN  \n",
       "80052      Bing           3      0   0.0         NaN  \n",
       "80081      Bing           1      0   0.0         NaN  \n",
       "80490      Bing           2      0   0.0         NaN  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DMA_cleaning=pd.read_excel(\"/home/jian/Projects/Big_Lots/TMR/DMA cleaning.xlsx\")\n",
    "output=pd.merge(output,DMA_cleaning,on=\"dma\",how=\"left\")\n",
    "output['cleaned dma']=output['cleaned dma'].replace(\"xx\",\"National\")\n",
    "output[pd.isnull(output['cleaned dma'])]\n",
    "\n",
    "# Check the small number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output=output[~pd.isnull(output['cleaned dma'])]\n",
    "\n",
    "output.reset_index(inplace=True)\n",
    "del output['index']\n",
    "output.to_csv(\"/home/jian/Projects/Big_Lots/TMR/Jian_TMR_Update/Repull_Dec_13/BL_SEM_PLA_GDN_TMR_Till_\"+str(week_end_saturday)+\"_JL.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
