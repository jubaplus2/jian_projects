{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/Projects/Big_Lots/TMR/TMR_data/Up_to_2018Q4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "os.getcwd()\n",
    "\n",
    "# Note email cpm updated based on the Q4 client number\n",
    "# Flipp hosted not included in wide version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TMR_up_to_2018Q3=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/TMR_data/Up_to_2018Q3/output/BL_MMM_long_JL_2019-01-04.csv\",dtype=str)\n",
    "TMR_up_to_2018Q3['impression']=TMR_up_to_2018Q3['impression'].astype(float).astype(int)\n",
    "TMR_up_to_2018Q3['click']=TMR_up_to_2018Q3['click'].astype(float).astype(int)\n",
    "TMR_up_to_2018Q3['cost']=TMR_up_to_2018Q3['cost'].astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-04-02'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMR_up_to_2018Q3[(TMR_up_to_2018Q3['submedia']==\"Flipp\") &(TMR_up_to_2018Q3['placement']==\"Native Network\")]['week date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Flipp App', 'Hosted', 'Native Network'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMR_up_to_2018Q3[(TMR_up_to_2018Q3['submedia']==\"Flipp\")]['placement'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "TMR_up_to_2018Q3_non_Email=TMR_up_to_2018Q3[TMR_up_to_2018Q3['media']!=\"Email\"]\n",
    "\n",
    "df_email=TMR_up_to_2018Q3[TMR_up_to_2018Q3['media']==\"Email\"]\n",
    "df_email['cost']=df_email['impression']*0.000455784518529597\n",
    "\n",
    "TMR_up_to_2018Q3=TMR_up_to_2018Q3_non_Email.append(df_email)\n",
    "\n",
    "TMR_up_to_2018Q3=TMR_up_to_2018Q3.sort_values(['week date','media','submedia','placement'])\n",
    "TMR_up_to_2018Q3.to_csv(\"/home/jian/Projects/Big_Lots/TMR/TMR_data/Up_to_2018Q3/output/BL_MMM_long_JL_2019-04-29.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-25\n",
      "2018-10-28\n"
     ]
    }
   ],
   "source": [
    "TMR_up_to_2018Q3_no_DMA=TMR_up_to_2018Q3.groupby([\"week date\",\"media\",\"submedia\",\"placement\"])['impression','click','cost'].sum().reset_index()\n",
    "print(TMR_up_to_2018Q3_no_DMA['week date'].min())\n",
    "print(TMR_up_to_2018Q3_no_DMA['week date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TMR Report 3.20.19']\n"
     ]
    }
   ],
   "source": [
    "TV_logs=pd.ExcelFile(\"/home/jian/Projects/Big_Lots/TMR/TMR_data/Up_to_2018Q4/Q4_TV_logs/Q4 National TMR Report 3.20.19.xlsx\")\n",
    "print(TV_logs.sheet_names)\n",
    "TV_logs=TV_logs.parse(\"TMR Report 3.20.19\",dtype=str,skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W25-54' 'HH']\n",
      "['W25-54']\n"
     ]
    }
   ],
   "source": [
    "TV_logs=TV_logs[[\"Air Date\",\"Vendor Net\",'Act Impression','Demographic','Network']]\n",
    "print(TV_logs['Demographic'].unique())\n",
    "TV_logs=TV_logs[TV_logs['Demographic']==\"W25-54\"]\n",
    "TV_logs=TV_logs[TV_logs['Air Date']!=\"nan\"]\n",
    "print(TV_logs['Demographic'].unique())\n",
    "\n",
    "TV_logs['Vendor Net']=TV_logs['Vendor Net'].astype(float)\n",
    "TV_logs['Act Impression']=TV_logs['Act Impression'].astype(int)\n",
    "TV_logs=TV_logs.rename(columns={\"Vendor Net\":\"cost\",\"Act Impression\":\"impression\"})\n",
    "\n",
    "TV_logs['date']=TV_logs['Air Date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").date())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_week_end_date_BL(x):\n",
    "    if x.weekday()==6:\n",
    "        y=x+datetime.timedelta(days=6)\n",
    "    else:\n",
    "        y=x+datetime.timedelta(days=5-x.weekday())\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TV_logs['week_end_dt']=TV_logs['date'].apply(lambda x: get_week_end_date_BL(x))\n",
    "TV_logs['week date']=TV_logs['week_end_dt'].apply(lambda x: x-datetime.timedelta(days=6))\n",
    "TV_TMR_data=TV_logs.groupby(['week date','Network'])[['cost','impression']].sum().reset_index()\n",
    "TV_TMR_data=TV_TMR_data.rename(columns={\"Network\":\"placement\"})\n",
    "TV_TMR_data['media']=\"TV\"\n",
    "TV_TMR_data['submedia']=\"National\"\n",
    "TV_TMR_data['click']=0\n",
    "TV_TMR_data=TV_TMR_data[TMR_up_to_2018Q3_no_DMA.columns.tolist()]\n",
    "TV_TMR_data['week date']=TV_TMR_data['week date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-28\n",
      "2018-12-23\n"
     ]
    }
   ],
   "source": [
    "print(TV_TMR_data['week date'].min())\n",
    "print(TV_TMR_data['week date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Others_TMR_week=pd.read_excel(\"/home/jian/Projects/Big_Lots/TMR/TMR_data/Up_to_2018Q4/data_from_Joann/DatoramaData0328.xlsx\",dtype=str,sheetname=\"2018 Q4 TMR\")\n",
    "del Others_TMR_week['cleaned dma']\n",
    "\n",
    "Others_TMR_week['week date']=Others_TMR_week['week date'].apply(lambda x: x[:10])\n",
    "Others_TMR_week['impression']=Others_TMR_week['impression'].replace(\"nan\",0).astype(float).astype(int)\n",
    "Others_TMR_week['click']=Others_TMR_week['click'].replace(\"nan\",0).astype(float).astype(int)\n",
    "Others_TMR_week['cost']=Others_TMR_week['cost'].replace(\"nan\",0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Others_TMR_week_1=Others_TMR_week[Others_TMR_week['media']!=\"Email\"]\n",
    "Others_TMR_week_2=Others_TMR_week[Others_TMR_week['media']==\"Email\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "email_cost_client=634791\n",
    "email_cost_impression=2117203832\n",
    "new_email_c_p_impr=634791/2117203832\n",
    "\n",
    "Others_TMR_week_2['cost']=Others_TMR_week_2['impression']*new_email_c_p_impr\n",
    "Others_TMR_week=Others_TMR_week_1.append(Others_TMR_week_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2998251705412557"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_email_c_p_impr*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week date</th>\n",
       "      <th>media</th>\n",
       "      <th>submedia</th>\n",
       "      <th>placement</th>\n",
       "      <th>impression</th>\n",
       "      <th>click</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>Circulation</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>14415897</td>\n",
       "      <td>0</td>\n",
       "      <td>871371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-11</td>\n",
       "      <td>Circulation</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>14661742</td>\n",
       "      <td>0</td>\n",
       "      <td>871371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-18</td>\n",
       "      <td>Circulation</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>62429393</td>\n",
       "      <td>0</td>\n",
       "      <td>4199072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>Circulation</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>20611213</td>\n",
       "      <td>0</td>\n",
       "      <td>1230471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-02</td>\n",
       "      <td>Circulation</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>15400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1085123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-12-09</td>\n",
       "      <td>Circulation</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>15400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1085123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-12-16</td>\n",
       "      <td>Circulation</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>15400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1085123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>Circulation</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>15400000</td>\n",
       "      <td>0</td>\n",
       "      <td>699502.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    week date        media submedia placement  impression  click       cost\n",
       "0  2018-11-04  Circulation       xx        xx    14415897      0   871371.0\n",
       "1  2018-11-11  Circulation       xx        xx    14661742      0   871371.0\n",
       "2  2018-11-18  Circulation       xx        xx    62429393      0  4199072.0\n",
       "3  2018-11-25  Circulation       xx        xx    20611213      0  1230471.0\n",
       "4  2018-12-02  Circulation       xx        xx    15400000      0  1085123.0\n",
       "5  2018-12-09  Circulation       xx        xx    15400000      0  1085123.0\n",
       "6  2018-12-16  Circulation       xx        xx    15400000      0  1085123.0\n",
       "7  2019-01-06  Circulation       xx        xx    15400000      0   699502.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Others_TMR_week[Others_TMR_week['media']==\"Circulation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-04\n",
      "2019-01-27\n"
     ]
    }
   ],
   "source": [
    "print(Others_TMR_week_2['week date'].min())\n",
    "print(Others_TMR_week_2['week date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative Q4 TMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 TV last day: 2018-09-02\n"
     ]
    }
   ],
   "source": [
    "print(\"Q3 TV last day:\", TMR_up_to_2018Q3[(TMR_up_to_2018Q3['media']==\"TV\")]['week date'].max())\n",
    "\n",
    "# no TV for the 2018 Oct up to Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q4_2018_only_TMR=Others_TMR_week.append(TV_TMR_data)\n",
    "\n",
    "Cum_Q4_2018_TMR=TMR_up_to_2018Q3.append(Q4_2018_only_TMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q4_2018_only_TMR.to_csv(\"/home/jian/Projects/Big_Lots/TMR/TMR_data/Up_to_2018Q4/BL_MMM_Q4_Only_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "Cum_Q4_2018_TMR.to_csv(\"/home/jian/Projects/Big_Lots/TMR/TMR_data/Up_to_2018Q4/BL_MMM_long_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned dma</th>\n",
       "      <th>click</th>\n",
       "      <th>cost</th>\n",
       "      <th>impression</th>\n",
       "      <th>media</th>\n",
       "      <th>placement</th>\n",
       "      <th>submedia</th>\n",
       "      <th>week date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321716</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1941</td>\n",
       "      <td>562.89</td>\n",
       "      <td>4037</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Flipp App</td>\n",
       "      <td>Flipp</td>\n",
       "      <td>2016-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322291</th>\n",
       "      <td>Dallas-Ft. Worth, TX</td>\n",
       "      <td>1799</td>\n",
       "      <td>521.71</td>\n",
       "      <td>4017</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Flipp App</td>\n",
       "      <td>Flipp</td>\n",
       "      <td>2016-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323963</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>1521</td>\n",
       "      <td>441.09</td>\n",
       "      <td>2796</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Flipp App</td>\n",
       "      <td>Flipp</td>\n",
       "      <td>2016-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325159</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>1405</td>\n",
       "      <td>407.45</td>\n",
       "      <td>3267</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Flipp App</td>\n",
       "      <td>Flipp</td>\n",
       "      <td>2016-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325336</th>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>1381</td>\n",
       "      <td>400.49</td>\n",
       "      <td>3460</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Flipp App</td>\n",
       "      <td>Flipp</td>\n",
       "      <td>2016-10-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 cleaned dma  click    cost  impression    media  placement  \\\n",
       "321716          New York, NY   1941  562.89        4037  Digital  Flipp App   \n",
       "322291  Dallas-Ft. Worth, TX   1799  521.71        4017  Digital  Flipp App   \n",
       "323963       Los Angeles, CA   1521  441.09        2796  Digital  Flipp App   \n",
       "325159           Houston, TX   1405  407.45        3267  Digital  Flipp App   \n",
       "325336           Phoenix, AZ   1381  400.49        3460  Digital  Flipp App   \n",
       "\n",
       "       submedia   week date  \n",
       "321716    Flipp  2016-10-02  \n",
       "322291    Flipp  2016-10-02  \n",
       "323963    Flipp  2016-10-02  \n",
       "325159    Flipp  2016-10-02  \n",
       "325336    Flipp  2016-10-02  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cum_Q4_2018_TMR[(Cum_Q4_2018_TMR['submedia']==\"Flipp\")].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cum_Q4_2018_TMR[(Cum_Q4_2018_TMR['submedia']==\"Flipp\") & (Cum_Q4_2018_TMR['placement']==\"Hosted\")]['cost'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FSI+Instore', 'Valassis', 'xx'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cum_Q4_2018_TMR[Cum_Q4_2018_TMR['media']==\"Circulation\"]['submedia'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# seperate the hosted flipp\n",
    "Cum_Q4_2018_TMR_FlippHost=Cum_Q4_2018_TMR[(Cum_Q4_2018_TMR['submedia']==\"Flipp\") & (Cum_Q4_2018_TMR['placement']==\"Hosted\")]\n",
    "Cum_Q4_2018_TMR_FlippHost['submedia']=\"Flipp(hosted)\"\n",
    "\n",
    "Cum_Q4_2018_TMR_FlippNonHost=Cum_Q4_2018_TMR[(Cum_Q4_2018_TMR['submedia']==\"Flipp\") & (Cum_Q4_2018_TMR['placement']!=\"Hosted\")]\n",
    "Cum_Q4_2018_TMR_FlippNonHost['submedia']=\"Flipp(nonhosted)\"\n",
    "\n",
    "\n",
    "Cum_Q4_2018_TMR=Cum_Q4_2018_TMR[(Cum_Q4_2018_TMR['submedia']!=\"Flipp\")]\n",
    "Cum_Q4_2018_TMR['submedia']=np.where(Cum_Q4_2018_TMR['media']==\"Circulation\",\"xx\",Cum_Q4_2018_TMR['submedia'])\n",
    "\n",
    "\n",
    "Cum_Q4_2018_TMR=Cum_Q4_2018_TMR.append(Cum_Q4_2018_TMR_FlippHost).append(Cum_Q4_2018_TMR_FlippNonHost)\n",
    "\n",
    "\n",
    "########################\n",
    "\n",
    "data_media_national=Cum_Q4_2018_TMR.groupby(['week date','media'])['impression','click','cost'].sum().reset_index()\n",
    "data_submedia_national=Cum_Q4_2018_TMR.groupby(['week date','media','submedia'])['impression','click','cost'].sum().reset_index()\n",
    "data_submedia_national['media_submedia']=data_submedia_national['media']+\"-\"+data_submedia_national['submedia']\n",
    "data_submedia_national=data_submedia_national[['week date','media_submedia','impression','click','cost']]\n",
    "\n",
    "\n",
    "data_media_national_wide=data_media_national[['week date']].drop_duplicates()\n",
    "for col in data_media_national.columns.tolist()[-3:]:\n",
    "    df=data_media_national[['week date','media']+[col]].pivot(index='week date',columns='media',values=col).reset_index()\n",
    "    df_new_col_list=df.columns.tolist()\n",
    "    df_new_col_list.remove('week date')\n",
    "    df_new_col_dict={}\n",
    "    for new_col in df_new_col_list:\n",
    "        df_new_col_dict.update({new_col:new_col+\"_\"+col})\n",
    "    df=df.rename(columns=df_new_col_dict)\n",
    "    data_media_national_wide=pd.merge(data_media_national_wide,df,on='week date',how=\"outer\")\n",
    "data_media_national_wide=data_media_national_wide.fillna(0)\n",
    "data_media_national_wide=data_media_national_wide.drop_duplicates()\n",
    "#############\n",
    "\n",
    "data_submedia_national_wide=data_submedia_national[['week date']].drop_duplicates()\n",
    "for col in data_submedia_national.columns.tolist()[-3:]:\n",
    "    df=data_submedia_national[['week date','media_submedia']+[col]].pivot(index='week date',columns='media_submedia',values=col).reset_index()\n",
    "    df_new_col_list=df.columns.tolist()\n",
    "    df_new_col_list.remove('week date')\n",
    "    df_new_col_dict={}\n",
    "    for new_col in df_new_col_list:\n",
    "        df_new_col_dict.update({new_col:new_col+\"_\"+col})\n",
    "    df=df.rename(columns=df_new_col_dict)\n",
    "    data_submedia_national_wide=pd.merge(data_submedia_national_wide,df,on='week date',how=\"outer\")\n",
    "data_submedia_national_wide=data_submedia_national_wide.fillna(0)\n",
    "data_submedia_national_wide=data_submedia_national_wide.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "including_weeks=[str(datetime.date(2019,2,2)-datetime.timedelta(days=7*x+6)) for x in range(104)]\n",
    "\n",
    "\n",
    "data_media_national_wide=data_media_national_wide.sort_values(\"week date\")\n",
    "data_media_national_wide=data_media_national_wide[data_media_national_wide['week date'].isin(including_weeks)]\n",
    "\n",
    "data_submedia_national_wide=data_submedia_national_wide.sort_values(\"week date\")\n",
    "data_submedia_national_wide=data_submedia_national_wide[data_submedia_national_wide['week date'].isin(including_weeks)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_data=pd.read_csv(\"/home/jian/BiglotsCode/outputs/combined_sales_long_2019-02-09.csv\",dtype=str)\n",
    "sales_data['week_end_date']=sales_data['week_end_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "sales_data['sales']=sales_data['sales'].astype(float)\n",
    "sales_data['transactions']=sales_data['transactions'].astype(float)\n",
    "sales_data['week date']=sales_data['week_end_date'].apply(lambda x: x-datetime.timedelta(days=6))\n",
    "sales_data_naitonal=sales_data.groupby(['week date'])['sales','transactions'].sum().reset_index()\n",
    "sales_data_naitonal=sales_data_naitonal.set_index(['week date'])\n",
    "sales_data_naitonal.at[datetime.date(2017,4,30),'transactions']=(sales_data_naitonal.at[datetime.date(2017,4,23),'transactions']+sales_data_naitonal.at[datetime.date(2017,5,7),'transactions'])/2\n",
    "sales_data_naitonal=sales_data_naitonal.reset_index()\n",
    "sales_data_store_counts=sales_data[sales_data['sales']>0]\n",
    "sales_data_store_counts=sales_data_store_counts.groupby(['week date'])['location_id'].count().to_frame().reset_index().rename(columns={\"location_id\":\"store_counts\"})\n",
    "\n",
    "sales_data_naitonal=pd.merge(sales_data_naitonal,sales_data_store_counts,on=\"week date\",how=\"outer\")\n",
    "sales_data_naitonal['week date']=sales_data_naitonal['week date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_media_national_wide=pd.merge(data_media_national_wide,sales_data_naitonal,on=\"week date\",how=\"left\")\n",
    "data_submedia_national_wide=pd.merge(data_submedia_national_wide,sales_data_naitonal,on=\"week date\",how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "Rewards_Promotion_list=[datetime.date(2016,10,1),datetime.date(2016,10,2),\n",
    "                        datetime.date(2017,1,21),datetime.date(2017,1,22),\n",
    "                        datetime.date(2017,4,1),datetime.date(2017,4,2),\n",
    "                        datetime.date(2017,7,8),datetime.date(2017,7,9),\n",
    "                        datetime.date(2017,9,30),datetime.date(2017,10,1),\n",
    "                        datetime.date(2018,1,20),datetime.date(2018,1,21),\n",
    "                        datetime.date(2018,4,7),datetime.date(2018,4,8),\n",
    "                        datetime.date(2018,7,7),datetime.date(2018,7,8),\n",
    "                        datetime.date(2018,9,29),datetime.date(2018,9,30),\n",
    "                        datetime.date(2019,1,19),datetime.date(2019,1,20)]\n",
    "\n",
    "df_Rewards_Promotion=pd.DataFrame({\"Date\":Rewards_Promotion_list},index=range(len(Rewards_Promotion_list)))\n",
    "df_Rewards_Promotion['weekday']=df_Rewards_Promotion['Date'].apply(lambda x: x.weekday())\n",
    "df_Rewards_Promotion['week date']=np.where(df_Rewards_Promotion['weekday']==6,df_Rewards_Promotion['Date'],df_Rewards_Promotion['Date']-datetime.timedelta(days=6))\n",
    "\n",
    "del df_Rewards_Promotion['Date']\n",
    "\n",
    "df_Rewards_Promotion_Sunday=df_Rewards_Promotion[df_Rewards_Promotion['weekday']==6]\n",
    "df_Rewards_Promotion_Sunday['Sunday_rewards_ind']=1\n",
    "del df_Rewards_Promotion_Sunday['weekday']\n",
    "df_Rewards_Promotion_Sunday['week date']=df_Rewards_Promotion_Sunday['week date'].astype(str)\n",
    "\n",
    "\n",
    "df_Rewards_Promotion_Saturday=df_Rewards_Promotion[df_Rewards_Promotion['weekday']==5]\n",
    "df_Rewards_Promotion_Saturday['Saturday_rewards_ind']=1\n",
    "del df_Rewards_Promotion_Saturday['weekday']\n",
    "df_Rewards_Promotion_Saturday['week date']=df_Rewards_Promotion_Saturday['week date'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holiday_1_week_df=pd.DataFrame({\"week date\":[datetime.date(2016,12,18),datetime.date(2017,12,17),datetime.date(2018,12,23)],\"Holiday_1_week_only_Ind\":[1]*3},index=[0,1,2])\n",
    "holiday_5_weeks_df=pd.DataFrame({\"week date\":[datetime.date(2016,12,18)-datetime.timedelta(days=x*7) for x in range(5)] +[datetime.date(2017,12,17)-datetime.timedelta(days=x*7) for x in range(5)]+[datetime.date(2018,12,23)-datetime.timedelta(days=x*7) for x in range(5)],\n",
    "                                 \"Holiday_5_weeks_only_Ind\":[1]*15},index=[x for x in range(15)])\n",
    "\n",
    "holiday_1_week_df['week date']=holiday_1_week_df['week date'].astype(str)\n",
    "holiday_5_weeks_df['week date']=holiday_5_weeks_df['week date'].astype(str)\n",
    "\n",
    "\n",
    "df_special_weeks_ind=pd.merge(df_Rewards_Promotion_Saturday,df_Rewards_Promotion_Sunday,on=\"week date\",how=\"outer\")\n",
    "df_special_weeks_ind=pd.merge(df_special_weeks_ind,holiday_1_week_df,on=\"week date\",how=\"outer\")\n",
    "df_special_weeks_ind=pd.merge(df_special_weeks_ind,holiday_5_weeks_df,on=\"week date\",how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_media_national_wide=pd.merge(data_media_national_wide,df_special_weeks_ind,on=\"week date\",how=\"left\")\n",
    "\n",
    "data_submedia_national_wide=pd.merge(data_submedia_national_wide,df_special_weeks_ind,on=\"week date\",how=\"left\")\n",
    "\n",
    "data_media_national_wide=data_media_national_wide.fillna(0)\n",
    "data_submedia_national_wide=data_submedia_national_wide.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_media_national_wide.to_csv(\"/home/jian/Projects/Big_Lots/TMR/TMR_data/Up_to_2018Q4/output_wide/BL_MMM_data_media_national_wide_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "data_submedia_national_wide.to_csv(\"/home/jian/Projects/Big_Lots/TMR/TMR_data/Up_to_2018Q4/output_wide/BL_MMM_data_submedia_national_wide_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "\n",
    "# Note email cpm updated based on the Q4 client number\n",
    "# Flipp hosted seperated in wide version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
