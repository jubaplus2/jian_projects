{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "os.getcwd()\n",
    "\n",
    "# Note email cpm updated based on the Q1 client number\n",
    "# Flipp hosted not included in wide version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_quarter=\"2020Q2\"\n",
    "new_quarter_start_date=\"2020-05-03\"\n",
    "new_quarter_end_date=\"2020-08-01\"\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMR_up_to_2020Q1=pd.read_csv(\"/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q1/output/BL_MMM_long_cumu_up_to_2020Q1_JL_2020-12-07.csv\",dtype=str)\n",
    "TMR_up_to_2020Q1['impression']=TMR_up_to_2020Q1['impression'].fillna(0).astype(float).astype(int)\n",
    "TMR_up_to_2020Q1['click']=TMR_up_to_2020Q1['click'].fillna(0).astype(float).astype(int)\n",
    "TMR_up_to_2020Q1['cost']=TMR_up_to_2020Q1['cost'].fillna(0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-25\n",
      "2020-04-26\n"
     ]
    }
   ],
   "source": [
    "TMR_up_to_2020Q1_no_DMA=TMR_up_to_2020Q1.groupby([\"week date\",\"media\",\"submedia\",\"placement\"])['impression','click','cost'].sum().reset_index()\n",
    "print(TMR_up_to_2020Q1_no_DMA['week date'].min())\n",
    "print(TMR_up_to_2020Q1_no_DMA['week date'].max())\n",
    "# TMR_up_to_2020Q1_no_DMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week date</th>\n",
       "      <th>media</th>\n",
       "      <th>submedia</th>\n",
       "      <th>placement</th>\n",
       "      <th>impression</th>\n",
       "      <th>click</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-25</td>\n",
       "      <td>Email</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>11581550</td>\n",
       "      <td>113834</td>\n",
       "      <td>5278.691191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Flipp</td>\n",
       "      <td>Flipp App</td>\n",
       "      <td>74691</td>\n",
       "      <td>37222</td>\n",
       "      <td>10794.380000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    week date    media submedia  placement  impression   click          cost\n",
       "0  2016-09-25    Email       xx         xx    11581550  113834   5278.691191\n",
       "1  2016-10-02  Digital    Flipp  Flipp App       74691   37222  10794.380000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMR_up_to_2020Q1_no_DMA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_week_end_date_BL(x):\n",
    "    if x.weekday()==6:\n",
    "        y=x+datetime.timedelta(days=6)\n",
    "    else:\n",
    "        y=x+datetime.timedelta(days=5-x.weekday())\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email: Big Lots Q2 TMR from Jessica, Fhursday, Sept 9, 2020 at 3:28 PM\n",
    "'''\n",
    "Media   (net)                                        \n",
    "National&Sinclair $1,106,458\n",
    "DRTV $384,878\n",
    "'''\n",
    "\n",
    "# Only 1 week for local sinclair, ignore it\n",
    "NationalSinclair_tv_cost=1106458\n",
    "DRTV_tv_cost=384878\n",
    "TV_TMR_data=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['National', 'DRTV', 'Circ Spend']\n",
      "(2720, 18) (2958, 18)\n"
     ]
    }
   ],
   "source": [
    "TV_print_excel=pd.ExcelFile(\"/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2/input_2020Q2/Big Lots Q2 TMR 9.9.20.xlsx\")\n",
    "print(TV_print_excel.sheet_names)\n",
    "                      \n",
    "df_TV_national=TV_print_excel.parse(\"National\",dtype=str,skiprows=2)\n",
    "# df_TV_sinclair=TV_print_excel.parse(\"Sinclair\",dtype=str,skiprows=2)\n",
    "df_TV_DRTV=TV_print_excel.parse(\"DRTV\",dtype=str,skiprows=2)\n",
    "\n",
    "print(df_TV_national.shape,df_TV_DRTV.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Post</th>\n",
       "      <th>Strata: NHI ACM Live +3</th>\n",
       "      <th>Baltimore</th>\n",
       "      <th>WeTV</th>\n",
       "      <th>Spot Cable</th>\n",
       "      <th>W25-54</th>\n",
       "      <th>2018-02-05 00:00:00</th>\n",
       "      <th>2/10/2018</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>5:27 PM</th>\n",
       "      <th>30</th>\n",
       "      <th>LIVE PD</th>\n",
       "      <th>21.25</th>\n",
       "      <th>0.77</th>\n",
       "      <th>3935</th>\n",
       "      <th>6740 COMCAST, Baltimore Interconnect-Cable</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2 2020</td>\n",
       "      <td>Post</td>\n",
       "      <td>Strata: NHI ACM Live +3</td>\n",
       "      <td>National</td>\n",
       "      <td>BRVO</td>\n",
       "      <td>Cable</td>\n",
       "      <td>W25-54</td>\n",
       "      <td>2020-05-11 00:00:00</td>\n",
       "      <td>05/17/2020</td>\n",
       "      <td>Su</td>\n",
       "      <td>3:25AM</td>\n",
       "      <td>:15</td>\n",
       "      <td>CASH CAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04189048239895697</td>\n",
       "      <td>25704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2 2020</td>\n",
       "      <td>Post</td>\n",
       "      <td>Strata: NHI ACM Live +3</td>\n",
       "      <td>National</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Cable</td>\n",
       "      <td>W25-54</td>\n",
       "      <td>2020-05-11 00:00:00</td>\n",
       "      <td>05/17/2020</td>\n",
       "      <td>Su</td>\n",
       "      <td>6:16AM</td>\n",
       "      <td>:15</td>\n",
       "      <td>NEW DAY SUNDAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02770208604954368</td>\n",
       "      <td>16998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Q1  Post  Strata: NHI ACM Live +3 Baltimore  WeTV Spot Cable  W25-54  \\\n",
       "0  Q2 2020  Post  Strata: NHI ACM Live +3  National  BRVO      Cable  W25-54   \n",
       "1  Q2 2020  Post  Strata: NHI ACM Live +3  National   CNN      Cable  W25-54   \n",
       "\n",
       "   2018-02-05 00:00:00    2/10/2018 Saturday   5:27 PM   30         LIVE PD  \\\n",
       "0  2020-05-11 00:00:00   05/17/2020       Su    3:25AM  :15        CASH CAB   \n",
       "1  2020-05-11 00:00:00   05/17/2020       Su    6:16AM  :15  NEW DAY SUNDAY   \n",
       "\n",
       "  21.25                 0.77   3935  \\\n",
       "0   NaN  0.04189048239895697  25704   \n",
       "1   NaN  0.02770208604954368  16998   \n",
       "\n",
       "  6740 COMCAST, Baltimore Interconnect-Cable Unnamed: 17  \n",
       "0                                        NaN         NaN  \n",
       "1                                        NaN         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TV_national.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_TV_national['cost'].sum() 1106458.0\n"
     ]
    }
   ],
   "source": [
    "df_TV_national=df_TV_national[[\"Q1\",'Baltimore',\"WeTV\",' 2/10/2018',3935]]\n",
    "df_TV_national.columns=[\"Q1 2020\",'National',\"Network\",\"Air Date\",' Imp(000) - Women 25-54']\n",
    "# df_TV_national['Air Date']=df_TV_national['Air Date'].apply(lambda x: x.strip())\n",
    "df_TV_national=df_TV_national[pd.notnull(df_TV_national['Air Date'])]\n",
    "\n",
    "df_TV_national=df_TV_national.rename(columns={\"Network\":\"placement\"})\n",
    "df_TV_national['date']=df_TV_national['Air Date'].apply(lambda x: datetime.datetime.strptime(x,\" %m/%d/%Y\").date() if \"/\" in x else datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").date())\n",
    "df_TV_national['impression']=df_TV_national[' Imp(000) - Women 25-54'].astype(float)\n",
    "\n",
    "df_TV_national['media']=\"TV\"\n",
    "df_TV_national['submedia']=\"National\"\n",
    "df_TV_national['click']=0\n",
    "df_TV_national['week date']=df_TV_national['date'].apply(get_week_end_date_BL)\n",
    "df_TV_national['week date']=df_TV_national['week date'].apply(lambda x: x-datetime.timedelta(days=6))\n",
    "\n",
    "sum_national_cable_impr=df_TV_national['impression'].sum()\n",
    "df_TV_national['cost']=df_TV_national['impression']/sum_national_cable_impr*NationalSinclair_tv_cost\n",
    "print(\"df_TV_national['cost'].sum()\",df_TV_national['cost'].sum())\n",
    "df_TV_national=df_TV_national[TMR_up_to_2020Q1_no_DMA.columns.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Post</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Baltimore</th>\n",
       "      <th>WeTV</th>\n",
       "      <th>Spot Cable</th>\n",
       "      <th>W25-54</th>\n",
       "      <th>2018-02-05 00:00:00</th>\n",
       "      <th>2/10/2018</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>5:27 PM</th>\n",
       "      <th>30</th>\n",
       "      <th>LIVE PD</th>\n",
       "      <th>21.25</th>\n",
       "      <th>0.77</th>\n",
       "      <th>3935</th>\n",
       "      <th>6740 COMCAST, Baltimore Interconnect-Cable</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2 2020</td>\n",
       "      <td>Post</td>\n",
       "      <td>Strata: NHI ACM Live +3</td>\n",
       "      <td>National</td>\n",
       "      <td>Fox News Channel</td>\n",
       "      <td>Cable</td>\n",
       "      <td>W25-54</td>\n",
       "      <td>2020-06-15 00:00:00</td>\n",
       "      <td>2020-06-21 00:00:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>06:59A</td>\n",
       "      <td>:15</td>\n",
       "      <td>FOX AND FRIENDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.06</td>\n",
       "      <td>36714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2 2020</td>\n",
       "      <td>Post</td>\n",
       "      <td>Strata: NHI ACM Live +3</td>\n",
       "      <td>National</td>\n",
       "      <td>Fox News Channel</td>\n",
       "      <td>Cable</td>\n",
       "      <td>W25-54</td>\n",
       "      <td>2020-06-15 00:00:00</td>\n",
       "      <td>2020-06-21 00:00:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>07:43A</td>\n",
       "      <td>:15</td>\n",
       "      <td>FOX AND FRIENDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>55071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Q1  Post               Unnamed: 2 Baltimore              WeTV  \\\n",
       "0  Q2 2020  Post  Strata: NHI ACM Live +3  National  Fox News Channel   \n",
       "1  Q2 2020  Post  Strata: NHI ACM Live +3  National  Fox News Channel   \n",
       "\n",
       "  Spot Cable  W25-54  2018-02-05 00:00:00            2/10/2018   Saturday  \\\n",
       "0      Cable  W25-54  2020-06-15 00:00:00  2020-06-21 00:00:00  Sunday      \n",
       "1      Cable  W25-54  2020-06-15 00:00:00  2020-06-21 00:00:00  Sunday      \n",
       "\n",
       "   5:27 PM   30          LIVE PD 21.25  0.77   3935  \\\n",
       "0   06:59A  :15  FOX AND FRIENDS   NaN  0.06  36714   \n",
       "1   07:43A  :15  FOX AND FRIENDS   NaN  0.09  55071   \n",
       "\n",
       "  6740 COMCAST, Baltimore Interconnect-Cable Unnamed: 17  \n",
       "0                                        NaN         NaN  \n",
       "1                                        NaN         NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TV_DRTV.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_TV_DRTV['cost'].sum() 384878.0\n"
     ]
    }
   ],
   "source": [
    "df_TV_DRTV=df_TV_DRTV[[\"Q1\",'Baltimore',\"WeTV\",' 2/10/2018',3935]]\n",
    "df_TV_DRTV.columns=[\"Q1 2020\",'National',\"Network\",\"Air Date\",' Imp(000) - Women 25-54']\n",
    "# df_TV_DRTV['Air Date']=df_TV_DRTV['Air Date'].apply(lambda x: x.strip())\n",
    "df_TV_DRTV=df_TV_DRTV[pd.notnull(df_TV_DRTV['Air Date'])]\n",
    "\n",
    "df_TV_DRTV=df_TV_DRTV.rename(columns={\"Network\":\"placement\"})\n",
    "df_TV_DRTV['date']=df_TV_DRTV['Air Date'].apply(lambda x: datetime.datetime.strptime(x,\" %m/%d/%Y\").date() if \"/\" in x else datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").date())\n",
    "df_TV_DRTV['impression']=df_TV_DRTV[' Imp(000) - Women 25-54'].astype(float)\n",
    "\n",
    "df_TV_DRTV['media']=\"TV\"\n",
    "df_TV_DRTV['submedia']=\"National\"\n",
    "df_TV_DRTV['click']=0\n",
    "df_TV_DRTV['week date']=df_TV_DRTV['date'].apply(get_week_end_date_BL)\n",
    "df_TV_DRTV['week date']=df_TV_DRTV['week date'].apply(lambda x: x-datetime.timedelta(days=6))\n",
    "\n",
    "sum_DRTV_impr=df_TV_DRTV['impression'].sum()\n",
    "df_TV_DRTV['cost']=df_TV_DRTV['impression']/sum_DRTV_impr*DRTV_tv_cost\n",
    "print(\"df_TV_DRTV['cost'].sum()\",df_TV_DRTV['cost'].sum())\n",
    "df_TV_DRTV=df_TV_DRTV[TMR_up_to_2020Q1_no_DMA.columns.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV_TMR_data['cost'].sum() 1491336.0\n",
      "TV_TMR_data['impression'].sum() 30574214.5\n"
     ]
    }
   ],
   "source": [
    "TV_TMR_data=df_TV_national.append(df_TV_DRTV)\n",
    "TV_TMR_data['week date']=TV_TMR_data['week date'].astype(str)\n",
    "print(\"TV_TMR_data['cost'].sum()\",TV_TMR_data['cost'].sum())\n",
    "print(\"TV_TMR_data['impression'].sum()\",TV_TMR_data['impression'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3994, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TV_TMR_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(333, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TV_TMR_data=TV_TMR_data.groupby(['week date','media','submedia','placement'])['impression','click','cost'].sum().reset_index()\n",
    "TV_TMR_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 7)\n",
      "4\n",
      "2020-05-17\n",
      "2020-06-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submedia</th>\n",
       "      <th>impression</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>30574214</td>\n",
       "      <td>1491336.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   submedia  impression       cost\n",
       "0  National    30574214  1491336.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TV_TMR_data=TV_TMR_data[TV_TMR_data['week date']>=new_quarter_start_date]\n",
    "TV_TMR_data=TV_TMR_data[TV_TMR_data['week date']<=new_quarter_end_date]\n",
    "print(TV_TMR_data.shape)\n",
    "print(TV_TMR_data['week date'].nunique())\n",
    "print(TV_TMR_data['week date'].min())\n",
    "print(TV_TMR_data['week date'].max())\n",
    "\n",
    "\n",
    "df_TV_summary=TV_TMR_data.groupby(['submedia'])['impression','cost'].sum().reset_index()\n",
    "df_TV_summary['impression']=df_TV_summary['impression'].astype(int)\n",
    "df_TV_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1697094.7 111259722\n"
     ]
    }
   ],
   "source": [
    "df_qc_tv_lastyear=TMR_up_to_2020Q1_no_DMA[TMR_up_to_2020Q1_no_DMA['week date']>=\"2019-05-05\"]\n",
    "df_qc_tv_lastyear=df_qc_tv_lastyear[df_qc_tv_lastyear['week date']<=\"2019-08-03\"]\n",
    "df_qc_tv_lastyear=df_qc_tv_lastyear[df_qc_tv_lastyear['media']==\"TV\"]\n",
    "print(df_qc_tv_lastyear['cost'].sum(),df_qc_tv_lastyear['impression'].sum())\n",
    "\n",
    "# In line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1491336.0000000002, 30574214)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TV_summary['cost'].sum(),df_TV_summary['impression'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878758268469049"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1491336.0000000002/1697094.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2748003810399598"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30574214/111259722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-08 15:54:57.718363\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Circulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_1=datetime.date(2020,2,2)\n",
    "df_week_2020Q2=pd.DataFrame({\"week date\":week_1},index=range(13,26))\n",
    "df_week_2020Q2['Week']=range(13,26)\n",
    "df_week_2020Q2['week date']=df_week_2020Q2['Week'].apply(lambda x: week_1+datetime.timedelta(days=x*7))\n",
    "df_week_2020Q2['Week']=df_week_2020Q2['Week']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7)\n",
      "5 2020-05-17 2020-07-26\n",
      "['Sunday']\n"
     ]
    }
   ],
   "source": [
    "df_print_circ=TV_print_excel.parse(\"Circ Spend\",dtype=str,skiprows=1)\n",
    "df_print_circ['Week']=df_print_circ['Week'].apply(lambda x: int(x.split(\"(\")[0].split(\" \")[1]))\n",
    "df_print_circ=pd.merge(df_print_circ,df_week_2020Q2,on=\"Week\")\n",
    "df_print_circ=df_print_circ.rename(columns={\"Quantities\":\"impression\",\"Spend\":\"cost\"})\n",
    "df_print_circ['click']=0\n",
    "df_print_circ['cost']=df_print_circ['cost'].astype(float)\n",
    "df_print_circ['impression']=df_print_circ['impression'].astype(int)\n",
    "\n",
    "df_print_circ['media']=\"Circulation\"\n",
    "df_print_circ['submedia']=\"xx\"\n",
    "df_print_circ['placement']=\"xx\"\n",
    "\n",
    "df_print_circ=df_print_circ[TMR_up_to_2020Q1_no_DMA.columns.tolist()]\n",
    "print(df_print_circ.shape)\n",
    "print(df_print_circ['week date'].nunique(),df_print_circ['week date'].min(),df_print_circ['week date'].max())\n",
    "print(pd.to_datetime(df_print_circ['week date']).dt.day_name().unique())\n",
    "\n",
    "# Update for this quarter some circulation was printed but not delivered\n",
    "df_print_circ['cost']=np.where(df_print_circ['impression']==0,0,df_print_circ['cost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others from Datorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2/input_2020Q2/datorama_files/Digital Weekly Media Data  (Search).csv',\n",
       " '/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2/input_2020Q2/datorama_files/Digital Weekly Media Data without Placement (excluded FB).csv',\n",
       " '/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2/input_2020Q2/datorama_files/E-circular_Flipp & Print Circular & Email by Week.csv',\n",
       " '/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2/input_2020Q2/datorama_files/Social Daily Media Data.csv']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_datorama_files=glob.glob(\"/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2/input_2020Q2/datorama_files/*.csv\")\n",
    "list_datorama_files.sort()\n",
    "list_datorama_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>media</th>\n",
       "      <th>submedia</th>\n",
       "      <th>placement</th>\n",
       "      <th>impression</th>\n",
       "      <th>click</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-05-17 00:00</td>\n",
       "      <td>Digital</td>\n",
       "      <td>PLA</td>\n",
       "      <td>Bing</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-05-31 00:00</td>\n",
       "      <td>Digital</td>\n",
       "      <td>PLA</td>\n",
       "      <td>Bing</td>\n",
       "      <td>618901.0</td>\n",
       "      <td>12864.0</td>\n",
       "      <td>2586.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                week    media submedia placement  impression    click     cost\n",
       "7   2020-05-17 00:00  Digital      PLA      Bing      1731.0     40.0    21.11\n",
       "14  2020-05-31 00:00  Digital      PLA      Bing    618901.0  12864.0  2586.76"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_search=pd.read_csv(list_datorama_files[0])\n",
    "df_1_search.columns=[x.lower() for x in df_1_search.columns.tolist()]\n",
    "df_1_search=df_1_search.rename(columns={\"impressions\":\"impression\",\"clicks\":\"click\",\"media cost\":\"cost\"})\n",
    "df_1_search=df_1_search[['week','media','submedia','placement','impression','click','cost']]\n",
    "df_1_search['submedia']=df_1_search['submedia'].replace({\"Paid SEM Campaign\":\"SEM\"}).replace({\"Shopping Campaign\":\"PLA\"})\n",
    "df_1_search=df_1_search.sort_values(['media','submedia','placement','week'])\n",
    "df_1_search.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>media</th>\n",
       "      <th>submedia</th>\n",
       "      <th>placement</th>\n",
       "      <th>impression</th>\n",
       "      <th>click</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-26 00:00</td>\n",
       "      <td>Digital</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>Multiplatform Video</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89041.431619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-26 00:00</td>\n",
       "      <td>Digital</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>Programmatic Video</td>\n",
       "      <td>25442562.0</td>\n",
       "      <td>15519.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               week    media submedia            placement  impression  \\\n",
       "3  2020-07-26 00:00  Digital  YouTube  Multiplatform Video         0.0   \n",
       "4  2020-07-26 00:00  Digital  YouTube   Programmatic Video  25442562.0   \n",
       "\n",
       "     click          cost  \n",
       "3      0.0  89041.431619  \n",
       "4  15519.0      0.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some weeks for The Reddit programmatic are broken down, cost and (impr + click) are seperated to different rows\n",
    "# Doesn't matter since gonna rolling up\n",
    "\n",
    "df_2_digital=pd.read_csv(list_datorama_files[1])\n",
    "df_2_digital.columns=[x.lower() for x in df_2_digital.columns.tolist()]\n",
    "df_2_digital=df_2_digital.rename(columns={\"impressions\":\"impression\",\"clicks\":\"click\",\"media cost\":\"cost\"})\n",
    "df_2_digital=df_2_digital[['week','media','submedia','impression','click','cost','partner','tactic']]\n",
    "\n",
    "df_2_digital_YT=df_2_digital[df_2_digital['partner']==\"YouTube\"]\n",
    "df_2_digital_YT['placement']=df_2_digital_YT['submedia']\n",
    "df_2_digital_YT['submedia']=\"YouTube\"\n",
    "df_2_digital_YT=df_2_digital_YT[df_1_search.columns.tolist()]\n",
    "\n",
    "df_2_digital_Pandora=df_2_digital[df_2_digital['partner']==\"Pandora\"]\n",
    "df_2_digital_Pandora['placement']=df_2_digital_Pandora['submedia']\n",
    "df_2_digital_Pandora['submedia']=\"Pandora\"\n",
    "df_2_digital_Pandora=df_2_digital_Pandora[df_1_search.columns.tolist()]\n",
    "\n",
    "df_2_digital_Programmatic=df_2_digital[~df_2_digital['partner'].isin([\"YouTube\",'Pandora'])]\n",
    "df_2_digital_Programmatic['placement']=df_2_digital_Programmatic['submedia']\n",
    "df_2_digital_Programmatic['submedia']=\"Programmatic\"\n",
    "df_2_digital_Programmatic=df_2_digital_Programmatic[df_1_search.columns.tolist()]\n",
    "df_2_digital_Programmatic['cost']=df_2_digital_Programmatic['cost'].fillna(0)\n",
    "df_2_digital_Programmatic['impression']=df_2_digital_Programmatic['impression'].fillna(0)\n",
    "df_2_digital_Programmatic['click']=df_2_digital_Programmatic['click'].fillna(0)\n",
    "df_2_digital_Programmatic['media']=df_2_digital_Programmatic['media'].fillna(\"Digital\")\n",
    "\n",
    "df_2_digital=df_2_digital_YT.append(df_2_digital_Pandora).append(df_2_digital_Programmatic)\n",
    "\n",
    "\n",
    "df_2_digital.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>media</th>\n",
       "      <th>submedia</th>\n",
       "      <th>placement</th>\n",
       "      <th>impression</th>\n",
       "      <th>click</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-26 00:00</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Flipp</td>\n",
       "      <td>Hosted</td>\n",
       "      <td>157520.0</td>\n",
       "      <td>134286.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-19 00:00</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Flipp</td>\n",
       "      <td>Hosted</td>\n",
       "      <td>191881.0</td>\n",
       "      <td>166735.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-12 00:00</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Flipp</td>\n",
       "      <td>Hosted</td>\n",
       "      <td>164553.0</td>\n",
       "      <td>142066.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               week    media submedia placement  impression     click  cost\n",
       "0  2020-07-26 00:00  Digital    Flipp    Hosted    157520.0  134286.0   0.0\n",
       "1  2020-07-19 00:00  Digital    Flipp    Hosted    191881.0  166735.0   0.0\n",
       "2  2020-07-12 00:00  Digital    Flipp    Hosted    164553.0  142066.0   0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_email_ecirc=pd.read_csv(list_datorama_files[2])\n",
    "df_3_email_ecirc.columns=[x.lower() for x in df_3_email_ecirc.columns.tolist()]\n",
    "df_3_email_ecirc=df_3_email_ecirc.rename(columns={\"impressions\":\"impression\",\"clicks\":\"click\",\"media cost\":\"cost\"})\n",
    "df_3_email_ecirc=df_3_email_ecirc[['week','media','placement','impression','click','cost']]\n",
    "df_3_email_ecirc.insert(2,\"submedia\",np.nan)\n",
    "df_3_email_ecirc['submedia']=np.where(df_3_email_ecirc['media']==\"Digital\",\"Flipp\",\"xx\")\n",
    "df_3_email_ecirc['placement']=np.where(df_3_email_ecirc['media']==\"Digital\",df_3_email_ecirc['placement'],\"xx\")\n",
    "\n",
    "df_3_email_ecirc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>media</th>\n",
       "      <th>submedia</th>\n",
       "      <th>placement</th>\n",
       "      <th>impression</th>\n",
       "      <th>click</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-03 00:00</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Social</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>57542.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-03 00:00</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Social</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>3430553.0</td>\n",
       "      <td>7721.0</td>\n",
       "      <td>9651.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-03 00:00</td>\n",
       "      <td>Digital</td>\n",
       "      <td>Social</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>9636280.0</td>\n",
       "      <td>96410.0</td>\n",
       "      <td>30935.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               week    media submedia  placement  impression    click  \\\n",
       "0  2020-05-03 00:00  Digital   Social  Pinterest     57542.0     94.0   \n",
       "1  2020-05-03 00:00  Digital   Social  Pinterest   3430553.0   7721.0   \n",
       "2  2020-05-03 00:00  Digital   Social   Facebook   9636280.0  96410.0   \n",
       "\n",
       "       cost  \n",
       "0      0.00  \n",
       "1   9651.54  \n",
       "2  30935.49  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4_email_social=pd.read_csv(list_datorama_files[3])\n",
    "df_4_email_social.columns=[x.lower() for x in df_4_email_social.columns.tolist()]\n",
    "df_4_email_social=df_4_email_social.rename(columns={\"impressions\":\"impression\",\"clicks\":\"click\",\"media cost\":\"cost\"})\n",
    "\n",
    "df_4_email_social=df_4_email_social[['week','media','submedia','partner','impression','click','cost']]\n",
    "df_4_email_social=df_4_email_social.rename(columns={\"partner\":\"placement\"})\n",
    "df_4_email_social.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sunday']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week date</th>\n",
       "      <th>media</th>\n",
       "      <th>submedia</th>\n",
       "      <th>placement</th>\n",
       "      <th>impression</th>\n",
       "      <th>click</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>Digital</td>\n",
       "      <td>PLA</td>\n",
       "      <td>Bing</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>Digital</td>\n",
       "      <td>PLA</td>\n",
       "      <td>Bing</td>\n",
       "      <td>618901.0</td>\n",
       "      <td>12864.0</td>\n",
       "      <td>2586.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     week date    media submedia placement  impression    click     cost\n",
       "7   2020-05-17  Digital      PLA      Bing      1731.0     40.0    21.11\n",
       "14  2020-05-31  Digital      PLA      Bing    618901.0  12864.0  2586.76"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_digital_from_datorama=pd.concat([df_1_search,df_2_digital,df_3_email_ecirc,df_4_email_social])\n",
    "df_all_digital_from_datorama['week']=df_all_digital_from_datorama['week'].apply(lambda x: x.split(\" \")[0])\n",
    "df_all_digital_from_datorama=df_all_digital_from_datorama.rename(columns={\"week\":\"week date\"})\n",
    "\n",
    "# QC week date as \n",
    "df_all_digital_from_datorama['week_as_date'] = pd.to_datetime(df_all_digital_from_datorama['week date'])\n",
    "df_all_digital_from_datorama['day_of_week'] = df_all_digital_from_datorama['week_as_date'].dt.day_name()\n",
    "print(df_all_digital_from_datorama['day_of_week'].unique())\n",
    "del df_all_digital_from_datorama['week_as_date']\n",
    "del df_all_digital_from_datorama['day_of_week']\n",
    "\n",
    "df_all_digital_from_datorama.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "2020-05-03\n",
      "2020-07-26\n"
     ]
    }
   ],
   "source": [
    "print(df_all_digital_from_datorama['week date'].nunique())\n",
    "print(df_all_digital_from_datorama['week date'].min())\n",
    "print(df_all_digital_from_datorama['week date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2_2020_only_TMR=df_all_digital_from_datorama.append(df_print_circ).append(TV_TMR_data)\n",
    "#\n",
    "Cum_Q2_2020_TMR=TMR_up_to_2020Q1.append(Q2_2020_only_TMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.stat(\"/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2/output/\")\n",
    "except:\n",
    "    os.mkdir(\"/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2/output/\")\n",
    "\n",
    "Q2_2020_only_TMR.to_csv(\"/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2/output/BL_MMM_2020Q2_Only_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "Cum_Q2_2020_TMR.to_csv(\"/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2/output/BL_MMM_long_cumu_up_to_2020Q2_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# seperate the hosted flipp\n",
    "Cum_Q2_2020_TMR_FlippHost=Cum_Q2_2020_TMR[(Cum_Q2_2020_TMR['submedia']==\"Flipp\") & (Cum_Q2_2020_TMR['placement']==\"Hosted\")]\n",
    "Cum_Q2_2020_TMR_FlippHost['submedia']=\"Flipp(hosted)\"\n",
    "\n",
    "Cum_Q2_2020_TMR_FlippNonHost=Cum_Q2_2020_TMR[(Cum_Q2_2020_TMR['submedia']==\"Flipp\") & (Cum_Q2_2020_TMR['placement']!=\"Hosted\")]\n",
    "Cum_Q2_2020_TMR_FlippNonHost['submedia']=\"Flipp(nonhosted)\"\n",
    "\n",
    "Cum_Q2_2020_TMR=Cum_Q2_2020_TMR[(Cum_Q2_2020_TMR['submedia']!=\"Flipp\")]\n",
    "Cum_Q2_2020_TMR['submedia']=np.where(Cum_Q2_2020_TMR['media']==\"Circulation\",\"xx\",Cum_Q2_2020_TMR['submedia'])\n",
    "\n",
    "Cum_Q2_2020_TMR=Cum_Q2_2020_TMR.append(Cum_Q2_2020_TMR_FlippHost).append(Cum_Q2_2020_TMR_FlippNonHost)\n",
    "########################\n",
    "Cum_Q2_2020_TMR['week date']=Cum_Q2_2020_TMR['week date'].astype(str)\n",
    "\n",
    "data_media_national=Cum_Q2_2020_TMR.groupby(['week date','media'])['impression','click','cost'].sum().reset_index()\n",
    "data_submedia_national=Cum_Q2_2020_TMR.groupby(['week date','media','submedia'])['impression','click','cost'].sum().reset_index()\n",
    "data_submedia_national['media_submedia']=data_submedia_national['media']+\"-\"+data_submedia_national['submedia']\n",
    "data_submedia_national=data_submedia_national[['week date','media_submedia','impression','click','cost']]\n",
    "\n",
    "\n",
    "data_media_national_wide=data_media_national[['week date']].drop_duplicates()\n",
    "for col in data_media_national.columns.tolist()[-3:]:\n",
    "    df=data_media_national[['week date','media']+[col]].pivot(index='week date',columns='media',values=col).reset_index()\n",
    "    df_new_col_list=df.columns.tolist()\n",
    "    df_new_col_list.remove('week date')\n",
    "    df_new_col_dict={}\n",
    "    for new_col in df_new_col_list:\n",
    "        df_new_col_dict.update({new_col:new_col+\"_\"+col})\n",
    "    df=df.rename(columns=df_new_col_dict)\n",
    "    data_media_national_wide=pd.merge(data_media_national_wide,df,on='week date',how=\"outer\")\n",
    "data_media_national_wide=data_media_national_wide.fillna(0)\n",
    "data_media_national_wide=data_media_national_wide.drop_duplicates()\n",
    "#############\n",
    "\n",
    "data_submedia_national_wide=data_submedia_national[['week date']].drop_duplicates()\n",
    "for col in data_submedia_national.columns.tolist()[-3:]:\n",
    "    df=data_submedia_national[['week date','media_submedia']+[col]].pivot(index='week date',columns='media_submedia',values=col).reset_index()\n",
    "    df_new_col_list=df.columns.tolist()\n",
    "    df_new_col_list.remove('week date')\n",
    "    df_new_col_dict={}\n",
    "    for new_col in df_new_col_list:\n",
    "        df_new_col_dict.update({new_col:new_col+\"_\"+col})\n",
    "    df=df.rename(columns=df_new_col_dict)\n",
    "    data_submedia_national_wide=pd.merge(data_submedia_national_wide,df,on='week date',how=\"outer\")\n",
    "data_submedia_national_wide=data_submedia_national_wide.fillna(0)\n",
    "data_submedia_national_wide=data_submedia_national_wide.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "including_weeks=[str(datetime.datetime.strptime(new_quarter_end_date,\"%Y-%m-%d\").date()-datetime.timedelta(days=7*x+6)) for x in range(104)]\n",
    "\n",
    "\n",
    "data_media_national_wide=data_media_national_wide.sort_values(\"week date\")\n",
    "data_media_national_wide=data_media_national_wide[data_media_national_wide['week date'].isin(including_weeks)]\n",
    "\n",
    "data_submedia_national_wide=data_submedia_national_wide.sort_values(\"week date\")\n",
    "data_submedia_national_wide=data_submedia_national_wide[data_submedia_national_wide['week date'].isin(including_weeks)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "sales_data=pd.read_csv(\"/mnt/clients/juba/hqjubaapp02/sharefolder/Automation/Weekly_Operation_Reports/outputs/combined_sales_long_2020-11-28.csv\",dtype=str)\n",
    "sales_data=sales_data[sales_data['week_end_date']<=new_quarter_end_date]\n",
    "sales_data['week_end_date']=sales_data['week_end_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "sales_data['sales']=sales_data['sales'].astype(float)\n",
    "sales_data['transactions']=sales_data['transactions'].astype(float)\n",
    "sales_data['week date']=sales_data['week_end_date'].apply(lambda x: x-datetime.timedelta(days=6))\n",
    "sales_data_naitonal=sales_data.groupby(['week date'])['sales','transactions'].sum().reset_index()\n",
    "sales_data_naitonal=sales_data_naitonal.set_index(['week date'])\n",
    "sales_data_naitonal.at[datetime.date(2017,4,30),'transactions']=(sales_data_naitonal.at[datetime.date(2017,4,23),'transactions']+sales_data_naitonal.at[datetime.date(2017,5,7),'transactions'])/2\n",
    "sales_data_naitonal=sales_data_naitonal.reset_index()\n",
    "sales_data_store_counts=sales_data[sales_data['sales']>0]\n",
    "sales_data_store_counts=sales_data_store_counts.groupby(['week date'])['location_id'].count().to_frame().reset_index().rename(columns={\"location_id\":\"store_counts\"})\n",
    "\n",
    "sales_data_naitonal=pd.merge(sales_data_naitonal,sales_data_store_counts,on=\"week date\",how=\"outer\")\n",
    "sales_data_naitonal['week date']=sales_data_naitonal['week date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_media_national_wide=pd.merge(data_media_national_wide,sales_data_naitonal,on=\"week date\",how=\"left\")\n",
    "data_submedia_national_wide=pd.merge(data_submedia_national_wide,sales_data_naitonal,on=\"week date\",how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "Rewards_Promotion_list=[datetime.date(2016,10,1),datetime.date(2016,10,2),\n",
    "                        datetime.date(2017,1,21),datetime.date(2017,1,22),\n",
    "                        datetime.date(2017,4,1),datetime.date(2017,4,2),\n",
    "                        datetime.date(2017,7,8),datetime.date(2017,7,9),\n",
    "                        datetime.date(2017,9,30),datetime.date(2017,10,1),\n",
    "                        datetime.date(2018,1,20),datetime.date(2018,1,21),\n",
    "                        datetime.date(2018,4,7),datetime.date(2018,4,8),\n",
    "                        datetime.date(2018,7,7),datetime.date(2018,7,8),\n",
    "                        datetime.date(2018,9,29),datetime.date(2018,9,30),\n",
    "                        datetime.date(2019,1,26),datetime.date(2019,1,27),  \n",
    "                        datetime.date(2019,4,6),datetime.date(2019,4,7),\n",
    "                        datetime.date(2019,7,13),datetime.date(2019,7,14),\n",
    "                        datetime.date(2020,1,18),datetime.date(2020,1,19)\n",
    "                        # Q1 2020 F&F canceled due to COVID, according to the 2020 Marcom Calendar_11.11.xlsx\n",
    "                        # Don't see the Q2 F&F event neither in the same excel above\n",
    "                        \n",
    "                       ]\n",
    "\n",
    "df_Rewards_Promotion=pd.DataFrame({\"Date\":Rewards_Promotion_list},index=range(len(Rewards_Promotion_list)))\n",
    "df_Rewards_Promotion['weekday']=df_Rewards_Promotion['Date'].apply(lambda x: x.weekday())\n",
    "df_Rewards_Promotion['week date']=np.where(df_Rewards_Promotion['weekday']==6,df_Rewards_Promotion['Date'],df_Rewards_Promotion['Date']-datetime.timedelta(days=6))\n",
    "\n",
    "del df_Rewards_Promotion['Date']\n",
    "\n",
    "df_Rewards_Promotion_Sunday=df_Rewards_Promotion[df_Rewards_Promotion['weekday']==6]\n",
    "df_Rewards_Promotion_Sunday['Sunday_rewards_ind']=1\n",
    "del df_Rewards_Promotion_Sunday['weekday']\n",
    "df_Rewards_Promotion_Sunday['week date']=df_Rewards_Promotion_Sunday['week date'].astype(str)\n",
    "\n",
    "\n",
    "df_Rewards_Promotion_Saturday=df_Rewards_Promotion[df_Rewards_Promotion['weekday']==5]\n",
    "df_Rewards_Promotion_Saturday['Saturday_rewards_ind']=1\n",
    "del df_Rewards_Promotion_Saturday['weekday']\n",
    "df_Rewards_Promotion_Saturday['week date']=df_Rewards_Promotion_Saturday['week date'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_1_week_df=pd.DataFrame({\"week date\":[datetime.date(2016,12,18),datetime.date(2017,12,17),datetime.date(2018,12,23),datetime.date(2019,12,22)],\"Holiday_1_week_only_Ind\":[1]*4},index=[0,1,2,3])\n",
    "holiday_5_weeks_df=pd.DataFrame({\"week date\":[datetime.date(2016,12,18)-datetime.timedelta(days=x*7) for x in range(5)] +\\\n",
    "                                 [datetime.date(2017,12,17)-datetime.timedelta(days=x*7) for x in range(5)]+\\\n",
    "                                 [datetime.date(2018,12,23)-datetime.timedelta(days=x*7) for x in range(5)]+\\\n",
    "                                 [datetime.date(2019,12,22)-datetime.timedelta(days=x*7) for x in range(5)],\n",
    "                                 \"Holiday_5_weeks_only_Ind\":[1]*20},index=[x for x in range(20)])\n",
    "\n",
    "holiday_1_week_df['week date']=holiday_1_week_df['week date'].astype(str)\n",
    "holiday_5_weeks_df['week date']=holiday_5_weeks_df['week date'].astype(str)\n",
    "\n",
    "df_special_weeks_ind=pd.merge(df_Rewards_Promotion_Saturday,df_Rewards_Promotion_Sunday,on=\"week date\",how=\"outer\")\n",
    "df_special_weeks_ind=pd.merge(df_special_weeks_ind,holiday_1_week_df,on=\"week date\",how=\"outer\")\n",
    "df_special_weeks_ind=pd.merge(df_special_weeks_ind,holiday_5_weeks_df,on=\"week date\",how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_media_national_wide=pd.merge(data_media_national_wide,df_special_weeks_ind,on=\"week date\",how=\"left\")\n",
    "\n",
    "data_submedia_national_wide=pd.merge(data_submedia_national_wide,df_special_weeks_ind,on=\"week date\",how=\"left\")\n",
    "\n",
    "data_media_national_wide=data_media_national_wide.fillna(0)\n",
    "data_submedia_national_wide=data_submedia_national_wide.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quarter label\n",
    "week_start_1st_2018Q1=datetime.date(2018,2,4)\n",
    "\n",
    "def quarter_of_FY(input_str_x):\n",
    "    date_x=datetime.datetime.strptime(input_str_x,\"%Y-%m-%d\").date()\n",
    "    quarter_diff=int(np.floor(((date_x-week_start_1st_2018Q1).days)/(7*13)))\n",
    "    year_diff=int(np.floor(((date_x-week_start_1st_2018Q1).days)/(7*52)))\n",
    "    year=year_diff+week_start_1st_2018Q1.year\n",
    "    quarter=1+quarter_diff%4\n",
    "    return \"Q%i_%i\"%(quarter,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-04 Q1_2018\n",
      "2018-02-11 Q1_2018\n",
      "2018-02-18 Q1_2018\n",
      "2018-02-25 Q1_2018\n",
      "2018-03-04 Q1_2018\n",
      "2018-03-11 Q1_2018\n",
      "2018-03-18 Q1_2018\n",
      "2018-03-25 Q1_2018\n",
      "2018-04-01 Q1_2018\n",
      "2018-04-08 Q1_2018\n",
      "2018-04-15 Q1_2018\n",
      "2018-04-22 Q1_2018\n",
      "2018-04-29 Q1_2018\n",
      "2018-05-06 Q2_2018\n",
      "2018-05-13 Q2_2018\n",
      "2018-05-20 Q2_2018\n",
      "2018-05-27 Q2_2018\n",
      "2018-06-03 Q2_2018\n",
      "2018-06-10 Q2_2018\n",
      "2018-06-17 Q2_2018\n",
      "2018-06-24 Q2_2018\n",
      "2018-07-01 Q2_2018\n",
      "2018-07-08 Q2_2018\n",
      "2018-07-15 Q2_2018\n",
      "2018-07-22 Q2_2018\n",
      "2018-07-29 Q2_2018\n",
      "2018-08-05 Q3_2018\n",
      "2018-08-12 Q3_2018\n",
      "2018-08-19 Q3_2018\n",
      "2018-08-26 Q3_2018\n",
      "2018-09-02 Q3_2018\n",
      "2018-09-09 Q3_2018\n",
      "2018-09-16 Q3_2018\n",
      "2018-09-23 Q3_2018\n",
      "2018-09-30 Q3_2018\n",
      "2018-10-07 Q3_2018\n",
      "2018-10-14 Q3_2018\n",
      "2018-10-21 Q3_2018\n",
      "2018-10-28 Q3_2018\n",
      "2018-11-04 Q4_2018\n",
      "2018-11-11 Q4_2018\n",
      "2018-11-18 Q4_2018\n",
      "2018-11-25 Q4_2018\n",
      "2018-12-02 Q4_2018\n",
      "2018-12-09 Q4_2018\n",
      "2018-12-16 Q4_2018\n",
      "2018-12-23 Q4_2018\n",
      "2018-12-30 Q4_2018\n",
      "2019-01-06 Q4_2018\n",
      "2019-01-13 Q4_2018\n",
      "2019-01-20 Q4_2018\n",
      "2019-01-27 Q4_2018\n",
      "2019-02-03 Q1_2019\n",
      "2019-02-10 Q1_2019\n",
      "2019-02-17 Q1_2019\n",
      "2019-02-24 Q1_2019\n",
      "2019-03-03 Q1_2019\n",
      "2019-03-10 Q1_2019\n",
      "2019-03-17 Q1_2019\n",
      "2019-03-24 Q1_2019\n",
      "2019-03-31 Q1_2019\n",
      "2019-04-07 Q1_2019\n",
      "2019-04-14 Q1_2019\n",
      "2019-04-21 Q1_2019\n",
      "2019-04-28 Q1_2019\n",
      "2019-05-05 Q2_2019\n",
      "2019-05-12 Q2_2019\n",
      "2019-05-19 Q2_2019\n",
      "2019-05-26 Q2_2019\n",
      "2019-06-02 Q2_2019\n",
      "2019-06-09 Q2_2019\n",
      "2019-06-16 Q2_2019\n",
      "2019-06-23 Q2_2019\n",
      "2019-06-30 Q2_2019\n",
      "2019-07-07 Q2_2019\n",
      "2019-07-14 Q2_2019\n",
      "2019-07-21 Q2_2019\n",
      "2019-07-28 Q2_2019\n",
      "2019-08-04 Q3_2019\n",
      "2019-08-11 Q3_2019\n",
      "2019-08-18 Q3_2019\n",
      "2019-08-25 Q3_2019\n",
      "2019-09-01 Q3_2019\n",
      "2019-09-08 Q3_2019\n",
      "2019-09-15 Q3_2019\n",
      "2019-09-22 Q3_2019\n",
      "2019-09-29 Q3_2019\n",
      "2019-10-06 Q3_2019\n",
      "2019-10-13 Q3_2019\n",
      "2019-10-20 Q3_2019\n",
      "2019-10-27 Q3_2019\n",
      "2019-11-03 Q4_2019\n",
      "2019-11-10 Q4_2019\n",
      "2019-11-17 Q4_2019\n",
      "2019-11-24 Q4_2019\n",
      "2019-12-01 Q4_2019\n",
      "2019-12-08 Q4_2019\n",
      "2019-12-15 Q4_2019\n",
      "2019-12-22 Q4_2019\n",
      "2019-12-29 Q4_2019\n",
      "2020-01-05 Q4_2019\n",
      "2020-01-12 Q4_2019\n",
      "2020-01-19 Q4_2019\n",
      "2020-01-26 Q4_2019\n",
      "2020-02-02 Q1_2020\n",
      "2020-02-09 Q1_2020\n",
      "2020-02-16 Q1_2020\n",
      "2020-02-23 Q1_2020\n",
      "2020-03-01 Q1_2020\n",
      "2020-03-08 Q1_2020\n",
      "2020-03-15 Q1_2020\n",
      "2020-03-22 Q1_2020\n",
      "2020-03-29 Q1_2020\n",
      "2020-04-05 Q1_2020\n",
      "2020-04-12 Q1_2020\n",
      "2020-04-19 Q1_2020\n",
      "2020-04-26 Q1_2020\n",
      "2020-05-03 Q2_2020\n",
      "2020-05-10 Q2_2020\n",
      "2020-05-17 Q2_2020\n",
      "2020-05-24 Q2_2020\n",
      "2020-05-31 Q2_2020\n",
      "2020-06-07 Q2_2020\n",
      "2020-06-14 Q2_2020\n",
      "2020-06-21 Q2_2020\n",
      "2020-06-28 Q2_2020\n",
      "2020-07-05 Q2_2020\n",
      "2020-07-12 Q2_2020\n",
      "2020-07-19 Q2_2020\n",
      "2020-07-26 Q2_2020\n",
      "2020-08-02 Q3_2020\n",
      "2020-08-09 Q3_2020\n",
      "2020-08-16 Q3_2020\n",
      "2020-08-23 Q3_2020\n",
      "2020-08-30 Q3_2020\n",
      "2020-09-06 Q3_2020\n",
      "2020-09-13 Q3_2020\n",
      "2020-09-20 Q3_2020\n",
      "2020-09-27 Q3_2020\n",
      "2020-10-04 Q3_2020\n",
      "2020-10-11 Q3_2020\n",
      "2020-10-18 Q3_2020\n",
      "2020-10-25 Q3_2020\n",
      "2020-11-01 Q4_2020\n",
      "2020-11-08 Q4_2020\n",
      "2020-11-15 Q4_2020\n",
      "2020-11-22 Q4_2020\n",
      "2020-11-29 Q4_2020\n",
      "2020-12-06 Q4_2020\n",
      "2020-12-13 Q4_2020\n",
      "2020-12-20 Q4_2020\n",
      "2020-12-27 Q4_2020\n",
      "2021-01-03 Q4_2020\n",
      "2021-01-10 Q4_2020\n",
      "2021-01-17 Q4_2020\n",
      "2021-01-24 Q4_2020\n",
      "2021-01-31 Q1_2021\n",
      "2021-02-07 Q1_2021\n",
      "2021-02-14 Q1_2021\n",
      "2021-02-21 Q1_2021\n",
      "2021-02-28 Q1_2021\n",
      "2021-03-07 Q1_2021\n",
      "2021-03-14 Q1_2021\n",
      "2021-03-21 Q1_2021\n",
      "2021-03-28 Q1_2021\n",
      "2021-04-04 Q1_2021\n",
      "2021-04-11 Q1_2021\n",
      "2021-04-18 Q1_2021\n",
      "2021-04-25 Q1_2021\n",
      "2021-05-02 Q2_2021\n",
      "2021-05-09 Q2_2021\n",
      "2021-05-16 Q2_2021\n",
      "2021-05-23 Q2_2021\n",
      "2021-05-30 Q2_2021\n",
      "2021-06-06 Q2_2021\n",
      "2021-06-13 Q2_2021\n",
      "2021-06-20 Q2_2021\n",
      "2021-06-27 Q2_2021\n",
      "2021-07-04 Q2_2021\n",
      "2021-07-11 Q2_2021\n",
      "2021-07-18 Q2_2021\n",
      "2021-07-25 Q2_2021\n",
      "2021-08-01 Q3_2021\n",
      "2021-08-08 Q3_2021\n",
      "2021-08-15 Q3_2021\n",
      "2021-08-22 Q3_2021\n",
      "2021-08-29 Q3_2021\n",
      "2021-09-05 Q3_2021\n",
      "2021-09-12 Q3_2021\n",
      "2021-09-19 Q3_2021\n",
      "2021-09-26 Q3_2021\n",
      "2021-10-03 Q3_2021\n",
      "2021-10-10 Q3_2021\n",
      "2021-10-17 Q3_2021\n",
      "2021-10-24 Q3_2021\n",
      "2021-10-31 Q4_2021\n",
      "2021-11-07 Q4_2021\n",
      "2021-11-14 Q4_2021\n",
      "2021-11-21 Q4_2021\n",
      "2021-11-28 Q4_2021\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    input_x=week_start_1st_2018Q1+datetime.timedelta(days=i*7)\n",
    "    input_x=str(input_x)\n",
    "    print(str(input_x),quarter_of_FY(input_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_media_national_wide['BL_quarter']=data_media_national_wide['week date'].apply(quarter_of_FY)\n",
    "data_submedia_national_wide['BL_quarter']=data_submedia_national_wide['week date'].apply(quarter_of_FY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/clients/juba/hqjubaapp02/sharefolder/Media/TMR/TMR_data/Up_to_2020Q2'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_media_national_wide.to_csv(\"./output/BL_MMM_data_media_national_wide_2020Q2_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "data_submedia_national_wide.to_csv(\"./output/BL_MMM_data_submedia_national_wide_2020Q2_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "\n",
    "\n",
    "# Gonna QC for the last 3 quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week date</th>\n",
       "      <th>Cinema-xx_impression</th>\n",
       "      <th>Circulation-xx_impression</th>\n",
       "      <th>Digital-Flipp(hosted)_impression</th>\n",
       "      <th>Digital-Flipp(nonhosted)_impression</th>\n",
       "      <th>Digital-PLA_impression</th>\n",
       "      <th>Digital-Pandora_impression</th>\n",
       "      <th>Digital-Programmatic_impression</th>\n",
       "      <th>Digital-SEM_impression</th>\n",
       "      <th>Digital-Social_impression</th>\n",
       "      <th>...</th>\n",
       "      <th>TV-Local_cost</th>\n",
       "      <th>TV-National_cost</th>\n",
       "      <th>sales</th>\n",
       "      <th>transactions</th>\n",
       "      <th>store_counts</th>\n",
       "      <th>Saturday_rewards_ind</th>\n",
       "      <th>Sunday_rewards_ind</th>\n",
       "      <th>Holiday_1_week_only_Ind</th>\n",
       "      <th>Holiday_5_weeks_only_Ind</th>\n",
       "      <th>BL_quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133902.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>3912625.0</td>\n",
       "      <td>390810.0</td>\n",
       "      <td>2061801.0</td>\n",
       "      <td>1052808.0</td>\n",
       "      <td>4038136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>82799208.79</td>\n",
       "      <td>2798841.0</td>\n",
       "      <td>1411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q3_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4505762.0</td>\n",
       "      <td>318803.0</td>\n",
       "      <td>4228711.0</td>\n",
       "      <td>1202253.0</td>\n",
       "      <td>13221622.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44723.7960</td>\n",
       "      <td>86833815.44</td>\n",
       "      <td>2808603.0</td>\n",
       "      <td>1411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q3_2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13481187.0</td>\n",
       "      <td>303785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3830969.0</td>\n",
       "      <td>510792.0</td>\n",
       "      <td>5861033.0</td>\n",
       "      <td>985952.0</td>\n",
       "      <td>11660601.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139026.9485</td>\n",
       "      <td>83433994.48</td>\n",
       "      <td>2824239.0</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q3_2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    week date  Cinema-xx_impression  Circulation-xx_impression  \\\n",
       "0  2018-08-05                   0.0                        0.0   \n",
       "1  2018-08-12                   0.0                        0.0   \n",
       "2  2018-08-19                   0.0                 13481187.0   \n",
       "\n",
       "   Digital-Flipp(hosted)_impression  Digital-Flipp(nonhosted)_impression  \\\n",
       "0                          133902.0                                542.0   \n",
       "1                          153357.0                                  0.0   \n",
       "2                          303785.0                                  0.0   \n",
       "\n",
       "   Digital-PLA_impression  Digital-Pandora_impression  \\\n",
       "0               3912625.0                    390810.0   \n",
       "1               4505762.0                    318803.0   \n",
       "2               3830969.0                    510792.0   \n",
       "\n",
       "   Digital-Programmatic_impression  Digital-SEM_impression  \\\n",
       "0                        2061801.0               1052808.0   \n",
       "1                        4228711.0               1202253.0   \n",
       "2                        5861033.0                985952.0   \n",
       "\n",
       "   Digital-Social_impression  ...  TV-Local_cost  TV-National_cost  \\\n",
       "0                  4038136.0  ...            0.0            0.0000   \n",
       "1                 13221622.0  ...            0.0        44723.7960   \n",
       "2                 11660601.0  ...            0.0       139026.9485   \n",
       "\n",
       "         sales  transactions  store_counts  Saturday_rewards_ind  \\\n",
       "0  82799208.79     2798841.0          1411                   0.0   \n",
       "1  86833815.44     2808603.0          1411                   0.0   \n",
       "2  83433994.48     2824239.0          1412                   0.0   \n",
       "\n",
       "   Sunday_rewards_ind  Holiday_1_week_only_Ind  Holiday_5_weeks_only_Ind  \\\n",
       "0                 0.0                      0.0                       0.0   \n",
       "1                 0.0                      0.0                       0.0   \n",
       "2                 0.0                      0.0                       0.0   \n",
       "\n",
       "   BL_quarter  \n",
       "0     Q3_2018  \n",
       "1     Q3_2018  \n",
       "2     Q3_2018  \n",
       "\n",
       "[3 rows x 51 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_submedia_national_wide.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
