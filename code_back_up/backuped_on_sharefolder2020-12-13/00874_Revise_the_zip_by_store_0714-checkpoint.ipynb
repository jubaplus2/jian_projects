{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the unknown zip then create new labels\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import gc\n",
    "from haversine import haversine\n",
    "import json\n",
    "os.getcwd()\n",
    "zip_centers=json.load(open(\"/home/jian/Docs/Geo_mapping/updated_zip_centers_JL_2019-05-23.json\",\"r\"))\n",
    "\n",
    "\n",
    "output_folder=\"/home/jian/Projects/Big_Lots/New_TA/TA_created_in_201906/output_\"+str(datetime.datetime.now().date())+\"/\"\n",
    "\n",
    "try:\n",
    "    os.stat(output_folder)\n",
    "except:\n",
    "    os.mkdir(output_folder)\n",
    "    \n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>zip_validation</th>\n",
       "      <th>sales</th>\n",
       "      <th>trans</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>cum_sales</th>\n",
       "      <th>sales_pctg_cum</th>\n",
       "      <th>revenue_flag</th>\n",
       "      <th>cum_trans</th>\n",
       "      <th>trans_pctg_cum</th>\n",
       "      <th>transactions_flag</th>\n",
       "      <th>transaction_dt_nunique</th>\n",
       "      <th>transaction_dt_max</th>\n",
       "      <th>transaction_dt_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43232</td>\n",
       "      <td>Valid_Zip</td>\n",
       "      <td>602768.3400000014</td>\n",
       "      <td>16101.0</td>\n",
       "      <td>3245</td>\n",
       "      <td>602768.3400000014</td>\n",
       "      <td>0.21498328905757522</td>\n",
       "      <td>P</td>\n",
       "      <td>16101.0</td>\n",
       "      <td>0.26084632083724846</td>\n",
       "      <td>P</td>\n",
       "      <td>363</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>2018-06-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43207</td>\n",
       "      <td>Valid_Zip</td>\n",
       "      <td>348158.19999999925</td>\n",
       "      <td>6688.0</td>\n",
       "      <td>1798</td>\n",
       "      <td>950926.5400000006</td>\n",
       "      <td>0.339157353920313</td>\n",
       "      <td>P</td>\n",
       "      <td>30159.0</td>\n",
       "      <td>0.4885947574765901</td>\n",
       "      <td>P</td>\n",
       "      <td>363</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>2018-06-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id customer_zip_code zip_validation               sales    trans  \\\n",
       "0           1             43232      Valid_Zip   602768.3400000014  16101.0   \n",
       "1           1             43207      Valid_Zip  348158.19999999925   6688.0   \n",
       "\n",
       "  customer_id_hashed          cum_sales       sales_pctg_cum revenue_flag  \\\n",
       "0               3245  602768.3400000014  0.21498328905757522            P   \n",
       "1               1798  950926.5400000006    0.339157353920313            P   \n",
       "\n",
       "  cum_trans       trans_pctg_cum transactions_flag transaction_dt_nunique  \\\n",
       "0   16101.0  0.26084632083724846                 P                    363   \n",
       "1   30159.0   0.4885947574765901                 P                    363   \n",
       "\n",
       "  transaction_dt_max transaction_dt_min  \n",
       "0         2019-06-22         2018-06-24  \n",
       "1         2019-06-22         2018-06-24  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_previous_zip_by_store=pd.read_csv(\"/home/jian/Projects/Big_Lots/New_TA/TA_created_in_201906/output_by_store_zip_sales_cum_JL_2019-06-27.csv\",dtype=str)\n",
    "df_previous_zip_by_store.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-06-22'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_previous_zip_by_store['transaction_dt_max'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_previous_zip_by_store['transaction_dt_nunique']=df_previous_zip_by_store['transaction_dt_nunique'].astype(int)\n",
    "df_previous_zip_by_store['sales']=df_previous_zip_by_store['sales'].astype(float)\n",
    "df_previous_zip_by_store['trans']=df_previous_zip_by_store['trans'].astype(float)\n",
    "df_previous_zip_by_store['customer_id_hashed']=df_previous_zip_by_store['customer_id_hashed'].astype(int)\n",
    "del df_previous_zip_by_store['cum_sales']\n",
    "del df_previous_zip_by_store['sales_pctg_cum']\n",
    "del df_previous_zip_by_store['cum_trans']\n",
    "del df_previous_zip_by_store['trans_pctg_cum']\n",
    "del df_previous_zip_by_store['revenue_flag']\n",
    "del df_previous_zip_by_store['transactions_flag']\n",
    "\n",
    "df_stores_in_2_months_6990=df_previous_zip_by_store[(df_previous_zip_by_store['transaction_dt_nunique']<=60) | (df_previous_zip_by_store['location_id']==\"6990\")]\n",
    "df_stores_more_than_2_months=df_previous_zip_by_store[(df_previous_zip_by_store['transaction_dt_nunique']>60) & (df_previous_zip_by_store['location_id']!=\"6990\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unknown_Zip'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stores_more_than_2_months_valid=df_stores_more_than_2_months[df_stores_more_than_2_months['zip_validation']==\"Valid_Zip\"]\n",
    "df_stores_more_than_2_months_unknown=df_stores_more_than_2_months[df_stores_more_than_2_months['zip_validation']!=\"Valid_Zip\"]\n",
    "\n",
    "df_stores_more_than_2_months_unknown['zip_validation'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_output=pd.DataFrame()\n",
    "\n",
    "for store,df_store in df_stores_more_than_2_months_valid.groupby(\"location_id\"):\n",
    "    total_valid_sales=df_store['sales'].sum()\n",
    "    total_valid_trans=df_store['trans'].sum()\n",
    "    \n",
    "    df_store=df_store.sort_values(\"sales\",ascending=False)\n",
    "    df_store['cumulative_sales']=df_store['sales'].cumsum()\n",
    "    df_store['cumu_pctg_sales']=df_store['cumulative_sales']/total_valid_sales\n",
    "    df_store=df_store.reset_index()\n",
    "    del df_store['index']\n",
    "    \n",
    "    df_store_1st=df_store.iloc[0,].to_frame().T\n",
    "    df_store_1st['revenue_flag']=\"P\"\n",
    "    \n",
    "    df_store_others=df_store.iloc[1:,]\n",
    "    df_store_others['revenue_flag']=np.where(df_store_others['cumu_pctg_sales']>=0.8,\"T\",\n",
    "                                  np.where(df_store_others['cumu_pctg_sales']>=0.6,\"S\",\"P\"))\n",
    "    df_store=df_store_1st.append(df_store_others)\n",
    "    ######### \n",
    "    df_store=df_store.sort_values(\"trans\",ascending=False)\n",
    "    df_store['cumulative_trans']=df_store['trans'].cumsum()\n",
    "    df_store['cumu_pctg_trans']=df_store['cumulative_trans']/total_valid_trans\n",
    "    df_store=df_store.reset_index()\n",
    "    del df_store['index']\n",
    "    \n",
    "    df_store_1st=df_store.iloc[0,].to_frame().T\n",
    "    df_store_1st['trans_flag']=\"P\"\n",
    "    \n",
    "    df_store_others=df_store.iloc[1:,]\n",
    "    df_store_others['trans_flag']=np.where(df_store_others['cumu_pctg_trans']>=0.8,\"T\",\n",
    "                                  np.where(df_store_others['cumu_pctg_trans']>=0.6,\"S\",\"P\"))\n",
    "    df_store=df_store_1st.append(df_store_others)\n",
    "\n",
    "    df_output=df_output.append(df_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue_flag</th>\n",
       "      <th>trans_flag</th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>sales</th>\n",
       "      <th>trans</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>4849</td>\n",
       "      <td>1.495196e+09</td>\n",
       "      <td>38638183.0</td>\n",
       "      <td>9127678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>S</td>\n",
       "      <td>1271</td>\n",
       "      <td>1.385980e+08</td>\n",
       "      <td>3098561.0</td>\n",
       "      <td>910600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  revenue_flag trans_flag  customer_zip_code         sales       trans  \\\n",
       "0            P          P               4849  1.495196e+09  38638183.0   \n",
       "1            P          S               1271  1.385980e+08   3098561.0   \n",
       "\n",
       "   customer_id_hashed  \n",
       "0             9127678  \n",
       "1              910600  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_agg={'customer_zip_code':\"nunique\",'sales':\"sum\",'trans':\"sum\",\"customer_id_hashed\":\"sum\"}\n",
    "\n",
    "df_matrics_data=df_output.groupby(['revenue_flag','trans_flag'])['customer_zip_code','sales','trans','customer_id_hashed'].agg(func_agg).reset_index()\n",
    "df_matrics_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"Excel_BL_new_ta_matrix_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in df_matrics_data.columns.tolist()[2:]:\n",
    "    df=df_matrics_data[['revenue_flag','trans_flag',col]]\n",
    "    globals()[\"df_all_\"+col]=df.pivot(index=\"revenue_flag\",columns=\"trans_flag\",values=col).fillna(0)\n",
    "    globals()[\"df_all_\"+col].to_excel(writer,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_matrics_data_store=df_output.groupby(['location_id','revenue_flag','trans_flag'])['customer_zip_code','sales','trans','customer_id_hashed'].agg(func_agg).reset_index()\n",
    "\n",
    "\n",
    "for col in df_matrics_data.columns.tolist()[2:]:\n",
    "    globals()['df_every_store_'+col]=pd.DataFrame()\n",
    "    df=df_matrics_data_store[['location_id','revenue_flag','trans_flag',col]]\n",
    "    for store,df_store in df.groupby(\"location_id\"):\n",
    "        del df_store['location_id']\n",
    "        locals()[\"df_store_\"+col]=df_store.pivot(index=\"revenue_flag\",columns=\"trans_flag\",values=col).fillna(0)\n",
    "        locals()[\"df_store_\"+col]['location_id']=store\n",
    "        globals()['df_every_store_'+col]=globals()['df_every_store_'+col].append(locals()[\"df_store_\"+col])\n",
    "    globals()['df_every_store_'+col].to_excel(writer,\"by_store_\"+col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_output.to_csv(output_folder+\"BL_new_ta_by_store_zip_60_days_valid_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "df_stores_more_than_2_months_unknown.to_csv(output_folder+\"BL_new_ta_by_store_zip_60_days_unknown_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "df_stores_in_2_months_6990.to_csv(output_folder+\"BL_new_ta_by_store_zip_lower60_days_6990_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_summary=df_output.groupby(['location_id','revenue_flag','trans_flag','transaction_dt_nunique','transaction_dt_min','transaction_dt_max'])['customer_zip_code'].count().to_frame().reset_index()\n",
    "df_summary.to_csv(output_folder+\"BL_summary_zip_count_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_list=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20190701-134908-815.txt\",\n",
    "                         dtype=str,sep=\"|\",usecols=['location_id','latitude_meas','longitude_meas'])\n",
    "store_list['latitude_meas']=store_list['latitude_meas'].astype(float)\n",
    "store_list['longitude_meas']=store_list['longitude_meas'].astype(float)\n",
    "df_output=pd.merge(df_output,store_list,on=\"location_id\",how=\"left\")\n",
    "\n",
    "df_output_closed=df_output[pd.isnull(df_output['latitude_meas'])]\n",
    "df_output=df_output[pd.notnull(df_output['latitude_meas'])]\n",
    "df_output.to_csv(output_folder+\"BL_new_ta_by_store_zip_60_days_valid_open_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "df_output_closed.to_csv(output_folder+\"BL_new_ta_by_store_zip_60_days_valid_closed_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "del df_output_closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dist_in_df(zip_cd,store_lat,store_long):\n",
    "    try:\n",
    "        dist=haversine(zip_centers[zip_cd],(store_lat,store_long),miles=True)\n",
    "    except:\n",
    "        dist=np.nan\n",
    "    return dist\n",
    "df_output['dist_miles']=df_output.apply(lambda x: get_dist_in_df(x['customer_zip_code'],x['latitude_meas'],x['longitude_meas']),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22209, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>customer_zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>318</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>548</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>5197</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>5332</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>4566</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1369</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1501</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1789</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>4195</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>513</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     location_id  customer_zip_code\n",
       "605          318                 92\n",
       "1338         548                 91\n",
       "1147        5197                 91\n",
       "1281        5332                 80\n",
       "907         4566                 78\n",
       "168         1369                 63\n",
       "242         1501                 61\n",
       "407         1789                 61\n",
       "732         4195                 61\n",
       "1083         513                 60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_PS_50_miles=df_output[(df_output['trans_flag'].isin(['P','S'])) &(df_output['dist_miles']<=50)]\n",
    "print(df_output_PS_50_miles.shape)\n",
    "df_output_PS_50_miles.groupby(['location_id'])['customer_zip_code'].count().to_frame().reset_index().sort_values(\"customer_zip_code\",ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.994776679479415"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_PS_50_miles['dist_miles'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>zip_validation</th>\n",
       "      <th>sales</th>\n",
       "      <th>trans</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>transaction_dt_nunique</th>\n",
       "      <th>transaction_dt_max</th>\n",
       "      <th>transaction_dt_min</th>\n",
       "      <th>cumulative_sales</th>\n",
       "      <th>cumu_pctg_sales</th>\n",
       "      <th>revenue_flag</th>\n",
       "      <th>cumulative_trans</th>\n",
       "      <th>cumu_pctg_trans</th>\n",
       "      <th>trans_flag</th>\n",
       "      <th>longitude_meas</th>\n",
       "      <th>latitude_meas</th>\n",
       "      <th>dist_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43232</td>\n",
       "      <td>Valid_Zip</td>\n",
       "      <td>602768</td>\n",
       "      <td>16101</td>\n",
       "      <td>3245</td>\n",
       "      <td>363</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>2018-06-24</td>\n",
       "      <td>602768</td>\n",
       "      <td>0.236332</td>\n",
       "      <td>P</td>\n",
       "      <td>16101</td>\n",
       "      <td>0.278853</td>\n",
       "      <td>P</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>2.717654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43209</td>\n",
       "      <td>Valid_Zip</td>\n",
       "      <td>270028</td>\n",
       "      <td>7370</td>\n",
       "      <td>1340</td>\n",
       "      <td>363</td>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>2018-06-24</td>\n",
       "      <td>1.22095e+06</td>\n",
       "      <td>0.47871</td>\n",
       "      <td>P</td>\n",
       "      <td>23471</td>\n",
       "      <td>0.406495</td>\n",
       "      <td>P</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>3.095917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id customer_zip_code zip_validation   sales  trans  \\\n",
       "0           1             43232      Valid_Zip  602768  16101   \n",
       "1           1             43209      Valid_Zip  270028   7370   \n",
       "\n",
       "  customer_id_hashed transaction_dt_nunique transaction_dt_max  \\\n",
       "0               3245                    363         2019-06-22   \n",
       "1               1340                    363         2019-06-22   \n",
       "\n",
       "  transaction_dt_min cumulative_sales cumu_pctg_sales revenue_flag  \\\n",
       "0         2018-06-24           602768        0.236332            P   \n",
       "1         2018-06-24      1.22095e+06         0.47871            P   \n",
       "\n",
       "  cumulative_trans cumu_pctg_trans trans_flag  longitude_meas  latitude_meas  \\\n",
       "0            16101        0.278853          P      -82.914789      39.913636   \n",
       "1            23471        0.406495          P      -82.914789      39.913636   \n",
       "\n",
       "   dist_miles  \n",
       "0    2.717654  \n",
       "1    3.095917  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_PS_50_miles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting overlaps between stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_store_zip_both=df_output_PS_50_miles[['location_id','trans_flag','customer_zip_code','latitude_meas','longitude_meas']].rename(columns={\"customer_zip_code\":\"zip_list_P_and_S\"}).drop_duplicates()\n",
    "df_store_zip_both=df_store_zip_both.groupby([\"location_id\",'latitude_meas','longitude_meas'])['zip_list_P_and_S'].apply(set).to_frame().reset_index()\n",
    "df_store_zip_both['zip_list_P_and_S']=df_store_zip_both['zip_list_P_and_S'].apply(lambda x: list(x))\n",
    "\n",
    "df_store_zip_P=df_output_PS_50_miles[df_output_PS_50_miles['trans_flag']==\"P\"]\n",
    "df_store_zip_P=df_store_zip_P[['location_id','trans_flag','customer_zip_code','latitude_meas','longitude_meas']].rename(columns={\"customer_zip_code\":\"zip_list_P\"}).drop_duplicates()\n",
    "df_store_zip_P=df_store_zip_P.groupby([\"location_id\",'latitude_meas','longitude_meas'])['zip_list_P'].apply(set).to_frame().reset_index()\n",
    "df_store_zip_P['zip_list_P']=df_store_zip_P['zip_list_P'].apply(lambda x: list(x))\n",
    "\n",
    "df_store_zip_S=df_output_PS_50_miles[df_output_PS_50_miles['trans_flag']==\"S\"]\n",
    "df_store_zip_S=df_store_zip_S[['location_id','trans_flag','customer_zip_code','latitude_meas','longitude_meas']].rename(columns={\"customer_zip_code\":\"zip_list_S\"}).drop_duplicates()\n",
    "df_store_zip_S=df_store_zip_S.groupby([\"location_id\",'latitude_meas','longitude_meas'])['zip_list_S'].apply(set).to_frame().reset_index()\n",
    "df_store_zip_S['zip_list_S']=df_store_zip_S['zip_list_S'].apply(lambda x: list(x))\n",
    "\n",
    "df_store_zip=pd.merge(df_store_zip_both,df_store_zip_P,on=[\"location_id\",'latitude_meas','longitude_meas'],how=\"outer\")\n",
    "df_store_zip=pd.merge(df_store_zip,df_store_zip_S,on=[\"location_id\",'latitude_meas','longitude_meas'],how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_zip_0=df_store_zip.copy()\n",
    "\n",
    "df_store_zip.columns=[\"store_A_\"+x for x in df_store_zip.columns.tolist()]\n",
    "df_store_zip_0.columns=[\"store_B_\"+x for x in df_store_zip_0.columns.tolist()]\n",
    "\n",
    "df_store_zip['key']=1\n",
    "df_store_zip_0['key']=1\n",
    "\n",
    "df_store_zip=pd.merge(df_store_zip,df_store_zip_0,on=\"key\",how=\"outer\")\n",
    "del df_store_zip_0\n",
    "\n",
    "\n",
    "df_store_zip=df_store_zip[df_store_zip['store_A_location_id']!=df_store_zip['store_B_location_id']]\n",
    "df_store_zip=df_store_zip.reset_index()\n",
    "del df_store_zip['index']\n",
    "del df_store_zip['key']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_intersection(list_1,list_2):\n",
    "    return list(set(list_1).intersection(set(list_2)))\n",
    "def dist_miles(lat_1,log_1,lat_2,log_2):\n",
    "    return haversine((lat_1,log_1),(lat_2,log_2),miles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_store_zip['intersection_both_P_S']=df_store_zip.apply(lambda x: find_intersection(x['store_A_zip_list_P_and_S'],x['store_B_zip_list_P_and_S']),axis=1)\n",
    "\n",
    "df_store_zip['count_of_overlap_zips']=df_store_zip['intersection_both_P_S'].apply(lambda x: len(x))\n",
    "df_store_zip['count_of_A_zips']=df_store_zip['store_A_zip_list_P_and_S'].apply(lambda x: len(x))\n",
    "df_store_zip['count_of_B_zips']=df_store_zip['store_B_zip_list_P_and_S'].apply(lambda x: len(x))\n",
    "df_store_zip['total_zips']=df_store_zip['count_of_A_zips']+df_store_zip['count_of_B_zips']-df_store_zip['count_of_overlap_zips']\n",
    "\n",
    "df_store_zip['overlap_pctg']=df_store_zip['count_of_overlap_zips']/df_store_zip['total_zips']\n",
    "\n",
    "df_store_zip=df_store_zip[df_store_zip['count_of_overlap_zips']>0]\n",
    "df_store_zip['dist_between_stores']=df_store_zip.apply(lambda x: dist_miles(x['store_A_latitude_meas'],x['store_A_longitude_meas'],x['store_B_latitude_meas'],x['store_B_longitude_meas']),axis=1)\n",
    "df_store_zip=df_store_zip.reset_index()\n",
    "del df_store_zip['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_store_zip.to_csv(output_folder+\"BL_zip_overlap_between_stores_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_pair_func(store_A,store_B):\n",
    "    return sorted([store_A,store_B])\n",
    "df_store_zip_unique_pairs=df_store_zip.copy()\n",
    "df_store_zip_unique_pairs['store_pair']=df_store_zip_unique_pairs.apply(lambda x: store_pair_func(x['store_A_location_id'],x['store_B_location_id']),axis=1)\n",
    "df_store_zip_unique_pairs['store_pair_str']=df_store_zip_unique_pairs['store_pair'].astype(str)\n",
    "df_store_zip_unique_pairs=df_store_zip_unique_pairs.sort_values(['store_pair_str','store_A_location_id','store_B_location_id'])\n",
    "df_store_zip_unique_pairs=df_store_zip_unique_pairs.drop_duplicates(\"store_pair_str\")\n",
    "df_store_zip_unique_pairs.to_csv(output_folder+\"BL_zip_overlap_between_stores_unique_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_store_zip_unique_pairs['overlap_group']=np.where(df_store_zip_unique_pairs['overlap_pctg']>0.2,\"20%+\",\n",
    "                                                   np.where(df_store_zip_unique_pairs['overlap_pctg']>0.15,\"15%-20%\",\n",
    "                                                           np.where(df_store_zip_unique_pairs['overlap_pctg']>0.1,\"10%-15%\",\n",
    "                                                                   np.where(df_store_zip_unique_pairs['overlap_pctg']>0.05,'5%-10%',\n",
    "                                                                           np.where(df_store_zip_unique_pairs['overlap_pctg']>0.03,'3%-5%',\"<3%\")\n",
    "                                                                           )\n",
    "                                                                   )\n",
    "                                                           )\n",
    "                                                   )\n",
    "\n",
    "df_store_zip_unique_pairs['dist_group']=np.where(df_store_zip_unique_pairs['dist_between_stores']>28,\"28+ miles\",\n",
    "                                                   np.where(df_store_zip_unique_pairs['dist_between_stores']>20,\"20-28 miles\",\n",
    "                                                           np.where(df_store_zip_unique_pairs['dist_between_stores']>10,\"10-20 miles\",\"0-10 miles\")\n",
    "                                                           )\n",
    "                                                   )\n",
    "df_summary_overlap_dist_group_pair_count=df_store_zip_unique_pairs.groupby(['overlap_group','dist_group'])['store_pair_str'].count().to_frame().reset_index().rename(columns={\"store_pair_str\":\"pairs_count\"})\n",
    "df_summary_overlap_dist_group_unique_stores=df_store_zip_unique_pairs.groupby(['overlap_group','dist_group'])['store_pair'].sum().to_frame().reset_index().rename(columns={\"store_pair\":\"stores_involved\"})\n",
    "\n",
    "df_store_zip_unique_pairs['zips_P_S_50_both_stores']=df_store_zip_unique_pairs['store_B_zip_list_P_and_S']+df_store_zip_unique_pairs['store_A_zip_list_P_and_S']\n",
    "df_store_zip_unique_pairs['zips_P_S_50_both_stores']=df_store_zip_unique_pairs['zips_P_S_50_both_stores'].apply(lambda x: list(set(x)))\n",
    "df_summary_overlap_dist_group_unique_zips=df_store_zip_unique_pairs.groupby(['overlap_group','dist_group'])['zips_P_S_50_both_stores'].sum().to_frame().reset_index().rename(columns={\"zips_P_S_50_both_stores\":\"zips_involved\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_overlap_dist_group_unique_stores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sort_dict={\"<3%\":1,\"3%-5%\":2,\"5%-10%\":3,\"10%-15%\":4,\"15%-20%\":5,\"20%+\":6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_summary_pivot_pair=df_summary_overlap_dist_group_pair_count.pivot_table(index=\"overlap_group\",columns='dist_group',values=\"pairs_count\").reset_index()\n",
    "df_summary_pivot_pair['sort']=df_summary_pivot_pair['overlap_group'].apply(lambda x: sort_dict[x])\n",
    "df_summary_pivot_pair=df_summary_pivot_pair.sort_values(\"sort\").reset_index()\n",
    "del df_summary_pivot_pair['sort']\n",
    "del df_summary_pivot_pair['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_summary_overlap_dist_group_unique_stores['stores_involved']=df_summary_overlap_dist_group_unique_stores['stores_involved'].apply(lambda x: set(x))\n",
    "df_summary_overlap_dist_group_unique_stores['store_count_involved']=df_summary_overlap_dist_group_unique_stores['stores_involved'].apply(lambda x: len(x))\n",
    "\n",
    "df_summary_pivot_store=df_summary_overlap_dist_group_unique_stores.pivot_table(index=\"overlap_group\",columns='dist_group',values=\"store_count_involved\").reset_index()\n",
    "df_summary_pivot_store['sort']=df_summary_pivot_store['overlap_group'].apply(lambda x: sort_dict[x])\n",
    "df_summary_pivot_store=df_summary_pivot_store.sort_values(\"sort\").reset_index()\n",
    "del df_summary_pivot_store['sort']\n",
    "del df_summary_pivot_store['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_summary_overlap_dist_group_unique_zips['zips_involved']=df_summary_overlap_dist_group_unique_zips['zips_involved'].apply(lambda x: set(x))\n",
    "df_summary_overlap_dist_group_unique_zips['zip_count_involved']=df_summary_overlap_dist_group_unique_zips['zips_involved'].apply(lambda x: len(x))\n",
    "\n",
    "df_summary_pivot_zip=df_summary_overlap_dist_group_unique_zips.pivot_table(index=\"overlap_group\",columns='dist_group',values=\"zip_count_involved\").reset_index()\n",
    "df_summary_pivot_zip['sort']=df_summary_pivot_zip['overlap_group'].apply(lambda x: sort_dict[x])\n",
    "df_summary_pivot_zip=df_summary_pivot_zip.sort_values(\"sort\").reset_index()\n",
    "del df_summary_pivot_zip['sort']\n",
    "del df_summary_pivot_zip['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '1379']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_zip_unique_pairs['store_pair'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist_group=df_store_zip_unique_pairs.groupby(['dist_group'])['store_pair'].sum().to_frame().reset_index().rename(columns={\"store_pair\":\"unique_store_list\"})\n",
    "dist_group['unique_store_list']=dist_group['unique_store_list'].apply(lambda x: list(set(x)))\n",
    "dist_group['unique_store_count']=dist_group['unique_store_list'].apply(lambda x: len(x))\n",
    "\n",
    "dist_group_pair_count=df_store_zip_unique_pairs.groupby(['dist_group'])['store_pair'].count().to_frame().reset_index().rename(columns={\"store_pair\":\"pair_counts\"})\n",
    "\n",
    "dist_group=pd.merge(dist_group,dist_group_pair_count,on=\"dist_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_list_July=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20190701-134908-815.txt\",dtype=str,sep=\"|\")\n",
    "store_list_July=store_list_July[['location_id','address_line_1','address_line_2','city_nm','state_nm','zip_cd','latitude_meas','longitude_meas']]\n",
    "store_list_July['latitude_meas']=store_list_July['latitude_meas'].astype(float)\n",
    "store_list_July['longitude_meas']=store_list_July['longitude_meas'].astype(float)\n",
    "store_list_July=store_list_July[store_list_July['location_id']!=\"6990\"]\n",
    "store_list_July=store_list_July[store_list_July['location_id']!=\"145\"]\n",
    "\n",
    "store_lat_dict=store_list_July.set_index(\"location_id\").to_dict()['latitude_meas']\n",
    "store_long_dict=store_list_July.set_index(\"location_id\").to_dict()['longitude_meas']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all_P_zips_by_store=df_output[df_output['trans_flag']==\"P\"].groupby(['location_id'])['customer_zip_code'].apply(list).to_frame().reset_index().rename(columns={\"customer_zip_code\":\"all_P_zips\"})\n",
    "df_all_S_zips_by_store=df_output[df_output['trans_flag']==\"S\"].groupby(['location_id'])['customer_zip_code'].apply(list).to_frame().reset_index().rename(columns={\"customer_zip_code\":\"all_S_zips\"})\n",
    "\n",
    "df_50_miles_P_zips_by_store=df_output[(df_output['trans_flag']==\"P\") & (df_output['dist_miles']<=50)].groupby(['location_id'])['customer_zip_code'].apply(list).to_frame().reset_index().rename(columns={\"customer_zip_code\":\"50_miles_P_zips\"})\n",
    "df_50_miles_S_zips_by_store=df_output[(df_output['trans_flag']==\"S\") & (df_output['dist_miles']<=50)].groupby(['location_id'])['customer_zip_code'].apply(list).to_frame().reset_index().rename(columns={\"customer_zip_code\":\"50_miles_S_zips\"})\n",
    "\n",
    "df_P_S_zips_by_store=pd.merge(df_all_P_zips_by_store,df_all_S_zips_by_store,on=\"location_id\",how=\"outer\")\n",
    "df_P_S_zips_by_store=pd.merge(df_P_S_zips_by_store,df_50_miles_P_zips_by_store,on=\"location_id\",how=\"outer\")\n",
    "df_P_S_zips_by_store=pd.merge(df_P_S_zips_by_store,df_50_miles_S_zips_by_store,on=\"location_id\",how=\"outer\")\n",
    "df_P_S_zips_by_store=df_P_S_zips_by_store.fillna(\"[]\")\n",
    "df_P_S_zips_by_store['all_P_zips']=df_P_S_zips_by_store['all_P_zips'].astype(str).apply(lambda x: eval(x))\n",
    "df_P_S_zips_by_store['all_S_zips']=df_P_S_zips_by_store['all_S_zips'].astype(str).apply(lambda x: eval(x))\n",
    "df_P_S_zips_by_store['50_miles_P_zips']=df_P_S_zips_by_store['50_miles_P_zips'].astype(str).apply(lambda x: eval(x))\n",
    "df_P_S_zips_by_store['50_miles_S_zips']=df_P_S_zips_by_store['50_miles_S_zips'].astype(str).apply(lambda x: eval(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>all_P_zips</th>\n",
       "      <th>all_S_zips</th>\n",
       "      <th>50_miles_P_zips</th>\n",
       "      <th>50_miles_S_zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[43232, 43209, 43207, 43227]</td>\n",
       "      <td>[43125, 43110, 43206, 43068, 43213, 43205]</td>\n",
       "      <td>[43232, 43209, 43207, 43227]</td>\n",
       "      <td>[43125, 43110, 43206, 43068, 43213, 43205]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>[37110]</td>\n",
       "      <td>[37357, 38581, 37166]</td>\n",
       "      <td>[37110]</td>\n",
       "      <td>[37357, 38581, 37166]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id                    all_P_zips  \\\n",
       "0           1  [43232, 43209, 43207, 43227]   \n",
       "1        1001                       [37110]   \n",
       "\n",
       "                                   all_S_zips               50_miles_P_zips  \\\n",
       "0  [43125, 43110, 43206, 43068, 43213, 43205]  [43232, 43209, 43207, 43227]   \n",
       "1                       [37357, 38581, 37166]                       [37110]   \n",
       "\n",
       "                              50_miles_S_zips  \n",
       "0  [43125, 43110, 43206, 43068, 43213, 43205]  \n",
       "1                       [37357, 38581, 37166]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P_S_zips_by_store.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1391, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P_S_zips_by_store.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_group</th>\n",
       "      <th>unique_store_list</th>\n",
       "      <th>unique_store_count</th>\n",
       "      <th>pair_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-10 miles</td>\n",
       "      <td>[4031, 5096, 1861, 1927, 4291, 5222, 1966, 468...</td>\n",
       "      <td>742</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-20 miles</td>\n",
       "      <td>[5096, 4031, 5237, 1861, 1927, 246, 1171, 4291...</td>\n",
       "      <td>853</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-28 miles</td>\n",
       "      <td>[1471, 5237, 1861, 1171, 4291, 1781, 1966, 120...</td>\n",
       "      <td>597</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28+ miles</td>\n",
       "      <td>[1471, 1861, 1125, 246, 5220, 1171, 4291, 1068...</td>\n",
       "      <td>596</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dist_group                                  unique_store_list  \\\n",
       "0   0-10 miles  [4031, 5096, 1861, 1927, 4291, 5222, 1966, 468...   \n",
       "1  10-20 miles  [5096, 4031, 5237, 1861, 1927, 246, 1171, 4291...   \n",
       "2  20-28 miles  [1471, 5237, 1861, 1171, 4291, 1781, 1966, 120...   \n",
       "3    28+ miles  [1471, 1861, 1125, 246, 5220, 1171, 4291, 1068...   \n",
       "\n",
       "   unique_store_count  pair_counts  \n",
       "0                 742          889  \n",
       "1                 853         1282  \n",
       "2                 597          579  \n",
       "3                 596          823  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep this table and remove all of the stores for the bottom group store list\n",
    "dist_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2788"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_group['unique_store_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_A_location_id</th>\n",
       "      <th>store_A_latitude_meas</th>\n",
       "      <th>store_A_longitude_meas</th>\n",
       "      <th>store_A_zip_list_P_and_S</th>\n",
       "      <th>store_A_zip_list_P</th>\n",
       "      <th>store_A_zip_list_S</th>\n",
       "      <th>store_B_location_id</th>\n",
       "      <th>store_B_latitude_meas</th>\n",
       "      <th>store_B_longitude_meas</th>\n",
       "      <th>store_B_zip_list_P_and_S</th>\n",
       "      <th>store_B_zip_list_P</th>\n",
       "      <th>store_B_zip_list_S</th>\n",
       "      <th>intersection_both_P_S</th>\n",
       "      <th>count_of_overlap_zips</th>\n",
       "      <th>count_of_A_zips</th>\n",
       "      <th>count_of_B_zips</th>\n",
       "      <th>total_zips</th>\n",
       "      <th>overlap_pctg</th>\n",
       "      <th>dist_between_stores</th>\n",
       "      <th>store_pair</th>\n",
       "      <th>store_pair_str</th>\n",
       "      <th>overlap_group</th>\n",
       "      <th>dist_group</th>\n",
       "      <th>zips_P_S_50_both_stores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>[43125, 43227, 43232, 43205, 43209, 43213, 431...</td>\n",
       "      <td>[43227, 43207, 43209, 43232]</td>\n",
       "      <td>[43125, 43205, 43213, 43110, 43206, 43068]</td>\n",
       "      <td>1379</td>\n",
       "      <td>40.141346</td>\n",
       "      <td>-82.985584</td>\n",
       "      <td>[43050, 43021, 43209, 43147, 43207, 43015, 430...</td>\n",
       "      <td>[43065, 43240, 43021, 43081, 43235, 43085, 432...</td>\n",
       "      <td>[43050, 43209, 43147, 43207, 43068, 43074, 432...</td>\n",
       "      <td>[43232, 43209, 43110, 43207, 43068]</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>16.172938</td>\n",
       "      <td>[1, 1379]</td>\n",
       "      <td>['1', '1379']</td>\n",
       "      <td>10%-15%</td>\n",
       "      <td>10-20 miles</td>\n",
       "      <td>[43050, 43227, 43021, 43205, 43209, 43147, 432...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>[43125, 43227, 43232, 43205, 43209, 43213, 431...</td>\n",
       "      <td>[43227, 43207, 43209, 43232]</td>\n",
       "      <td>[43125, 43205, 43213, 43110, 43206, 43068]</td>\n",
       "      <td>1666</td>\n",
       "      <td>40.100960</td>\n",
       "      <td>-83.091519</td>\n",
       "      <td>[43040, 43015, 43035, 43068, 43228, 43081, 432...</td>\n",
       "      <td>[43220, 43026, 43235, 43085, 43016, 43017, 43065]</td>\n",
       "      <td>[43228, 43224, 43119, 43212, 43232, 43081, 432...</td>\n",
       "      <td>[43068, 43232]</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>15.968608</td>\n",
       "      <td>[1, 1666]</td>\n",
       "      <td>['1', '1666']</td>\n",
       "      <td>5%-10%</td>\n",
       "      <td>10-20 miles</td>\n",
       "      <td>[43227, 43205, 43209, 43040, 43207, 43015, 430...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_A_location_id  store_A_latitude_meas  store_A_longitude_meas  \\\n",
       "0                   1              39.913636              -82.914789   \n",
       "1                   1              39.913636              -82.914789   \n",
       "\n",
       "                            store_A_zip_list_P_and_S  \\\n",
       "0  [43125, 43227, 43232, 43205, 43209, 43213, 431...   \n",
       "1  [43125, 43227, 43232, 43205, 43209, 43213, 431...   \n",
       "\n",
       "             store_A_zip_list_P                          store_A_zip_list_S  \\\n",
       "0  [43227, 43207, 43209, 43232]  [43125, 43205, 43213, 43110, 43206, 43068]   \n",
       "1  [43227, 43207, 43209, 43232]  [43125, 43205, 43213, 43110, 43206, 43068]   \n",
       "\n",
       "  store_B_location_id  store_B_latitude_meas  store_B_longitude_meas  \\\n",
       "0                1379              40.141346              -82.985584   \n",
       "1                1666              40.100960              -83.091519   \n",
       "\n",
       "                            store_B_zip_list_P_and_S  \\\n",
       "0  [43050, 43021, 43209, 43147, 43207, 43015, 430...   \n",
       "1  [43040, 43015, 43035, 43068, 43228, 43081, 432...   \n",
       "\n",
       "                                  store_B_zip_list_P  \\\n",
       "0  [43065, 43240, 43021, 43081, 43235, 43085, 432...   \n",
       "1  [43220, 43026, 43235, 43085, 43016, 43017, 43065]   \n",
       "\n",
       "                                  store_B_zip_list_S  \\\n",
       "0  [43050, 43209, 43147, 43207, 43068, 43074, 432...   \n",
       "1  [43228, 43224, 43119, 43212, 43232, 43081, 432...   \n",
       "\n",
       "                 intersection_both_P_S  count_of_overlap_zips  \\\n",
       "0  [43232, 43209, 43110, 43207, 43068]                      5   \n",
       "1                       [43068, 43232]                      2   \n",
       "\n",
       "   count_of_A_zips  count_of_B_zips  total_zips  overlap_pctg  \\\n",
       "0               10               38          43      0.116279   \n",
       "1               10               26          34      0.058824   \n",
       "\n",
       "   dist_between_stores store_pair store_pair_str overlap_group   dist_group  \\\n",
       "0            16.172938  [1, 1379]  ['1', '1379']       10%-15%  10-20 miles   \n",
       "1            15.968608  [1, 1666]  ['1', '1666']        5%-10%  10-20 miles   \n",
       "\n",
       "                             zips_P_S_50_both_stores  \n",
       "0  [43050, 43227, 43021, 43205, 43209, 43147, 432...  \n",
       "1  [43227, 43205, 43209, 43040, 43207, 43015, 430...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_zip_unique_pairs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def dist_of_2_str_stores(pair_stores_str):\n",
    "    pair_stores_str=eval(pair_stores_str)\n",
    "    store_a=pair_stores_str[0]\n",
    "    store_b=pair_stores_str[1]\n",
    "    dist=haversine([store_lat_dict[store_a],store_long_dict[store_a]],[store_lat_dict[store_b],store_long_dict[store_b]],miles=True)\n",
    "    return dist\n",
    "\n",
    "# Only used in below loop\n",
    "def find_nearest_store(store_id):\n",
    "    shortest_dist=99999\n",
    "    nearest_store=np.nan\n",
    "    for i_store in store_list_July['location_id'].tolist():\n",
    "        if i_store!=store_id:\n",
    "            dist=haversine([store_lat_dict[store_id],store_long_dict[store_id]],[store_lat_dict[i_store],store_long_dict[i_store]],miles=True)\n",
    "            if dist<shortest_dist:\n",
    "                shortest_dist=dist\n",
    "                nearest_store=i_store\n",
    "    return nearest_store, shortest_dist\n",
    "\n",
    "def find_overlaped_stores(store_id):\n",
    "    df=df_store_zip_unique_pairs[df_store_zip_unique_pairs['store_pair'].apply(lambda x: store_id in x)]\n",
    "    df=df.sort_values('overlap_pctg',ascending=True).reset_index()\n",
    "    min_overlap_pctg=df.loc[0,'overlap_pctg']\n",
    "    min_overlap_store_pair_str=df.loc[0,'store_pair_str']\n",
    "    \n",
    "    max_overlap_pctg=df.loc[len(df)-1,'overlap_pctg']\n",
    "    max_overlap_store_pair_str=df.loc[len(df)-1,'store_pair_str']\n",
    "    \n",
    "    return min_overlap_pctg,min_overlap_store_pair_str,max_overlap_pctg,max_overlap_store_pair_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3573, 24)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_zip_unique_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "nearest_store_dist_criteria_dict={\"0-10 miles\":0,\"10-20 miles\":10,\"20-28 miles\":20,\"28+ miles\":28}\n",
    "\n",
    "writer=pd.ExcelWriter(output_folder+\"BL_new_TA_pair_dist_table_summary_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "dist_group.to_excel(writer,\"pairs_and_stores_by_pair_dist\",index=False)\n",
    "\n",
    "ordered_cols=['dist_group','location_id','address_line_1','address_line_2','city_nm','state_nm','zip_cd','latitude_meas','longitude_meas',\n",
    "              'all_P_zips','all_S_zips','All_P&S_zips','50_miles_P_zips','50_miles_S_zips','All_P&S_zips_50_miles',\n",
    "              'nearest_store','dist_to_nearest_store',\n",
    "              'max_overlap_store','max_overlap_pctg','dist_max_overlap_pairs',\n",
    "              'min_overlap_pctg','min_overlap_store','dist_min_overlap_pairs']\n",
    "\n",
    "all_paired_group_store_df=pd.DataFrame(columns=ordered_cols)\n",
    "all_single_store_df=pd.DataFrame(columns=['nearest_store_dist_criteria']+ordered_cols)\n",
    "all_high_overlap_store_df=pd.DataFrame(columns=ordered_cols)\n",
    "\n",
    "for dist,group in dist_group.groupby(\"dist_group\"):\n",
    "    store_list_in_dist_group=group['unique_store_list'].values[0]\n",
    "    df_store_zip_unique_pairs_removed=df_store_zip_unique_pairs[(~df_store_zip_unique_pairs['store_A_location_id'].isin(store_list_in_dist_group)) &\\\n",
    "                                                                 (~df_store_zip_unique_pairs['store_B_location_id'].isin(store_list_in_dist_group))]\n",
    "\n",
    "    df_removed_pairs_rows=df_store_zip_unique_pairs[df_store_zip_unique_pairs['dist_group']==dist]\n",
    "    df_store_zip_unique_pairs_removed_stores=df_store_zip_unique_pairs[(df_store_zip_unique_pairs['store_A_location_id'].isin(store_list_in_dist_group)) |\\\n",
    "                                                                 (df_store_zip_unique_pairs['store_B_location_id'].isin(store_list_in_dist_group))]\n",
    "    \n",
    "    df_removed_stores_1=pd.DataFrame({\"location_id\":store_list_in_dist_group})\n",
    "    df_removed_stores_1=pd.merge(df_removed_stores_1,store_list_July,on=\"location_id\",how=\"left\")\n",
    "    df_removed_stores_1=pd.merge(df_removed_stores_1,df_P_S_zips_by_store,on=\"location_id\",how=\"left\")\n",
    "    \n",
    "    df_removed_stores_1['nearest_store']=df_removed_stores_1['location_id'].apply(lambda x: find_nearest_store(x)[0])\n",
    "    df_removed_stores_1['dist_to_nearest_store']=df_removed_stores_1['location_id'].apply(lambda x: find_nearest_store(x)[1])\n",
    "\n",
    "    df_removed_stores_1['min_overlap_pctg']=df_removed_stores_1['location_id'].apply(lambda x: find_overlaped_stores(x)[0])\n",
    "    df_removed_stores_1['min_overlap_store']=df_removed_stores_1['location_id'].apply(lambda x: find_overlaped_stores(x)[1])\n",
    "    df_removed_stores_1['max_overlap_pctg']=df_removed_stores_1['location_id'].apply(lambda x: find_overlaped_stores(x)[2])\n",
    "    df_removed_stores_1['max_overlap_store']=df_removed_stores_1['location_id'].apply(lambda x: find_overlaped_stores(x)[3])\n",
    "\n",
    "    df_removed_stores_1['All_P&S_zips']=df_removed_stores_1['all_P_zips']+df_removed_stores_1['all_S_zips']\n",
    "    df_removed_stores_1['All_P&S_zips_50_miles']=df_removed_stores_1['50_miles_P_zips']+df_removed_stores_1['50_miles_S_zips']\n",
    "\n",
    "    df_removed_stores_1['dist_min_overlap_pairs']=df_removed_stores_1['min_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "    df_removed_stores_1['dist_max_overlap_pairs']=df_removed_stores_1['max_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "    df_removed_stores_1['dist_group']=dist\n",
    "        \n",
    "    df_removed_stores_1=df_removed_stores_1[ordered_cols]\n",
    "    df_removed_stores_1=df_removed_stores_1.sort_values(\"dist_to_nearest_store\",ascending=False)\n",
    "    \n",
    "    \n",
    "    nearest_store_dist_criteria=nearest_store_dist_criteria_dict[dist]\n",
    "    single_store_df=df_removed_stores_1[(df_removed_stores_1['dist_to_nearest_store']>nearest_store_dist_criteria) &\\\n",
    "                                        (df_removed_stores_1['max_overlap_pctg']<=0.15)]\n",
    "    single_store_df['nearest_store_dist_criteria']=nearest_store_dist_criteria\n",
    "    \n",
    "    high_overlap_store_df=df_removed_stores_1[(df_removed_stores_1['dist_to_nearest_store']<=10) &\\\n",
    "                                        (df_removed_stores_1['max_overlap_pctg']>=0.5)]\n",
    "       \n",
    "    df_removed_stores_1.to_excel(writer,dist+\"_all_stores\",index=False)\n",
    "    \n",
    "    \n",
    "    all_paired_group_store_df=all_paired_group_store_df.append(df_removed_stores_1)\n",
    "    all_single_store_df=all_single_store_df.append(single_store_df)\n",
    "\n",
    "    all_high_overlap_store_df=all_high_overlap_store_df.append(high_overlap_store_df)\n",
    "    \n",
    "\n",
    "def clean_list_col(df):\n",
    "    for col in df.columns.tolist():\n",
    "        if df[col].apply(lambda x: type(x)).unique()[0]==list:\n",
    "            df[col]=df[col].astype(str)\n",
    "    return df\n",
    "            \n",
    "all_single_store_df=clean_list_col(all_single_store_df)\n",
    "all_paired_group_store_df=clean_list_col(all_paired_group_store_df)\n",
    "all_high_overlap_store_df=clean_list_col(all_high_overlap_store_df)\n",
    "\n",
    "all_single_store_df=all_single_store_df.drop_duplicates()\n",
    "all_paired_group_store_df=all_paired_group_store_df.drop_duplicates()\n",
    "all_high_overlap_store_df=all_high_overlap_store_df.drop_duplicates()\n",
    "\n",
    "all_single_store_df=all_single_store_df[['nearest_store_dist_criteria']+ordered_cols]\n",
    "all_single_store_df.to_excel(writer,\"all_single_store_df\",index=False)\n",
    "all_paired_group_store_df.to_excel(writer,\"all_paired_group_store_df\",index=False)\n",
    "all_high_overlap_store_df.to_excel(writer,\"all_high_overlap_store_df\",index=False)\n",
    "\n",
    "all_unique_high_overlap_stores=all_high_overlap_store_df.copy()\n",
    "del all_high_overlap_store_df['dist_group']\n",
    "all_high_overlap_store_df=all_high_overlap_store_df.drop_duplicates()\n",
    "all_high_overlap_store_df=all_high_overlap_store_df.sort_values([\"state_nm\",'city_nm','dist_to_nearest_store'])\n",
    "all_high_overlap_store_df.to_excel(writer,\"unique_all_high_overlap_store\",index=False)\n",
    "\n",
    "df_summary_high_overlap_store_st=all_high_overlap_store_df.groupby(all_high_overlap_store_df['state_nm'])['location_id'].nunique().to_frame().reset_index()\n",
    "df_summary_high_overlap_store_st.to_excel(writer,\"summary_high_overlap_st_count\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_the_hold_store(pair_list,hold_store):\n",
    "    y=pair_list.copy()\n",
    "    y.remove(hold_store)\n",
    "    return y[0]\n",
    "\n",
    "all_paired_group_store_df['min_overlap_store']=all_paired_group_store_df['min_overlap_store'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['max_overlap_store']=all_paired_group_store_df['max_overlap_store'].apply(lambda x: eval(x))\n",
    "\n",
    "all_paired_group_store_df['all_P_zips']=all_paired_group_store_df['all_P_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['all_S_zips']=all_paired_group_store_df['all_S_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['All_P&S_zips']=all_paired_group_store_df['All_P&S_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['50_miles_P_zips']=all_paired_group_store_df['50_miles_P_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['50_miles_S_zips']=all_paired_group_store_df['50_miles_S_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['All_P&S_zips_50_miles']=all_paired_group_store_df['All_P&S_zips_50_miles'].apply(lambda x: eval(x))\n",
    "\n",
    "    \n",
    "all_paired_group_store_df['min_paired_store']=all_paired_group_store_df.apply(lambda x: remove_the_hold_store(x['min_overlap_store'],x['location_id']),axis=1)\n",
    "all_paired_group_store_df['max_paired_store']=all_paired_group_store_df.apply(lambda x: remove_the_hold_store(x['max_overlap_store'],x['location_id']),axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "store_PS_50=df_P_S_zips_by_store[['location_id','50_miles_P_zips','50_miles_S_zips']]\n",
    "store_PS_50['all_PS_50']=store_PS_50['50_miles_P_zips']+store_PS_50['50_miles_S_zips']\n",
    "store_PS_50['all_PS_50']=store_PS_50['all_PS_50'].apply(lambda x: list(set(x)))\n",
    "store_PS_50=store_PS_50[['location_id','all_PS_50']]\n",
    "\n",
    "store_PS_50_min=store_PS_50.rename(columns={\"location_id\":\"min_paired_store\",\"all_PS_50\":\"min_store_all_PS_50\"})\n",
    "store_PS_50_max=store_PS_50.rename(columns={\"location_id\":\"max_paired_store\",\"all_PS_50\":\"max_store_all_PS_50\"})\n",
    "store_PS_50_near=store_PS_50.rename(columns={\"location_id\":\"nearest_store\",\"all_PS_50\":\"near_store_all_PS_50\"})\n",
    "\n",
    "all_paired_group_store_df=pd.merge(all_paired_group_store_df,store_PS_50_min,on=\"min_paired_store\")\n",
    "all_paired_group_store_df=pd.merge(all_paired_group_store_df,store_PS_50_max,on=\"max_paired_store\")\n",
    "all_paired_group_store_df=pd.merge(all_paired_group_store_df,store_PS_50_near,on=\"nearest_store\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_group</th>\n",
       "      <th>location_id</th>\n",
       "      <th>address_line_1</th>\n",
       "      <th>address_line_2</th>\n",
       "      <th>city_nm</th>\n",
       "      <th>state_nm</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>latitude_meas</th>\n",
       "      <th>longitude_meas</th>\n",
       "      <th>all_P_zips</th>\n",
       "      <th>all_S_zips</th>\n",
       "      <th>All_P&amp;S_zips</th>\n",
       "      <th>50_miles_P_zips</th>\n",
       "      <th>50_miles_S_zips</th>\n",
       "      <th>All_P&amp;S_zips_50_miles</th>\n",
       "      <th>nearest_store</th>\n",
       "      <th>dist_to_nearest_store</th>\n",
       "      <th>max_overlap_store</th>\n",
       "      <th>max_overlap_pctg</th>\n",
       "      <th>dist_max_overlap_pairs</th>\n",
       "      <th>min_overlap_pctg</th>\n",
       "      <th>min_overlap_store</th>\n",
       "      <th>dist_min_overlap_pairs</th>\n",
       "      <th>min_paired_store</th>\n",
       "      <th>max_paired_store</th>\n",
       "      <th>min_store_all_PS_50</th>\n",
       "      <th>max_store_all_PS_50</th>\n",
       "      <th>near_store_all_PS_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-10 miles</td>\n",
       "      <td>1663</td>\n",
       "      <td>2028 N MAIN ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PEARLAND</td>\n",
       "      <td>TX</td>\n",
       "      <td>77581-3308</td>\n",
       "      <td>29.569981</td>\n",
       "      <td>-95.287342</td>\n",
       "      <td>[77581, 77584, 77089, 77598]</td>\n",
       "      <td>[77075, 77048, 77047, 77511, 77087, 77578, 770...</td>\n",
       "      <td>[77581, 77584, 77089, 77598, 77075, 77048, 770...</td>\n",
       "      <td>[77581, 77584, 77089, 77598]</td>\n",
       "      <td>[77075, 77048, 77047, 77511, 77087, 77578, 770...</td>\n",
       "      <td>[77581, 77584, 77089, 77598, 77075, 77048, 770...</td>\n",
       "      <td>4148</td>\n",
       "      <td>9.960398</td>\n",
       "      <td>[1663, 4148]</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>9.960398</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[1663, 4194]</td>\n",
       "      <td>29.893365</td>\n",
       "      <td>4194</td>\n",
       "      <td>4148</td>\n",
       "      <td>[77049, 77373, 77336, 77090, 77535, 77327, 773...</td>\n",
       "      <td>[77590, 77581, 77539, 77034, 77511, 77573, 775...</td>\n",
       "      <td>[77590, 77581, 77539, 77034, 77511, 77573, 775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-20 miles</td>\n",
       "      <td>1663</td>\n",
       "      <td>2028 N MAIN ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PEARLAND</td>\n",
       "      <td>TX</td>\n",
       "      <td>77581-3308</td>\n",
       "      <td>29.569981</td>\n",
       "      <td>-95.287342</td>\n",
       "      <td>[77581, 77584, 77089, 77598]</td>\n",
       "      <td>[77075, 77048, 77047, 77511, 77087, 77578, 770...</td>\n",
       "      <td>[77581, 77584, 77089, 77598, 77075, 77048, 770...</td>\n",
       "      <td>[77581, 77584, 77089, 77598]</td>\n",
       "      <td>[77075, 77048, 77047, 77511, 77087, 77578, 770...</td>\n",
       "      <td>[77581, 77584, 77089, 77598, 77075, 77048, 770...</td>\n",
       "      <td>4148</td>\n",
       "      <td>9.960398</td>\n",
       "      <td>[1663, 4148]</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>9.960398</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[1663, 4194]</td>\n",
       "      <td>29.893365</td>\n",
       "      <td>4194</td>\n",
       "      <td>4148</td>\n",
       "      <td>[77049, 77373, 77336, 77090, 77535, 77327, 773...</td>\n",
       "      <td>[77590, 77581, 77539, 77034, 77511, 77573, 775...</td>\n",
       "      <td>[77590, 77581, 77539, 77034, 77511, 77573, 775...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dist_group location_id  address_line_1 address_line_2   city_nm state_nm  \\\n",
       "0   0-10 miles        1663  2028 N MAIN ST            NaN  PEARLAND       TX   \n",
       "1  10-20 miles        1663  2028 N MAIN ST            NaN  PEARLAND       TX   \n",
       "\n",
       "       zip_cd  latitude_meas  longitude_meas                    all_P_zips  \\\n",
       "0  77581-3308      29.569981      -95.287342  [77581, 77584, 77089, 77598]   \n",
       "1  77581-3308      29.569981      -95.287342  [77581, 77584, 77089, 77598]   \n",
       "\n",
       "                                          all_S_zips  \\\n",
       "0  [77075, 77048, 77047, 77511, 77087, 77578, 770...   \n",
       "1  [77075, 77048, 77047, 77511, 77087, 77578, 770...   \n",
       "\n",
       "                                        All_P&S_zips  \\\n",
       "0  [77581, 77584, 77089, 77598, 77075, 77048, 770...   \n",
       "1  [77581, 77584, 77089, 77598, 77075, 77048, 770...   \n",
       "\n",
       "                50_miles_P_zips  \\\n",
       "0  [77581, 77584, 77089, 77598]   \n",
       "1  [77581, 77584, 77089, 77598]   \n",
       "\n",
       "                                     50_miles_S_zips  \\\n",
       "0  [77075, 77048, 77047, 77511, 77087, 77578, 770...   \n",
       "1  [77075, 77048, 77047, 77511, 77087, 77578, 770...   \n",
       "\n",
       "                               All_P&S_zips_50_miles nearest_store  \\\n",
       "0  [77581, 77584, 77089, 77598, 77075, 77048, 770...          4148   \n",
       "1  [77581, 77584, 77089, 77598, 77075, 77048, 770...          4148   \n",
       "\n",
       "   dist_to_nearest_store max_overlap_store  max_overlap_pctg  \\\n",
       "0               9.960398      [1663, 4148]          0.258065   \n",
       "1               9.960398      [1663, 4148]          0.258065   \n",
       "\n",
       "   dist_max_overlap_pairs  min_overlap_pctg min_overlap_store  \\\n",
       "0                9.960398              0.02      [1663, 4194]   \n",
       "1                9.960398              0.02      [1663, 4194]   \n",
       "\n",
       "   dist_min_overlap_pairs min_paired_store max_paired_store  \\\n",
       "0               29.893365             4194             4148   \n",
       "1               29.893365             4194             4148   \n",
       "\n",
       "                                 min_store_all_PS_50  \\\n",
       "0  [77049, 77373, 77336, 77090, 77535, 77327, 773...   \n",
       "1  [77049, 77373, 77336, 77090, 77535, 77327, 773...   \n",
       "\n",
       "                                 max_store_all_PS_50  \\\n",
       "0  [77590, 77581, 77539, 77034, 77511, 77573, 775...   \n",
       "1  [77590, 77581, 77539, 77034, 77511, 77573, 775...   \n",
       "\n",
       "                                near_store_all_PS_50  \n",
       "0  [77590, 77581, 77539, 77034, 77511, 77573, 775...  \n",
       "1  [77590, 77581, 77539, 77034, 77511, 77573, 775...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paired_group_store_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection_2_list(list_1,list_2):\n",
    "    inter_list=list(set(list_1).intersection(set(list_2)))\n",
    "    inter_pctg_1=len(inter_list)/len(list_1)\n",
    "    inter_pctg_2=len(inter_list)/len(list_2)\n",
    "    return inter_list,inter_pctg_1,inter_pctg_2\n",
    "    \n",
    "                    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_paired_group_store_df['nearest_intersection_zips']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[0],axis=1)\n",
    "all_paired_group_store_df['nearest_pair_overlap_with_hold']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[1],axis=1)\n",
    "all_paired_group_store_df['nearest_pair_overlap_with_nearest']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[2],axis=1)\n",
    "\n",
    "all_paired_group_store_df['max_intersection_zips']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[0],axis=1)\n",
    "all_paired_group_store_df['max_pair_overlap_with_hold']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[1],axis=1)\n",
    "all_paired_group_store_df['max_pair_overlap_with_max']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[2],axis=1)\n",
    "\n",
    "all_paired_group_store_df['min_intersection_zips']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[0],axis=1)\n",
    "all_paired_group_store_df['min_pair_overlap_with_hold']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[1],axis=1)\n",
    "all_paired_group_store_df['min_pair_overlap_with_min']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2765, 37)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list=['dist_group','location_id','address_line_1','address_line_2','city_nm','state_nm','zip_cd','latitude_meas','longitude_meas',\n",
    "          'all_P_zips','all_S_zips','All_P&S_zips','50_miles_P_zips','50_miles_S_zips','All_P&S_zips_50_miles',\n",
    "          'nearest_store','dist_to_nearest_store','near_store_all_PS_50','nearest_intersection_zips','nearest_pair_overlap_with_hold','nearest_pair_overlap_with_nearest',\n",
    "          'max_overlap_store','max_overlap_pctg','dist_max_overlap_pairs','max_paired_store','max_store_all_PS_50',\n",
    "          'max_intersection_zips','max_pair_overlap_with_hold','max_pair_overlap_with_max',\n",
    "          'min_overlap_store','min_overlap_pctg','dist_min_overlap_pairs','min_paired_store','min_store_all_PS_50',\n",
    "          'min_intersection_zips','min_pair_overlap_with_hold','min_pair_overlap_with_min']\n",
    "all_paired_group_store_df=all_paired_group_store_df[col_list]\n",
    "all_paired_group_store_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>address_line_1</th>\n",
       "      <th>address_line_2</th>\n",
       "      <th>city_nm</th>\n",
       "      <th>state_nm</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>longitude_meas</th>\n",
       "      <th>latitude_meas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2837 WINCHESTER PIKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLUMBUS</td>\n",
       "      <td>OH</td>\n",
       "      <td>43232-9301</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>39.913636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>918 E STATE ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ATHENS</td>\n",
       "      <td>OH</td>\n",
       "      <td>45701-2188</td>\n",
       "      <td>-82.069765</td>\n",
       "      <td>39.337172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id        address_line_1 address_line_2   city_nm state_nm  \\\n",
       "0           1  2837 WINCHESTER PIKE            NaN  COLUMBUS       OH   \n",
       "1          29        918 E STATE ST            NaN    ATHENS       OH   \n",
       "\n",
       "       zip_cd  longitude_meas  latitude_meas  \n",
       "0  43232-9301      -82.914789      39.913636  \n",
       "1  45701-2188      -82.069765      39.337172  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20190701-134908-815.txt\",dtype=str,sep=\"|\")\n",
    "store_list_cols=[x for x in store_list.columns.tolist() if x in col_list]\n",
    "store_list=store_list[store_list_cols]\n",
    "store_list['latitude_meas']=store_list['latitude_meas'].astype(float)\n",
    "store_list['longitude_meas']=store_list['longitude_meas'].astype(float)\n",
    "\n",
    "store_list.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_removed_stores_1['All_P&S_zips']=df_removed_stores_1['all_P_zips']+df_removed_stores_1['all_S_zips']\n",
    "df_removed_stores_1['All_P&S_zips_50_miles']=df_removed_stores_1['50_miles_P_zips']+df_removed_stores_1['50_miles_S_zips']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_all_stores_in_single_TA_1 142\n",
      "list_all_stores_in_single_TA_2 78\n",
      "already_defined_stores, 220\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "\n",
    "# list_all_stores_in_single_TA_1 -- no overlap at all\n",
    "list_all_stores_in_single_TA_1=df_P_S_zips_by_store[~df_P_S_zips_by_store['location_id'].isin(all_paired_group_store_df['location_id'].tolist())]\n",
    "list_all_stores_in_single_TA_1=list_all_stores_in_single_TA_1['location_id'].unique().tolist()\n",
    "print(\"list_all_stores_in_single_TA_1\",len(list_all_stores_in_single_TA_1))\n",
    "df_no_overlap_at_all=pd.DataFrame({\"location_id\":list_all_stores_in_single_TA_1})\n",
    "df_no_overlap_at_all=pd.merge(df_no_overlap_at_all,store_list,on=\"location_id\",how=\"left\")\n",
    "df_no_overlap_at_all=pd.merge(df_no_overlap_at_all,df_P_S_zips_by_store,on=\"location_id\",how=\"left\")\n",
    "df_no_overlap_at_all['All_P&S_zips']=df_no_overlap_at_all['all_P_zips']+df_no_overlap_at_all['all_S_zips']\n",
    "df_no_overlap_at_all['All_P&S_zips_50_miles']=df_no_overlap_at_all['50_miles_P_zips']+df_no_overlap_at_all['50_miles_S_zips']\n",
    "\n",
    "\n",
    "\n",
    "# list_all_stores_in_single_TA_2 -- low oeverlap\n",
    "list_all_stores_in_single_TA_2=all_paired_group_store_df[(all_paired_group_store_df['nearest_store']==all_paired_group_store_df['max_paired_store']) &\\\n",
    "                                                         (all_paired_group_store_df['nearest_store']==all_paired_group_store_df['min_paired_store']) &\\\n",
    "                                                         (all_paired_group_store_df['max_overlap_pctg']<0.15) &\\\n",
    "                                                         (all_paired_group_store_df['nearest_pair_overlap_with_hold']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['nearest_pair_overlap_with_nearest']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['max_pair_overlap_with_hold']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['max_pair_overlap_with_max']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['min_pair_overlap_with_hold']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['min_pair_overlap_with_min']<0.5)]['location_id'].unique().tolist()\n",
    "print(\"list_all_stores_in_single_TA_2\",len(list_all_stores_in_single_TA_2))\n",
    "col_single_store_TA=all_paired_group_store_df.columns.tolist()\n",
    "df_all_single_store_TA=all_paired_group_store_df[all_paired_group_store_df['location_id'].isin(list_all_stores_in_single_TA_2)]\n",
    "df_all_single_store_TA=df_all_single_store_TA.append(df_no_overlap_at_all)[col_single_store_TA]\n",
    "\n",
    "already_defined_stores=df_all_single_store_TA['location_id'].unique().tolist()\n",
    "print(\"already_defined_stores,\",len(already_defined_stores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_included_P_S_stores=df_P_S_zips_by_store['location_id'].unique().tolist()\n",
    "\n",
    "new_stores=store_list[~store_list['location_id'].isin(all_included_P_S_stores)]\n",
    "new_stores=new_stores[new_stores['location_id']!=\"145\"]\n",
    "new_stores=new_stores[new_stores['location_id']!=\"6990\"]\n",
    "\n",
    "new_stores.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_stores_already_asigned(stores_per_row,all_defined_list):\n",
    "    # y_in_defined_list=[x for x in stores_per_row if x in all_defined_list]\n",
    "    y_notin_defined_list=[x for x in stores_per_row if x not in all_defined_list]\n",
    "    \n",
    "    return y_notin_defined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_paired_group_store_df['original_combined_stores_4']=\"[\"+\"'\"+all_paired_group_store_df['location_id']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['nearest_store']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['max_paired_store']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['min_paired_store']+\"'\"+\"]\"\n",
    "all_paired_group_store_df['original_combined_stores_4']=all_paired_group_store_df['original_combined_stores_4'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "all_paired_group_store_df['original_combined_stores_3']=\"[\"+\"'\"+all_paired_group_store_df['location_id']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['nearest_store']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['max_paired_store']+\"'\"+\"]\"\n",
    "all_paired_group_store_df['original_combined_stores_3']=all_paired_group_store_df['original_combined_stores_3'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['original_combined_stores_4']\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['original_combined_stores_3']\n",
    "\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T1- >=50% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_B_all_merge_4_50_above_involved_stores 27\n",
      "already_defined_stores 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# B - T1 >=50%\n",
    "# merge 1: 4 stores - hold, max&min, nearest 10 miles\n",
    "\n",
    "\n",
    "df_B_all_merge_4_50_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']<=10) &\\\n",
    "                                         (all_paired_group_store_df['max_overlap_pctg']>=0.5) &\\\n",
    "                                         (all_paired_group_store_df['min_overlap_pctg']>=0.5)]\n",
    "df_B_all_merge_4_50_above['result_combined_stores']=df_B_all_merge_4_50_above['cleaned_combined_stores_4']\n",
    "\n",
    "list_df_B_all_merge_4_50_above_involved_stores=list(set(df_B_all_merge_4_50_above['result_combined_stores'].sum()))\n",
    "print('list_df_B_all_merge_4_50_above_involved_stores',len(list_df_B_all_merge_4_50_above_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_B_all_merge_4_50_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_C_all_merge_3_50_above_involved_stores 253\n",
      "already_defined_stores 500\n"
     ]
    }
   ],
   "source": [
    "# C - T1 >=50%\n",
    "# merge 2: 3 stores - hold, max|min, nearest 10 miles\n",
    "\n",
    "df_C_all_merge_3_50_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']<=10) &\\\n",
    "                                           ((all_paired_group_store_df['max_overlap_pctg']>=0.5) | (all_paired_group_store_df['min_overlap_pctg']>=0.5))]\n",
    "df_C_all_merge_3_50_above['result_combined_stores']=df_C_all_merge_3_50_above['cleaned_combined_stores_3']\n",
    "\n",
    "list_df_C_all_merge_3_50_above_involved_stores=list(set(df_C_all_merge_3_50_above['result_combined_stores'].sum()))\n",
    "print('list_df_C_all_merge_3_50_above_involved_stores',len(list_df_C_all_merge_3_50_above_involved_stores))\n",
    "\n",
    "####\n",
    "already_defined_stores=list(set(already_defined_stores+list_df_C_all_merge_3_50_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_D_all_merge_4_50_above_involved_stores 0\n",
      "already_defined_stores 500\n"
     ]
    }
   ],
   "source": [
    "# D - T1 >=50%\n",
    "# merge 3: 4 stores - hold, max&min, nearest 10-28 miles\n",
    "\n",
    "\n",
    "df_D_all_merge_4_50_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']>10) &\\\n",
    "                                           (all_paired_group_store_df['dist_to_nearest_store']<=28) &\\\n",
    "                                           (all_paired_group_store_df['max_overlap_pctg']>=0.5) &\\\n",
    "                                           (all_paired_group_store_df['min_overlap_pctg']>=0.5)]\n",
    "df_D_all_merge_4_50_above['result_combined_stores']=df_D_all_merge_4_50_above['cleaned_combined_stores_4']\n",
    "if len(df_D_all_merge_4_50_above)>0:\n",
    "    list_df_D_all_merge_4_50_above_involved_stores=list(set(df_D_all_merge_4_50_above['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_D_all_merge_4_50_above_involved_stores=[]\n",
    "print('list_df_D_all_merge_4_50_above_involved_stores',len(list_df_D_all_merge_4_50_above_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_D_all_merge_4_50_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_E_all_merge_3_50_above_involved_stores 8\n",
      "already_defined_stores 508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# E - T1 >=50%\n",
    "# merge 4: 3 stores - hold, max|min, nearest 10-28 miles\n",
    "\n",
    "\n",
    "df_E_all_merge_3_50_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']>10) &\\\n",
    "                                           (all_paired_group_store_df['dist_to_nearest_store']<=28) &\\\n",
    "                                           ((all_paired_group_store_df['max_overlap_pctg']>=0.5)|(all_paired_group_store_df['min_overlap_pctg']>=0.5))]\n",
    "df_E_all_merge_3_50_above['result_combined_stores']=df_E_all_merge_3_50_above['cleaned_combined_stores_3']\n",
    "\n",
    "if len(df_E_all_merge_3_50_above)>0:\n",
    "    list_df_E_all_merge_3_50_above_involved_stores=list(set(df_E_all_merge_3_50_above['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_E_all_merge_3_50_above_involved_stores=[]\n",
    "print('list_df_E_all_merge_3_50_above_involved_stores',len(list_df_E_all_merge_3_50_above_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_E_all_merge_3_50_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-18 14:53:24.237285\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T2- >=35% & <50% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_B_all_merge_4_35_50_involved_stores 43\n",
      "already_defined_stores 551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# B - T2 [35%,50%)\n",
    "# merge 1: 4 stores - hold, max&min, nearest without dist criteria\n",
    "\n",
    "# nearest_always kept in the result\n",
    "# whichever satisfied the cretearia, whichever should be included, max or min \n",
    "\n",
    "df_B_all_merge_4_35_50=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.35) & (all_paired_group_store_df['max_overlap_pctg']<0.5)) &\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.35) & (all_paired_group_store_df['min_overlap_pctg']<0.5))]\n",
    "df_B_all_merge_4_35_50['result_combined_stores']=df_B_all_merge_4_35_50['cleaned_combined_stores_4']\n",
    "\n",
    "if len(df_B_all_merge_4_35_50)>0:\n",
    "    list_df_B_all_merge_4_35_50_involved_stores=list(set(df_B_all_merge_4_35_50['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_B_all_merge_4_35_50_involved_stores=[]\n",
    "    \n",
    "print('list_df_B_all_merge_4_35_50_involved_stores',len(list_df_B_all_merge_4_35_50_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_B_all_merge_4_35_50_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_C_all_merge_3_35_50_involved_stores 269\n",
      "already_defined_stores 820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# C - T2 [35%,50%)\n",
    "# merge 2: 3 stores - hold, max|min, nearest without dist criteria\n",
    "\n",
    "df_C_all_merge_3_35_50=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.35) & (all_paired_group_store_df['max_overlap_pctg']<0.5)) |\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.35) & (all_paired_group_store_df['min_overlap_pctg']<0.5))]\n",
    "\n",
    "df_C_all_merge_3_35_50_1_Max=df_C_all_merge_3_35_50[(df_C_all_merge_3_35_50['max_overlap_pctg']>=0.35) & (df_C_all_merge_3_35_50['max_overlap_pctg']<0.5)]\n",
    "df_C_all_merge_3_35_50_2_Min=df_C_all_merge_3_35_50[(df_C_all_merge_3_35_50['min_overlap_pctg']>=0.35) & (df_C_all_merge_3_35_50['min_overlap_pctg']<0.5)]\n",
    "\n",
    "df_C_all_merge_3_35_50_1_Max['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_35_50_1_Max['location_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_50_1_Max['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_50_1_Max['max_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_35_50_1_Max['result_combined_stores']=df_C_all_merge_3_35_50_1_Max['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_35_50_2_Min['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_35_50_2_Min['location_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_50_2_Min['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_50_2_Min['min_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_35_50_2_Min['result_combined_stores']=df_C_all_merge_3_35_50_2_Min['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_35_50=df_C_all_merge_3_35_50_1_Max.append(df_C_all_merge_3_35_50_2_Min)\n",
    "\n",
    "df_C_all_merge_3_35_50['result_combined_stores']=df_C_all_merge_3_35_50['result_combined_stores'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "\n",
    "\n",
    "list_df_C_all_merge_3_35_50_involved_stores=list(set(df_C_all_merge_3_35_50['result_combined_stores'].sum()))\n",
    "print('list_df_C_all_merge_3_35_50_involved_stores',len(list_df_C_all_merge_3_35_50_involved_stores))\n",
    "\n",
    "####\n",
    "already_defined_stores=list(set(already_defined_stores+list_df_C_all_merge_3_35_50_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# # T3- >=15% & <35% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_B_all_merge_4_15_35_involved_stores 101\n",
      "already_defined_stores 921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# B - T3 [15%,35%)\n",
    "# merge 1: 4 stores - hold, max&min, nearest without dist criteria\n",
    "\n",
    "# nearest_always kept in the result\n",
    "# whichever satisfied the cretearia, whichever should be included, max or min \n",
    "\n",
    "df_B_all_merge_4_15_35=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.15) & (all_paired_group_store_df['max_overlap_pctg']<0.35)) &\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.15) & (all_paired_group_store_df['min_overlap_pctg']<0.35))]\n",
    "df_B_all_merge_4_15_35['result_combined_stores']=df_B_all_merge_4_15_35['cleaned_combined_stores_4']\n",
    "\n",
    "if len(df_B_all_merge_4_15_35)>0:\n",
    "    list_df_B_all_merge_4_15_35_involved_stores=list(set(df_B_all_merge_4_15_35['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_B_all_merge_4_15_35_involved_stores=[]\n",
    "    \n",
    "print('list_df_B_all_merge_4_15_35_involved_stores',len(list_df_B_all_merge_4_15_35_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_B_all_merge_4_15_35_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_C_all_merge_3_15_35_involved_stores 273\n",
      "already_defined_stores 1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# C - T3 [15%,35%)\n",
    "# merge 2: 3 stores - hold, max|min, nearest without dist criteria\n",
    "\n",
    "df_C_all_merge_3_15_35=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.15) & (all_paired_group_store_df['max_overlap_pctg']<0.35)) |\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.15) & (all_paired_group_store_df['min_overlap_pctg']<0.35))]\n",
    "\n",
    "df_C_all_merge_3_15_35_1_Max=df_C_all_merge_3_15_35[(df_C_all_merge_3_15_35['max_overlap_pctg']>=0.15) & (df_C_all_merge_3_15_35['max_overlap_pctg']<0.35)]\n",
    "df_C_all_merge_3_15_35_2_Min=df_C_all_merge_3_15_35[(df_C_all_merge_3_15_35['min_overlap_pctg']>=0.15) & (df_C_all_merge_3_15_35['min_overlap_pctg']<0.35)]\n",
    "\n",
    "df_C_all_merge_3_15_35_1_Max['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_15_35_1_Max['location_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_1_Max['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_1_Max['max_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_15_35_1_Max['result_combined_stores']=df_C_all_merge_3_15_35_1_Max['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_15_35_2_Min['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_15_35_2_Min['location_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_2_Min['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_2_Min['min_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_15_35_2_Min['result_combined_stores']=df_C_all_merge_3_15_35_2_Min['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_15_35=df_C_all_merge_3_15_35_1_Max.append(df_C_all_merge_3_15_35_2_Min)\n",
    "\n",
    "df_C_all_merge_3_15_35['result_combined_stores']=df_C_all_merge_3_15_35['result_combined_stores'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "\n",
    "\n",
    "list_df_C_all_merge_3_15_35_involved_stores=list(set(df_C_all_merge_3_15_35['result_combined_stores'].sum()))\n",
    "print('list_df_C_all_merge_3_15_35_involved_stores',len(list_df_C_all_merge_3_15_35_involved_stores))\n",
    "\n",
    "####\n",
    "already_defined_stores=list(set(already_defined_stores+list_df_C_all_merge_3_15_35_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remained_stores=all_paired_group_store_df[~all_paired_group_store_df['location_id'].isin(already_defined_stores)]\n",
    "\n",
    "remained_stores['location_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1391"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "928+463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273, 9)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store list by group column\n",
    "\n",
    "max_len_store=max(len(df_all_single_store_TA['location_id'].unique().tolist()),\n",
    "                 len(list_df_B_all_merge_4_50_above_involved_stores),\n",
    "                 len(list_df_C_all_merge_3_50_above_involved_stores),\n",
    "                 len(list_df_D_all_merge_4_50_above_involved_stores),\n",
    "                 len(list_df_E_all_merge_3_50_above_involved_stores),\n",
    "                 len(list_df_B_all_merge_4_35_50_involved_stores),\n",
    "                 len(list_df_C_all_merge_3_35_50_involved_stores),\n",
    "                 len(list_df_B_all_merge_4_15_35_involved_stores),\n",
    "                 len(list_df_C_all_merge_3_15_35_involved_stores),\n",
    "                 )\n",
    "\n",
    "df_stores_in_each_group=pd.DataFrame({\"T1_A_single_store_TA\":df_all_single_store_TA['location_id'].unique().tolist()+[np.nan]*(max_len_store-len(df_all_single_store_TA['location_id'].unique().tolist())),\n",
    "                                      \"T1_B_all_merge_4_50_above_involved_stores\":list_df_B_all_merge_4_50_above_involved_stores+[np.nan]*(max_len_store-len(list_df_B_all_merge_4_50_above_involved_stores)),\n",
    "                                      \"T1_C_all_merge_3_50_above_involved_stores\":list_df_C_all_merge_3_50_above_involved_stores+[np.nan]*(max_len_store-len(list_df_C_all_merge_3_50_above_involved_stores)),\n",
    "                                      \"T1_D_all_merge_4_50_above_involved_stores\":list_df_D_all_merge_4_50_above_involved_stores+[np.nan]*(max_len_store-len(list_df_D_all_merge_4_50_above_involved_stores)),\n",
    "                                      \"T1_E_all_merge_3_50_above_involved_stores\":list_df_E_all_merge_3_50_above_involved_stores+[np.nan]*(max_len_store-len(list_df_E_all_merge_3_50_above_involved_stores)),\n",
    "                                      \"T2_B_all_merge_4_35_50_involved_stores\":list_df_B_all_merge_4_35_50_involved_stores+[np.nan]*(max_len_store-len(list_df_B_all_merge_4_35_50_involved_stores)),\n",
    "                                      \"T2_C_all_merge_3_35_50_involved_stores\":list_df_C_all_merge_3_35_50_involved_stores+[np.nan]*(max_len_store-len(list_df_C_all_merge_3_35_50_involved_stores)),\n",
    "                                      \"T3_B_all_merge_4_15_35_involved_stores\":list_df_B_all_merge_4_15_35_involved_stores+[np.nan]*(max_len_store-len(list_df_B_all_merge_4_15_35_involved_stores)),\n",
    "                                      \"T3_C_all_merge_3_15_35_involved_stores\":list_df_C_all_merge_3_15_35_involved_stores+[np.nan]*(max_len_store-len(list_df_C_all_merge_3_15_35_involved_stores)),\n",
    "                                     },index=[x for x in range(max_len_store)])\n",
    "df_stores_in_each_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>store_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_A_single_store_TA</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_B_all_merge_4_50_above_involved_stores</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_C_all_merge_3_50_above_involved_stores</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_D_all_merge_4_50_above_involved_stores</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_E_all_merge_3_50_above_involved_stores</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2_B_all_merge_4_35_50_involved_stores</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2_C_all_merge_3_35_50_involved_stores</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T3_B_all_merge_4_15_35_involved_stores</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T3_C_all_merge_3_15_35_involved_stores</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       group  store_count\n",
       "0                       T1_A_single_store_TA          220\n",
       "0  T1_B_all_merge_4_50_above_involved_stores           27\n",
       "0  T1_C_all_merge_3_50_above_involved_stores          253\n",
       "0  T1_D_all_merge_4_50_above_involved_stores            0\n",
       "0  T1_E_all_merge_3_50_above_involved_stores            8\n",
       "0     T2_B_all_merge_4_35_50_involved_stores           43\n",
       "0     T2_C_all_merge_3_35_50_involved_stores          269\n",
       "0     T3_B_all_merge_4_15_35_involved_stores          101\n",
       "0     T3_C_all_merge_3_15_35_involved_stores          273"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_count=pd.DataFrame()\n",
    "\n",
    "for col in df_stores_in_each_group.columns.tolist():\n",
    "    list_col=df_stores_in_each_group[col].unique().tolist()\n",
    "    list_col=[x for x in list_col if str(x)!=\"nan\"]\n",
    "    len_col=len(list_col)\n",
    "    df=pd.DataFrame({\"group\":col,\"store_count\":len_col},index=[0])\n",
    "    df_store_count=df_store_count.append(df)\n",
    "df_store_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"BL_TA_combination_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_all_single_store_TA.to_excel(writer,\"T1_df_all_single_store_TA\",index=False)\n",
    "df_B_all_merge_4_50_above.to_excel(writer,\"T1_df_B_all_merge_4\",index=False)\n",
    "df_C_all_merge_3_50_above.to_excel(writer,\"T1_df_C_all_merge_3\",index=False)\n",
    "df_D_all_merge_4_50_above.to_excel(writer,\"T1_df_D_all_merge_4\",index=False)\n",
    "df_E_all_merge_3_50_above.to_excel(writer,\"T1_df_E_all_merge_3\",index=False)\n",
    "\n",
    "df_B_all_merge_4_35_50.to_excel(writer,\"T2_df_B_all_merge_4_15_35\",index=False)\n",
    "df_C_all_merge_3_35_50.to_excel(writer,\"T2_df_C_all_merge_3_15_35\",index=False)\n",
    "\n",
    "df_B_all_merge_4_15_35.to_excel(writer,\"T3_df_B_all_merge_4_15_35\",index=False)\n",
    "df_C_all_merge_3_15_35.to_excel(writer,\"T3_df_C_all_merge_3_15_35\",index=False)\n",
    "\n",
    "df_store_count.to_excel(writer,\"group_store_count\",index=False)\n",
    "\n",
    "df_stores_in_each_group.to_excel(writer,\"defined_stores\",index=False)\n",
    "\n",
    "all_paired_group_store_df.to_excel(writer,\"all_paired_group_store_df\",index=False)\n",
    "remained_stores.to_excel(writer,\"remained_stores\",index=False)\n",
    "new_stores.to_excel(writer,\"new_stores_without_P_S\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remained_stores['location_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected_600_stores_as_initial_aggregated_TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DMA_nielsen=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",\n",
    "                          dtype=str,skiprows=1,usecols=['CODE','NAME','NAME.1'])\n",
    "DMA_nielsen=DMA_nielsen.rename(columns={\"CODE\":\"zip_cd\",\"NAME\":\"DMA\",\"NAME.1\":\"CTY\"})\n",
    "DMA_nielsen=DMA_nielsen.drop_duplicates()\n",
    "zip_DMA=DMA_nielsen.groupby(\"zip_cd\")['DMA'].apply(set).to_frame().reset_index()\n",
    "zip_CTY=DMA_nielsen.groupby(\"zip_cd\")['CTY'].apply(set).to_frame().reset_index()\n",
    "DMA_nielsen=pd.merge(zip_DMA,zip_CTY,on=\"zip_cd\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected T1B - T2C\n",
    "selected_groups=['T1_B_all_merge_4_50_above_involved_stores',\n",
    "                 'T1_C_all_merge_3_50_above_involved_stores',\n",
    "                 'T1_D_all_merge_4_50_above_involved_stores',\n",
    "                 'T1_E_all_merge_3_50_above_involved_stores',\n",
    "                 'T2_B_all_merge_4_35_50_involved_stores',\n",
    "                 'T2_C_all_merge_3_35_50_involved_stores']\n",
    "\n",
    "df_output_600_stores_selected=pd.DataFrame()\n",
    "\n",
    "for group in selected_groups:\n",
    "    store_list=df_stores_in_each_group[group].unique().tolist()\n",
    "    store_list=[x for x in store_list if str(x)!=\"nan\"]\n",
    "    df=pd.DataFrame({\"location_id\":store_list},index=[group]*len(store_list)).reset_index().rename(columns={\"index\":\"group\"})\n",
    "    df_output_600_stores_selected=df_output_600_stores_selected.append(df)\n",
    "df_output_600_stores_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_list=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20190701-134908-815.txt\",sep=\"|\",dtype=str)\n",
    "store_list.columns.tolist()\n",
    "store_list=store_list[['location_id','address_line_1','address_line_2','zip_cd','city_nm','state_nm','latitude_meas','longitude_meas']]\n",
    "store_list['latitude_meas']=store_list['latitude_meas'].astype(float)\n",
    "store_list['longitude_meas']=store_list['longitude_meas'].astype(float)\n",
    "store_list['zip_cd']=store_list['zip_cd'].apply(lambda x: x.split(\"-\")[0].zfill(5))\n",
    "\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,store_list,on=\"location_id\",how=\"left\")\n",
    "\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "\n",
    "df_output_600_stores_selected['DMA']=df_output_600_stores_selected['DMA'].astype(str)\n",
    "df_output_600_stores_selected['CTY']=df_output_600_stores_selected['CTY'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410, 8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_P_S_zips_by_store_copy=df_P_S_zips_by_store.copy()\n",
    "df_P_S_zips_by_store_copy['All_P&S_zips']=df_P_S_zips_by_store_copy['all_P_zips']+df_P_S_zips_by_store_copy['all_S_zips']\n",
    "df_P_S_zips_by_store_copy['All_P&S_zips_50_miles']=df_P_S_zips_by_store_copy['50_miles_P_zips']+df_P_S_zips_by_store_copy['50_miles_S_zips']\n",
    "df_P_S_zips_by_store_copy=df_P_S_zips_by_store_copy[['location_id','all_P_zips','all_S_zips','All_P&S_zips','50_miles_P_zips','50_miles_S_zips','All_P&S_zips_50_miles']]\n",
    "\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,df_P_S_zips_by_store_copy,on=\"location_id\",how=\"left\")\n",
    "\n",
    "df_output_600_stores_selected['nearest_store']=df_output_600_stores_selected['location_id'].apply(lambda x: find_nearest_store(x)[0])\n",
    "df_output_600_stores_selected['dist_to_nearest_store']=df_output_600_stores_selected['location_id'].apply(lambda x: find_nearest_store(x)[1])\n",
    "\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,store_PS_50_near,on=\"nearest_store\")\n",
    "df_output_600_stores_selected['nearest_intersection_zips']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[0],axis=1)\n",
    "df_output_600_stores_selected['nearest_pair_overlap_with_hold']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[1],axis=1)\n",
    "df_output_600_stores_selected['nearest_pair_overlap_with_nearest']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[2],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output_600_stores_selected['min_overlap_pctg']=df_output_600_stores_selected['location_id'].apply(lambda x: find_overlaped_stores(x)[0])\n",
    "df_output_600_stores_selected['min_overlap_store']=df_output_600_stores_selected['location_id'].apply(lambda x: find_overlaped_stores(x)[1])\n",
    "df_output_600_stores_selected['max_overlap_pctg']=df_output_600_stores_selected['location_id'].apply(lambda x: find_overlaped_stores(x)[2])\n",
    "df_output_600_stores_selected['max_overlap_store']=df_output_600_stores_selected['location_id'].apply(lambda x: find_overlaped_stores(x)[3])\n",
    "\n",
    "\n",
    "df_output_600_stores_selected['min_overlap_store']=df_output_600_stores_selected['min_overlap_store'].apply(lambda x: eval(x))\n",
    "df_output_600_stores_selected['max_overlap_store']=df_output_600_stores_selected['max_overlap_store'].apply(lambda x: eval(x))\n",
    "\n",
    "df_output_600_stores_selected['min_paired_store']=df_output_600_stores_selected.apply(lambda x: remove_the_hold_store(x['min_overlap_store'],x['location_id']),axis=1)\n",
    "df_output_600_stores_selected['max_paired_store']=df_output_600_stores_selected.apply(lambda x: remove_the_hold_store(x['max_overlap_store'],x['location_id']),axis=1)\n",
    "\n",
    "df_output_600_stores_selected['min_overlap_store']=df_output_600_stores_selected['min_overlap_store'].astype(str)\n",
    "df_output_600_stores_selected['max_overlap_store']=df_output_600_stores_selected['max_overlap_store'].astype(str)\n",
    "\n",
    "df_output_600_stores_selected['dist_min_overlap_pairs']=df_output_600_stores_selected['min_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "df_output_600_stores_selected['dist_max_overlap_pairs']=df_output_600_stores_selected['max_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "\n",
    "\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,store_PS_50_min,on=\"min_paired_store\")\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,store_PS_50_max,on=\"max_paired_store\")\n",
    "\n",
    "\n",
    "df_output_600_stores_selected['max_intersection_zips']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[0],axis=1)\n",
    "df_output_600_stores_selected['max_pair_overlap_with_hold']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[1],axis=1)\n",
    "df_output_600_stores_selected['max_pair_overlap_with_max']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[2],axis=1)\n",
    "\n",
    "df_output_600_stores_selected['min_intersection_zips']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[0],axis=1)\n",
    "df_output_600_stores_selected['min_pair_overlap_with_hold']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[1],axis=1)\n",
    "df_output_600_stores_selected['min_pair_overlap_with_min']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_B_all_merge_4_50_above_involved_stores 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_B_all_merge_4_50_above_involved_stores 27\n",
      "T1_C_all_merge_3_50_above_involved_stores 253\n",
      "T1_C_all_merge_3_50_above_involved_stores 253\n",
      "T1_E_all_merge_3_50_above_involved_stores 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_E_all_merge_3_50_above_involved_stores 8\n",
      "T2_B_all_merge_4_35_50_involved_stores 43\n",
      "T2_B_all_merge_4_35_50_involved_stores 43\n",
      "T2_C_all_merge_3_35_50_involved_stores 269\n",
      "T2_C_all_merge_3_35_50_involved_stores 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_output_600_stores_selected_with_result=pd.DataFrame()\n",
    "for group,df_group in df_output_600_stores_selected.groupby(\"group\"):\n",
    "    print(group,df_group.shape[0])\n",
    "\n",
    "    if (group in ['T1_B_all_merge_4_50_above_involved_stores','T2_B_all_merge_4_35_50_involved_stores']):\n",
    "        df_1=df_group[df_group['min_overlap_pctg']>=0.35]\n",
    "        df_2=df_group[df_group['min_overlap_pctg']<0.35]\n",
    "        \n",
    "        df_1['result_combined_store']=df_1[['location_id','nearest_store','max_paired_store','min_paired_store']].values.tolist()\n",
    "        df_2['result_combined_store']=df_2[['location_id','nearest_store','max_paired_store']].values.tolist()\n",
    "        \n",
    "        df_group=df_1.append(df_2)\n",
    "        \n",
    "    elif (group in ['T1_C_all_merge_3_50_above_involved_stores','T1_E_all_merge_3_50_above_involved_stores']):\n",
    "        df_group['result_combined_store']=df_group[['location_id','nearest_store','max_paired_store']].values.tolist()\n",
    "        \n",
    "    elif group==\"T2_C_all_merge_3_35_50_involved_stores\":\n",
    "        df_group_max=df_group[(df_group['max_overlap_pctg']>=0.35) & (df_group['max_overlap_pctg']<0.5)]\n",
    "        df_group_min=df_group[(df_group['min_overlap_pctg']>=0.35) & (df_group['min_overlap_pctg']<0.5)]\n",
    "        list_max_group=df_group_max['location_id'].unique().tolist()\n",
    "        list_min_group=df_group_min['location_id'].unique().tolist()\n",
    "        list_both_group=list_max_group+list_min_group\n",
    "        \n",
    "        df_group_others=df_group[~df_group['location_id'].isin(list_both_group)]\n",
    "        \n",
    "        \n",
    "        df_group_max['result_combined_store']=df_group_max[['location_id','nearest_store','max_paired_store']].values.tolist()\n",
    "        df_group_min['result_combined_store']=df_group_min[['location_id','nearest_store','min_paired_store']].values.tolist()\n",
    "        \n",
    "        df_group=df_group_max.append(df_group_min).append(df_group_others)\n",
    "        \n",
    "    print(group,len(df_group))\n",
    "    df_output_600_stores_selected_with_result=df_output_600_stores_selected_with_result.append(df_group)\n",
    "df_output_600_stores_selected_with_result['result_combined_store']=df_output_600_stores_selected_with_result['result_combined_store'].fillna(\"[]\")\n",
    "df_output_600_stores_selected_with_result['result_combined_store']=df_output_600_stores_selected_with_result['result_combined_store'].astype(str)\n",
    "df_output_600_stores_selected_with_result['result_combined_store']=df_output_600_stores_selected_with_result['result_combined_store'].apply(lambda x: sorted(list(set(eval(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_list_2=col_list.copy()\n",
    "col_list_2.remove(\"dist_group\")\n",
    "\n",
    "col_list_2=col_list_2[:6]+['CTY','DMA']+col_list_2[6:]\n",
    "df_output_600_stores_selected_with_result=df_output_600_stores_selected_with_result[[\"group\"]+col_list_2+[\"result_combined_store\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output_600_stores_selected_with_result=df_output_600_stores_selected_with_result.sort_values([\"dist_to_nearest_store\",\"state_nm\",\"CTY\",\"city_nm\"])\n",
    "\n",
    "writer=pd.ExcelWriter(output_folder+\"sorted_600_stores_T1B_T2C_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_output_600_stores_selected_with_result.to_excel(writer,\"sorted_600_stores\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 40)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_600_stores_selected_with_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_data=df_output_600_stores_selected_with_result[['location_id','result_combined_store']]\n",
    "df_ta_store_result_pairs=pd.DataFrame(columns=['TA','location_id'])\n",
    "df_data=df_data.reset_index()\n",
    "del df_data['index']\n",
    "\n",
    "ta=0\n",
    "for i,row in df_data.iterrows():\n",
    "    location_hold=row['location_id']\n",
    "    location_associatd=row['result_combined_store']\n",
    "    intersection_existing=set(location_associatd).intersection(set(df_ta_store_result_pairs['location_id'].tolist()))\n",
    "    \n",
    "    if len(intersection_existing)==0:\n",
    "        ta+=1\n",
    "        df=pd.DataFrame({\"TA\":[ta]*len(location_associatd),\"location_id\":location_associatd},index=[ta]*len(location_associatd))\n",
    "        df_ta_store_result_pairs=df_ta_store_result_pairs.append(df)\n",
    "    else:\n",
    "        TA_list_overlapped=df_ta_store_result_pairs[df_ta_store_result_pairs['location_id'].isin(intersection_existing)]['TA'].unique().tolist()\n",
    "        grouped_ta=df_ta_store_result_pairs[df_ta_store_result_pairs['TA'].isin(TA_list_overlapped)]\n",
    "        grouped_ta_others=df_ta_store_result_pairs[~df_ta_store_result_pairs['TA'].isin(TA_list_overlapped)]\n",
    "        \n",
    "        grouped_ta['TA']=grouped_ta['TA'].min()\n",
    "        \n",
    "        new_stores_added=[x for x in location_associatd if x not in grouped_ta['location_id'].tolist()]\n",
    "        df=pd.DataFrame({\"TA\":[grouped_ta['TA'].min()]*len(new_stores_added),\"location_id\":new_stores_added},index=[grouped_ta['TA'].min()]*len(new_stores_added))\n",
    "        grouped_ta=grouped_ta.append(df)\n",
    "        df_ta_store_result_pairs=grouped_ta_others.append(grouped_ta)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ta_store_result_pairs=df_ta_store_result_pairs[df_ta_store_result_pairs['location_id'].isin(df_output_600_stores_selected_with_result['location_id'].tolist())]\n",
    "df_ta_store_result_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output_600_stores_selected_with_result=pd.merge(df_output_600_stores_selected_with_result,df_ta_store_result_pairs,on=\"location_id\",how=\"left\")\n",
    "\n",
    "summary_df_600_stores=df_output_600_stores_selected_with_result.groupby(\"TA\")['location_id'].count().to_frame().reset_index().sort_values(\"location_id\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>location_id</th>\n",
       "      <th>address_line_1</th>\n",
       "      <th>address_line_2</th>\n",
       "      <th>city_nm</th>\n",
       "      <th>state_nm</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>CTY</th>\n",
       "      <th>DMA</th>\n",
       "      <th>latitude_meas</th>\n",
       "      <th>longitude_meas</th>\n",
       "      <th>all_P_zips</th>\n",
       "      <th>all_S_zips</th>\n",
       "      <th>All_P&amp;S_zips</th>\n",
       "      <th>50_miles_P_zips</th>\n",
       "      <th>50_miles_S_zips</th>\n",
       "      <th>All_P&amp;S_zips_50_miles</th>\n",
       "      <th>nearest_store</th>\n",
       "      <th>dist_to_nearest_store</th>\n",
       "      <th>near_store_all_PS_50</th>\n",
       "      <th>nearest_intersection_zips</th>\n",
       "      <th>nearest_pair_overlap_with_hold</th>\n",
       "      <th>nearest_pair_overlap_with_nearest</th>\n",
       "      <th>max_overlap_store</th>\n",
       "      <th>max_overlap_pctg</th>\n",
       "      <th>dist_max_overlap_pairs</th>\n",
       "      <th>max_paired_store</th>\n",
       "      <th>max_store_all_PS_50</th>\n",
       "      <th>max_intersection_zips</th>\n",
       "      <th>max_pair_overlap_with_hold</th>\n",
       "      <th>max_pair_overlap_with_max</th>\n",
       "      <th>min_overlap_store</th>\n",
       "      <th>min_overlap_pctg</th>\n",
       "      <th>dist_min_overlap_pairs</th>\n",
       "      <th>min_paired_store</th>\n",
       "      <th>min_store_all_PS_50</th>\n",
       "      <th>min_intersection_zips</th>\n",
       "      <th>min_pair_overlap_with_hold</th>\n",
       "      <th>min_pair_overlap_with_min</th>\n",
       "      <th>result_combined_store</th>\n",
       "      <th>TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_C_all_merge_3_50_above_involved_stores</td>\n",
       "      <td>4688</td>\n",
       "      <td>4430 ONTARIO MILLS PKWY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONTARIO</td>\n",
       "      <td>CA</td>\n",
       "      <td>91764</td>\n",
       "      <td>{'SAN BERNARDNO'}</td>\n",
       "      <td>{'LOS ANGELES'}</td>\n",
       "      <td>34.068393</td>\n",
       "      <td>-117.554891</td>\n",
       "      <td>[92335, 91730, 91764, 92337, 92336, 91761, 917...</td>\n",
       "      <td>[91786, 91762, 92880, 91710, 91737, 92407, 923...</td>\n",
       "      <td>[92335, 91730, 91764, 92337, 92336, 91761, 917...</td>\n",
       "      <td>[92335, 91730, 91764, 92337, 92336, 91761, 917...</td>\n",
       "      <td>[91786, 91762, 92880, 91710, 91737, 92407, 923...</td>\n",
       "      <td>[92335, 91730, 91764, 92337, 92336, 91761, 917...</td>\n",
       "      <td>4103</td>\n",
       "      <td>1.540506</td>\n",
       "      <td>[91764, 92374, 91730, 92399, 92503, 91766, 923...</td>\n",
       "      <td>[91764, 92374, 91730, 92399, 92503, 91766, 923...</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>['4103', '4688']</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>1.540506</td>\n",
       "      <td>4103</td>\n",
       "      <td>[91764, 92374, 91730, 92399, 92503, 91766, 923...</td>\n",
       "      <td>[91764, 92374, 91730, 92399, 92503, 91766, 923...</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>['4060', '4688']</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>36.900363</td>\n",
       "      <td>4060</td>\n",
       "      <td>[90011, 90044, 90280, 90241, 90240, 90201, 908...</td>\n",
       "      <td>[92335]</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>[4103, 4688]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1_C_all_merge_3_50_above_involved_stores</td>\n",
       "      <td>4103</td>\n",
       "      <td>12322 4TH ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RANCHO CUCAMONGA</td>\n",
       "      <td>CA</td>\n",
       "      <td>91730</td>\n",
       "      <td>{'SAN BERNARDNO'}</td>\n",
       "      <td>{'LOS ANGELES'}</td>\n",
       "      <td>34.078632</td>\n",
       "      <td>-117.530980</td>\n",
       "      <td>[92335, 92336, 91730, 92337, 91739, 91764, 917...</td>\n",
       "      <td>[91761, 91701, 91786, 91737, 91762, 92407, 925...</td>\n",
       "      <td>[92335, 92336, 91730, 92337, 91739, 91764, 917...</td>\n",
       "      <td>[92335, 92336, 91730, 92337, 91739, 91764, 917...</td>\n",
       "      <td>[91761, 91701, 91786, 91737, 91762, 92407, 925...</td>\n",
       "      <td>[92335, 92336, 91730, 92337, 91739, 91764, 917...</td>\n",
       "      <td>4688</td>\n",
       "      <td>1.540506</td>\n",
       "      <td>[91764, 91784, 92374, 91730, 92399, 92503, 917...</td>\n",
       "      <td>[91764, 92374, 92399, 91730, 92503, 91766, 923...</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>['4103', '4688']</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>1.540506</td>\n",
       "      <td>4688</td>\n",
       "      <td>[91764, 91784, 92374, 91730, 92399, 92503, 917...</td>\n",
       "      <td>[91764, 92374, 92399, 91730, 92503, 91766, 923...</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>['4060', '4103']</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>38.383134</td>\n",
       "      <td>4060</td>\n",
       "      <td>[90011, 90044, 90280, 90241, 90240, 90201, 908...</td>\n",
       "      <td>[92335]</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>[4103, 4688]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       group location_id  \\\n",
       "0  T1_C_all_merge_3_50_above_involved_stores        4688   \n",
       "1  T1_C_all_merge_3_50_above_involved_stores        4103   \n",
       "\n",
       "            address_line_1 address_line_2           city_nm state_nm zip_cd  \\\n",
       "0  4430 ONTARIO MILLS PKWY            NaN           ONTARIO       CA  91764   \n",
       "1             12322 4TH ST            NaN  RANCHO CUCAMONGA       CA  91730   \n",
       "\n",
       "                 CTY              DMA  latitude_meas  longitude_meas  \\\n",
       "0  {'SAN BERNARDNO'}  {'LOS ANGELES'}      34.068393     -117.554891   \n",
       "1  {'SAN BERNARDNO'}  {'LOS ANGELES'}      34.078632     -117.530980   \n",
       "\n",
       "                                          all_P_zips  \\\n",
       "0  [92335, 91730, 91764, 92337, 92336, 91761, 917...   \n",
       "1  [92335, 92336, 91730, 92337, 91739, 91764, 917...   \n",
       "\n",
       "                                          all_S_zips  \\\n",
       "0  [91786, 91762, 92880, 91710, 91737, 92407, 923...   \n",
       "1  [91761, 91701, 91786, 91737, 91762, 92407, 925...   \n",
       "\n",
       "                                        All_P&S_zips  \\\n",
       "0  [92335, 91730, 91764, 92337, 92336, 91761, 917...   \n",
       "1  [92335, 92336, 91730, 92337, 91739, 91764, 917...   \n",
       "\n",
       "                                     50_miles_P_zips  \\\n",
       "0  [92335, 91730, 91764, 92337, 92336, 91761, 917...   \n",
       "1  [92335, 92336, 91730, 92337, 91739, 91764, 917...   \n",
       "\n",
       "                                     50_miles_S_zips  \\\n",
       "0  [91786, 91762, 92880, 91710, 91737, 92407, 923...   \n",
       "1  [91761, 91701, 91786, 91737, 91762, 92407, 925...   \n",
       "\n",
       "                               All_P&S_zips_50_miles nearest_store  \\\n",
       "0  [92335, 91730, 91764, 92337, 92336, 91761, 917...          4103   \n",
       "1  [92335, 92336, 91730, 92337, 91739, 91764, 917...          4688   \n",
       "\n",
       "   dist_to_nearest_store                               near_store_all_PS_50  \\\n",
       "0               1.540506  [91764, 92374, 91730, 92399, 92503, 91766, 923...   \n",
       "1               1.540506  [91764, 91784, 92374, 91730, 92399, 92503, 917...   \n",
       "\n",
       "                           nearest_intersection_zips  \\\n",
       "0  [91764, 92374, 91730, 92399, 92503, 91766, 923...   \n",
       "1  [91764, 92374, 92399, 91730, 92503, 91766, 923...   \n",
       "\n",
       "   nearest_pair_overlap_with_hold  nearest_pair_overlap_with_nearest  \\\n",
       "0                        0.755556                           0.971429   \n",
       "1                        0.971429                           0.755556   \n",
       "\n",
       "  max_overlap_store  max_overlap_pctg  dist_max_overlap_pairs  \\\n",
       "0  ['4103', '4688']           0.73913                1.540506   \n",
       "1  ['4103', '4688']           0.73913                1.540506   \n",
       "\n",
       "  max_paired_store                                max_store_all_PS_50  \\\n",
       "0             4103  [91764, 92374, 91730, 92399, 92503, 91766, 923...   \n",
       "1             4688  [91764, 91784, 92374, 91730, 92399, 92503, 917...   \n",
       "\n",
       "                               max_intersection_zips  \\\n",
       "0  [91764, 92374, 91730, 92399, 92503, 91766, 923...   \n",
       "1  [91764, 92374, 92399, 91730, 92503, 91766, 923...   \n",
       "\n",
       "   max_pair_overlap_with_hold  max_pair_overlap_with_max min_overlap_store  \\\n",
       "0                    0.755556                   0.971429  ['4060', '4688']   \n",
       "1                    0.971429                   0.755556  ['4060', '4103']   \n",
       "\n",
       "   min_overlap_pctg  dist_min_overlap_pairs min_paired_store  \\\n",
       "0          0.011364               36.900363             4060   \n",
       "1          0.012821               38.383134             4060   \n",
       "\n",
       "                                 min_store_all_PS_50 min_intersection_zips  \\\n",
       "0  [90011, 90044, 90280, 90241, 90240, 90201, 908...               [92335]   \n",
       "1  [90011, 90044, 90280, 90241, 90240, 90201, 908...               [92335]   \n",
       "\n",
       "   min_pair_overlap_with_hold  min_pair_overlap_with_min  \\\n",
       "0                    0.022222                   0.022727   \n",
       "1                    0.028571                   0.022727   \n",
       "\n",
       "  result_combined_store   TA  \n",
       "0          [4103, 4688]  1.0  \n",
       "1          [4103, 4688]  1.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_600_stores_selected_with_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output_600_stores_selected_with_result=df_output_600_stores_selected_with_result[['TA']+[x for x in df_output_600_stores_selected_with_result.columns.tolist() if x!=\"TA\"]]\n",
    "df_output_600_stores_selected_with_result=df_output_600_stores_selected_with_result.sort_values(['TA','state_nm','CTY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rename_TA=df_output_600_stores_selected_with_result[['TA']].drop_duplicates()\n",
    "df_rename_TA['new_name']=[x+1 for x in range(len(df_rename_TA))]\n",
    "dict_rename_TA=df_rename_TA.set_index(\"TA\").to_dict()[\"new_name\"]\n",
    "\n",
    "\n",
    "df_output_600_stores_selected_with_result['TA']=df_output_600_stores_selected_with_result['TA'].apply(lambda x: dict_rename_TA[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"initial_TA_output.xlsx\",engine=\"xlsxwriter\")\n",
    "\n",
    "df_output_600_stores_selected_with_result.to_excel(writer,\"with_TA\",index=False)\n",
    "summary_df_600_stores.to_excel(writer,\"summary\",index=False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 4)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_600_TA_zips=df_output_600_stores_selected_with_result.groupby(\"TA\")['All_P&S_zips_50_miles','All_P&S_zips'].sum().reset_index()\n",
    "\n",
    "df_output_600_TA_zips=df_output_600_TA_zips.rename(columns={\"All_P&S_zips_50_miles\":\"zip_cd_50\",\"All_P&S_zips\":\"zip_cd_all\",\"location_id\":\"store_list\"})\n",
    "df_output_600_TA_zips['zip_cd_50']=df_output_600_TA_zips['zip_cd_50'].apply(lambda x: list(set(x)))\n",
    "df_output_600_TA_zips['zip_cd_all']=df_output_600_TA_zips['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "\n",
    "df_output_600_TA_zips_2=df_output_600_stores_selected_with_result.groupby(\"TA\")['location_id'].apply(list).reset_index()\n",
    "df_output_600_TA_zips_2=df_output_600_TA_zips_2.rename(columns={\"location_id\":\"store_list\"})\n",
    "df_output_600_TA_zips_2['store_list']=df_output_600_TA_zips_2['store_list'].apply(lambda x: list(set(x)))\n",
    "\n",
    "df_output_600_TA_zips=pd.merge(df_output_600_TA_zips,df_output_600_TA_zips_2,on=\"TA\")\n",
    "df_output_600_TA_zips.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Store TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haversine import haversine\n",
    "\n",
    "new_stores=new_stores.reset_index()\n",
    "\n",
    "df_new_store_zips=pd.DataFrame()\n",
    "\n",
    "del new_stores['index']\n",
    "\n",
    "for ind,row in new_stores.iterrows():\n",
    "    store_num=row['location_id']\n",
    "    store_center=[row['latitude_meas'],row['longitude_meas']]\n",
    "    \n",
    "    for zip_cd in zip_centers.keys():\n",
    "        dist=haversine(store_center,zip_centers[zip_cd],miles=True)\n",
    "        \n",
    "        if dist<=10:\n",
    "\n",
    "            df=pd.DataFrame({\"location_id\":store_num,\"zips_in_10\":zip_cd,\"dist_miles\":dist},index=[store_num])\n",
    "            df_new_store_zips=df_new_store_zips.append(df)\n",
    "        \n",
    "df_new_store_zips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>All_P&amp;S_zips_50_miles</th>\n",
       "      <th>All_P&amp;S_zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1918</td>\n",
       "      <td>[95831, 95825, 95673, 94258, 95830, 95628, 956...</td>\n",
       "      <td>[95831, 95825, 95673, 94258, 95830, 95628, 956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4668</td>\n",
       "      <td>[26684, 26681, 26662, 26675, 26678, 26651, 266...</td>\n",
       "      <td>[26684, 26681, 26662, 26675, 26678, 26651, 266...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id                              All_P&S_zips_50_miles  \\\n",
       "0        1918  [95831, 95825, 95673, 94258, 95830, 95628, 956...   \n",
       "1        4668  [26684, 26681, 26662, 26675, 26678, 26651, 266...   \n",
       "\n",
       "                                        All_P&S_zips  \n",
       "0  [95831, 95825, 95673, 94258, 95830, 95628, 956...  \n",
       "1  [26684, 26681, 26662, 26675, 26678, 26651, 266...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_store_zips_wide=df_new_store_zips.groupby(\"location_id\")['zips_in_10'].apply(list).to_frame().reset_index()\n",
    "df_new_store_zips_wide['zips_in_10']=df_new_store_zips_wide['zips_in_10'].apply(lambda x: list(set(x)))\n",
    "\n",
    "\n",
    "df_new_store_zips_wide_copy=df_new_store_zips_wide.copy()\n",
    "df_new_store_zips_wide_copy['All_P&S_zips_50_miles']=df_new_store_zips_wide_copy['zips_in_10']\n",
    "df_new_store_zips_wide_copy['All_P&S_zips']=df_new_store_zips_wide_copy['zips_in_10']\n",
    "del df_new_store_zips_wide_copy['zips_in_10']\n",
    "\n",
    "df_new_store_zips_wide_copy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new_store_zips_wide_copy=pd.merge(df_new_store_zips_wide_copy,store_list,on=\"location_id\",how=\"left\")\n",
    "df_new_store_zips_wide_copy=pd.merge(df_new_store_zips_wide_copy,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "df_new_store_zips_wide_copy['DMA']=df_new_store_zips_wide_copy['DMA'].astype(str)\n",
    "df_new_store_zips_wide_copy['CTY']=df_new_store_zips_wide_copy['CTY'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1410, 8)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 12)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_store_zips_wide_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sing_store_zips_wide=df_all_single_store_TA[['location_id','All_P&S_zips_50_miles','All_P&S_zips']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sing_store_zips_wide=df_sing_store_zips_wide.sort_values(\"location_id\")\n",
    "df_sing_store_zips_wide=df_sing_store_zips_wide.rename(columns={\"All_P&S_zips_50_miles\":\"zip_cd_50\",\n",
    "                                                                                               \"All_P&S_zips\":\"zip_cd_all\",\n",
    "                                                                                               \"location_id\":\"store_list\"})\n",
    "df_sing_store_zips_wide['store_list']=df_sing_store_zips_wide['store_list'].apply(lambda x: [x])\n",
    "df_sing_store_zips_wide['TA']=[x+185 for x in range(len(df_sing_store_zips_wide))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820\n"
     ]
    }
   ],
   "source": [
    "all_defined_TA=df_output_600_TA_zips.append(df_sing_store_zips_wide)\n",
    "all_defined_stores=all_defined_TA['store_list'].sum()\n",
    "print(len(all_defined_stores))\n",
    "\n",
    "all_defined_TA=all_defined_TA.reset_index()\n",
    "del all_defined_TA['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 4)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_defined_TA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remaining stores\n",
    "\n",
    "df_remain_stores=store_list[['location_id']].drop_duplicates()\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(df_new_store_zips_wide_copy['location_id'].tolist())]\n",
    "df_remain_stores=df_remain_stores[df_remain_stores['location_id']!=\"145\"]\n",
    "df_remain_stores=df_remain_stores[df_remain_stores['location_id']!=\"6990\"]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(all_defined_stores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_remain_stores=pd.merge(df_remain_stores,store_list,on=\"location_id\",how=\"left\")\n",
    "df_remain_stores=pd.merge(df_remain_stores,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "\n",
    "df_remain_stores['DMA']=df_remain_stores['DMA'].astype(str)\n",
    "df_remain_stores['CTY']=df_remain_stores['CTY'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_remain_stores=pd.merge(df_remain_stores,df_P_S_zips_by_store_copy,on=\"location_id\",how=\"left\")\n",
    "\n",
    "df_remain_stores['nearest_store']=df_remain_stores['location_id'].apply(lambda x: find_nearest_store(x)[0])\n",
    "df_remain_stores['dist_to_nearest_store']=df_remain_stores['location_id'].apply(lambda x: find_nearest_store(x)[1])\n",
    "\n",
    "df_remain_stores=pd.merge(df_remain_stores,store_PS_50_near,on=\"nearest_store\")\n",
    "df_remain_stores['nearest_intersection_zips']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[0],axis=1)\n",
    "df_remain_stores['nearest_pair_overlap_with_hold']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[1],axis=1)\n",
    "df_remain_stores['nearest_pair_overlap_with_nearest']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_remain_stores['min_overlap_pctg']=df_remain_stores['location_id'].apply(lambda x: find_overlaped_stores(x)[0])\n",
    "df_remain_stores['min_overlap_store']=df_remain_stores['location_id'].apply(lambda x: find_overlaped_stores(x)[1])\n",
    "df_remain_stores['max_overlap_pctg']=df_remain_stores['location_id'].apply(lambda x: find_overlaped_stores(x)[2])\n",
    "df_remain_stores['max_overlap_store']=df_remain_stores['location_id'].apply(lambda x: find_overlaped_stores(x)[3])\n",
    "\n",
    "\n",
    "df_remain_stores['min_overlap_store']=df_remain_stores['min_overlap_store'].apply(lambda x: eval(x))\n",
    "df_remain_stores['max_overlap_store']=df_remain_stores['max_overlap_store'].apply(lambda x: eval(x))\n",
    "\n",
    "df_remain_stores['min_paired_store']=df_remain_stores.apply(lambda x: remove_the_hold_store(x['min_overlap_store'],x['location_id']),axis=1)\n",
    "df_remain_stores['max_paired_store']=df_remain_stores.apply(lambda x: remove_the_hold_store(x['max_overlap_store'],x['location_id']),axis=1)\n",
    "\n",
    "df_remain_stores['min_overlap_store']=df_remain_stores['min_overlap_store'].astype(str)\n",
    "df_remain_stores['max_overlap_store']=df_remain_stores['max_overlap_store'].astype(str)\n",
    "\n",
    "df_remain_stores['dist_min_overlap_pairs']=df_remain_stores['min_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "df_remain_stores['dist_max_overlap_pairs']=df_remain_stores['max_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "\n",
    "\n",
    "df_remain_stores=pd.merge(df_remain_stores,store_PS_50_min,on=\"min_paired_store\")\n",
    "df_remain_stores=pd.merge(df_remain_stores,store_PS_50_max,on=\"max_paired_store\")\n",
    "\n",
    "\n",
    "df_remain_stores['max_intersection_zips']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[0],axis=1)\n",
    "df_remain_stores['max_pair_overlap_with_hold']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[1],axis=1)\n",
    "df_remain_stores['max_pair_overlap_with_max']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[2],axis=1)\n",
    "\n",
    "df_remain_stores['min_intersection_zips']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[0],axis=1)\n",
    "df_remain_stores['min_pair_overlap_with_hold']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[1],axis=1)\n",
    "df_remain_stores['min_pair_overlap_with_min']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_remain_stores=df_remain_stores.append(df_new_store_zips_wide_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_max_covered_TA(zip_list_store):\n",
    "    max_intersect_count=0\n",
    "    max_intersect_list=[]\n",
    "    intersect_TA=0\n",
    "    for ind,row in all_defined_TA.iterrows():\n",
    "        ta_50_zips=row['zip_cd_50']\n",
    "        intersection_zips_P_S_50=list(set(zip_list_store).intersection(set(ta_50_zips)))\n",
    "        intersection_zips_P_S_50_len=len(intersection_zips_P_S_50)\n",
    "        if intersection_zips_P_S_50_len>max_intersect_count:\n",
    "            max_intersect_count=intersection_zips_P_S_50_len\n",
    "            max_intersect_list=intersection_zips_P_S_50\n",
    "            intersect_TA=row['TA']\n",
    "    max_intersect_pctc=max_intersect_count/len(zip_list_store)\n",
    "            \n",
    "    return intersect_TA,max_intersect_list,max_intersect_count,max_intersect_pctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_50']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_all_single_store_TA['dist_group']\n",
    "df_sing_store_zips_wide_copy=df_sing_store_zips_wide.copy()\n",
    "df_sing_store_zips_wide_copy=df_sing_store_zips_wide_copy[['store_list','TA']]\n",
    "df_sing_store_zips_wide_copy['location_id']=df_sing_store_zips_wide_copy['store_list'].apply(lambda x: x[0])\n",
    "df_sing_store_zips_wide_copy=df_sing_store_zips_wide_copy[['location_id',\"TA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all_single_store_TA=pd.merge(df_all_single_store_TA,df_sing_store_zips_wide_copy,on=\"location_id\",how=\"left\")\n",
    "df_all_single_store_TA=df_all_single_store_TA[[\"TA\"]+[x for x in df_all_single_store_TA.columns.tolist() if x!=\"TA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_all_single_store_TA_cols_1=[x for x in df_output_600_stores_selected_with_result.columns.tolist() if x in df_all_single_store_TA.columns.tolist()]\n",
    "df_all_single_store_TA_cols_2=[x for x in df_all_single_store_TA.columns.tolist() if x not in df_all_single_store_TA_cols_1]\n",
    "df_all_single_store_TA=df_all_single_store_TA[df_all_single_store_TA_cols_1+df_all_single_store_TA_cols_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_remain_stores_cols_1=[x for x in df_output_600_stores_selected_with_result.columns.tolist() if x in df_remain_stores.columns.tolist()]\n",
    "df_remain_stores_cols_2=[x for x in df_remain_stores.columns.tolist() if x not in df_remain_stores_cols_1]\n",
    "df_remain_stores=df_remain_stores[df_remain_stores_cols_1+df_remain_stores_cols_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"BL_remaining_stores_and_defined_TA_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_remain_stores.to_excel(writer,\"df_remain_stores\",index=False)\n",
    "all_defined_TA.to_excel(writer,\"all_defined_TA\",index=False)\n",
    "df_output_600_stores_selected_with_result.to_excel(writer,\"TA_by_store_multiple\",index=False)\n",
    "df_all_single_store_TA.to_excel(writer,\"TA_by_store_single\",index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Iter the balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iter 1 - >=40% \n",
    "\n",
    "df_remain_stores_Iter1_50=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.4]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50[['location_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_50_miles']]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "df_remain_stores_Iter1_50['location_id']=df_remain_stores_Iter1_50['location_id'].apply(lambda x: [x])\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.groupby(\"TA\")['location_id','All_P&S_zips','All_P&S_zips_50_miles'].sum().reset_index()\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    df_remain_stores_Iter1_50[col]=df_remain_stores_Iter1_50[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "###\n",
    "all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_50,on=\"TA\",how=\"left\")\n",
    "\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "    all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "    all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "    \n",
    "all_defined_TA['store_list']=all_defined_TA[['store_list','location_id']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA[['zip_cd_50','All_P&S_zips_50_miles']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA['zip_cd_50'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_50','zip_cd_all']]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_50']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iter 2 - >=30% \n",
    "\n",
    "df_remain_stores_Iter1_50=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.3]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50[['location_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_50_miles']]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "df_remain_stores_Iter1_50['location_id']=df_remain_stores_Iter1_50['location_id'].apply(lambda x: [x])\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.groupby(\"TA\")['location_id','All_P&S_zips','All_P&S_zips_50_miles'].sum().reset_index()\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    df_remain_stores_Iter1_50[col]=df_remain_stores_Iter1_50[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "###\n",
    "all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_50,on=\"TA\",how=\"left\")\n",
    "\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "    all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "    all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "    \n",
    "all_defined_TA['store_list']=all_defined_TA[['store_list','location_id']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA[['zip_cd_50','All_P&S_zips_50_miles']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA['zip_cd_50'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_50','zip_cd_all']]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_50']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iter 3 - >=20% \n",
    "\n",
    "df_remain_stores_Iter1_50=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.2]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50[['location_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_50_miles']]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "df_remain_stores_Iter1_50['location_id']=df_remain_stores_Iter1_50['location_id'].apply(lambda x: [x])\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.groupby(\"TA\")['location_id','All_P&S_zips','All_P&S_zips_50_miles'].sum().reset_index()\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    df_remain_stores_Iter1_50[col]=df_remain_stores_Iter1_50[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "###\n",
    "all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_50,on=\"TA\",how=\"left\")\n",
    "\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "    all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "    all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "    \n",
    "all_defined_TA['store_list']=all_defined_TA[['store_list','location_id']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA[['zip_cd_50','All_P&S_zips_50_miles']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA['zip_cd_50'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_50','zip_cd_all']]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_50']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 42)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>0.2].shape[0]>0:\n",
    "    df_remain_stores_Iter1_50=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.2]\n",
    "    df_remain_stores_Iter1_50=df_remain_stores_Iter1_50[['location_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_50_miles']]\n",
    "    df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "    df_remain_stores_Iter1_50['location_id']=df_remain_stores_Iter1_50['location_id'].apply(lambda x: [x])\n",
    "    df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.groupby(\"TA\")['location_id','All_P&S_zips','All_P&S_zips_50_miles'].sum().reset_index()\n",
    "    for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "        df_remain_stores_Iter1_50[col]=df_remain_stores_Iter1_50[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "    ###\n",
    "    all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_50,on=\"TA\",how=\"left\")\n",
    "\n",
    "    for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "        all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "        all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "        all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "\n",
    "    all_defined_TA['store_list']=all_defined_TA[['store_list','location_id']].sum(axis=1)\n",
    "    all_defined_TA['zip_cd_50']=all_defined_TA[['zip_cd_50','All_P&S_zips_50_miles']].sum(axis=1)\n",
    "    all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "    all_defined_TA['zip_cd_50']=all_defined_TA['zip_cd_50'].apply(lambda x: list(set(x)))\n",
    "    all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "    all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_50','zip_cd_all']]\n",
    "\n",
    "    df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "    df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "    df_remain_stores['Overlap_zips_with_TA_50']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "    df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "    df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n",
    "df_remain_stores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_defined_TA['store_count']=all_defined_TA['store_list'].apply(lambda x: len(x))\n",
    "all_defined_TA['store_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"BL_remaining_stores_and_defined_2_TA_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_remain_stores.to_excel(writer,\"df_remain_stores\",index=False)\n",
    "all_defined_TA.to_excel(writer,\"all_defined_TA\",index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_list [<class 'list'>]\n",
      "zip_cd_all [<class 'list'>]\n",
      "zip_cd_50 [<class 'list'>]\n",
      "TA [<class 'int'>]\n",
      "TA [<class 'int'>]\n",
      "store_list [<class 'list'>]\n",
      "zip_cd_50 [<class 'list'>]\n",
      "zip_cd_all [<class 'list'>]\n",
      "store_count [<class 'int'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_remain_stores_single_TA=df_remain_stores[['location_id','All_P&S_zips','All_P&S_zips_50_miles']]\n",
    "df_remain_stores_single_TA['TA']=[all_defined_TA['TA'].max()+1+x for x in range(len(df_remain_stores_single_TA))]\n",
    "df_remain_stores_single_TA=df_remain_stores_single_TA.rename(columns={\"location_id\":\"store_list\"})\n",
    "df_remain_stores_single_TA=df_remain_stores_single_TA.rename(columns={\"All_P&S_zips_50_miles\":\"zip_cd_50\"})\n",
    "df_remain_stores_single_TA=df_remain_stores_single_TA.rename(columns={\"All_P&S_zips\":\"zip_cd_all\"})\n",
    "df_remain_stores_single_TA['store_list']=df_remain_stores_single_TA['store_list'].apply(lambda x: [x])\n",
    "df_remain_stores_single_TA.head(2)\n",
    "\n",
    "for col in df_remain_stores_single_TA.columns.tolist():\n",
    "    print(col,df_remain_stores_single_TA[col].apply(lambda x: type(x)).unique())\n",
    "    \n",
    "for col in all_defined_TA.columns.tolist():\n",
    "    print(col,all_defined_TA[col].apply(lambda x: type(x)).unique())\n",
    "    \n",
    "all_defined_TA=all_defined_TA.append(df_remain_stores_single_TA)\n",
    "\n",
    "all_defined_TA['store_count']=all_defined_TA['store_list'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_defined_TA['store_count']=all_defined_TA['store_list'].apply(lambda x: len(x))\n",
    "\n",
    "all_defined_TA['temp_1st_store']=all_defined_TA['store_list'].apply(lambda x: \"single_\"+str(x[0]))\n",
    "all_defined_TA['temp_TA_str']=all_defined_TA['TA'].apply(lambda x: \"multiple_\"+str(x))\n",
    "\n",
    "all_defined_TA['ta_name']=np.where(all_defined_TA['store_count']==1,all_defined_TA['temp_1st_store'],all_defined_TA['temp_TA_str'])\n",
    "\n",
    "del all_defined_TA['temp_1st_store']\n",
    "del all_defined_TA['temp_TA_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_store_count_TA=all_defined_TA.groupby(\"store_count\")['TA'].count().to_frame().reset_index().sort_values(\"store_count\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output_by_store=pd.DataFrame(columns={\"location_id\",\"TA\",\"ta_name\"})\n",
    "\n",
    "for ind,row in all_defined_TA.iterrows():\n",
    "    store_list_in_TA=row['store_list']\n",
    "    TA_num=row['TA']\n",
    "    TA_name=row['ta_name']\n",
    "    df=pd.DataFrame({\"location_id\":store_list_in_TA,\"TA\":[TA_num]*len(store_list_in_TA),\"ta_name\":[TA_name]*len(store_list_in_TA)},index=range(len(store_list_in_TA)))\n",
    "    df_output_by_store=df_output_by_store.append(df)\n",
    "df_output_by_store=df_output_by_store.sort_values([\"TA\",\"location_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_previous_zip_by_store_copy=df_output[df_output['location_id'].isin(df_output_by_store['location_id'].tolist())]\n",
    "df_previous_zip_by_store_copy=df_previous_zip_by_store_copy[['location_id','customer_zip_code','trans_flag']]\n",
    "df_previous_zip_by_store_copy=df_previous_zip_by_store_copy[df_previous_zip_by_store_copy['trans_flag'].isin([\"P\",\"S\"])]\n",
    "df_previous_zip_by_store_copy=df_previous_zip_by_store_copy.rename(columns={\"customer_zip_code\":\"zip_cd\"})\n",
    "\n",
    "df_previous_zip_by_store_copy.shape\n",
    "\n",
    "df_trans_zips=df_previous_zip_by_store_copy.groupby([\"location_id\",\"trans_flag\"])['zip_cd'].apply(list).to_frame().reset_index()\n",
    "\n",
    "df_trans_zips=df_trans_zips.pivot(index=\"location_id\",columns=\"trans_flag\",values=\"zip_cd\").reset_index()\n",
    "df_trans_zips=df_trans_zips.rename(columns={\"P\":\"all_trans_P_zips\",\"S\":\"all_trans_S_zips\"})\n",
    "df_10_zips=df_new_store_zips.groupby(\"location_id\")['zips_in_10'].apply(list).to_frame().reset_index()\n",
    "df_output_by_store_zips=df_trans_zips.append(df_10_zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=pd.merge(df_output_by_store,store_list,on=\"location_id\",how=\"left\")\n",
    "df_output_by_store=pd.merge(df_output_by_store,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "df_output_by_store=pd.merge(df_output_by_store,df_output_by_store_zips,on=\"location_id\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output_by_store['all_trans_P_zips']=df_output_by_store['all_trans_P_zips'].fillna(\"[]\")\n",
    "df_output_by_store['all_trans_S_zips']=df_output_by_store['all_trans_S_zips'].fillna(\"[]\")\n",
    "df_output_by_store['zips_in_10']=df_output_by_store['zips_in_10'].fillna(\"[]\")\n",
    "\n",
    "df_output_by_store['all_trans_P_zips']=df_output_by_store['all_trans_P_zips'].astype(str)\n",
    "df_output_by_store['all_trans_S_zips']=df_output_by_store['all_trans_S_zips'].astype(str)\n",
    "df_output_by_store['zips_in_10']=df_output_by_store['zips_in_10'].astype(str)\n",
    "\n",
    "df_output_by_store['all_trans_P_zips']=df_output_by_store['all_trans_P_zips'].apply(lambda x: eval(x))\n",
    "df_output_by_store['all_trans_S_zips']=df_output_by_store['all_trans_S_zips'].apply(lambda x: eval(x))\n",
    "df_output_by_store['zips_in_10']=df_output_by_store['zips_in_10'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit 70 miles zips to the associated stores\n",
    "df_output_by_store_copy=df_output_by_store.copy()\n",
    "df_output_by_store_copy=df_output_by_store_copy.reset_index()\n",
    "del df_output_by_store_copy['index']\n",
    "\n",
    "location_lat_long_dict=df_output_by_store_copy[['location_id','latitude_meas','longitude_meas']].drop_duplicates()\n",
    "location_lat_long_dict['store_center']=location_lat_long_dict[['latitude_meas','longitude_meas']].values.tolist()\n",
    "location_lat_long_dict=location_lat_long_dict.set_index(\"location_id\")['store_center']\n",
    "\n",
    "\n",
    "df_output_by_store_1=pd.DataFrame()\n",
    "df_output_by_store_copy['trans_P_zips_70_within_TA']=np.nan\n",
    "df_output_by_store_copy['trans_S_zips_70_within_TA']=np.nan\n",
    "\n",
    "\n",
    "\n",
    "for TA,df_group in df_output_by_store_copy.groupby(\"TA\"):\n",
    "    store_list=df_group['location_id'].tolist()\n",
    "    df_group=df_group.reset_index()\n",
    "    del df_group['index']\n",
    "    \n",
    "    for ind,row in df_group.iterrows():\n",
    "        all_P_zips_list=row['all_trans_P_zips']\n",
    "        all_S_zips_list=row['all_trans_S_zips']\n",
    "        P_zips_list_70_in_TA=[]\n",
    "        S_zips_list_70_in_TA=[]\n",
    "        \n",
    "        for zip_P in all_P_zips_list:\n",
    "            for store in store_list:\n",
    "                store_center=location_lat_long_dict[store]\n",
    "                dist=haversine(store_center, zip_centers[zip_P],miles=True)\n",
    "                if dist<=70:\n",
    "                    P_zips_list_70_in_TA=P_zips_list_70_in_TA+[zip_P]\n",
    "                \n",
    "        for zip_S in all_S_zips_list:\n",
    "            for store in store_list:\n",
    "                store_center=location_lat_long_dict[store]\n",
    "                dist=haversine(store_center, zip_centers[zip_S],miles=True)\n",
    "                if dist<=70:\n",
    "                    S_zips_list_70_in_TA=S_zips_list_70_in_TA+[zip_S]\n",
    "                    \n",
    "        P_zips_list_70_in_TA=list(set(P_zips_list_70_in_TA))\n",
    "        S_zips_list_70_in_TA=list(set(S_zips_list_70_in_TA))\n",
    "        \n",
    "        df_group.loc[ind,'trans_P_zips_70_within_TA']=str(P_zips_list_70_in_TA)\n",
    "        df_group.loc[ind,'trans_S_zips_70_within_TA']=str(S_zips_list_70_in_TA)\n",
    "        \n",
    "    df_output_by_store_1=df_output_by_store_1.append(df_group)\n",
    "        \n",
    "df_output_by_store_1['trans_P_zips_70_within_TA']=df_output_by_store_1['trans_P_zips_70_within_TA'].apply(lambda x: eval(x))\n",
    "df_output_by_store_1['trans_S_zips_70_within_TA']=df_output_by_store_1['trans_S_zips_70_within_TA'].apply(lambda x: eval(x))\n",
    "\n",
    "df_output_by_store=df_output_by_store_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_output_by_store=df_output_by_store.reset_index()\n",
    "del df_output_by_store['index']\n",
    "\n",
    "df_output_by_store_zip_long=pd.DataFrame(columns=[\"TA\",\"ta_name\",\"location_id\",'zip_cd','zip_type'])\n",
    "\n",
    "for ind,row in df_output_by_store.iterrows():\n",
    "    TA=row['TA']\n",
    "    ta_name=row['ta_name']\n",
    "    location_id=row['location_id']\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    all_P_zips=row['trans_P_zips_70_within_TA']\n",
    "    all_S_zips=row['trans_S_zips_70_within_TA']\n",
    "    all_10_zips=row['zips_in_10']\n",
    "    \n",
    "    df_P=pd.DataFrame({\"location_id\":[location_id]*len(all_P_zips),'zip_cd':all_P_zips})\n",
    "    df_P['zip_type']=\"trans_P\"\n",
    "    \n",
    "    df_S=pd.DataFrame({\"location_id\":[location_id]*len(all_S_zips),'zip_cd':all_S_zips})\n",
    "    df_S['zip_type']=\"trans_S\"\n",
    "    \n",
    "    df_10=pd.DataFrame({\"location_id\":[location_id]*len(all_10_zips),'zip_cd':all_10_zips})\n",
    "    df_10['zip_type']=\"zips_10\"\n",
    "    \n",
    "    df=df_P.append(df_S).append(df_10)\n",
    "    df['TA']=TA\n",
    "    df['ta_name']=ta_name\n",
    "    df_output_by_store_zip_long=df_output_by_store_zip_long.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>store_list</th>\n",
       "      <th>trans_P_zips</th>\n",
       "      <th>trans_S_zips</th>\n",
       "      <th>distance_10_zips</th>\n",
       "      <th>store_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>multiple_1</td>\n",
       "      <td>[1995, 4014, 4045, 4103, 4274, 4321, 4688]</td>\n",
       "      <td>[91701, 91730, 91739, 91752, 91761, 91764, 923...</td>\n",
       "      <td>[91709, 91710, 91729, 91737, 91744, 91762, 917...</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>multiple_2</td>\n",
       "      <td>[1966, 4144]</td>\n",
       "      <td>[75006, 75220, 75229, 75230, 75234, 75235, 752...</td>\n",
       "      <td>[75001, 75007, 75019, 75043, 75056, 75061, 750...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TA     ta_name                                  store_list  \\\n",
       "0  1  multiple_1  [1995, 4014, 4045, 4103, 4274, 4321, 4688]   \n",
       "1  2  multiple_2                                [1966, 4144]   \n",
       "\n",
       "                                        trans_P_zips  \\\n",
       "0  [91701, 91730, 91739, 91752, 91761, 91764, 923...   \n",
       "1  [75006, 75220, 75229, 75230, 75234, 75235, 752...   \n",
       "\n",
       "                                        trans_S_zips distance_10_zips  \\\n",
       "0  [91709, 91710, 91729, 91737, 91744, 91762, 917...             None   \n",
       "1  [75001, 75007, 75019, 75043, 75056, 75061, 750...             None   \n",
       "\n",
       "   store_count  \n",
       "0            7  \n",
       "1            2  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_TA=df_output_by_store_zip_long.sort_values([\"TA\",'ta_name','zip_type','zip_cd'])\n",
    "df_output_by_TA=df_output_by_TA.drop_duplicates([\"TA\",'ta_name','zip_cd'])\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.groupby([\"TA\",\"ta_name\",\"zip_type\"])['zip_cd'].apply(list).to_frame().reset_index()\n",
    "df_output_by_TA=df_output_by_TA.pivot(index=\"TA\",columns=\"zip_type\",values=\"zip_cd\").reset_index()\n",
    "\n",
    "\n",
    "ta_name=df_output_by_store_zip_long[['TA','ta_name']].drop_duplicates()\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_name,on=\"TA\",how=\"left\")\n",
    "\n",
    "ta_store_list=df_output_by_store.groupby(\"TA\")['location_id'].apply(list).to_frame().reset_index()\n",
    "\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_store_list,on='TA',how=\"left\")\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.rename(columns={\"location_id\":\"store_list\",\"trans_P\":\"trans_P_zips\",\"trans_S\":\"trans_S_zips\",\"zips_10\":\"distance_10_zips\"})\n",
    "df_output_by_TA=df_output_by_TA[['TA','ta_name','store_list','trans_P_zips','trans_S_zips','distance_10_zips']]\n",
    "df_output_by_TA['store_count']=df_output_by_TA['store_list'].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "df_output_by_TA.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge multiple TA with 30% overlap + \n",
    "df_output_by_TA['trans_P_zips']=df_output_by_TA['trans_P_zips'].fillna(\"[]\").astype(str).apply(lambda x: eval(x))\n",
    "df_output_by_TA['trans_S_zips']=df_output_by_TA['trans_S_zips'].fillna(\"[]\").astype(str).apply(lambda x: eval(x))\n",
    "df_output_by_TA['distance_10_zips']=df_output_by_TA['distance_10_zips'].fillna(\"[]\").astype(str).apply(lambda x: eval(x))\n",
    "\n",
    "\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.reset_index()\n",
    "del df_output_by_TA['index']\n",
    "df_output_by_TA['all_zips']=df_output_by_TA['trans_P_zips']+df_output_by_TA['trans_S_zips']+df_output_by_TA['distance_10_zips']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>store_list</th>\n",
       "      <th>trans_P_zips</th>\n",
       "      <th>trans_S_zips</th>\n",
       "      <th>distance_10_zips</th>\n",
       "      <th>store_count</th>\n",
       "      <th>all_zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>multiple_1</td>\n",
       "      <td>[1995, 4014, 4045, 4103, 4274, 4321, 4688]</td>\n",
       "      <td>[91701, 91730, 91739, 91752, 91761, 91764, 923...</td>\n",
       "      <td>[91709, 91710, 91729, 91737, 91744, 91762, 917...</td>\n",
       "      <td>[]</td>\n",
       "      <td>7</td>\n",
       "      <td>[91701, 91730, 91739, 91752, 91761, 91764, 923...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>multiple_2</td>\n",
       "      <td>[1966, 4144]</td>\n",
       "      <td>[75006, 75220, 75229, 75230, 75234, 75235, 752...</td>\n",
       "      <td>[75001, 75007, 75019, 75043, 75056, 75061, 750...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>[75006, 75220, 75229, 75230, 75234, 75235, 752...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TA     ta_name                                  store_list  \\\n",
       "0  1  multiple_1  [1995, 4014, 4045, 4103, 4274, 4321, 4688]   \n",
       "1  2  multiple_2                                [1966, 4144]   \n",
       "\n",
       "                                        trans_P_zips  \\\n",
       "0  [91701, 91730, 91739, 91752, 91761, 91764, 923...   \n",
       "1  [75006, 75220, 75229, 75230, 75234, 75235, 752...   \n",
       "\n",
       "                                        trans_S_zips distance_10_zips  \\\n",
       "0  [91709, 91710, 91729, 91737, 91744, 91762, 917...               []   \n",
       "1  [75001, 75007, 75019, 75043, 75056, 75061, 750...               []   \n",
       "\n",
       "   store_count                                           all_zips  \n",
       "0            7  [91701, 91730, 91739, 91752, 91761, 91764, 923...  \n",
       "1            2  [75006, 75220, 75229, 75230, 75234, 75235, 752...  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_TA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qc_overlap_1=df_output_by_TA[['TA','ta_name','all_zips']].rename(columns={\"TA\":\"TA_1\",\"all_zips\":\"all_zips_1\"})\n",
    "df_qc_overlap_1=df_qc_overlap_1[df_qc_overlap_1['ta_name'].apply(lambda x: x.split(\"_\")[0]==\"multiple\")]\n",
    "df_qc_overlap_1['temp']=1\n",
    "del df_qc_overlap_1['ta_name']\n",
    "\n",
    "df_qc_overlap_2=df_output_by_TA[['TA','ta_name','all_zips']].rename(columns={\"TA\":\"TA_2\",\"all_zips\":\"all_zips_2\"})\n",
    "df_qc_overlap_2=df_qc_overlap_2[df_qc_overlap_2['ta_name'].apply(lambda x: x.split(\"_\")[0]==\"multiple\")]\n",
    "df_qc_overlap_2['temp']=1\n",
    "del df_qc_overlap_2['ta_name']\n",
    "\n",
    "df_qc_overlap=pd.merge(df_qc_overlap_1,df_qc_overlap_2,on=\"temp\",how=\"outer\")\n",
    "df_qc_overlap=df_qc_overlap[df_qc_overlap['TA_1']!=df_qc_overlap['TA_2']]\n",
    "del df_qc_overlap['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intsection_pctg_qc_TA(list_1,list_2):\n",
    "    intersection_list=list(set(list_1).intersection(set(list_2)))\n",
    "    intersection_pctg=len(intersection_list)/len(set(list_1+list_2))\n",
    "    return intersection_pctg\n",
    "\n",
    "df_qc_overlap['intersecion_pctg']=df_qc_overlap.apply(lambda x: intsection_pctg_qc_TA(x['all_zips_1'],x['all_zips_2']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_overlap_high_TA=df_qc_overlap[df_qc_overlap['intersecion_pctg']>0.3]\n",
    "df_overlap_high_TA['pairs']=df_overlap_high_TA[['TA_1','TA_2']].values.tolist()\n",
    "df_overlap_high_TA['pairs']=df_overlap_high_TA['pairs'].apply(lambda x: str(sorted(x)))\n",
    "df_overlap_high_TA=df_overlap_high_TA[['TA_1','TA_2','pairs']].drop_duplicates()\n",
    "\n",
    "df_overlap_high_TA_all_pairs=df_overlap_high_TA['pairs'].unique().tolist()\n",
    "df_overlap_high_TA_all_pairs=[eval(x) for x in df_overlap_high_TA_all_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{19: 6, 46: 1, 52: 48, 72: 61, 112: 49, 149: 78}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_M_M_TA_dict={}\n",
    "for pair_list in df_overlap_high_TA_all_pairs:\n",
    "    merge_M_M_TA_dict.update({pair_list[1]:pair_list[0]}) \n",
    "    \n",
    "merge_M_M_TA_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "del df_output_by_store['ta_name']\n",
    "df_output_by_store_1=df_output_by_store[df_output_by_store['TA'].isin(merge_M_M_TA_dict.keys())]\n",
    "df_output_by_store_2=df_output_by_store[~df_output_by_store['TA'].isin(merge_M_M_TA_dict.keys())]\n",
    "\n",
    "df_output_by_store_1['TA']=df_output_by_store_1['TA'].apply(lambda x: merge_M_M_TA_dict[x])\n",
    "df_output_by_store=df_output_by_store_1.append(df_output_by_store_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_name=df_output_by_store.groupby(\"TA\")['location_id'].apply(list).to_frame().reset_index()\n",
    "df_ta_name['store_count']=df_ta_name['location_id'].apply(lambda x: len(x))\n",
    "df_ta_name=df_ta_name.sort_values(\"store_count\",ascending=False)\n",
    "df_ta_name['TA_num']=[str(x+1) for x in range(len(df_ta_name))]\n",
    "df_ta_name['location_id_0_temp']=df_ta_name['location_id'].apply(lambda x: x[0])\n",
    "df_ta_name['location_id_0_temp']=\"single_\"+df_ta_name['location_id_0_temp']\n",
    "df_ta_name['multiple_temp']=\"multiple_\"+df_ta_name['TA_num']\n",
    "\n",
    "df_ta_name['ta_name']=np.where(df_ta_name['store_count']==1,df_ta_name['location_id_0_temp'],df_ta_name['multiple_temp'])\n",
    "\n",
    "df_ta_name=df_ta_name[['TA','TA_num','ta_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_num</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>location_id</th>\n",
       "      <th>address_line_1</th>\n",
       "      <th>address_line_2</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>city_nm</th>\n",
       "      <th>state_nm</th>\n",
       "      <th>latitude_meas</th>\n",
       "      <th>longitude_meas</th>\n",
       "      <th>DMA</th>\n",
       "      <th>CTY</th>\n",
       "      <th>all_trans_P_zips</th>\n",
       "      <th>all_trans_S_zips</th>\n",
       "      <th>zips_in_10</th>\n",
       "      <th>trans_P_zips_70_within_TA</th>\n",
       "      <th>trans_S_zips_70_within_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>multiple_50</td>\n",
       "      <td>4166</td>\n",
       "      <td>5587 SEPULVEDA BLVD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90230</td>\n",
       "      <td>CULVER CITY</td>\n",
       "      <td>CA</td>\n",
       "      <td>33.990694</td>\n",
       "      <td>-118.396195</td>\n",
       "      <td>{LOS ANGELES}</td>\n",
       "      <td>{LOS ANGELES}</td>\n",
       "      <td>[90230, 90066, 90034, 90045, 90043, 90016, 903...</td>\n",
       "      <td>[90301, 90019, 90018, 90047, 90062, 90250, 900...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[90016, 90066, 90008, 90056, 90230, 90034, 903...</td>\n",
       "      <td>[90037, 90044, 90405, 90018, 90301, 90250, 900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>multiple_50</td>\n",
       "      <td>4600</td>\n",
       "      <td>3115 SOUTH SEPULVEDA BLVD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90034</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CA</td>\n",
       "      <td>34.025902</td>\n",
       "      <td>-118.427931</td>\n",
       "      <td>{LOS ANGELES}</td>\n",
       "      <td>{LOS ANGELES}</td>\n",
       "      <td>[90034, 90064, 90066, 90025, 90230, 90404]</td>\n",
       "      <td>[90405, 90016, 90291, 90019, 90024, 90035, 902...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[90066, 90230, 90034, 90404, 90064, 90025]</td>\n",
       "      <td>[90044, 90016, 90024, 90035, 90292, 90019, 900...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TA_num      ta_name location_id             address_line_1 address_line_2  \\\n",
       "0     50  multiple_50        4166        5587 SEPULVEDA BLVD            NaN   \n",
       "1     50  multiple_50        4600  3115 SOUTH SEPULVEDA BLVD            NaN   \n",
       "\n",
       "  zip_cd      city_nm state_nm  latitude_meas  longitude_meas            DMA  \\\n",
       "0  90230  CULVER CITY       CA      33.990694     -118.396195  {LOS ANGELES}   \n",
       "1  90034  LOS ANGELES       CA      34.025902     -118.427931  {LOS ANGELES}   \n",
       "\n",
       "             CTY                                   all_trans_P_zips  \\\n",
       "0  {LOS ANGELES}  [90230, 90066, 90034, 90045, 90043, 90016, 903...   \n",
       "1  {LOS ANGELES}         [90034, 90064, 90066, 90025, 90230, 90404]   \n",
       "\n",
       "                                    all_trans_S_zips zips_in_10  \\\n",
       "0  [90301, 90019, 90018, 90047, 90062, 90250, 900...         []   \n",
       "1  [90405, 90016, 90291, 90019, 90024, 90035, 902...         []   \n",
       "\n",
       "                           trans_P_zips_70_within_TA  \\\n",
       "0  [90016, 90066, 90008, 90056, 90230, 90034, 903...   \n",
       "1         [90066, 90230, 90034, 90404, 90064, 90025]   \n",
       "\n",
       "                           trans_S_zips_70_within_TA  \n",
       "0  [90037, 90044, 90405, 90018, 90301, 90250, 900...  \n",
       "1  [90044, 90016, 90024, 90035, 90292, 90019, 900...  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_store=pd.merge(df_output_by_store,df_ta_name,on=\"TA\",how=\"left\")\n",
    "df_output_by_store=df_output_by_store[['TA_num','ta_name']+[x for x in df_output_by_store.columns.tolist() if x not in ['TA_num','ta_name']]]\n",
    "\n",
    "del df_output_by_store['TA']\n",
    "df_output_by_store['TA_num']=df_output_by_store['TA_num'].astype(int)\n",
    "df_output_by_store=df_output_by_store.sort_values(\"TA_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=df_output_by_store.reset_index()\n",
    "del df_output_by_store['index']\n",
    "\n",
    "df_output_by_store_zip_long=pd.DataFrame(columns=[\"TA_num\",\"ta_name\",\"location_id\",'zip_cd','zip_type'])\n",
    "\n",
    "for ind,row in df_output_by_store.iterrows():\n",
    "    TA=row['TA_num']\n",
    "    ta_name=row['ta_name']\n",
    "    location_id=row['location_id']\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    all_P_zips=row['trans_P_zips_70_within_TA']\n",
    "    all_S_zips=row['trans_S_zips_70_within_TA']\n",
    "    all_10_zips=row['zips_in_10']\n",
    "    \n",
    "    df_P=pd.DataFrame({\"location_id\":[location_id]*len(all_P_zips),'zip_cd':all_P_zips})\n",
    "    df_P['zip_type']=\"trans_P\"\n",
    "    \n",
    "    df_S=pd.DataFrame({\"location_id\":[location_id]*len(all_S_zips),'zip_cd':all_S_zips})\n",
    "    df_S['zip_type']=\"trans_S\"\n",
    "    \n",
    "    df_10=pd.DataFrame({\"location_id\":[location_id]*len(all_10_zips),'zip_cd':all_10_zips})\n",
    "    df_10['zip_type']=\"zips_10\"\n",
    "    \n",
    "    df=df_P.append(df_S).append(df_10)\n",
    "    df['TA_num']=TA\n",
    "    df['ta_name']=ta_name\n",
    "    df_output_by_store_zip_long=df_output_by_store_zip_long.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_num</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>store_list</th>\n",
       "      <th>trans_P_zips</th>\n",
       "      <th>trans_S_zips</th>\n",
       "      <th>distance_10_zips</th>\n",
       "      <th>store_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>multiple_1</td>\n",
       "      <td>[1949, 1255, 4543, 1027, 1072, 1106, 4622, 456...</td>\n",
       "      <td>[75002, 75006, 75007, 75020, 75023, 75024, 750...</td>\n",
       "      <td>[73448, 73459, 74701, 74733, 75001, 75009, 750...</td>\n",
       "      <td>None</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>multiple_2</td>\n",
       "      <td>[5220, 5356, 1666, 1667, 1668, 77, 5369, 5243,...</td>\n",
       "      <td>[43015, 43016, 43017, 43021, 43026, 43035, 430...</td>\n",
       "      <td>[43003, 43004, 43008, 43009, 43011, 43023, 430...</td>\n",
       "      <td>None</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TA_num     ta_name                                         store_list  \\\n",
       "0      1  multiple_1  [1949, 1255, 4543, 1027, 1072, 1106, 4622, 456...   \n",
       "1      2  multiple_2  [5220, 5356, 1666, 1667, 1668, 77, 5369, 5243,...   \n",
       "\n",
       "                                        trans_P_zips  \\\n",
       "0  [75002, 75006, 75007, 75020, 75023, 75024, 750...   \n",
       "1  [43015, 43016, 43017, 43021, 43026, 43035, 430...   \n",
       "\n",
       "                                        trans_S_zips distance_10_zips  \\\n",
       "0  [73448, 73459, 74701, 74733, 75001, 75009, 750...             None   \n",
       "1  [43003, 43004, 43008, 43009, 43011, 43023, 430...             None   \n",
       "\n",
       "   store_count  \n",
       "0           21  \n",
       "1           17  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_TA=df_output_by_store_zip_long.sort_values([\"TA_num\",'ta_name','zip_type','zip_cd'])\n",
    "df_output_by_TA=df_output_by_TA.drop_duplicates([\"TA_num\",'ta_name','zip_cd'])\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.groupby([\"TA_num\",\"ta_name\",\"zip_type\"])['zip_cd'].apply(list).to_frame().reset_index()\n",
    "df_output_by_TA=df_output_by_TA.pivot(index=\"TA_num\",columns=\"zip_type\",values=\"zip_cd\").reset_index()\n",
    "\n",
    "\n",
    "ta_name=df_output_by_store_zip_long[['TA_num','ta_name']].drop_duplicates()\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_name,on=\"TA_num\",how=\"left\")\n",
    "\n",
    "ta_store_list=df_output_by_store.groupby(\"TA_num\")['location_id'].apply(list).to_frame().reset_index()\n",
    "\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_store_list,on='TA_num',how=\"left\")\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.rename(columns={\"location_id\":\"store_list\",\"trans_P\":\"trans_P_zips\",\"trans_S\":\"trans_S_zips\",\"zips_10\":\"distance_10_zips\"})\n",
    "df_output_by_TA=df_output_by_TA[['TA_num','ta_name','store_list','trans_P_zips','trans_S_zips','distance_10_zips']]\n",
    "df_output_by_TA['store_count']=df_output_by_TA['store_list'].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "df_output_by_TA.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12980, 2)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_unique_zips=df_output_by_store_zip_long[['zip_type','zip_cd']].drop_duplicates()\n",
    "df_output_unique_zips=df_output_unique_zips.sort_values(\"zip_type\")\n",
    "df_output_unique_zips=df_output_unique_zips.drop_duplicates(\"zip_cd\")\n",
    "df_output_unique_zips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_list=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20190701-134908-815.txt\",\n",
    "                        dtype=str,sep=\"|\")\n",
    "store_list['latitude_meas']=store_list['latitude_meas'].astype(float)\n",
    "store_list['longitude_meas']=store_list['longitude_meas'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_lat_long=store_list[['location_id','latitude_meas','longitude_meas']]\n",
    "df_output_by_store_zip_long=pd.merge(df_output_by_store_zip_long,location_lat_long,on=\"location_id\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"BL_final_TA_updated_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_output_unique_zips.to_excel(writer,\"unique_zips_full_footprint\",index=False)\n",
    "df_output_by_TA.to_excel(writer,\"view_by_TA\",index=False)\n",
    "df_output_by_store.to_excel(writer,\"view_by_store\",index=False)\n",
    "df_output_by_store_zip_long.to_excel(writer,\"view_for_Tableau\",index=False)\n",
    "writer.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
