{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "folderpath = '/home/jubauser1/BiglotsCode/outputs/'\n",
    "lastweeksdate = '2017-09-09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsalespath = '/home/jubauser1/BigLots/MediaStorm Data Extract week ending 2017-09-16/MediaStormSalesWeekly.txt'\n",
    "newtrafficpath = '/home/jubauser1/BigLots/MediaStorm Data Extract week ending 2017-09-16/MediaStormTrafficWeekly.txt'\n",
    "newinventorypath = '/home/jubauser1/BigLots/MediaStorm Data Extract week ending 2017-09-16/MediaStormInventoryWeekly.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "closed_onlinestorelist = ['6990','280', '298', '388', '507', '824', '1098', \n",
    "                          '1120', '1148', '1182', '1374', '1773', '1822', '1913',\n",
    "                          '1967', '4085', '4099', '4113', '145',\n",
    "                          '4165', '4280', '4326', '4362', '4382', '4428', '5133']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new sales data column header matches:\n",
      "[ True  True  True  True  True  True  True]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfsales = pd.read_csv(folderpath + 'combinedsales'+ lastweeksdate + '.csv',sep = '|',dtype = 'str')\n",
    "df = pd.read_csv(newsalespath,sep = '|',dtype = 'str')\n",
    "a = df.columns\n",
    "print(\"new sales data column header matches:\")\n",
    "print(a == ['location_id', 'week_end_dt', 'fiscal_week_nbr', 'gross_sales_amt',\n",
    "       'gross_transaction_cnt', 'class_code_id', 'class_gross_sales_amt'])\n",
    "dfsales = dfsales.append(df,ignore_index = True)\n",
    "a = (len(dfsales.index))\n",
    "dfsales = dfsales.drop_duplicates(['location_id', 'week_end_dt', 'fiscal_week_nbr', \n",
    "       'class_code_id'])\n",
    "b = (len(dfsales.index))\n",
    "if a==b:\n",
    "    print(\"\")\n",
    "else:\n",
    "    print(\"last week traffic data duplication deduped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recentweek = (max(dfsales['week_end_dt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales.to_csv(folderpath + 'combinedsales'+ recentweek + '.csv',index = False,sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales = dfsales[~dfsales['location_id'].isin(closed_onlinestorelist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputpath = folderpath +'Output_' + recentweek +'/'\n",
    "try:\n",
    "    os.stat(outputpath)\n",
    "except:\n",
    "    os.mkdir(outputpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stores with ? sales/transaction: 0\n"
     ]
    }
   ],
   "source": [
    "dfnodata = dfsales[(dfsales['class_gross_sales_amt'] == '?')&\\\n",
    "                   (dfsales['week_end_dt'] == recentweek)]\n",
    "dfnodata.to_csv(outputpath + 'sales_nodata.csv',index = False)\n",
    "print(\"stores with ? sales/transaction: \" + str(len(dfnodata.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales['week_end_dt'] = pd.to_datetime(dfsales['week_end_dt'])\n",
    "dfsales = dfsales[dfsales['class_gross_sales_amt']!='?']\n",
    "dfsales = dfsales.reset_index(drop = True)\n",
    "\n",
    "dfsales['gross_sales_amt'] = dfsales['gross_sales_amt'].astype('float')\n",
    "dfsales['gross_transaction_cnt'] = dfsales['gross_transaction_cnt'].astype('float')\n",
    "dfsales['class_gross_sales_amt'] = dfsales['class_gross_sales_amt'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfweeklist = dfsales[['week_end_dt','fiscal_week_nbr']].drop_duplicates()\n",
    "dfweeklist = dfweeklist.sort_values('week_end_dt',ascending = False)\n",
    "dfweeklist.reset_index(drop = True,inplace = True)\n",
    "dfweeklist.reset_index(inplace = True)\n",
    "\n",
    "dfweeklist_wow = dfweeklist.copy()\n",
    "dfweeklist_wow['index'] = dfweeklist_wow['index'] - 1\n",
    "dfweeklist_wow = dfweeklist_wow[['index','week_end_dt']]\n",
    "dfweeklist_wow.columns = ['index','weeklastweek']\n",
    "\n",
    "dfweeklist = dfweeklist[dfweeklist['index']<104]\n",
    "dfweeklist.reset_index(drop = True,inplace = True)\n",
    "dfweeklist['year'] = np.ceil((dfweeklist['index'] + 1)/52)\n",
    "\n",
    "dfweeklist1 = dfweeklist[dfweeklist['year'] == 1]\n",
    "dfweeklist1 = dfweeklist1[['index', 'week_end_dt', 'fiscal_week_nbr']]\n",
    "dfweeklist2 = dfweeklist[dfweeklist['year'] == 2]\n",
    "dfweeklist2 = dfweeklist2[['week_end_dt', 'fiscal_week_nbr']]\n",
    "dfweeklist2.columns = ['weeklastyear', 'fiscal_week_nbr']\n",
    "\n",
    "dfweeklist = pd.merge(dfweeklist1,dfweeklist2,on ='fiscal_week_nbr' )\n",
    "dfweeklist = pd.merge(dfweeklist,dfweeklist_wow,on ='index')\n",
    "del dfweeklist1,dfweeklist2,dfweeklist_wow\n",
    "\n",
    "dfweeklist.to_csv(outputpath + 'weeklist.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recentweek_date = (max(dfsales['week_end_dt']))\n",
    "dfcheck = dfsales[dfsales['week_end_dt'] == recentweek_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stores with zero sales/transaction: 0\n",
      "stores gross sales can not match sum of class sales: 1\n",
      "stores with zero class sales: 0\n"
     ]
    }
   ],
   "source": [
    "dfcheck_total1 = dfcheck[['location_id', 'week_end_dt', 'fiscal_week_nbr',\n",
    "                         'gross_sales_amt','gross_transaction_cnt']].drop_duplicates()\n",
    "a = (len(dfcheck_total1.index))\n",
    "dfcheck_total1 = dfcheck_total1.drop_duplicates(['location_id', 'week_end_dt', 'fiscal_week_nbr'])\n",
    "b = (len(dfcheck_total1.index))\n",
    "if a==b:\n",
    "    print(\"\")\n",
    "else:\n",
    "    print(\"last week sales multiple gross sales/trasaction in the same store\")\n",
    "\n",
    "dfcheck_total2 = dfcheck[['location_id', 'week_end_dt', 'fiscal_week_nbr',\n",
    "                         'class_gross_sales_amt']].groupby(['location_id', 'week_end_dt', 'fiscal_week_nbr']).sum()\n",
    "dfcheck_total2.reset_index(inplace = True)\n",
    "\n",
    "dfcheck_total = pd.merge(dfcheck_total1,dfcheck_total2,\n",
    "                        on = ['location_id', 'week_end_dt', 'fiscal_week_nbr'] ,\n",
    "                        how = 'outer')\n",
    "del dfcheck_total1,dfcheck_total2\n",
    "\n",
    "dfcheck_zero = dfcheck_total[(dfcheck_total['class_gross_sales_amt']<=0)|\\\n",
    "                            (dfcheck_total['gross_transaction_cnt']<=0) ]\n",
    "\n",
    "dfcheck_zero.to_csv(outputpath + 'zerosales.csv',index = False)\n",
    "print(\"stores with zero sales/transaction: \" + str(len(dfcheck_zero.index)))\n",
    "del dfcheck_zero\n",
    "\n",
    "dfcheck_total['TotalDiff'] = dfcheck_total['gross_sales_amt']-dfcheck_total['class_gross_sales_amt']\n",
    "dfcheck_total['TotalDiff'] = dfcheck_total['TotalDiff'].round()\n",
    "dfcheck_totalnonmatch = dfcheck_total[dfcheck_total['TotalDiff']!=0]\n",
    "print(\"stores gross sales can not match sum of class sales: \" + str(len(dfcheck_totalnonmatch.index)))\n",
    "\n",
    "dfcheck_totalnonmatch.to_csv(outputpath + 'totalnonmatch.csv',index = False)\n",
    "del dfcheck_totalnonmatch\n",
    "\n",
    "dfcheck_zeroclass = dfcheck[(dfcheck['class_gross_sales_amt']==0)]\n",
    "dfcheck_zeroclass.to_csv(outputpath + 'zeroclasssales.csv',index = False)\n",
    "print(\"stores with zero class sales: \" + str(len(dfcheck_zeroclass.index)))\n",
    "del dfcheck_zeroclass\n",
    "del dfcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_total1 = dfsales[['location_id', 'week_end_dt', 'fiscal_week_nbr',\n",
    "                         'gross_sales_amt','gross_transaction_cnt']].drop_duplicates()\n",
    "dfsales_total1 = dfsales_total1.drop_duplicates(['location_id', 'week_end_dt', 'fiscal_week_nbr'])\n",
    "\n",
    "dfsales_total2 = dfsales[['location_id', 'week_end_dt', 'fiscal_week_nbr',\n",
    "                         'class_gross_sales_amt']].groupby(['location_id', 'week_end_dt', 'fiscal_week_nbr']).sum()\n",
    "dfsales_total2.reset_index(inplace = True)\n",
    "\n",
    "dfsales_total = pd.merge(dfsales_total1,dfsales_total2,\n",
    "                        on = ['location_id', 'week_end_dt', 'fiscal_week_nbr'] ,\n",
    "                        how = 'outer')\n",
    "del dfsales_total1,dfsales_total2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfstore = pd.read_table('/home/jubauser1/BigLots/static_files/MediaStormStoresList_0913.txt',\n",
    "                        sep = '|',dtype = 'str')\n",
    "dfstore['open_dt'] = pd.to_datetime(dfstore['open_dt'])\n",
    "dfstore['open_dtwd'] = dfstore['open_dt'].dt.dayofweek\n",
    "dfstore['open_wk'] = np.where(dfstore['open_dtwd']<=5,\n",
    "                       dfstore['open_dt'].apply(lambda x:x+datetime.timedelta(days=(5-x.weekday()))),\n",
    "                       dfstore['open_dt'].apply(lambda x:x+datetime.timedelta(days=(12-x.weekday()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stores w/o detailed info: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "dfstorematch = dfsales_total[['location_id']].drop_duplicates()\n",
    "dfstorematch = pd.merge(dfstorematch,dfstore[['location_id','address_line_1']],\n",
    "                        on = 'location_id',how = 'left')\n",
    "dfstorematch['address_line_1'].fillna('empty',inplace = True)\n",
    "dfstorematch = dfstorematch[dfstorematch['address_line_1']=='empty']\n",
    "print(\"stores w/o detailed info: \")\n",
    "print(dfstorematch['location_id'].unique())\n",
    "del dfstorematch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_total = pd.merge(dfsales_total,dfstore[['location_id','open_wk']],\n",
    "                        on = 'location_id',how = 'left')\n",
    "dfsales_total['open_wk'].fillna(datetime.datetime.strptime(str(20200101), '%Y%m%d').date(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new traffic data column header matches:\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dftraffic = pd.read_csv(folderpath + 'combinedtraffic'+ lastweeksdate + '.csv',\n",
    "               sep = '|',dtype = 'str')\n",
    "\n",
    "df = pd.read_csv(newtrafficpath,sep = '|',dtype = 'str')\n",
    "a = df.columns\n",
    "print(\"new traffic data column header matches:\")\n",
    "print(a == ['location_id', 'week_end_dt', 'fiscal_week_nbr', 'traffic_day_1',\n",
    "       'traffic_day_2', 'traffic_day_3', 'traffic_day_4', 'traffic_day_5',\n",
    "       'traffic_day_6', 'traffic_day_7'])\n",
    "dftraffic = dftraffic.append(df,ignore_index = True)\n",
    "a = (len(dftraffic.index))\n",
    "dftraffic = dftraffic.drop_duplicates(['location_id', 'week_end_dt', 'fiscal_week_nbr'])\n",
    "b = (len(dftraffic.index))\n",
    "if a==b:\n",
    "    print(\"\")\n",
    "else:\n",
    "    print(\"last week traffic data duplication deduped\")\n",
    "dftraffic.to_csv(folderpath + 'combinedtraffic'+ recentweek + '.csv',index = False,sep = '|')\n",
    "\n",
    "dftraffic['traffic_week'] = 0 \n",
    "for i in ['traffic_day_1','traffic_day_2', 'traffic_day_3', 'traffic_day_4',\n",
    "          'traffic_day_5', 'traffic_day_6', 'traffic_day_7']:\n",
    "    dftraffic[i] = dftraffic[i].astype('float')\n",
    "    dftraffic['traffic_week'] = dftraffic['traffic_week'] +dftraffic[i]\n",
    "dftraffic['week_end_dt'] = pd.to_datetime(dftraffic['week_end_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new inventory data column header matches:\n",
      "[ True  True  True  True False]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfinventory = pd.read_csv(folderpath + 'combinedinventory'+ lastweeksdate + '.csv',\n",
    "               sep = '|',dtype = 'str')\n",
    "\n",
    "df = pd.read_csv(newinventorypath,sep = '|',dtype = 'str')\n",
    "a = df.columns\n",
    "print(\"new inventory data column header matches:\")\n",
    "print(a == ['location_id', 'week_end_dt', 'fiscal_week_nbr', 'class_code_id','on_hand'])\n",
    "df.columns = ['location_id', 'week_end_dt', 'fiscal_week_nbr', 'class_code_id','on_hand']\n",
    "dfinventory = dfinventory.append(df,ignore_index = True)\n",
    "a = (len(dfinventory.index))\n",
    "dfinventory = dfinventory.drop_duplicates(['location_id', 'week_end_dt', 'fiscal_week_nbr', 'class_code_id'])\n",
    "b = (len(dfinventory.index))\n",
    "if a==b:\n",
    "    print(\"\")\n",
    "else:\n",
    "    print(\"last week inventory data duplication deduped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfinventory.to_csv(folderpath + 'combinedinventory'+ recentweek + '.csv',index = False,sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfinventory['week_end_dt'] = pd.to_datetime(dfinventory['week_end_dt'])\n",
    "dfinventory['on_hand'] = dfinventory['on_hand'].astype('float')\n",
    "dfinventory_total = dfinventory.groupby(['location_id', 'week_end_dt', 'fiscal_week_nbr']).sum()\n",
    "dfinventory_total.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_total_recent = pd.merge(dfsales_total,\n",
    "                                dfweeklist[['week_end_dt', 'fiscal_week_nbr','weeklastyear','weeklastweek']],\n",
    "                                on= ['week_end_dt', 'fiscal_week_nbr'])\n",
    "\n",
    "dfsales_total_lastyear = pd.merge(dfsales_total,\n",
    "                                 dfweeklist[['weeklastyear']],\n",
    "                                 left_on= 'week_end_dt',right_on = 'weeklastyear')\n",
    "\n",
    "dfsales_total_lastyear = dfsales_total_lastyear[['location_id','gross_transaction_cnt', 'class_gross_sales_amt','weeklastyear']]\n",
    "dfsales_total_lastyear.columns = ['location_id','gross_transaction_cnt_ly', 'class_gross_sales_amt_ly','weeklastyear']\n",
    "\n",
    "dfsales_total_recent = pd.merge(dfsales_total_recent,dfsales_total_lastyear,\n",
    "                                on = ['location_id','weeklastyear'],how = 'outer')\n",
    "dfsales_total_recent.fillna(0,inplace = True)\n",
    "\n",
    "dfsales_total_recent['Store_Category'] = np.where(dfsales_total_recent['open_wk']>=dfsales_total_recent['weeklastyear'],'New',\n",
    "                                         np.where((dfsales_total_recent['gross_transaction_cnt_ly']==0)&(dfsales_total_recent['class_gross_sales_amt_ly']==0),\n",
    "                                         'Converted',\n",
    "                                         np.where((dfsales_total_recent['gross_transaction_cnt']==0)&(dfsales_total_recent['class_gross_sales_amt']==0),\n",
    "                                        'Converted','Complete')))\n",
    "\n",
    "dfsales_total_lastweek = pd.merge(dfsales_total,\n",
    "                                 dfweeklist[['weeklastweek']],\n",
    "                                 left_on= 'week_end_dt',right_on = 'weeklastweek')\n",
    "\n",
    "dfsales_total_lastweek = dfsales_total_lastweek[['location_id','gross_transaction_cnt', 'class_gross_sales_amt','weeklastweek']]\n",
    "dfsales_total_lastweek.columns = ['location_id','gross_transaction_cnt_lw', 'class_gross_sales_amt_lw','weeklastweek']\n",
    "dfsales_total_recent = pd.merge(dfsales_total_recent,dfsales_total_lastweek,\n",
    "                                on = ['location_id','weeklastweek'],how = 'left')\n",
    "dfsales_total_recent.fillna(0,inplace = True)\n",
    "\n",
    "dfsales_total_recent['week_end_dt'] = np.where(dfsales_total_recent['week_end_dt']=='1970-01-01',\n",
    "                                       dfsales_total_recent['weeklastyear'] + pd.DateOffset(364),\n",
    "                                       dfsales_total_recent['week_end_dt'])\n",
    "dfsales_total_recent['weeklastyear'] = np.where(dfsales_total_recent['weeklastyear']=='1970-01-01',\n",
    "                                       dfsales_total_recent['week_end_dt'] + pd.DateOffset(-364),\n",
    "                                       dfsales_total_recent['weeklastyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stores with no 2017&2016 sales and transaction data: 466\n",
      "Last Week: stores with no 2017&2016 sales and transaction data: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "dfallstorelist = dfstore[~dfstore['location_id'].isin(closed_onlinestorelist)]\n",
    "dfallstorelist.reset_index(drop = True, inplace = True)\n",
    "dfweeklist2 = dfweeklist.copy()\n",
    "dfallstorelist['concat'] = 1\n",
    "dfweeklist2['concat'] = 1\n",
    "dfallstorelist = pd.merge(dfallstorelist,dfweeklist2,on='concat')\n",
    "dfallstorelist = dfallstorelist[['location_id','week_end_dt']]\n",
    "dfallstorelist = pd.merge(dfallstorelist,dfsales_total_recent,on=['location_id','week_end_dt'],\n",
    "                         how = 'left')\n",
    "\n",
    "dfallstorelist.fillna(0,inplace = True)\n",
    "dfallstorelist = dfallstorelist[(dfallstorelist['gross_sales_amt']==0)&\\\n",
    "                               (dfallstorelist['gross_transaction_cnt']==0)&\\\n",
    "                               (dfallstorelist['class_gross_sales_amt']==0)&\\\n",
    "                               (dfallstorelist['gross_transaction_cnt_ly']==0)&\\\n",
    "                               (dfallstorelist['class_gross_sales_amt_ly']==0)]\n",
    "dfallstorelist = dfallstorelist.sort_values(['week_end_dt','location_id'],ascending = [0,1])\n",
    "dfallstorelist = dfallstorelist[['week_end_dt','location_id']]\n",
    "dfallstorelist.to_csv(outputpath + 'nobothyeardatastores.csv',index = False)\n",
    "print(\"stores with no 2017&2016 sales and transaction data: \" + str(len(dfallstorelist.index)))\n",
    "test = dfallstorelist[dfallstorelist['week_end_dt']==recentweek_date]\n",
    "print(\"Last Week: stores with no 2017&2016 sales and transaction data: \" + str(len(test.index)))\n",
    "del test,dfweeklist2,dfallstorelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_total_recent = pd.merge(dfsales_total_recent,dftraffic,\n",
    "                                on=['location_id', 'week_end_dt', 'fiscal_week_nbr'],how = 'left')\n",
    "\n",
    "dftraffic2 = dftraffic[['location_id', 'week_end_dt','traffic_day_1',\n",
    "       'traffic_day_2', 'traffic_day_3', 'traffic_day_4', 'traffic_day_5',\n",
    "       'traffic_day_6', 'traffic_day_7','traffic_week']]\n",
    "dftraffic2.columns = ['location_id', 'weeklastyear','traffic_day_1_ly',\n",
    "       'traffic_day_2_ly', 'traffic_day_3_ly', 'traffic_day_4_ly', 'traffic_day_5_ly',\n",
    "       'traffic_day_6_ly', 'traffic_day_7_ly','traffic_week_ly']\n",
    "\n",
    "dfsales_total_recent = pd.merge(dfsales_total_recent,dftraffic2,\n",
    "                                on=['location_id', 'weeklastyear'],how = 'left')\n",
    "del dftraffic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_total_recent = pd.merge(dfsales_total_recent,dfinventory_total,\n",
    "                                on=['location_id', 'week_end_dt', 'fiscal_week_nbr'],how = 'left')\n",
    "\n",
    "dfinventory_total2 = dfinventory_total[['location_id', 'week_end_dt','on_hand']]\n",
    "dfinventory_total2.columns = ['location_id', 'weeklastyear','on_hand_ly']\n",
    "\n",
    "dfsales_total_recent = pd.merge(dfsales_total_recent,dfinventory_total2,\n",
    "                                on=['location_id', 'weeklastyear'],how = 'left')\n",
    "del dfinventory_total2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recentweek_last=datetime.datetime.strptime(recentweek, '%Y-%m-%d').date()\n",
    "recentweek_last=recentweek_last+datetime.timedelta(days=(-84))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_total_recent['yoysales'] = dfsales_total_recent['class_gross_sales_amt']/dfsales_total_recent['class_gross_sales_amt_ly'] - 1\n",
    "dfsales_total_recent['yoytrans'] = dfsales_total_recent['gross_transaction_cnt']/dfsales_total_recent['gross_transaction_cnt_ly'] - 1\n",
    "dfsales_total_recent['wowsales'] = dfsales_total_recent['class_gross_sales_amt']/dfsales_total_recent['class_gross_sales_amt_lw'] - 1\n",
    "dfsales_total_recent['wowtrans'] = dfsales_total_recent['gross_transaction_cnt']/dfsales_total_recent['gross_transaction_cnt_lw'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stores with high yoy change: 1978\n",
      "Last Week: stores with high yoy change: 98\n"
     ]
    }
   ],
   "source": [
    "dfsales_total_recent_delete = dfsales_total_recent[(dfsales_total_recent['Store_Category']=='Complete')&\\\n",
    "                                                   ((abs(dfsales_total_recent['yoysales'])>0.2)&\\\n",
    "                                                   (abs(dfsales_total_recent['yoytrans'])>0.2))]#|\\\n",
    "                                                   #(abs(dfsales_total_recent['wowsales'])>0.2)|\\\n",
    "                                                   #(abs(dfsales_total_recent['wowtrans'])>0.2))]\n",
    "dfsales_total_recent_delete = dfsales_total_recent_delete.sort_values(['week_end_dt','location_id'],\n",
    "                                                                     ascending = [0,1])\n",
    "dfsales_total_recent_delete.to_csv(outputpath + 'highyoy_wowchangestores.csv',index = False)\n",
    "print(\"stores with high yoy change: \" + str(len(dfsales_total_recent_delete.index)))\n",
    "test = dfsales_total_recent_delete[dfsales_total_recent_delete['week_end_dt']==recentweek_date]\n",
    "print(\"Last Week: stores with high yoy change: \" + str(len(test.index)))\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dfsales_total_recent =  dfsales_total_recent[(dfsales_total_recent['gross_transaction_cnt']!=0)|\\\n",
    "#                                             (dfsales_total_recent['class_gross_sales_amt']!=0)]\n",
    "dfsales_total_recent = dfsales_total_recent[(dfsales_total_recent['Store_Category']!='Complete')|\\\n",
    "                                            ((dfsales_total_recent['Store_Category']=='Complete')&\\\n",
    "                                            (abs(dfsales_total_recent['yoysales'])<=0.2)|\\\n",
    "                                            (abs(dfsales_total_recent['yoytrans'])<=0.2))]#&\\\n",
    "                                            #(abs(dfsales_total_recent['wowsales'])<=0.2)&\\\n",
    "                                            #(abs(dfsales_total_recent['wowtrans'])<=0.2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dfweeklist2 = dfweeklist[['week_end_dt']]\n",
    "dfweeklist2['week_end_dt_8w'] = dfweeklist2['week_end_dt']+pd.DateOffset(-84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfweeklist_12plus = dfsales[['week_end_dt']].drop_duplicates()\n",
    "dfweeklist_12plus = dfweeklist_12plus.sort_values('week_end_dt',ascending = False)\n",
    "dfweeklist_12plus.reset_index(drop = True,inplace = True)\n",
    "dfweeklist_12plus.reset_index(inplace = True)\n",
    "dfweeklist_12plus = dfweeklist_12plus[dfweeklist_12plus['index']<64]\n",
    "dfweeklist_12plus['weeklastyear'] = dfweeklist_12plus['week_end_dt'] + pd.DateOffset(-364)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_12plus = pd.merge(dfsales_total,dfweeklist_12plus,on= ['week_end_dt'])\n",
    "\n",
    "dfsales_12plus_lastyear = pd.merge(dfsales_total,\n",
    "                                 dfweeklist_12plus[['weeklastyear']],\n",
    "                                 left_on= 'week_end_dt',right_on = 'weeklastyear')\n",
    "\n",
    "dfsales_12plus_lastyear = dfsales_12plus_lastyear[['location_id','gross_transaction_cnt', 'class_gross_sales_amt','weeklastyear']]\n",
    "dfsales_12plus_lastyear.columns = ['location_id','gross_transaction_cnt_ly', 'class_gross_sales_amt_ly','weeklastyear']\n",
    "\n",
    "dfsales_12plus = pd.merge(dfsales_12plus,dfsales_12plus_lastyear,\n",
    "                                on = ['location_id','weeklastyear'],how = 'left')\n",
    "dfsales_12plus.fillna(0,inplace = True)\n",
    "\n",
    "dfsales_12plus['Store_Category'] = np.where(dfsales_12plus['open_wk']>=dfsales_12plus['weeklastyear'],'New',\n",
    "                                         np.where((dfsales_12plus['gross_transaction_cnt_ly']==0)&(dfsales_12plus['class_gross_sales_amt_ly']==0),\n",
    "                                         'Converted',\n",
    "                                         np.where((dfsales_12plus['gross_transaction_cnt']==0)&(dfsales_12plus['class_gross_sales_amt']==0),\n",
    "                                        'Converted','Complete')))\n",
    "dfsales_12plus['yoysales'] = dfsales_12plus['class_gross_sales_amt']/dfsales_12plus['class_gross_sales_amt_ly'] - 1\n",
    "dfsales_12plus['yoytrans'] = dfsales_12plus['gross_transaction_cnt']/dfsales_12plus['gross_transaction_cnt_ly'] - 1\n",
    "dfsales_12plus = dfsales_12plus[(dfsales_12plus['Store_Category']!='Complete')|\\\n",
    "                                            ((dfsales_12plus['Store_Category']=='Complete')&\\\n",
    "                                            (abs(dfsales_12plus['yoysales'])<=0.2)|\\\n",
    "                                            (abs(dfsales_12plus['yoytrans'])<=0.2))]#&\\\n",
    "dfsales_12plus = dfsales_12plus[['location_id','week_end_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_rankingall = pd.DataFrame()\n",
    "for i in range(52):\n",
    "    cweekdate = dfweeklist2['week_end_dt'][i]\n",
    "    recentweek_last = dfweeklist2['week_end_dt_8w'][i]\n",
    "    dfsales_ranking = dfsales_total[dfsales_total['week_end_dt']>recentweek_last]\n",
    "    dfsales_ranking = dfsales_ranking[dfsales_ranking['week_end_dt']<=cweekdate]\n",
    "    dfsales_ranking = pd.merge(dfsales_ranking,dfsales_12plus,\n",
    "                           on = ['location_id', 'week_end_dt'])\n",
    "    dfsales_ranking = pd.merge(dfsales_ranking,\n",
    "                               dftraffic[['location_id', 'week_end_dt', 'fiscal_week_nbr','traffic_week']],\n",
    "                               on =['location_id', 'week_end_dt', 'fiscal_week_nbr'],how = 'left')\n",
    "    dfsales_ranking.fillna(0,inplace = True)\n",
    "    dfsales_ranking = dfsales_ranking[['location_id','class_gross_sales_amt','traffic_week']].groupby('location_id').sum()\n",
    "    dfsales_ranking['Rev/Traffic'] = dfsales_ranking['class_gross_sales_amt']/dfsales_ranking['traffic_week']\n",
    "    dfsales_ranking.reset_index(inplace = True)\n",
    "    dfsales_ranking = dfsales_ranking.sort_values('class_gross_sales_amt',ascending = False)\n",
    "    dfsales_ranking.reset_index(drop = True,inplace = True)\n",
    "    dfsales_ranking.reset_index(inplace = True)\n",
    "    dfsales_ranking = dfsales_ranking.rename(columns = {'index':'rev_index'})\n",
    "    dfsales_ranking = dfsales_ranking.replace(np.inf, 0)\n",
    "    \n",
    "    dfsales_ranking = dfsales_ranking.sort_values('Rev/Traffic',ascending = False)\n",
    "    dfsales_ranking.reset_index(drop = True,inplace = True)\n",
    "    dfsales_ranking.reset_index(inplace = True)\n",
    "    dfsales_ranking = dfsales_ranking.rename(columns = {'index':'traffi_index'})\n",
    "    \n",
    "    cols = len(dfsales_ranking.index)\n",
    "    dfsales_ranking['Store_Revenue_Rank'] = np.where(dfsales_ranking['rev_index']/cols <=0.2,'H',\n",
    "                                                    np.where(dfsales_ranking['rev_index']/cols <=0.8,'M','L'))\n",
    "    dfsales_ranking['Store_Revenue/Traffic_Rank'] = np.where(dfsales_ranking['traffi_index']/cols <=0.2,'H',\n",
    "                                                    np.where(dfsales_ranking['traffi_index']/cols <=0.8,'M','L'))\n",
    "    dfsales_ranking['week_end_dt'] = cweekdate\n",
    "    dfsales_rankingall = dfsales_rankingall.append(dfsales_ranking,ignore_index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_total_recent.fillna(0,inplace = True)\n",
    "dfsales_total_recent.reset_index(drop = True,inplace = True)\n",
    "dfsales_total_recent = pd.merge(dfsales_total_recent,\n",
    "                                dfsales_rankingall[['location_id','week_end_dt','Store_Revenue_Rank','Store_Revenue/Traffic_Rank']],\n",
    "                                on = ['location_id','week_end_dt'],how = 'left')\n",
    "dfsales_total_recent['Store_Revenue_Rank'].fillna('NA',inplace = True)\n",
    "dfsales_total_recent['Store_Revenue/Traffic_Rank'].fillna('NA',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_total_recent['AOV'] = dfsales_total_recent['class_gross_sales_amt']/dfsales_total_recent['gross_transaction_cnt']\n",
    "dfsales_total_recent['AOV_ly'] = dfsales_total_recent['class_gross_sales_amt_ly']/dfsales_total_recent['gross_transaction_cnt_ly']\n",
    "dfsales_total_recent['Trans/Traffic'] = dfsales_total_recent['gross_transaction_cnt']/dfsales_total_recent['traffic_week']\n",
    "dfsales_total_recent['Trans/Traffic_ly'] = dfsales_total_recent['gross_transaction_cnt_ly']/dfsales_total_recent['traffic_week_ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Complete', 'Converted', 'New'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsales_total_recent['Store_Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "df_complete = dfsales_total_recent[dfsales_total_recent['Store_Category']=='Complete']\n",
    "df_complete.reset_index(drop = True, inplace = True)\n",
    "metricslist = ['class_gross_sales_amt','gross_transaction_cnt','AOV','traffic_week',\n",
    "              'Trans/Traffic', 'traffic_day_1', 'traffic_day_2', 'traffic_day_3',\n",
    "              'traffic_day_4', 'traffic_day_5', 'traffic_day_6', 'traffic_day_7','on_hand']\n",
    "columnheader = ['location_id', 'week_end_dt', 'fiscal_week_nbr', 'Store_Revenue_Rank', 'Store_Revenue/Traffic_Rank']\n",
    "for i in metricslist:\n",
    "    a = i+'_ly'\n",
    "    b = i+ 'YoYDiff'\n",
    "    columnheader = columnheader + [i,a,b]\n",
    "    df_complete[b] = df_complete[i]/df_complete[a] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del dfstore['open_dtwd']\n",
    "del dfstore['open_wk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dma = pd.read_csv('/home/jubauser1/BiglotsCode/OtherInput/zipdmamapping.csv',dtype = 'str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfstore['zip_cd'] = dfstore['zip_cd'].str[0:5]\n",
    "dfstore = pd.merge(dfstore,dma,on = 'zip_cd',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_complete = df_complete[columnheader]\n",
    "df_complete = pd.merge(df_complete,dfstore,on='location_id',how = 'left')\n",
    "df_complete = df_complete.sort_values(['location_id','week_end_dt'],ascending = [1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = dfsales_total_recent[dfsales_total_recent['Store_Category']=='New']\n",
    "df_new = df_new[['location_id', 'week_end_dt', 'fiscal_week_nbr',\n",
    "                 'Store_Revenue_Rank', 'Store_Revenue/Traffic_Rank',\n",
    "                 'class_gross_sales_amt','gross_transaction_cnt','AOV','traffic_week',\n",
    "                 'Trans/Traffic','on_hand','Store_Category']]\n",
    "df_new = pd.merge(df_new,dfstore,on='location_id',how = 'left')\n",
    "df_new = df_new.sort_values(['location_id','week_end_dt'],ascending = [1,0])\n",
    "del df_new['Store_Category']\n",
    "df_new.to_csv(outputpath + 'output2_new.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Complete', 'Converted', 'New'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsales_total_recent['Store_Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_converted = dfsales_total_recent[dfsales_total_recent['Store_Category']=='Converted']\n",
    "del df_converted['fiscal_week_nbr']\n",
    "df_converted['week_end_dt'] = np.where(df_converted['week_end_dt']=='1970-01-01',\n",
    "                                       df_converted['weeklastyear'] + pd.DateOffset(364),\n",
    "                                       df_converted['week_end_dt'])\n",
    "df_converted['weeklastyear'] = np.where(df_converted['weeklastyear']=='1970-01-01',\n",
    "                                       df_converted['week_end_dt'] + pd.DateOffset(-364),\n",
    "                                       df_converted['weeklastyear'])\n",
    "\n",
    "df_converted = pd.merge(df_converted,dfweeklist[['week_end_dt','fiscal_week_nbr']],\n",
    "                       on = 'week_end_dt',how='left')\n",
    "df_converted = df_converted[['location_id', 'week_end_dt', 'fiscal_week_nbr',\n",
    "                 'Store_Revenue_Rank', 'Store_Revenue/Traffic_Rank',\n",
    "                 'class_gross_sales_amt','gross_transaction_cnt','AOV','traffic_week',\n",
    "                 'Trans/Traffic','on_hand','Store_Category',\n",
    "                 'weeklastyear','gross_transaction_cnt_ly','class_gross_sales_amt_ly']]\n",
    "df_converted = pd.merge(df_converted,dfstore,on='location_id',how = 'left')\n",
    "df_converted = df_converted.sort_values(['location_id','week_end_dt'],ascending = [1,0])\n",
    "\n",
    "\n",
    "\n",
    "del df_converted['Store_Category']\n",
    "df_converted.to_csv(outputpath + 'output3_converted.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tradearea = pd.read_csv('/home/jubauser1/BiglotsCode/OtherInput/revised_trade_area_5_mile_using_zip_center.csv',dtype = 'str')\n",
    "\n",
    "df_tradearea_all = pd.DataFrame()\n",
    "for i in (range(len(df_tradearea.index))):\n",
    "    a = df_tradearea['stores'][i]\n",
    "    b = df_tradearea['trade_area_code'][i]\n",
    "    a = a.replace('[','')\n",
    "    a = a.replace(']','')\n",
    "    for c in range(a.count(',')+1):\n",
    "        df_tradearea_all = df_tradearea_all.append({'location_id': (a.split(',')[c]), 'trade_area_code': b}, ignore_index=True)\n",
    "df_tradearea_all['location_id'] = df_tradearea_all['location_id'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tradearea_all.to_csv('/home/jubauser1/BiglotsCode/OtherInput/talist.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_complete = pd.merge(df_complete,df_tradearea_all,on ='location_id',how = 'left')\n",
    "df_complete['trade_area_code'].fillna('NA',inplace = True)\n",
    "df_complete.to_csv(outputpath + 'output1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_complete.to_csv(outputpath + 'output1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tadata = df_complete.groupby(['week_end_dt', 'fiscal_week_nbr','trade_area_code']).sum()\n",
    "df_tadata.reset_index(inplace = True)\n",
    "\n",
    "df_tadata['AOV'] = df_tadata['class_gross_sales_amt']/df_tadata['gross_transaction_cnt']\n",
    "df_tadata['AOV_ly'] = df_tadata['class_gross_sales_amt_ly']/df_tadata['gross_transaction_cnt_ly']\n",
    "df_tadata['Trans/Traffic'] = df_tadata['gross_transaction_cnt']/df_tadata['traffic_week']\n",
    "df_tadata['Trans/Traffic_ly'] = df_tadata['gross_transaction_cnt_ly']/df_tadata['traffic_week_ly']\n",
    "\n",
    "metricslist = ['class_gross_sales_amt','gross_transaction_cnt','AOV','traffic_week',\n",
    "              'Trans/Traffic', 'traffic_day_1', 'traffic_day_2', 'traffic_day_3',\n",
    "              'traffic_day_4', 'traffic_day_5', 'traffic_day_6', 'traffic_day_7','on_hand']\n",
    "for i in metricslist:\n",
    "    a = i+'_ly'\n",
    "    b = i+ 'YoYDiff'\n",
    "    df_tadata[b] = df_tadata[i]/df_tadata[a] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_taclass1 = df_complete[['location_id','trade_area_code','week_end_dt','Store_Revenue_Rank',\n",
    "                           'Store_Revenue/Traffic_Rank']]\n",
    "df_taclass1.reset_index(drop = True, inplace = True)\n",
    "df_taclass1['Number_of_HMStores'] = np.where(df_taclass1['Store_Revenue_Rank']!='L',1,0)\n",
    "df_taclass1['Number_of_HMStores_RevTrafRank'] = np.where(df_taclass1['Store_Revenue/Traffic_Rank']!='L',1,0)\n",
    "df_taclass1['Number of Stores'] = 1\n",
    "df_taclass1 = df_taclass1.groupby(['trade_area_code','week_end_dt']).sum()\n",
    "df_taclass1.reset_index(inplace = True)\n",
    "\n",
    "df_taclass2 = df_complete[['trade_area_code','week_end_dt','zip_cd']].drop_duplicates()\n",
    "df_taclass2 = df_taclass2.groupby(['trade_area_code','week_end_dt']).count()\n",
    "df_taclass2.columns = ['NumberofZipcodes']\n",
    "df_taclass2.reset_index(inplace = True)\n",
    "\n",
    "df_taclass3 = df_complete[['trade_area_code','state_nm']].drop_duplicates(['trade_area_code'])\n",
    "\n",
    "df_tadata = pd.merge(df_tadata,df_taclass1,on =['trade_area_code','week_end_dt'])\n",
    "df_tadata = pd.merge(df_tadata,df_taclass2,on =['trade_area_code','week_end_dt'])\n",
    "df_tadata = pd.merge(df_tadata,df_taclass3,on =['trade_area_code'])\n",
    "\n",
    "df_tadata = df_tadata.sort_values(['trade_area_code','week_end_dt'],ascending = [1,0])\n",
    "df_tadata.to_csv(outputpath + 'output4.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dmadata = df_complete.groupby(['week_end_dt', 'fiscal_week_nbr','DMA']).sum()\n",
    "df_dmadata.reset_index(inplace = True)\n",
    "\n",
    "df_dmadata['AOV'] = df_dmadata['class_gross_sales_amt']/df_dmadata['gross_transaction_cnt']\n",
    "df_dmadata['AOV_ly'] = df_dmadata['class_gross_sales_amt_ly']/df_dmadata['gross_transaction_cnt_ly']\n",
    "df_dmadata['Trans/Traffic'] = df_dmadata['gross_transaction_cnt']/df_dmadata['traffic_week']\n",
    "df_dmadata['Trans/Traffic_ly'] = df_dmadata['gross_transaction_cnt_ly']/df_dmadata['traffic_week_ly']\n",
    "\n",
    "metricslist = ['class_gross_sales_amt','gross_transaction_cnt','AOV','traffic_week',\n",
    "              'Trans/Traffic', 'traffic_day_1', 'traffic_day_2', 'traffic_day_3',\n",
    "              'traffic_day_4', 'traffic_day_5', 'traffic_day_6', 'traffic_day_7','on_hand']\n",
    "for i in metricslist:\n",
    "    a = i+'_ly'\n",
    "    b = i+ 'YoYDiff'\n",
    "    df_dmadata[b] = df_dmadata[i]/df_dmadata[a] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_dmadata1 = df_complete[['location_id','DMA','week_end_dt','Store_Revenue_Rank',\n",
    "                           'Store_Revenue/Traffic_Rank']]\n",
    "df_dmadata1.reset_index(drop = True, inplace = True)\n",
    "df_dmadata1['Number_of_HMStores'] = np.where(df_dmadata1['Store_Revenue_Rank']!='L',1,0)\n",
    "df_dmadata1['Number_of_HMStores_RevTrafRank'] = np.where(df_dmadata1['Store_Revenue/Traffic_Rank']!='L',1,0)\n",
    "df_dmadata1['Number of Stores'] = 1\n",
    "df_dmadata1 = df_dmadata1.groupby(['DMA','week_end_dt']).sum()\n",
    "df_dmadata1.reset_index(inplace = True)\n",
    "\n",
    "df_dmadata2 = df_complete[['DMA','week_end_dt','zip_cd']].drop_duplicates()\n",
    "df_dmadata2 = df_dmadata2.groupby(['DMA','week_end_dt']).count()\n",
    "df_dmadata2.columns = ['NumberofZipcodes']\n",
    "df_dmadata2.reset_index(inplace = True)\n",
    "\n",
    "df_dmadata4 = df_complete[['DMA','week_end_dt','trade_area_code']].drop_duplicates()\n",
    "df_dmadata4 = df_dmadata4.groupby(['DMA','week_end_dt']).count()\n",
    "df_dmadata4.columns = ['NumberofTAs']\n",
    "df_dmadata4.reset_index(inplace = True)\n",
    "\n",
    "df_dmadata3 = df_complete[['DMA','state_nm']].drop_duplicates(['DMA'])\n",
    "\n",
    "df_dmadata = pd.merge(df_dmadata,df_dmadata1,on =['DMA','week_end_dt'])\n",
    "df_dmadata = pd.merge(df_dmadata,df_dmadata2,on =['DMA','week_end_dt'])\n",
    "df_dmadata = pd.merge(df_dmadata,df_dmadata4,on =['DMA','week_end_dt'])\n",
    "df_dmadata = pd.merge(df_dmadata,df_dmadata3,on =['DMA'])\n",
    "\n",
    "df_dmadata = df_dmadata.sort_values(['DMA','week_end_dt'],ascending = [1,0])\n",
    "df_dmadata.to_csv(outputpath + 'output5.csv',index = False)\n",
    "del df_dmadata1,df_dmadata2,df_dmadata3,df_dmadata4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_storeweeklist = pd.merge(df_complete[['location_id', 'week_end_dt']],\n",
    "                            dfweeklist[['week_end_dt','weeklastyear']],on ='week_end_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsales_class1 = pd.merge(dfsales[['location_id', 'week_end_dt','class_code_id','class_gross_sales_amt']],\n",
    "                          df_storeweeklist,\n",
    "                          on = ['location_id', 'week_end_dt'])\n",
    "dfsales_class2 = pd.merge(dfsales[['location_id', 'week_end_dt', 'class_code_id','class_gross_sales_amt']],\n",
    "                          df_storeweeklist,\n",
    "                          left_on = ['location_id', 'week_end_dt'],\n",
    "                          right_on = ['location_id', 'weeklastyear'])\n",
    "\n",
    "del dfsales_class2['week_end_dt_x']\n",
    "dfsales_class2 = dfsales_class2.rename(columns = {'week_end_dt_y':'week_end_dt'})\n",
    "\n",
    "dfsales_class1 = pd.merge(dfsales_class1,dfsales_class2,\n",
    "                          on =['location_id','week_end_dt','class_code_id'],how='outer')\n",
    "dfsales_class1.fillna(0,inplace = True)\n",
    "del dfsales_class2\n",
    "del dfsales_class1['weeklastyear_x']\n",
    "del dfsales_class1['weeklastyear_y']\n",
    "dfsales_class1 = dfsales_class1.rename(columns = {'class_gross_sales_amt_x':'class_gross_sales_amt'})\n",
    "dfsales_class1 = dfsales_class1.rename(columns = {'class_gross_sales_amt_y':'class_gross_sales_amt_ly'})\n",
    "dfsales_class1['class_gross_sales_amt_yoy'] = dfsales_class1['class_gross_sales_amt']/dfsales_class1['class_gross_sales_amt_ly'] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfinventory_class1 = pd.merge(dfinventory[['location_id', 'week_end_dt', 'class_code_id','on_hand']], \n",
    "                              df_storeweeklist,\n",
    "                          on = ['location_id', 'week_end_dt'])\n",
    "dfinventory_class2 = pd.merge(dfinventory[['location_id', 'week_end_dt', 'class_code_id','on_hand']],\n",
    "                          df_storeweeklist,\n",
    "                          left_on = ['location_id', 'week_end_dt'],\n",
    "                          right_on = ['location_id', 'weeklastyear'])\n",
    "\n",
    "del dfinventory_class2['week_end_dt_x']\n",
    "dfinventory_class2 = dfinventory_class2.rename(columns = {'week_end_dt_y':'week_end_dt'})\n",
    "\n",
    "dfinventory_class1 = pd.merge(dfinventory_class1,dfinventory_class2,\n",
    "                          on =['location_id','week_end_dt','class_code_id'],how='outer')\n",
    "dfinventory_class1.fillna(0,inplace = True)\n",
    "del dfinventory_class2\n",
    "del dfinventory_class1['weeklastyear_x']\n",
    "del dfinventory_class1['weeklastyear_y']\n",
    "dfinventory_class1 = dfinventory_class1.rename(columns = {'on_hand_x':'on_hand'})\n",
    "dfinventory_class1 = dfinventory_class1.rename(columns = {'on_hand_y':'on_hand_ly'})\n",
    "dfinventory_class1['on_hand_yoy'] = dfinventory_class1['on_hand']/dfinventory_class1['on_hand_ly'] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tadetail = pd.merge(dfsales_class1,dfinventory_class1,\n",
    "                      on=['location_id','week_end_dt','class_code_id'],how='outer')\n",
    "df_tadetail = pd.merge(df_tadetail,df_tradearea_all,on ='location_id',how = 'left')\n",
    "df_tadetail['trade_area_code'].fillna('NA',inplace = True)\n",
    "df_tadetail.fillna(0,inplace = True)\n",
    "\n",
    "df_tadetail = df_tadetail.groupby(['trade_area_code','week_end_dt','class_code_id']).sum()\n",
    "df_tadetail['class_gross_sales_amt_yoy'] = df_tadetail['class_gross_sales_amt']/df_tadetail['class_gross_sales_amt_ly'] -1\n",
    "df_tadetail['on_hand_yoy'] = df_tadetail['on_hand']/df_tadetail['on_hand_ly'] -1\n",
    "df_tadetail.reset_index(inplace = True)\n",
    "\n",
    "df_tadetail = pd.merge(df_tadetail,df_taclass1,on =['trade_area_code','week_end_dt'])\n",
    "df_tadetail = pd.merge(df_tadetail,df_taclass2,on =['trade_area_code','week_end_dt'])\n",
    "df_tadetail = pd.merge(df_tadetail,df_taclass3,on =['trade_area_code'])\n",
    "df_tadetail = pd.merge(dfweeklist[['week_end_dt','fiscal_week_nbr']],df_tadetail,\n",
    "                      on ='week_end_dt')\n",
    "df_tadetail.to_csv(outputpath + 'output4_classdetail.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(outputpath+'BigLots_Weekly_Data_'+recentweek+'.xlsx',\n",
    "                            #engine='xlsxwriter',\n",
    "                            datetime_format='yyyy-mm-dd',\n",
    "                            date_format='yyyy-mm-dd')\n",
    "test = dfsales_total[['location_id', 'week_end_dt', 'fiscal_week_nbr', 'gross_transaction_cnt']]\n",
    "test = test.sort_values(['location_id', 'week_end_dt'])\n",
    "test.to_excel(writer,'Transactions', index=False)\n",
    "test = dfsales_total[['location_id', 'week_end_dt', 'fiscal_week_nbr', 'class_gross_sales_amt']]\n",
    "test = test.sort_values(['location_id', 'week_end_dt'])\n",
    "test.to_excel(writer,'Revenue', index=False)\n",
    "dftraffic = dftraffic[~dftraffic['location_id'].isin(closed_onlinestorelist)]\n",
    "dftraffic = dftraffic.sort_values(['location_id', 'week_end_dt'])\n",
    "dfinventory_total = dfinventory_total[~dfinventory_total['location_id'].isin(closed_onlinestorelist)]\n",
    "dfinventory_total = dfinventory_total.sort_values(['location_id', 'week_end_dt'])\n",
    "dftraffic.to_excel(writer,'Traffic', index=False)\n",
    "dfinventory_total.to_excel(writer,'Inventory', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_complete_week = df_complete[df_complete['week_end_dt']==recentweek_date]\n",
    "df_complete_week.to_csv(outputpath + 'output1_' + recentweek + '.csv',index = False)\n",
    "\n",
    "df_tadetail_week = df_tadetail[df_tadetail['week_end_dt']==recentweek_date]\n",
    "df_tadetail_week.to_csv(outputpath + 'output4_classdetail_' + recentweek + '.csv',index = False)\n",
    "\n",
    "df_dmadata_week = df_dmadata[df_dmadata['week_end_dt']==recentweek_date]\n",
    "df_dmadata_week.to_csv(outputpath + 'output5_' + recentweek + '.csv',index = False)\n",
    "\n",
    "df_tadata_week = df_tadata[df_tadata['week_end_dt']==recentweek_date]\n",
    "df_tadata_week.to_csv(outputpath + 'output4_' + recentweek + '.csv',index = False)\n",
    "\n",
    "df_converted_week = df_converted[df_converted['week_end_dt']==recentweek_date]\n",
    "df_converted_week.to_csv(outputpath + 'output3_converted_' + recentweek + '.csv',index = False)\n",
    "\n",
    "df_new_week = df_new[df_new['week_end_dt']==recentweek_date]\n",
    "df_new_week.to_csv(outputpath + 'output2_new_' + recentweek + '.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_complete_week = df_complete_week[['location_id', 'week_end_dt', 'fiscal_week_nbr', \n",
    "                                     'location_desc', 'open_dt',\n",
    "                   'address_line_1', 'address_line_2', 'city_nm', 'state_nm', 'zip_cd',\n",
    "                   'longitude_meas', 'latitude_meas', 'DMA', 'trade_area_code',\n",
    "                   'class_gross_sales_amt',\n",
    "                   'class_gross_sales_amt_ly', 'class_gross_sales_amtYoYDiff',\n",
    "                   'gross_transaction_cnt', 'gross_transaction_cnt_ly','gross_transaction_cntYoYDiff',\n",
    "                   'Trans/Traffic', 'Trans/Traffic_ly', 'Trans/TrafficYoYDiff',\n",
    "                   'traffic_week', 'traffic_week_ly', 'traffic_weekYoYDiff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_complete_week1 = df_complete_week.sort_values(['gross_transaction_cntYoYDiff'],ascending = True)\n",
    "df_complete_week1 = df_complete_week1[df_complete_week1['gross_transaction_cntYoYDiff']<=-0.1]\n",
    "\n",
    "df_complete_week2 = df_complete_week.sort_values(['Trans/TrafficYoYDiff'],ascending = True)\n",
    "df_complete_week2 = df_complete_week2[df_complete_week2['Trans/TrafficYoYDiff']<=-0.1]\n",
    "\n",
    "df_complete_week3 = df_complete_week.sort_values(['traffic_weekYoYDiff'],ascending = True)\n",
    "df_complete_week3 = df_complete_week3[df_complete_week3['traffic_weekYoYDiff']<=-0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "writer = pd.ExcelWriter(outputpath+'Output1Tracker_'+recentweek+'.xlsx',\n",
    "                            engine='xlsxwriter',\n",
    "                            datetime_format='yyyy-mm-dd',\n",
    "                            date_format='yyyy-mm-dd')\n",
    "\n",
    "workbook  = writer.book\n",
    "\n",
    "format1 = workbook.add_format({'num_format': '#,##0'})\n",
    "format2 = workbook.add_format({'text_wrap' : True})\n",
    "format3 = workbook.add_format({'num_format': '0.0%'})\n",
    "format4 = workbook.add_format({'num_format': '0.0%',\n",
    "                               'bg_color': 'FF9999'})\n",
    "\n",
    "df_complete_week1.to_excel(writer,'TransactionTracker', index=False)\n",
    "worksheet = writer.sheets['TransactionTracker']\n",
    "worksheet.set_row(0,None, format2)\n",
    "worksheet.set_column('B:B', 12, None)\n",
    "worksheet.set_column('E:E', 12, None)\n",
    "worksheet.set_column('F:F', 16, None)\n",
    "worksheet.set_column('O:Y', None, format1)\n",
    "worksheet.set_column('Q:Q', None, format3)\n",
    "worksheet.set_column('T:T', None, format4)\n",
    "worksheet.set_column('W:W', None, format3)\n",
    "worksheet.set_column('Z:Z', None, format3)\n",
    "worksheet.set_column('U:V', None, format3)\n",
    "\n",
    "df_complete_week2.to_excel(writer,'ConversionTracker', index=False)\n",
    "worksheet = writer.sheets['ConversionTracker']\n",
    "worksheet.set_column('B:B', 12, None)\n",
    "worksheet.set_column('E:E', 12, None)\n",
    "worksheet.set_column('F:F', 16, None)\n",
    "worksheet.set_column('O:Y', None, format1)\n",
    "worksheet.set_column('Q:Q', None, format3)\n",
    "worksheet.set_column('T:T', None, format3)\n",
    "worksheet.set_column('W:W', None, format4)\n",
    "worksheet.set_column('Z:Z', None, format3)\n",
    "worksheet.set_column('U:V', None, format3)\n",
    "\n",
    "df_complete_week3.to_excel(writer,'TrafficTracker', index=False)\n",
    "worksheet = writer.sheets['TrafficTracker']\n",
    "worksheet.set_column('B:B', 12, None)\n",
    "worksheet.set_column('E:E', 12, None)\n",
    "worksheet.set_column('F:F', 16, None)\n",
    "worksheet.set_column('O:Y', None, format1)\n",
    "worksheet.set_column('Q:Q', None, format3)\n",
    "worksheet.set_column('T:T', None, format3)\n",
    "worksheet.set_column('W:W', None, format3)\n",
    "worksheet.set_column('Z:Z', None, format4)\n",
    "worksheet.set_column('U:V', None, format3)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_complete_week = df_tadata_week[['trade_area_code', 'week_end_dt', 'fiscal_week_nbr', \n",
    "                                     'Number_of_HMStores', 'Number_of_HMStores_RevTrafRank',\n",
    "                   'Number of Stores', 'NumberofZipcodes', 'state_nm',\n",
    "                   'class_gross_sales_amt',\n",
    "                   'class_gross_sales_amt_ly', 'class_gross_sales_amtYoYDiff',\n",
    "                   'gross_transaction_cnt', 'gross_transaction_cnt_ly','gross_transaction_cntYoYDiff',\n",
    "                   'Trans/Traffic', 'Trans/Traffic_ly', 'Trans/TrafficYoYDiff',\n",
    "                   'traffic_week', 'traffic_week_ly', 'traffic_weekYoYDiff']]\n",
    "\n",
    "df_complete_week1 = df_complete_week.sort_values(['gross_transaction_cntYoYDiff'],ascending = True)\n",
    "df_complete_week1 = df_complete_week1[df_complete_week1['gross_transaction_cntYoYDiff']<=-0.1]\n",
    "\n",
    "df_complete_week2 = df_complete_week.sort_values(['Trans/TrafficYoYDiff'],ascending = True)\n",
    "df_complete_week2 = df_complete_week2[df_complete_week2['Trans/TrafficYoYDiff']<=-0.1]\n",
    "\n",
    "df_complete_week3 = df_complete_week.sort_values(['traffic_weekYoYDiff'],ascending = True)\n",
    "df_complete_week3 = df_complete_week3[df_complete_week3['traffic_weekYoYDiff']<=-0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "writer = pd.ExcelWriter(outputpath+'Output4Tracker_'+recentweek+'.xlsx',\n",
    "                            engine='xlsxwriter',\n",
    "                            datetime_format='yyyy-mm-dd',\n",
    "                            date_format='yyyy-mm-dd')\n",
    "\n",
    "workbook  = writer.book\n",
    "\n",
    "format1 = workbook.add_format({'num_format': '#,##0'})\n",
    "format2 = workbook.add_format({'text_wrap' : True})\n",
    "format3 = workbook.add_format({'num_format': '0.0%'})\n",
    "format4 = workbook.add_format({'num_format': '0.0%',\n",
    "                               'bg_color': 'FF9999'})\n",
    "\n",
    "df_complete_week1.to_excel(writer,'TransactionTracker', index=False)\n",
    "worksheet = writer.sheets['TransactionTracker']\n",
    "worksheet.set_column('B:B', 12, None)\n",
    "worksheet.set_column('I:S', None, format1)\n",
    "worksheet.set_column('K:K', None, format3)\n",
    "worksheet.set_column('N:N', None, format4)\n",
    "worksheet.set_column('Q:Q', None, format3)\n",
    "worksheet.set_column('T:T', None, format3)\n",
    "worksheet.set_column('O:P', None, format3)\n",
    "\n",
    "df_complete_week2.to_excel(writer,'ConversionTracker', index=False)\n",
    "worksheet = writer.sheets['ConversionTracker']\n",
    "worksheet.set_column('B:B', 12, None)\n",
    "worksheet.set_column('I:S', None, format1)\n",
    "worksheet.set_column('K:K', None, format3)\n",
    "worksheet.set_column('N:N', None, format3)\n",
    "worksheet.set_column('Q:Q', None, format4)\n",
    "worksheet.set_column('T:T', None, format3)\n",
    "worksheet.set_column('O:P', None, format3)\n",
    "\n",
    "df_complete_week3.to_excel(writer,'TrafficTracker', index=False)\n",
    "worksheet = writer.sheets['TrafficTracker']\n",
    "worksheet.set_column('B:B', 12, None)\n",
    "worksheet.set_column('I:S', None, format1)\n",
    "worksheet.set_column('K:K', None, format3)\n",
    "worksheet.set_column('N:N', None, format3)\n",
    "worksheet.set_column('Q:Q', None, format3)\n",
    "worksheet.set_column('T:T', None, format4)\n",
    "worksheet.set_column('O:P', None, format3)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_complete_week = df_dmadata_week[['DMA', 'week_end_dt', 'fiscal_week_nbr', \n",
    "                                     'Number_of_HMStores',\n",
    "                     'Number_of_HMStores_RevTrafRank', 'Number of Stores',\n",
    "                     'NumberofZipcodes', 'NumberofTAs', 'state_nm',\n",
    "                   'class_gross_sales_amt',\n",
    "                   'class_gross_sales_amt_ly', 'class_gross_sales_amtYoYDiff',\n",
    "                   'gross_transaction_cnt', 'gross_transaction_cnt_ly','gross_transaction_cntYoYDiff',\n",
    "                   'Trans/Traffic', 'Trans/Traffic_ly', 'Trans/TrafficYoYDiff',\n",
    "                   'traffic_week', 'traffic_week_ly', 'traffic_weekYoYDiff']]\n",
    "\n",
    "df_complete_week1 = df_complete_week.sort_values(['gross_transaction_cntYoYDiff'],ascending = True)\n",
    "df_complete_week1 = df_complete_week1[df_complete_week1['gross_transaction_cntYoYDiff']<=-0.1]\n",
    "\n",
    "df_complete_week2 = df_complete_week.sort_values(['Trans/TrafficYoYDiff'],ascending = True)\n",
    "df_complete_week2 = df_complete_week2[df_complete_week2['Trans/TrafficYoYDiff']<=-0.1]\n",
    "\n",
    "df_complete_week3 = df_complete_week.sort_values(['traffic_weekYoYDiff'],ascending = True)\n",
    "df_complete_week3 = df_complete_week3[df_complete_week3['traffic_weekYoYDiff']<=-0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(outputpath+'Output5Tracker_'+recentweek+'.xlsx',\n",
    "                            engine='xlsxwriter',\n",
    "                            datetime_format='yyyy-mm-dd',\n",
    "                            date_format='yyyy-mm-dd')\n",
    "\n",
    "workbook  = writer.book\n",
    "\n",
    "format1 = workbook.add_format({'num_format': '#,##0'})\n",
    "format2 = workbook.add_format({'text_wrap' : True})\n",
    "format3 = workbook.add_format({'num_format': '0.0%'})\n",
    "format4 = workbook.add_format({'num_format': '0.0%',\n",
    "                               'bg_color': 'FF9999'})\n",
    "\n",
    "df_complete_week1.to_excel(writer,'TransactionTracker', index=False)\n",
    "worksheet = writer.sheets['TransactionTracker']\n",
    "worksheet.set_column('B:B', 12, None)\n",
    "worksheet.set_column('J:T', None, format1)\n",
    "worksheet.set_column('L:L', None, format3)\n",
    "worksheet.set_column('O:O', None, format4)\n",
    "worksheet.set_column('R:R', None, format3)\n",
    "worksheet.set_column('U:U', None, format3)\n",
    "worksheet.set_column('P:Q', None, format3)\n",
    "\n",
    "df_complete_week2.to_excel(writer,'ConversionTracker', index=False)\n",
    "worksheet = writer.sheets['ConversionTracker']\n",
    "worksheet.set_column('B:B', 12, None)\n",
    "worksheet.set_column('J:T', None, format1)\n",
    "worksheet.set_column('L:L', None, format3)\n",
    "worksheet.set_column('O:O', None, format3)\n",
    "worksheet.set_column('R:R', None, format4)\n",
    "worksheet.set_column('U:U', None, format3)\n",
    "worksheet.set_column('P:Q', None, format3)\n",
    "\n",
    "df_complete_week3.to_excel(writer,'TrafficTracker', index=False)\n",
    "worksheet = writer.sheets['TrafficTracker']\n",
    "worksheet.set_column('B:B', 12, None)\n",
    "worksheet.set_column('J:T', None, format1)\n",
    "worksheet.set_column('L:L', None, format3)\n",
    "worksheet.set_column('O:O', None, format3)\n",
    "worksheet.set_column('R:R', None, format3)\n",
    "worksheet.set_column('U:U', None, format4)\n",
    "worksheet.set_column('P:Q', None, format3)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
