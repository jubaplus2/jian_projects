{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/clients/juba/hqjubaapp02/sharefolder/GoodYear/jian/TA_creation\n",
      "2020-10-23 15:02:21.302294\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "from haversine import haversine\n",
    "from google.cloud import bigquery\n",
    "import glob\n",
    "import json\n",
    "import gc\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/mnt/clients/juba/hqjubaapp02/sharefolder/GoodYear/docs/merkle-gdyr-prod-9783607c77a1.json\"\n",
    "\n",
    "pd.options.display.max_columns=70\n",
    "zip_centers=json.load(open(\"/mnt/clients/juba/hqjubaapp02/sharefolder/Docs/Geo_mapping/updated_zip_centers_JL_2019-05-23.json\",\"r\"))\n",
    "path_nielsen_zip=\"/mnt/clients/juba/hqjubaapp02/sharefolder/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\"\n",
    "num_miles_to_create_TA=40\n",
    "num_final_inclusion_dist=40\n",
    "\n",
    "list_str_stores_to_remove=['1280','1288','3605']\n",
    "\n",
    "print(os.getcwd())\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "client=bigquery.Client()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "\n",
      "with t_mapping_id_zip as (\n",
      "select t1.indiv_key, LPAD(ifnull(t2.postal_cd,\"00000\"), 5, '0') as zip_5, from mdb.indiv_summary as t1 \n",
      "left join mdb.addr as t2 on t1.cr_addr_key=t2.cr_addr_key\n",
      ")\n",
      "\n",
      "select store_id, ifnull(zip_5,'99999') as zip_5, count(distinct trn_id) as unique_trans, sum(line_item_total_amt) as total_sales from mdb.trn_detail as t1\n",
      "left join t_mapping_id_zip as t2\n",
      "on t1.indiv_key=t2.indiv_key\n",
      "where invoice_date between DATE_SUB(CURRENT_DATE(), interval 3 YEAR) and DATE_SUB(CURRENT_DATE(), interval 1 DAY)\n",
      "group by 1, 2\n",
      "order by 1, 3 desc,4 desc;\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jliang/.local/lib/python3.7/site-packages/google/cloud/bigquery/client.py:441: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n",
      "  \"Cannot create BigQuery Storage client, the dependency \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_store_sales_by_zip.shape (435844, 4)\n"
     ]
    }
   ],
   "source": [
    "query_string='''\n",
    "with t_mapping_id_zip as (\n",
    "select t1.indiv_key, LPAD(ifnull(t2.postal_cd,\"00000\"), 5, '0') as zip_5, from mdb.indiv_summary as t1 \n",
    "left join mdb.addr as t2 on t1.cr_addr_key=t2.cr_addr_key\n",
    ")\n",
    "\n",
    "select store_id, ifnull(zip_5,'99999') as zip_5, count(distinct trn_id) as unique_trans, sum(line_item_total_amt) as total_sales from mdb.trn_detail as t1\n",
    "left join t_mapping_id_zip as t2\n",
    "on t1.indiv_key=t2.indiv_key\n",
    "where invoice_date between DATE_SUB(CURRENT_DATE(), interval 3 YEAR) and DATE_SUB(CURRENT_DATE(), interval 1 DAY)\n",
    "group by 1, 2\n",
    "order by 1, 3 desc,4 desc;\n",
    "'''\n",
    "print(\"query: \\n%s\"%query_string)\n",
    "df_store_sales_by_zip=client.query(query_string).result().to_dataframe()\n",
    "print(\"df_store_sales_by_zip.shape\",df_store_sales_by_zip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "\n",
      "select store_id, min(cast(invoice_date as date)) as min_date, max(cast(invoice_date as date)) as max_date, count(distinct cast(invoice_date as date)) as unique_dates from mdb.trn_detail \n",
      "where invoice_date between DATE_SUB(CURRENT_DATE(), interval 3 YEAR) and DATE_SUB(CURRENT_DATE(), interval 1 DAY)\n",
      "group by store_id\n",
      "order by store_id;\n",
      "\n",
      "df_store_open_dates.shape (594, 4)\n"
     ]
    }
   ],
   "source": [
    "query_string='''\n",
    "select store_id, min(cast(invoice_date as date)) as min_date, max(cast(invoice_date as date)) as max_date, count(distinct cast(invoice_date as date)) as unique_dates from mdb.trn_detail \n",
    "where invoice_date between DATE_SUB(CURRENT_DATE(), interval 3 YEAR) and DATE_SUB(CURRENT_DATE(), interval 1 DAY)\n",
    "group by store_id\n",
    "order by store_id;\n",
    "'''\n",
    "print(\"query: \\n%s\"%query_string)\n",
    "df_store_open_dates=client.query(query_string).result().to_dataframe()\n",
    "print(\"df_store_open_dates.shape\",df_store_open_dates.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# email from YG 2020-10-22 at 10:03 AM: Corporate stores with NO transactions in the last 12 months should considers closed\n",
    "max_date=df_store_open_dates['max_date'].max()\n",
    "date_1_year_ago=max_date-datetime.timedelta(days=365)\n",
    "df_store_open_dates=df_store_open_dates[df_store_open_dates['max_date']>=date_1_year_ago]\n",
    "df_store_open_dates=df_store_open_dates[df_store_open_dates['unique_dates']>90]\n",
    "df_store_open_dates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "\n",
      "SELECT * from mdb.vw__installer_master as t1\n",
      "left join mdb_cdl.store t2 on t1.store_num=t2.store_num\n",
      "where t1.company_owned_store_ind=\"Y\" and open_store_flag='Y';\n",
      "\n",
      "df_store_included.shape (572, 63)\n"
     ]
    }
   ],
   "source": [
    "# currently open and coorperated owned stores\n",
    "query_string='''\n",
    "SELECT * from mdb.vw__installer_master as t1\n",
    "left join mdb_cdl.store t2 on t1.store_num=t2.store_num\n",
    "where t1.company_owned_store_ind=\"Y\" and open_store_flag='Y';\n",
    "'''\n",
    "\n",
    "print(\"query: \\n%s\"%query_string)\n",
    "df_store_included=client.query(query_string).result().to_dataframe()\n",
    "print(\"df_store_included.shape\",df_store_included.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'str'>]\n",
      "[<class 'str'>]\n",
      "[<class 'str'>]\n",
      "[<class 'str'>]\n",
      "[<class 'str'>]\n",
      "[<class 'str'>]\n"
     ]
    }
   ],
   "source": [
    "print(df_store_sales_by_zip['store_id'].apply(type).unique())\n",
    "print(df_store_open_dates['store_id'].apply(type).unique())\n",
    "print(df_store_included['store_num'].apply(type).unique())\n",
    "\n",
    "df_store_sales_by_zip=df_store_sales_by_zip[df_store_sales_by_zip['store_id'].str.isdigit()]\n",
    "df_store_open_dates=df_store_open_dates[df_store_open_dates['store_id'].str.isdigit()]\n",
    "df_store_included=df_store_included[df_store_included['store_num'].str.isdigit()]\n",
    "\n",
    "df_store_sales_by_zip['store_id']=df_store_sales_by_zip['store_id'].astype(int).astype(str)\n",
    "df_store_open_dates['store_id']=df_store_open_dates['store_id'].astype(int).astype(str)\n",
    "df_store_included['store_num']=df_store_included['store_num'].astype(int).astype(str)\n",
    "\n",
    "print(df_store_sales_by_zip['store_id'].apply(type).unique())\n",
    "print(df_store_open_dates['store_id'].apply(type).unique())\n",
    "print(df_store_included['store_num'].apply(type).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(567, 67)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_included_with_dates=pd.merge(df_store_included,df_store_open_dates,left_on=\"store_num\",right_on=\"store_id\",how=\"inner\")\n",
    "# Remove 3 spread stores\n",
    "df_store_included_with_dates=df_store_included_with_dates[~df_store_included_with_dates['store_num'].isin(list_str_stores_to_remove)]\n",
    "\n",
    "df_store_included=df_store_included[df_store_included['store_num'].isin(df_store_included_with_dates['store_num'].tolist())]\n",
    "df_store_included_with_dates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n",
      "(406342, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_inclusion_stores=df_store_included_with_dates['store_num'].unique().tolist()\n",
    "print(len(list_inclusion_stores))\n",
    "df_store_sales_by_zip=df_store_sales_by_zip[df_store_sales_by_zip['store_id'].isin(list_inclusion_stores)]\n",
    "print(df_store_sales_by_zip.shape)\n",
    "df_store_sales_by_zip['store_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>zip_5</th>\n",
       "      <th>unique_trans</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>store_trans</th>\n",
       "      <th>store_sales</th>\n",
       "      <th>trans_cum</th>\n",
       "      <th>trans_rank</th>\n",
       "      <th>trans_cum_pctg</th>\n",
       "      <th>sales_cum</th>\n",
       "      <th>sales_rank</th>\n",
       "      <th>sales_cum_pctg</th>\n",
       "      <th>trans_label</th>\n",
       "      <th>sales_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53240</th>\n",
       "      <td>1023</td>\n",
       "      <td>15601</td>\n",
       "      <td>6939</td>\n",
       "      <td>1465636.61</td>\n",
       "      <td>17689</td>\n",
       "      <td>4160256.38</td>\n",
       "      <td>6939</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392278</td>\n",
       "      <td>1465636.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352295</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53241</th>\n",
       "      <td>1023</td>\n",
       "      <td>15644</td>\n",
       "      <td>2207</td>\n",
       "      <td>465083.23</td>\n",
       "      <td>17689</td>\n",
       "      <td>4160256.38</td>\n",
       "      <td>9146</td>\n",
       "      <td>2</td>\n",
       "      <td>0.517044</td>\n",
       "      <td>1930719.84</td>\n",
       "      <td>2</td>\n",
       "      <td>0.464087</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      store_id  zip_5  unique_trans  total_sales  store_trans  store_sales  \\\n",
       "53240     1023  15601          6939   1465636.61        17689   4160256.38   \n",
       "53241     1023  15644          2207    465083.23        17689   4160256.38   \n",
       "\n",
       "       trans_cum  trans_rank  trans_cum_pctg   sales_cum  sales_rank  \\\n",
       "53240       6939           1        0.392278  1465636.61           1   \n",
       "53241       9146           2        0.517044  1930719.84           2   \n",
       "\n",
       "       sales_cum_pctg trans_label sales_label  \n",
       "53240        0.352295           P           P  \n",
       "53241        0.464087           S           S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_store_sales_total=df_store_sales_by_zip.groupby('store_id')['unique_trans','total_sales'].sum().reset_index()\n",
    "df_store_sales_total=df_store_sales_total.rename(columns={\"unique_trans\":\"store_trans\",\"total_sales\":\"store_sales\"})\n",
    "df_store_sales_by_zip=pd.merge(df_store_sales_by_zip,df_store_sales_total,on=\"store_id\")\n",
    "df_store_sales_by_zip['temp_row_count']=1\n",
    "\n",
    "df_store_sales_by_zip=df_store_sales_by_zip.sort_values(['store_id','unique_trans','total_sales'],ascending=[True,False,False])\n",
    "df_store_sales_by_zip['trans_cum'] = df_store_sales_by_zip.groupby(['store_id'])['unique_trans'].cumsum()\n",
    "df_store_sales_by_zip['trans_rank'] = df_store_sales_by_zip.groupby(['store_id'])['temp_row_count'].cumsum()\n",
    "df_store_sales_by_zip['trans_cum_pctg']=df_store_sales_by_zip['trans_cum']/df_store_sales_by_zip['store_trans']\n",
    "\n",
    "df_store_sales_by_zip=df_store_sales_by_zip.sort_values(['store_id','total_sales','unique_trans'],ascending=[True,False,False])\n",
    "df_store_sales_by_zip['sales_cum'] = df_store_sales_by_zip.groupby(['store_id'])['total_sales'].cumsum()\n",
    "df_store_sales_by_zip['sales_rank'] = df_store_sales_by_zip.groupby(['store_id'])['temp_row_count'].cumsum()\n",
    "df_store_sales_by_zip['sales_cum_pctg']=df_store_sales_by_zip['sales_cum']/df_store_sales_by_zip['store_sales']\n",
    "\n",
    "df_store_sales_by_zip['trans_label']=np.where(((df_store_sales_by_zip['trans_cum_pctg']<=0.6) | (df_store_sales_by_zip['trans_rank']==1)),\"P\",\n",
    "                                             np.where(df_store_sales_by_zip['trans_cum_pctg']<=0.8,\"S\",\"T\")\n",
    "                                             )\n",
    "df_store_sales_by_zip['sales_label']=np.where(((df_store_sales_by_zip['sales_cum_pctg']<=0.6) | (df_store_sales_by_zip['sales_rank']==1)),\"P\",\n",
    "                                             np.where(df_store_sales_by_zip['sales_cum_pctg']<=0.8,\"S\",\"T\")\n",
    "                                             )\n",
    "# To make sure to have at least an S\n",
    "df_store_sales_by_zip['trans_label']=np.where(((df_store_sales_by_zip['trans_label']==\"T\") | (df_store_sales_by_zip['trans_rank']==2)),\"S\",\n",
    "                                              df_store_sales_by_zip['trans_label']\n",
    "                                             )\n",
    "df_store_sales_by_zip['sales_label']=np.where(((df_store_sales_by_zip['sales_label']==\"T\") | (df_store_sales_by_zip['sales_rank']==2)),\"S\",\n",
    "                                              df_store_sales_by_zip['sales_label']\n",
    "                                             )\n",
    "\n",
    "\n",
    "del df_store_sales_by_zip['temp_row_count']\n",
    "df_store_sales_by_zip.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_label</th>\n",
       "      <th>store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_label  store_id\n",
       "0           P       567\n",
       "1           S       567"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QC all store have P&S\n",
    "df=df_store_sales_by_zip.groupby(\"trans_label\")['store_id'].nunique().reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_label</th>\n",
       "      <th>store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sales_label  store_id\n",
       "0           P       567\n",
       "1           S       567"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QC all store have P&S\n",
    "df=df_store_sales_by_zip.groupby(\"sales_label\")['store_id'].nunique().reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensured that we have at least 1 P zips, but may lack of S zips which is fine\n",
    "list_S_store=df_store_sales_by_zip[df_store_sales_by_zip['trans_label']==\"S\"]['store_id'].unique().tolist()\n",
    "df=df_store_sales_by_zip[~df_store_sales_by_zip['store_id'].isin(list_S_store)]\n",
    "\n",
    "for store,df_group in df.groupby('store_id'):\n",
    "    df_group=df_group[df_group['trans_label']!=\"P\"]\n",
    "    print(store,df_group['trans_cum_pctg'].min())\n",
    "    print(df_group['trans_cum_pctg'].tolist()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>zip_5</th>\n",
       "      <th>unique_trans</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>store_trans</th>\n",
       "      <th>store_sales</th>\n",
       "      <th>trans_cum</th>\n",
       "      <th>trans_rank</th>\n",
       "      <th>trans_cum_pctg</th>\n",
       "      <th>sales_cum</th>\n",
       "      <th>sales_rank</th>\n",
       "      <th>sales_cum_pctg</th>\n",
       "      <th>trans_label</th>\n",
       "      <th>sales_label</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53240</th>\n",
       "      <td>1023</td>\n",
       "      <td>15601</td>\n",
       "      <td>6939</td>\n",
       "      <td>1465636.61</td>\n",
       "      <td>17689</td>\n",
       "      <td>4160256.38</td>\n",
       "      <td>6939</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392278</td>\n",
       "      <td>1465636.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352295</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>40.3048</td>\n",
       "      <td>-79.5831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53241</th>\n",
       "      <td>1023</td>\n",
       "      <td>15644</td>\n",
       "      <td>2207</td>\n",
       "      <td>465083.23</td>\n",
       "      <td>17689</td>\n",
       "      <td>4160256.38</td>\n",
       "      <td>9146</td>\n",
       "      <td>2</td>\n",
       "      <td>0.517044</td>\n",
       "      <td>1930719.84</td>\n",
       "      <td>2</td>\n",
       "      <td>0.464087</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>40.3048</td>\n",
       "      <td>-79.5831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      store_id  zip_5  unique_trans  total_sales  store_trans  store_sales  \\\n",
       "53240     1023  15601          6939   1465636.61        17689   4160256.38   \n",
       "53241     1023  15644          2207    465083.23        17689   4160256.38   \n",
       "\n",
       "       trans_cum  trans_rank  trans_cum_pctg   sales_cum  sales_rank  \\\n",
       "53240       6939           1        0.392278  1465636.61           1   \n",
       "53241       9146           2        0.517044  1930719.84           2   \n",
       "\n",
       "       sales_cum_pctg trans_label sales_label  latitude  longitude  \n",
       "53240        0.352295           P           P   40.3048   -79.5831  \n",
       "53241        0.464087           S           S   40.3048   -79.5831  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_store_lat=df_store_included.set_index(\"store_num\").to_dict()['latitude']\n",
    "dict_store_lng=df_store_included.set_index(\"store_num\").to_dict()['longitude']\n",
    "\n",
    "df_store_sales_by_zip['latitude']=df_store_sales_by_zip['store_id'].apply(lambda x: dict_store_lat[x])\n",
    "df_store_sales_by_zip['longitude']=df_store_sales_by_zip['store_id'].apply(lambda x: dict_store_lng[x])\n",
    "df_store_sales_by_zip.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>5160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             store_id\n",
       "trans_label          \n",
       "P                   8\n",
       "S                5160"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_store_sales_by_zip[~df_store_sales_by_zip['zip_5'].isin(list(zip_centers.keys()))]\n",
    "df.groupby(\"trans_label\")['store_id'].count().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>zip_5</th>\n",
       "      <th>unique_trans</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>store_trans</th>\n",
       "      <th>store_sales</th>\n",
       "      <th>trans_cum</th>\n",
       "      <th>trans_rank</th>\n",
       "      <th>trans_cum_pctg</th>\n",
       "      <th>sales_cum</th>\n",
       "      <th>sales_rank</th>\n",
       "      <th>sales_cum_pctg</th>\n",
       "      <th>trans_label</th>\n",
       "      <th>sales_label</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>dist_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1023</td>\n",
       "      <td>15601</td>\n",
       "      <td>6939</td>\n",
       "      <td>1465636.61</td>\n",
       "      <td>17689</td>\n",
       "      <td>4160256.38</td>\n",
       "      <td>6939</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392278</td>\n",
       "      <td>1465636.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352295</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "      <td>40.3048</td>\n",
       "      <td>-79.5831</td>\n",
       "      <td>2.283179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1023</td>\n",
       "      <td>15644</td>\n",
       "      <td>2207</td>\n",
       "      <td>465083.23</td>\n",
       "      <td>17689</td>\n",
       "      <td>4160256.38</td>\n",
       "      <td>9146</td>\n",
       "      <td>2</td>\n",
       "      <td>0.517044</td>\n",
       "      <td>1930719.84</td>\n",
       "      <td>2</td>\n",
       "      <td>0.464087</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>40.3048</td>\n",
       "      <td>-79.5831</td>\n",
       "      <td>2.576020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1023</td>\n",
       "      <td>15642</td>\n",
       "      <td>1522</td>\n",
       "      <td>396955.95</td>\n",
       "      <td>17689</td>\n",
       "      <td>4160256.38</td>\n",
       "      <td>10668</td>\n",
       "      <td>3</td>\n",
       "      <td>0.603087</td>\n",
       "      <td>2327675.79</td>\n",
       "      <td>3</td>\n",
       "      <td>0.559503</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>40.3048</td>\n",
       "      <td>-79.5831</td>\n",
       "      <td>7.150137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1023</td>\n",
       "      <td>15650</td>\n",
       "      <td>529</td>\n",
       "      <td>122323.66</td>\n",
       "      <td>17689</td>\n",
       "      <td>4160256.38</td>\n",
       "      <td>11197</td>\n",
       "      <td>4</td>\n",
       "      <td>0.632992</td>\n",
       "      <td>2449999.45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.588906</td>\n",
       "      <td>S</td>\n",
       "      <td>P</td>\n",
       "      <td>40.3048</td>\n",
       "      <td>-79.5831</td>\n",
       "      <td>9.946670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1023</td>\n",
       "      <td>15231</td>\n",
       "      <td>119</td>\n",
       "      <td>109824.29</td>\n",
       "      <td>17689</td>\n",
       "      <td>4160256.38</td>\n",
       "      <td>13185</td>\n",
       "      <td>15</td>\n",
       "      <td>0.745378</td>\n",
       "      <td>2559823.74</td>\n",
       "      <td>5</td>\n",
       "      <td>0.615304</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>40.3048</td>\n",
       "      <td>-79.5831</td>\n",
       "      <td>38.556427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id  zip_5  unique_trans  total_sales  store_trans  store_sales  \\\n",
       "0     1023  15601          6939   1465636.61        17689   4160256.38   \n",
       "1     1023  15644          2207    465083.23        17689   4160256.38   \n",
       "2     1023  15642          1522    396955.95        17689   4160256.38   \n",
       "3     1023  15650           529    122323.66        17689   4160256.38   \n",
       "4     1023  15231           119    109824.29        17689   4160256.38   \n",
       "\n",
       "   trans_cum  trans_rank  trans_cum_pctg   sales_cum  sales_rank  \\\n",
       "0       6939           1        0.392278  1465636.61           1   \n",
       "1       9146           2        0.517044  1930719.84           2   \n",
       "2      10668           3        0.603087  2327675.79           3   \n",
       "3      11197           4        0.632992  2449999.45           4   \n",
       "4      13185          15        0.745378  2559823.74           5   \n",
       "\n",
       "   sales_cum_pctg trans_label sales_label  latitude  longitude  dist_miles  \n",
       "0        0.352295           P           P   40.3048   -79.5831    2.283179  \n",
       "1        0.464087           S           S   40.3048   -79.5831    2.576020  \n",
       "2        0.559503           S           P   40.3048   -79.5831    7.150137  \n",
       "3        0.588906           S           P   40.3048   -79.5831    9.946670  \n",
       "4        0.615304           S           S   40.3048   -79.5831   38.556427  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_by_zip=df_store_sales_by_zip.copy()\n",
    "df_sales_by_zip=df_sales_by_zip[df_sales_by_zip['zip_5'].isin(list(zip_centers.keys()))]\n",
    "\n",
    "df_sales_by_zip=df_sales_by_zip.reset_index()\n",
    "del df_sales_by_zip['index']\n",
    "\n",
    "def cal_dist_zip_store_miles(zip_cd,store_lat,store_lng):\n",
    "    return haversine(zip_centers[zip_cd],(store_lat,store_lng),unit=\"mi\")\n",
    "\n",
    "df_sales_by_zip['dist_miles']=df_sales_by_zip.apply(lambda df: cal_dist_zip_store_miles(df['zip_5'],df['latitude'],df['longitude']),axis=1)\n",
    "\n",
    "\n",
    "df_sales_by_zip.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_sales_by_zip.to_csv('./df_store_sales_by_zip.csv',index=False)\n",
    "df_sales_by_zip.to_csv('./df_sales_by_zip.csv',index=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder=\"./output_%s/\"%str(datetime.datetime.now().date())\n",
    "try:\n",
    "    os.stat(output_folder)\n",
    "except:\n",
    "    os.mkdir(output_folder)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76878, 17)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_PS_40_miles=df_sales_by_zip[(df_sales_by_zip['trans_label'].isin(['P','S']))]\n",
    "df_output_PS_40_miles=df_output_PS_40_miles[df_output_PS_40_miles['dist_miles']<=num_miles_to_create_TA]\n",
    "df_output_PS_40_miles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_zip_both=df_output_PS_40_miles[['store_id','trans_label','zip_5','latitude','longitude']].rename(columns={\"zip_5\":\"zip_list_P_and_S\"}).drop_duplicates()\n",
    "df_store_zip_both=df_store_zip_both.groupby([\"store_id\",'latitude','longitude'])['zip_list_P_and_S'].apply(set).to_frame().reset_index()\n",
    "df_store_zip_both['zip_list_P_and_S']=df_store_zip_both['zip_list_P_and_S'].apply(lambda x: list(x))\n",
    "\n",
    "df_store_zip_P=df_output_PS_40_miles[df_output_PS_40_miles['trans_label']==\"P\"]\n",
    "df_store_zip_P=df_store_zip_P[['store_id','trans_label','zip_5','latitude','longitude']].rename(columns={\"zip_5\":\"zip_list_P\"}).drop_duplicates()\n",
    "df_store_zip_P=df_store_zip_P.groupby([\"store_id\",'latitude','longitude'])['zip_list_P'].apply(set).to_frame().reset_index()\n",
    "df_store_zip_P['zip_list_P']=df_store_zip_P['zip_list_P'].apply(lambda x: list(x))\n",
    "\n",
    "df_store_zip_S=df_output_PS_40_miles[df_output_PS_40_miles['trans_label']==\"S\"]\n",
    "df_store_zip_S=df_store_zip_S[['store_id','trans_label','zip_5','latitude','longitude']].rename(columns={\"zip_5\":\"zip_list_S\"}).drop_duplicates()\n",
    "df_store_zip_S=df_store_zip_S.groupby([\"store_id\",'latitude','longitude'])['zip_list_S'].apply(set).to_frame().reset_index()\n",
    "df_store_zip_S['zip_list_S']=df_store_zip_S['zip_list_S'].apply(lambda x: list(x))\n",
    "\n",
    "df_store_zip=pd.merge(df_store_zip_both,df_store_zip_P,on=[\"store_id\",'latitude','longitude'],how=\"outer\")\n",
    "df_store_zip=pd.merge(df_store_zip,df_store_zip_S,on=[\"store_id\",'latitude','longitude'],how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(567, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_zip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_zip_0=df_store_zip.copy()\n",
    "\n",
    "df_store_zip.columns=[\"store_A_\"+x for x in df_store_zip.columns.tolist()]\n",
    "df_store_zip_0.columns=[\"store_B_\"+x for x in df_store_zip_0.columns.tolist()]\n",
    "\n",
    "df_store_zip['key']=1\n",
    "df_store_zip_0['key']=1\n",
    "\n",
    "df_store_zip=pd.merge(df_store_zip,df_store_zip_0,on=\"key\",how=\"outer\")\n",
    "del df_store_zip_0\n",
    "\n",
    "\n",
    "df_store_zip=df_store_zip[df_store_zip['store_A_store_id']!=df_store_zip['store_B_store_id']]\n",
    "df_store_zip=df_store_zip.reset_index()\n",
    "del df_store_zip['index']\n",
    "del df_store_zip['key']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersection(list_1,list_2):\n",
    "    return list(set(list_1).intersection(set(list_2)))\n",
    "def dist_miles(lat_1,log_1,lat_2,log_2):\n",
    "    return haversine((lat_1,log_1),(lat_2,log_2),unit=\"mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_zip['intersection_both_P_S']=df_store_zip.apply(lambda x: find_intersection(x['store_A_zip_list_P_and_S'],x['store_B_zip_list_P_and_S']),axis=1)\n",
    "\n",
    "df_store_zip['count_of_overlap_zips']=df_store_zip['intersection_both_P_S'].apply(lambda x: len(x))\n",
    "df_store_zip['count_of_A_zips']=df_store_zip['store_A_zip_list_P_and_S'].apply(lambda x: len(x))\n",
    "df_store_zip['count_of_B_zips']=df_store_zip['store_B_zip_list_P_and_S'].apply(lambda x: len(x))\n",
    "df_store_zip['total_zips']=df_store_zip['count_of_A_zips']+df_store_zip['count_of_B_zips']-df_store_zip['count_of_overlap_zips']\n",
    "\n",
    "df_store_zip['overlap_pctg']=df_store_zip['count_of_overlap_zips']/df_store_zip['total_zips']\n",
    "\n",
    "df_store_zip=df_store_zip[df_store_zip['count_of_overlap_zips']>0]\n",
    "\n",
    "df_store_zip['dist_between_stores']=df_store_zip.apply(lambda x: dist_miles(x['store_A_latitude'],x['store_A_longitude'],x['store_B_latitude'],x['store_B_longitude']),axis=1)\n",
    "df_store_zip=df_store_zip.reset_index()\n",
    "del df_store_zip['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_zip.to_csv(\"df_store_zip_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_pair_func(store_A,store_B):\n",
    "    return sorted([store_A,store_B])\n",
    "df_store_zip_unique_pairs=df_store_zip.copy()\n",
    "df_store_zip_unique_pairs['store_pair']=df_store_zip_unique_pairs.apply(lambda x: store_pair_func(x['store_A_store_id'],x['store_B_store_id']),axis=1)\n",
    "df_store_zip_unique_pairs['store_pair_str']=df_store_zip_unique_pairs['store_pair'].astype(str)\n",
    "df_store_zip_unique_pairs=df_store_zip_unique_pairs.sort_values(['store_pair_str','store_A_store_id','store_B_store_id'])\n",
    "df_store_zip_unique_pairs=df_store_zip_unique_pairs.drop_duplicates(\"store_pair_str\")\n",
    "df_store_zip_unique_pairs.to_csv(\"df_store_zip_unique_pairs_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_zip_unique_pairs['overlap_group']=np.where(df_store_zip_unique_pairs['overlap_pctg']>0.2,\"20%+\",\n",
    "                                                   np.where(df_store_zip_unique_pairs['overlap_pctg']>0.15,\"15%-20%\",\n",
    "                                                           np.where(df_store_zip_unique_pairs['overlap_pctg']>0.1,\"10%-15%\",\n",
    "                                                                   np.where(df_store_zip_unique_pairs['overlap_pctg']>0.05,'5%-10%',\n",
    "                                                                           np.where(df_store_zip_unique_pairs['overlap_pctg']>0.03,'3%-5%',\"<3%\")\n",
    "                                                                           )\n",
    "                                                                   )\n",
    "                                                           )\n",
    "                                                   )\n",
    "\n",
    "df_store_zip_unique_pairs['dist_group']=np.where(df_store_zip_unique_pairs['dist_between_stores']>28,\"28+ miles\",\n",
    "                                                   np.where(df_store_zip_unique_pairs['dist_between_stores']>20,\"20-28 miles\",\n",
    "                                                           np.where(df_store_zip_unique_pairs['dist_between_stores']>10,\"10-20 miles\",\"0-10 miles\")\n",
    "                                                           )\n",
    "                                                   )\n",
    "df_summary_overlap_dist_group_pair_count=df_store_zip_unique_pairs.groupby(['overlap_group','dist_group'])['store_pair_str'].count().to_frame().reset_index().rename(columns={\"store_pair_str\":\"pairs_count\"})\n",
    "df_summary_overlap_dist_group_unique_stores=df_store_zip_unique_pairs.groupby(['overlap_group','dist_group'])['store_pair'].sum().to_frame().reset_index().rename(columns={\"store_pair\":\"stores_involved\"})\n",
    "\n",
    "df_store_zip_unique_pairs['zips_P_S_40_both_stores']=df_store_zip_unique_pairs['store_B_zip_list_P_and_S']+df_store_zip_unique_pairs['store_A_zip_list_P_and_S']\n",
    "df_store_zip_unique_pairs['zips_P_S_40_both_stores']=df_store_zip_unique_pairs['zips_P_S_40_both_stores'].apply(lambda x: list(set(x)))\n",
    "df_summary_overlap_dist_group_unique_zips=df_store_zip_unique_pairs.groupby(['overlap_group','dist_group'])['zips_P_S_40_both_stores'].sum().to_frame().reset_index().rename(columns={\"zips_P_S_40_both_stores\":\"zips_involved\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_dict={\"<3%\":1,\"3%-5%\":2,\"5%-10%\":3,\"10%-15%\":4,\"15%-20%\":5,\"20%+\":6}\n",
    "\n",
    "df_summary_pivot_pair=df_summary_overlap_dist_group_pair_count.pivot_table(index=\"overlap_group\",columns='dist_group',values=\"pairs_count\").reset_index()\n",
    "df_summary_pivot_pair['sort']=df_summary_pivot_pair['overlap_group'].apply(lambda x: sort_dict[x])\n",
    "df_summary_pivot_pair=df_summary_pivot_pair.sort_values(\"sort\").reset_index()\n",
    "del df_summary_pivot_pair['sort']\n",
    "del df_summary_pivot_pair['index']\n",
    "\n",
    "\n",
    "df_summary_overlap_dist_group_unique_stores['stores_involved']=df_summary_overlap_dist_group_unique_stores['stores_involved'].apply(lambda x: set(x))\n",
    "df_summary_overlap_dist_group_unique_stores['store_count_involved']=df_summary_overlap_dist_group_unique_stores['stores_involved'].apply(lambda x: len(x))\n",
    "\n",
    "df_summary_pivot_store=df_summary_overlap_dist_group_unique_stores.pivot_table(index=\"overlap_group\",columns='dist_group',values=\"store_count_involved\").reset_index()\n",
    "df_summary_pivot_store['sort']=df_summary_pivot_store['overlap_group'].apply(lambda x: sort_dict[x])\n",
    "df_summary_pivot_store=df_summary_pivot_store.sort_values(\"sort\").reset_index()\n",
    "del df_summary_pivot_store['sort']\n",
    "del df_summary_pivot_store['index']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_overlap_dist_group_unique_zips['zips_involved']=df_summary_overlap_dist_group_unique_zips['zips_involved'].apply(lambda x: set(x))\n",
    "df_summary_overlap_dist_group_unique_zips['zip_count_involved']=df_summary_overlap_dist_group_unique_zips['zips_involved'].apply(lambda x: len(x))\n",
    "\n",
    "df_summary_pivot_zip=df_summary_overlap_dist_group_unique_zips.pivot_table(index=\"overlap_group\",columns='dist_group',values=\"zip_count_involved\").reset_index()\n",
    "df_summary_pivot_zip['sort']=df_summary_pivot_zip['overlap_group'].apply(lambda x: sort_dict[x])\n",
    "df_summary_pivot_zip=df_summary_pivot_zip.sort_values(\"sort\").reset_index()\n",
    "del df_summary_pivot_zip['sort']\n",
    "del df_summary_pivot_zip['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_group=df_store_zip_unique_pairs.groupby(['dist_group'])['store_pair'].sum().to_frame().reset_index().rename(columns={\"store_pair\":\"unique_store_list\"})\n",
    "dist_group['unique_store_list']=dist_group['unique_store_list'].apply(lambda x: list(set(x)))\n",
    "dist_group['unique_store_count']=dist_group['unique_store_list'].apply(lambda x: len(x))\n",
    "\n",
    "dist_group_pair_count=df_store_zip_unique_pairs.groupby(['dist_group'])['store_pair'].count().to_frame().reset_index().rename(columns={\"store_pair\":\"pair_counts\"})\n",
    "\n",
    "dist_group=pd.merge(dist_group,dist_group_pair_count,on=\"dist_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_P_zips_by_store=df_sales_by_zip[df_sales_by_zip['trans_label']==\"P\"].groupby(['store_id'])['zip_5'].apply(list).to_frame().reset_index().rename(columns={\"zip_5\":\"all_P_zips\"})\n",
    "df_all_S_zips_by_store=df_sales_by_zip[df_sales_by_zip['trans_label']==\"S\"].groupby(['store_id'])['zip_5'].apply(list).to_frame().reset_index().rename(columns={\"zip_5\":\"all_S_zips\"})\n",
    "\n",
    "df_40_miles_P_zips_by_store=df_sales_by_zip[(df_sales_by_zip['trans_label']==\"P\") & (df_sales_by_zip['dist_miles']<=50)].groupby(['store_id'])['zip_5'].apply(list).to_frame().reset_index().rename(columns={\"zip_5\":\"40_miles_P_zips\"})\n",
    "df_40_miles_S_zips_by_store=df_sales_by_zip[(df_sales_by_zip['trans_label']==\"S\") & (df_sales_by_zip['dist_miles']<=50)].groupby(['store_id'])['zip_5'].apply(list).to_frame().reset_index().rename(columns={\"zip_5\":\"40_miles_S_zips\"})\n",
    "\n",
    "df_P_S_zips_by_store=pd.merge(df_all_P_zips_by_store,df_all_S_zips_by_store,on=\"store_id\",how=\"outer\")\n",
    "df_P_S_zips_by_store=pd.merge(df_P_S_zips_by_store,df_40_miles_P_zips_by_store,on=\"store_id\",how=\"outer\")\n",
    "df_P_S_zips_by_store=pd.merge(df_P_S_zips_by_store,df_40_miles_S_zips_by_store,on=\"store_id\",how=\"outer\")\n",
    "df_P_S_zips_by_store=df_P_S_zips_by_store.fillna(\"[]\")\n",
    "df_P_S_zips_by_store['all_P_zips']=df_P_S_zips_by_store['all_P_zips'].astype(str).apply(lambda x: eval(x))\n",
    "df_P_S_zips_by_store['all_S_zips']=df_P_S_zips_by_store['all_S_zips'].astype(str).apply(lambda x: eval(x))\n",
    "df_P_S_zips_by_store['40_miles_P_zips']=df_P_S_zips_by_store['40_miles_P_zips'].astype(str).apply(lambda x: eval(x))\n",
    "df_P_S_zips_by_store['40_miles_S_zips']=df_P_S_zips_by_store['40_miles_S_zips'].astype(str).apply(lambda x: eval(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>all_P_zips</th>\n",
       "      <th>all_S_zips</th>\n",
       "      <th>40_miles_P_zips</th>\n",
       "      <th>40_miles_S_zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1023</td>\n",
       "      <td>[15601]</td>\n",
       "      <td>[15644, 15642, 15650, 15231, 15401, 17103, 156...</td>\n",
       "      <td>[15601]</td>\n",
       "      <td>[15644, 15642, 15650, 15231, 15401, 15666, 156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1027</td>\n",
       "      <td>[15227, 15122, 15120, 15207]</td>\n",
       "      <td>[15236, 15025, 15210, 15102, 15129, 15037, 151...</td>\n",
       "      <td>[15227, 15122, 15120, 15207]</td>\n",
       "      <td>[15236, 15025, 15210, 15102, 15129, 15037, 151...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id                    all_P_zips  \\\n",
       "0     1023                       [15601]   \n",
       "1     1027  [15227, 15122, 15120, 15207]   \n",
       "\n",
       "                                          all_S_zips  \\\n",
       "0  [15644, 15642, 15650, 15231, 15401, 17103, 156...   \n",
       "1  [15236, 15025, 15210, 15102, 15129, 15037, 151...   \n",
       "\n",
       "                40_miles_P_zips  \\\n",
       "0                       [15601]   \n",
       "1  [15227, 15122, 15120, 15207]   \n",
       "\n",
       "                                     40_miles_S_zips  \n",
       "0  [15644, 15642, 15650, 15231, 15401, 15666, 156...  \n",
       "1  [15236, 15025, 15210, 15102, 15129, 15037, 151...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_P_S_zips_by_store.shape)\n",
    "df_P_S_zips_by_store.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P_S_zips_by_store['store_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dist_of_2_str_stores(pair_stores_str):\n",
    "    pair_stores_str=eval(pair_stores_str)\n",
    "    store_a=pair_stores_str[0]\n",
    "    store_b=pair_stores_str[1]\n",
    "    dist=haversine([dict_store_lat[store_a],dict_store_lng[store_a]],[dict_store_lat[store_b],dict_store_lng[store_b]],unit=\"mi\")\n",
    "    return dist\n",
    "\n",
    "# Only used in below loop\n",
    "def find_nearest_store(store_id):\n",
    "    shortest_dist=99999\n",
    "    nearest_store=np.nan\n",
    "    for i_store in df_store_address['store_id'].tolist():\n",
    "        if i_store!=store_id:\n",
    "            dist=haversine([dict_store_lat[store_id],dict_store_lng[store_id]],[dict_store_lat[i_store],dict_store_lng[i_store]],unit=\"mi\")\n",
    "            if dist<shortest_dist:\n",
    "                shortest_dist=dist\n",
    "                nearest_store=i_store\n",
    "    return nearest_store, shortest_dist\n",
    "\n",
    "def find_overlaped_stores(store_id):\n",
    "    df=df_store_zip_unique_pairs[df_store_zip_unique_pairs['store_pair'].apply(lambda x: store_id in x)]\n",
    "    df=df.sort_values('overlap_pctg',ascending=True).reset_index()\n",
    "    min_overlap_pctg=df.loc[0,'overlap_pctg']\n",
    "    min_overlap_store_pair_str=df.loc[0,'store_pair_str']\n",
    "    \n",
    "    max_overlap_pctg=df.loc[len(df)-1,'overlap_pctg']\n",
    "    max_overlap_store_pair_str=df.loc[len(df)-1,'store_pair_str']\n",
    "    \n",
    "    return min_overlap_pctg,min_overlap_store_pair_str,max_overlap_pctg,max_overlap_store_pair_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_group</th>\n",
       "      <th>unique_store_list</th>\n",
       "      <th>unique_store_count</th>\n",
       "      <th>pair_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-10 miles</td>\n",
       "      <td>[6324, 537, 8024, 2437, 869, 8837, 924, 2726, ...</td>\n",
       "      <td>422</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-20 miles</td>\n",
       "      <td>[6324, 537, 8024, 2437, 869, 8837, 924, 8166, ...</td>\n",
       "      <td>394</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-28 miles</td>\n",
       "      <td>[537, 2168, 2437, 4766, 869, 8837, 924, 8166, ...</td>\n",
       "      <td>334</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dist_group                                  unique_store_list  \\\n",
       "0   0-10 miles  [6324, 537, 8024, 2437, 869, 8837, 924, 2726, ...   \n",
       "1  10-20 miles  [6324, 537, 8024, 2437, 869, 8837, 924, 8166, ...   \n",
       "2  20-28 miles  [537, 2168, 2437, 4766, 869, 8837, 924, 8166, ...   \n",
       "\n",
       "   unique_store_count  pair_counts  \n",
       "0                 422          556  \n",
       "1                 394          757  \n",
       "2                 334          470  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_group.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_included['zip_cd']=df_store_included['zip_cd'].apply(lambda x: x.split(\"-\")[0].zfill(5))\n",
    "df_store_address=df_store_included[['store_num','address_1','city','state','zip_cd','latitude','longitude']]\n",
    "df_store_address=df_store_address.rename(columns={\"store_num\":\"store_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "nearest_store_dist_criteria_dict={\"0-10 miles\":0,\"10-20 miles\":10,\"20-28 miles\":20,\"28+ miles\":28}\n",
    "\n",
    "writer=pd.ExcelWriter(output_folder+\"GY_new_TA_pair_dist_table_summary_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "dist_group.to_excel(writer,\"pairs_and_stores_by_pair_dist\",index=False)\n",
    "\n",
    "ordered_cols=['dist_group','store_id','address_1','city','state','zip_cd','latitude','longitude',\n",
    "              'all_P_zips','all_S_zips','All_P&S_zips','40_miles_P_zips','40_miles_S_zips','All_P&S_zips_40_miles',\n",
    "              'nearest_store','dist_to_nearest_store',\n",
    "              'max_overlap_store','max_overlap_pctg','dist_max_overlap_pairs',\n",
    "              'min_overlap_pctg','min_overlap_store','dist_min_overlap_pairs']\n",
    "\n",
    "all_paired_group_store_df=pd.DataFrame(columns=ordered_cols)\n",
    "all_single_store_df=pd.DataFrame(columns=['nearest_store_dist_criteria']+ordered_cols)\n",
    "all_high_overlap_store_df=pd.DataFrame(columns=ordered_cols)\n",
    "\n",
    "for dist,group in dist_group.groupby(\"dist_group\"):\n",
    "    store_list_in_dist_group=group['unique_store_list'].values[0]\n",
    "    df_store_zip_unique_pairs_removed=df_store_zip_unique_pairs[(~df_store_zip_unique_pairs['store_A_store_id'].isin(store_list_in_dist_group)) &\\\n",
    "                                                                 (~df_store_zip_unique_pairs['store_B_store_id'].isin(store_list_in_dist_group))]\n",
    "\n",
    "    df_removed_pairs_rows=df_store_zip_unique_pairs[df_store_zip_unique_pairs['dist_group']==dist]\n",
    "    df_store_zip_unique_pairs_removed_stores=df_store_zip_unique_pairs[(df_store_zip_unique_pairs['store_A_store_id'].isin(store_list_in_dist_group)) |\\\n",
    "                                                                 (df_store_zip_unique_pairs['store_B_store_id'].isin(store_list_in_dist_group))]\n",
    "    \n",
    "    df_removed_stores_1=pd.DataFrame({\"store_id\":store_list_in_dist_group})\n",
    "    df_removed_stores_1=pd.merge(df_removed_stores_1,df_store_address,on=\"store_id\",how=\"left\")\n",
    "    df_removed_stores_1=pd.merge(df_removed_stores_1,df_P_S_zips_by_store,on=\"store_id\",how=\"left\")\n",
    "    \n",
    "    df_removed_stores_1['nearest_store']=df_removed_stores_1['store_id'].apply(lambda x: find_nearest_store(x)[0])\n",
    "    df_removed_stores_1['dist_to_nearest_store']=df_removed_stores_1['store_id'].apply(lambda x: find_nearest_store(x)[1])\n",
    "\n",
    "    df_removed_stores_1['min_overlap_pctg']=df_removed_stores_1['store_id'].apply(lambda x: find_overlaped_stores(x)[0])\n",
    "    df_removed_stores_1['min_overlap_store']=df_removed_stores_1['store_id'].apply(lambda x: find_overlaped_stores(x)[1])\n",
    "    df_removed_stores_1['max_overlap_pctg']=df_removed_stores_1['store_id'].apply(lambda x: find_overlaped_stores(x)[2])\n",
    "    df_removed_stores_1['max_overlap_store']=df_removed_stores_1['store_id'].apply(lambda x: find_overlaped_stores(x)[3])\n",
    "\n",
    "    df_removed_stores_1['All_P&S_zips']=df_removed_stores_1['all_P_zips']+df_removed_stores_1['all_S_zips']\n",
    "    df_removed_stores_1['All_P&S_zips_40_miles']=df_removed_stores_1['40_miles_P_zips']+df_removed_stores_1['40_miles_S_zips']\n",
    "\n",
    "    df_removed_stores_1['dist_min_overlap_pairs']=df_removed_stores_1['min_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "    df_removed_stores_1['dist_max_overlap_pairs']=df_removed_stores_1['max_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "    df_removed_stores_1['dist_group']=dist\n",
    "        \n",
    "    df_removed_stores_1=df_removed_stores_1[ordered_cols]\n",
    "    df_removed_stores_1=df_removed_stores_1.sort_values(\"dist_to_nearest_store\",ascending=False)\n",
    "    \n",
    "    \n",
    "    nearest_store_dist_criteria=nearest_store_dist_criteria_dict[dist]\n",
    "    single_store_df=df_removed_stores_1[(df_removed_stores_1['dist_to_nearest_store']>nearest_store_dist_criteria) &\\\n",
    "                                        (df_removed_stores_1['max_overlap_pctg']<=0.15)]\n",
    "    single_store_df['nearest_store_dist_criteria']=nearest_store_dist_criteria\n",
    "    \n",
    "    high_overlap_store_df=df_removed_stores_1[(df_removed_stores_1['dist_to_nearest_store']<=10) &\\\n",
    "                                        (df_removed_stores_1['max_overlap_pctg']>=0.5)]\n",
    "       \n",
    "    df_removed_stores_1.to_excel(writer,dist+\"_all_stores\",index=False)\n",
    "    \n",
    "    \n",
    "    all_paired_group_store_df=all_paired_group_store_df.append(df_removed_stores_1)\n",
    "    all_single_store_df=all_single_store_df.append(single_store_df)\n",
    "\n",
    "    all_high_overlap_store_df=all_high_overlap_store_df.append(high_overlap_store_df)\n",
    "    \n",
    "\n",
    "def clean_list_col(df):\n",
    "    for col in df.columns.tolist():\n",
    "        if df[col].apply(lambda x: type(x)).unique()[0]==list:\n",
    "            df[col]=df[col].astype(str)\n",
    "    return df\n",
    "            \n",
    "all_single_store_df=clean_list_col(all_single_store_df)\n",
    "all_paired_group_store_df=clean_list_col(all_paired_group_store_df)\n",
    "all_high_overlap_store_df=clean_list_col(all_high_overlap_store_df)\n",
    "\n",
    "all_single_store_df=all_single_store_df.drop_duplicates()\n",
    "all_paired_group_store_df=all_paired_group_store_df.drop_duplicates()\n",
    "all_high_overlap_store_df=all_high_overlap_store_df.drop_duplicates()\n",
    "\n",
    "all_single_store_df=all_single_store_df[['nearest_store_dist_criteria']+ordered_cols]\n",
    "all_single_store_df.to_excel(writer,\"all_single_store_df\",index=False)\n",
    "all_paired_group_store_df.to_excel(writer,\"all_paired_group_store_df\",index=False)\n",
    "all_high_overlap_store_df.to_excel(writer,\"all_high_overlap_store_df\",index=False)\n",
    "\n",
    "all_unique_high_overlap_stores=all_high_overlap_store_df.copy()\n",
    "del all_high_overlap_store_df['dist_group']\n",
    "all_high_overlap_store_df=all_high_overlap_store_df.drop_duplicates()\n",
    "all_high_overlap_store_df=all_high_overlap_store_df.sort_values([\"state\",'city','dist_to_nearest_store'])\n",
    "all_high_overlap_store_df.to_excel(writer,\"unique_all_high_overlap_store\",index=False)\n",
    "\n",
    "df_summary_high_overlap_store_st=all_high_overlap_store_df.groupby(all_high_overlap_store_df['state'])['store_id'].nunique().to_frame().reset_index()\n",
    "df_summary_high_overlap_store_st.to_excel(writer,\"summary_high_overlap_st_count\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_the_hold_store(pair_list,hold_store):\n",
    "    y=pair_list.copy()\n",
    "    y.remove(hold_store)\n",
    "    return y[0]\n",
    "\n",
    "all_paired_group_store_df['min_overlap_store']=all_paired_group_store_df['min_overlap_store'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['max_overlap_store']=all_paired_group_store_df['max_overlap_store'].apply(lambda x: eval(x))\n",
    "\n",
    "all_paired_group_store_df['all_P_zips']=all_paired_group_store_df['all_P_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['all_S_zips']=all_paired_group_store_df['all_S_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['All_P&S_zips']=all_paired_group_store_df['All_P&S_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['40_miles_P_zips']=all_paired_group_store_df['40_miles_P_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['40_miles_S_zips']=all_paired_group_store_df['40_miles_S_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['All_P&S_zips_40_miles']=all_paired_group_store_df['All_P&S_zips_40_miles'].apply(lambda x: eval(x))\n",
    "\n",
    "    \n",
    "all_paired_group_store_df['min_paired_store']=all_paired_group_store_df.apply(lambda x: remove_the_hold_store(x['min_overlap_store'],x['store_id']),axis=1)\n",
    "all_paired_group_store_df['max_paired_store']=all_paired_group_store_df.apply(lambda x: remove_the_hold_store(x['max_overlap_store'],x['store_id']),axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "store_PS_40=df_P_S_zips_by_store[['store_id','40_miles_P_zips','40_miles_S_zips']]\n",
    "store_PS_40['all_PS_40']=store_PS_40['40_miles_P_zips']+store_PS_40['40_miles_S_zips']\n",
    "store_PS_40['all_PS_40']=store_PS_40['all_PS_40'].apply(lambda x: list(set(x)))\n",
    "store_PS_40=store_PS_40[['store_id','all_PS_40']]\n",
    "\n",
    "store_PS_40_min=store_PS_40.rename(columns={\"store_id\":\"min_paired_store\",\"all_PS_40\":\"min_store_all_PS_40\"})\n",
    "store_PS_40_max=store_PS_40.rename(columns={\"store_id\":\"max_paired_store\",\"all_PS_40\":\"max_store_all_PS_40\"})\n",
    "store_PS_40_near=store_PS_40.rename(columns={\"store_id\":\"nearest_store\",\"all_PS_40\":\"near_store_all_PS_40\"})\n",
    "\n",
    "all_paired_group_store_df=pd.merge(all_paired_group_store_df,store_PS_40_min,on=\"min_paired_store\")\n",
    "all_paired_group_store_df=pd.merge(all_paired_group_store_df,store_PS_40_max,on=\"max_paired_store\")\n",
    "all_paired_group_store_df=pd.merge(all_paired_group_store_df,store_PS_40_near,on=\"nearest_store\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_2_list(list_1,list_2):\n",
    "    inter_list=list(set(list_1).intersection(set(list_2)))\n",
    "    inter_pctg_1=len(inter_list)/len(list_1)\n",
    "    inter_pctg_2=len(inter_list)/len(list_2)\n",
    "    return inter_list,inter_pctg_1,inter_pctg_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_group</th>\n",
       "      <th>store_id</th>\n",
       "      <th>address_1</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>all_P_zips</th>\n",
       "      <th>all_S_zips</th>\n",
       "      <th>All_P&amp;S_zips</th>\n",
       "      <th>40_miles_P_zips</th>\n",
       "      <th>40_miles_S_zips</th>\n",
       "      <th>All_P&amp;S_zips_40_miles</th>\n",
       "      <th>nearest_store</th>\n",
       "      <th>dist_to_nearest_store</th>\n",
       "      <th>max_overlap_store</th>\n",
       "      <th>max_overlap_pctg</th>\n",
       "      <th>dist_max_overlap_pairs</th>\n",
       "      <th>min_overlap_pctg</th>\n",
       "      <th>min_overlap_store</th>\n",
       "      <th>dist_min_overlap_pairs</th>\n",
       "      <th>min_paired_store</th>\n",
       "      <th>max_paired_store</th>\n",
       "      <th>min_store_all_PS_40</th>\n",
       "      <th>max_store_all_PS_40</th>\n",
       "      <th>near_store_all_PS_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dist_group, store_id, address_1, city, state, zip_cd, latitude, longitude, all_P_zips, all_S_zips, All_P&S_zips, 40_miles_P_zips, 40_miles_S_zips, All_P&S_zips_40_miles, nearest_store, dist_to_nearest_store, max_overlap_store, max_overlap_pctg, dist_max_overlap_pairs, min_overlap_pctg, min_overlap_store, dist_min_overlap_pairs, min_paired_store, max_paired_store, min_store_all_PS_40, max_store_all_PS_40, near_store_all_PS_40]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paired_group_store_df[all_paired_group_store_df['near_store_all_PS_40'].apply(len)==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paired_group_store_df['nearest_intersection_zips']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['near_store_all_PS_40'])[0],axis=1)\n",
    "all_paired_group_store_df['nearest_pair_overlap_with_hold']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['near_store_all_PS_40'])[1],axis=1)\n",
    "all_paired_group_store_df['nearest_pair_overlap_with_nearest']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['near_store_all_PS_40'])[2],axis=1)\n",
    "\n",
    "all_paired_group_store_df['max_intersection_zips']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['max_store_all_PS_40'])[0],axis=1)\n",
    "all_paired_group_store_df['max_pair_overlap_with_hold']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['max_store_all_PS_40'])[1],axis=1)\n",
    "all_paired_group_store_df['max_pair_overlap_with_max']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['max_store_all_PS_40'])[2],axis=1)\n",
    "\n",
    "all_paired_group_store_df['min_intersection_zips']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['min_store_all_PS_40'])[0],axis=1)\n",
    "all_paired_group_store_df['min_pair_overlap_with_hold']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['min_store_all_PS_40'])[1],axis=1)\n",
    "all_paired_group_store_df['min_pair_overlap_with_min']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['min_store_all_PS_40'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1665, 36)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list=['dist_group','store_id','address_1','city','state','zip_cd','latitude','longitude',\n",
    "          'all_P_zips','all_S_zips','All_P&S_zips','40_miles_P_zips','40_miles_S_zips','All_P&S_zips_40_miles',\n",
    "          'nearest_store','dist_to_nearest_store','near_store_all_PS_40','nearest_intersection_zips','nearest_pair_overlap_with_hold','nearest_pair_overlap_with_nearest',\n",
    "          'max_overlap_store','max_overlap_pctg','dist_max_overlap_pairs','max_paired_store','max_store_all_PS_40',\n",
    "          'max_intersection_zips','max_pair_overlap_with_hold','max_pair_overlap_with_max',\n",
    "          'min_overlap_store','min_overlap_pctg','dist_min_overlap_pairs','min_paired_store','min_store_all_PS_40',\n",
    "          'min_intersection_zips','min_pair_overlap_with_hold','min_pair_overlap_with_min']\n",
    "all_paired_group_store_df=all_paired_group_store_df[col_list]\n",
    "all_paired_group_store_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_removed_stores_1['All_P&S_zips']=df_removed_stores_1['all_P_zips']+df_removed_stores_1['all_S_zips']\n",
    "df_removed_stores_1['All_P&S_zips_40_miles']=df_removed_stores_1['40_miles_P_zips']+df_removed_stores_1['40_miles_S_zips']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_all_stores_in_single_TA_1 16\n",
      "list_all_stores_in_single_TA_2 5\n",
      "already_defined_stores, 21\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "\n",
    "# list_all_stores_in_single_TA_1 -- no overlap at all\n",
    "list_all_stores_in_single_TA_1=df_P_S_zips_by_store[~df_P_S_zips_by_store['store_id'].isin(all_paired_group_store_df['store_id'].tolist())]\n",
    "list_all_stores_in_single_TA_1=list_all_stores_in_single_TA_1['store_id'].unique().tolist()\n",
    "print(\"list_all_stores_in_single_TA_1\",len(list_all_stores_in_single_TA_1))\n",
    "df_no_overlap_at_all=pd.DataFrame({\"store_id\":list_all_stores_in_single_TA_1})\n",
    "df_no_overlap_at_all=pd.merge(df_no_overlap_at_all,df_store_address,on=\"store_id\",how=\"left\")\n",
    "df_no_overlap_at_all=pd.merge(df_no_overlap_at_all,df_P_S_zips_by_store,on=\"store_id\",how=\"left\")\n",
    "df_no_overlap_at_all['All_P&S_zips']=df_no_overlap_at_all['all_P_zips']+df_no_overlap_at_all['all_S_zips']\n",
    "df_no_overlap_at_all['All_P&S_zips_40_miles']=df_no_overlap_at_all['40_miles_P_zips']+df_no_overlap_at_all['40_miles_S_zips']\n",
    "\n",
    "\n",
    "\n",
    "# list_all_stores_in_single_TA_2 -- low oeverlap\n",
    "list_all_stores_in_single_TA_2=all_paired_group_store_df[(all_paired_group_store_df['nearest_store']==all_paired_group_store_df['max_paired_store']) &\\\n",
    "                                                         (all_paired_group_store_df['nearest_store']==all_paired_group_store_df['min_paired_store']) &\\\n",
    "                                                         (all_paired_group_store_df['max_overlap_pctg']<0.15) &\\\n",
    "                                                         (all_paired_group_store_df['nearest_pair_overlap_with_hold']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['nearest_pair_overlap_with_nearest']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['max_pair_overlap_with_hold']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['max_pair_overlap_with_max']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['min_pair_overlap_with_hold']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['min_pair_overlap_with_min']<0.5)]['store_id'].unique().tolist()\n",
    "print(\"list_all_stores_in_single_TA_2\",len(list_all_stores_in_single_TA_2))\n",
    "col_single_store_TA=all_paired_group_store_df.columns.tolist()\n",
    "df_all_single_store_TA=all_paired_group_store_df[all_paired_group_store_df['store_id'].isin(list_all_stores_in_single_TA_2)]\n",
    "df_all_single_store_TA=df_all_single_store_TA.append(df_no_overlap_at_all)[col_single_store_TA]\n",
    "\n",
    "already_defined_stores=df_all_single_store_TA['store_id'].unique().tolist()\n",
    "print(\"already_defined_stores,\",len(already_defined_stores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_included_P_S_stores=df_P_S_zips_by_store['store_id'].unique().tolist()\n",
    "\n",
    "new_stores=df_store_address[~df_store_address['store_id'].isin(all_included_P_S_stores)]\n",
    "\n",
    "new_stores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>address_1</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [store_id, address_1, city, state, zip_cd, latitude, longitude]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_stores_already_asigned(stores_per_row,all_defined_list):\n",
    "    # y_in_defined_list=[x for x in stores_per_row if x in all_defined_list]\n",
    "    y_notin_defined_list=[x for x in stores_per_row if x not in all_defined_list]\n",
    "    \n",
    "    return y_notin_defined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paired_group_store_df['original_combined_stores_4']=\"[\"+\"'\"+all_paired_group_store_df['store_id']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['nearest_store']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['max_paired_store']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['min_paired_store']+\"'\"+\"]\"\n",
    "all_paired_group_store_df['original_combined_stores_4']=all_paired_group_store_df['original_combined_stores_4'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "all_paired_group_store_df['original_combined_stores_3']=\"[\"+\"'\"+all_paired_group_store_df['store_id']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['nearest_store']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['max_paired_store']+\"'\"+\"]\"\n",
    "all_paired_group_store_df['original_combined_stores_3']=all_paired_group_store_df['original_combined_stores_3'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['original_combined_stores_4']\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['original_combined_stores_3']\n",
    "\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1- >=50% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_B_all_merge_4_40_above_involved_stores 40\n",
      "already_defined_stores 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# B - T1 >=50%\n",
    "# merge 1: 4 stores - hold, max&min, nearest 10 miles\n",
    "\n",
    "\n",
    "df_B_all_merge_4_40_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']<=10) &\\\n",
    "                                         (all_paired_group_store_df['max_overlap_pctg']>=0.5) &\\\n",
    "                                         (all_paired_group_store_df['min_overlap_pctg']>=0.5)]\n",
    "df_B_all_merge_4_40_above['result_combined_stores']=df_B_all_merge_4_40_above['cleaned_combined_stores_4']\n",
    "\n",
    "list_df_B_all_merge_4_40_above_involved_stores=list(set(df_B_all_merge_4_40_above['result_combined_stores'].sum()))\n",
    "print('list_df_B_all_merge_4_40_above_involved_stores',len(list_df_B_all_merge_4_40_above_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_B_all_merge_4_40_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_C_all_merge_3_40_above_involved_stores 389\n",
      "already_defined_stores 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# C - T1 >=50%\n",
    "# merge 2: 3 stores - hold, max|min, nearest 10 miles\n",
    "\n",
    "df_C_all_merge_3_40_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']<=10) &\\\n",
    "                                           ((all_paired_group_store_df['max_overlap_pctg']>=0.5) | (all_paired_group_store_df['min_overlap_pctg']>=0.5))]\n",
    "df_C_all_merge_3_40_above['result_combined_stores']=df_C_all_merge_3_40_above['cleaned_combined_stores_3']\n",
    "\n",
    "list_df_C_all_merge_3_40_above_involved_stores=list(set(df_C_all_merge_3_40_above['result_combined_stores'].sum()))\n",
    "print('list_df_C_all_merge_3_40_above_involved_stores',len(list_df_C_all_merge_3_40_above_involved_stores))\n",
    "\n",
    "####\n",
    "already_defined_stores=list(set(already_defined_stores+list_df_C_all_merge_3_40_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_D_all_merge_4_40_above_involved_stores 3\n",
      "already_defined_stores 453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# D - T1 >=50%\n",
    "# merge 3: 4 stores - hold, max&min, nearest 10-28 miles\n",
    "\n",
    "\n",
    "df_D_all_merge_4_40_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']>10) &\\\n",
    "                                           (all_paired_group_store_df['dist_to_nearest_store']<=28) &\\\n",
    "                                           (all_paired_group_store_df['max_overlap_pctg']>=0.5) &\\\n",
    "                                           (all_paired_group_store_df['min_overlap_pctg']>=0.5)]\n",
    "df_D_all_merge_4_40_above['result_combined_stores']=df_D_all_merge_4_40_above['cleaned_combined_stores_4']\n",
    "if len(df_D_all_merge_4_40_above)>0:\n",
    "    list_df_D_all_merge_4_40_above_involved_stores=list(set(df_D_all_merge_4_40_above['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_D_all_merge_4_40_above_involved_stores=[]\n",
    "print('list_df_D_all_merge_4_40_above_involved_stores',len(list_df_D_all_merge_4_40_above_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_D_all_merge_4_40_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_E_all_merge_3_40_above_involved_stores 58\n",
      "already_defined_stores 511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# E - T1 >=50%\n",
    "# merge 4: 3 stores - hold, max|min, nearest 10-28 miles\n",
    "\n",
    "\n",
    "df_E_all_merge_3_40_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']>10) &\\\n",
    "                                           (all_paired_group_store_df['dist_to_nearest_store']<=28) &\\\n",
    "                                           ((all_paired_group_store_df['max_overlap_pctg']>=0.5)|(all_paired_group_store_df['min_overlap_pctg']>=0.5))]\n",
    "df_E_all_merge_3_40_above['result_combined_stores']=df_E_all_merge_3_40_above['cleaned_combined_stores_3']\n",
    "\n",
    "if len(df_E_all_merge_3_40_above)>0:\n",
    "    list_df_E_all_merge_3_40_above_involved_stores=list(set(df_E_all_merge_3_40_above['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_E_all_merge_3_40_above_involved_stores=[]\n",
    "print('list_df_E_all_merge_3_40_above_involved_stores',len(list_df_E_all_merge_3_40_above_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_E_all_merge_3_40_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T2- >=35% & <50% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_B_all_merge_4_35_40_involved_stores 0\n",
      "already_defined_stores 511\n"
     ]
    }
   ],
   "source": [
    "# B - T2 [35%,50%)\n",
    "# merge 1: 4 stores - hold, max&min, nearest without dist criteria\n",
    "\n",
    "# nearest_always kept in the result\n",
    "# whichever satisfied the cretearia, whichever should be included, max or min \n",
    "\n",
    "df_B_all_merge_4_35_40=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.35) & (all_paired_group_store_df['max_overlap_pctg']<0.5)) &\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.35) & (all_paired_group_store_df['min_overlap_pctg']<0.5))]\n",
    "df_B_all_merge_4_35_40['result_combined_stores']=df_B_all_merge_4_35_40['cleaned_combined_stores_4']\n",
    "\n",
    "if len(df_B_all_merge_4_35_40)>0:\n",
    "    list_df_B_all_merge_4_35_40_involved_stores=list(set(df_B_all_merge_4_35_40['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_B_all_merge_4_35_40_involved_stores=[]\n",
    "    \n",
    "print('list_df_B_all_merge_4_35_40_involved_stores',len(list_df_B_all_merge_4_35_40_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_B_all_merge_4_35_40_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_C_all_merge_3_35_40_involved_stores 27\n",
      "already_defined_stores 538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# C - T2 [35%,50%)\n",
    "# merge 2: 3 stores - hold, max|min, nearest without dist criteria\n",
    "\n",
    "df_C_all_merge_3_35_40=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.35) & (all_paired_group_store_df['max_overlap_pctg']<0.5)) |\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.35) & (all_paired_group_store_df['min_overlap_pctg']<0.5))]\n",
    "\n",
    "df_C_all_merge_3_35_40_1_Max=df_C_all_merge_3_35_40[(df_C_all_merge_3_35_40['max_overlap_pctg']>=0.35) & (df_C_all_merge_3_35_40['max_overlap_pctg']<0.5)]\n",
    "df_C_all_merge_3_35_40_2_Min=df_C_all_merge_3_35_40[(df_C_all_merge_3_35_40['min_overlap_pctg']>=0.35) & (df_C_all_merge_3_35_40['min_overlap_pctg']<0.5)]\n",
    "\n",
    "df_C_all_merge_3_35_40_1_Max['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_35_40_1_Max['store_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_40_1_Max['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_40_1_Max['max_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_35_40_1_Max['result_combined_stores']=df_C_all_merge_3_35_40_1_Max['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_35_40_2_Min['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_35_40_2_Min['store_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_40_2_Min['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_40_2_Min['min_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_35_40_2_Min['result_combined_stores']=df_C_all_merge_3_35_40_2_Min['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_35_40=df_C_all_merge_3_35_40_1_Max.append(df_C_all_merge_3_35_40_2_Min)\n",
    "\n",
    "df_C_all_merge_3_35_40['result_combined_stores']=df_C_all_merge_3_35_40['result_combined_stores'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "\n",
    "\n",
    "list_df_C_all_merge_3_35_40_involved_stores=list(set(df_C_all_merge_3_35_40['result_combined_stores'].sum()))\n",
    "print('list_df_C_all_merge_3_35_40_involved_stores',len(list_df_C_all_merge_3_35_40_involved_stores))\n",
    "\n",
    "####\n",
    "already_defined_stores=list(set(already_defined_stores+list_df_C_all_merge_3_35_40_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T3- >=15% & <35% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_B_all_merge_4_15_35_involved_stores 1\n",
      "already_defined_stores 539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# B - T3 [15%,35%)\n",
    "# merge 1: 4 stores - hold, max&min, nearest without dist criteria\n",
    "\n",
    "# nearest_always kept in the result\n",
    "# whichever satisfied the cretearia, whichever should be included, max or min \n",
    "\n",
    "df_B_all_merge_4_15_35=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.15) & (all_paired_group_store_df['max_overlap_pctg']<0.35)) &\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.15) & (all_paired_group_store_df['min_overlap_pctg']<0.35))]\n",
    "df_B_all_merge_4_15_35['result_combined_stores']=df_B_all_merge_4_15_35['cleaned_combined_stores_4']\n",
    "\n",
    "if len(df_B_all_merge_4_15_35)>0:\n",
    "    list_df_B_all_merge_4_15_35_involved_stores=list(set(df_B_all_merge_4_15_35['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_B_all_merge_4_15_35_involved_stores=[]\n",
    "    \n",
    "print('list_df_B_all_merge_4_15_35_involved_stores',len(list_df_B_all_merge_4_15_35_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_B_all_merge_4_15_35_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_C_all_merge_3_15_35_involved_stores 14\n",
      "already_defined_stores 553\n"
     ]
    }
   ],
   "source": [
    "# C - T3 [15%,35%)\n",
    "# merge 2: 3 stores - hold, max|min, nearest without dist criteria\n",
    "\n",
    "df_C_all_merge_3_15_35=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.15) & (all_paired_group_store_df['max_overlap_pctg']<0.35)) |\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.15) & (all_paired_group_store_df['min_overlap_pctg']<0.35))]\n",
    "\n",
    "df_C_all_merge_3_15_35_1_Max=df_C_all_merge_3_15_35[(df_C_all_merge_3_15_35['max_overlap_pctg']>=0.15) & (df_C_all_merge_3_15_35['max_overlap_pctg']<0.35)]\n",
    "df_C_all_merge_3_15_35_2_Min=df_C_all_merge_3_15_35[(df_C_all_merge_3_15_35['min_overlap_pctg']>=0.15) & (df_C_all_merge_3_15_35['min_overlap_pctg']<0.35)]\n",
    "\n",
    "df_C_all_merge_3_15_35_1_Max['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_15_35_1_Max['store_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_1_Max['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_1_Max['max_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_15_35_1_Max['result_combined_stores']=df_C_all_merge_3_15_35_1_Max['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_15_35_2_Min['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_15_35_2_Min['store_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_2_Min['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_2_Min['min_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_15_35_2_Min['result_combined_stores']=df_C_all_merge_3_15_35_2_Min['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_15_35=df_C_all_merge_3_15_35_1_Max.append(df_C_all_merge_3_15_35_2_Min)\n",
    "\n",
    "df_C_all_merge_3_15_35['result_combined_stores']=df_C_all_merge_3_15_35['result_combined_stores'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "\n",
    "\n",
    "list_df_C_all_merge_3_15_35_involved_stores=list(set(df_C_all_merge_3_15_35['result_combined_stores'].sum()))\n",
    "print('list_df_C_all_merge_3_15_35_involved_stores',len(list_df_C_all_merge_3_15_35_involved_stores))\n",
    "\n",
    "####\n",
    "already_defined_stores=list(set(already_defined_stores+list_df_C_all_merge_3_15_35_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remained_stores=all_paired_group_store_df[~all_paired_group_store_df['store_id'].isin(already_defined_stores)]\n",
    "\n",
    "remained_stores['store_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389, 9)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store list by group column\n",
    "\n",
    "max_len_store=max(len(df_all_single_store_TA['store_id'].unique().tolist()),\n",
    "                 len(list_df_B_all_merge_4_40_above_involved_stores),\n",
    "                 len(list_df_C_all_merge_3_40_above_involved_stores),\n",
    "                 len(list_df_D_all_merge_4_40_above_involved_stores),\n",
    "                 len(list_df_E_all_merge_3_40_above_involved_stores),\n",
    "                 len(list_df_B_all_merge_4_35_40_involved_stores),\n",
    "                 len(list_df_C_all_merge_3_35_40_involved_stores),\n",
    "                 len(list_df_B_all_merge_4_15_35_involved_stores),\n",
    "                 len(list_df_C_all_merge_3_15_35_involved_stores),\n",
    "                 )\n",
    "\n",
    "df_stores_in_each_group=pd.DataFrame({\"T1_A_single_store_TA\":df_all_single_store_TA['store_id'].unique().tolist()+[np.nan]*(max_len_store-len(df_all_single_store_TA['store_id'].unique().tolist())),\n",
    "                                      \"T1_B_all_merge_4_40_above_involved_stores\":list_df_B_all_merge_4_40_above_involved_stores+[np.nan]*(max_len_store-len(list_df_B_all_merge_4_40_above_involved_stores)),\n",
    "                                      \"T1_C_all_merge_3_40_above_involved_stores\":list_df_C_all_merge_3_40_above_involved_stores+[np.nan]*(max_len_store-len(list_df_C_all_merge_3_40_above_involved_stores)),\n",
    "                                      \"T1_D_all_merge_4_40_above_involved_stores\":list_df_D_all_merge_4_40_above_involved_stores+[np.nan]*(max_len_store-len(list_df_D_all_merge_4_40_above_involved_stores)),\n",
    "                                      \"T1_E_all_merge_3_40_above_involved_stores\":list_df_E_all_merge_3_40_above_involved_stores+[np.nan]*(max_len_store-len(list_df_E_all_merge_3_40_above_involved_stores)),\n",
    "                                      \"T2_B_all_merge_4_35_40_involved_stores\":list_df_B_all_merge_4_35_40_involved_stores+[np.nan]*(max_len_store-len(list_df_B_all_merge_4_35_40_involved_stores)),\n",
    "                                      \"T2_C_all_merge_3_35_40_involved_stores\":list_df_C_all_merge_3_35_40_involved_stores+[np.nan]*(max_len_store-len(list_df_C_all_merge_3_35_40_involved_stores)),\n",
    "                                      \"T3_B_all_merge_4_15_35_involved_stores\":list_df_B_all_merge_4_15_35_involved_stores+[np.nan]*(max_len_store-len(list_df_B_all_merge_4_15_35_involved_stores)),\n",
    "                                      \"T3_C_all_merge_3_15_35_involved_stores\":list_df_C_all_merge_3_15_35_involved_stores+[np.nan]*(max_len_store-len(list_df_C_all_merge_3_15_35_involved_stores)),\n",
    "                                     },index=[x for x in range(max_len_store)])\n",
    "df_stores_in_each_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>store_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_A_single_store_TA</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_B_all_merge_4_40_above_involved_stores</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_C_all_merge_3_40_above_involved_stores</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_D_all_merge_4_40_above_involved_stores</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_E_all_merge_3_40_above_involved_stores</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2_B_all_merge_4_35_40_involved_stores</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2_C_all_merge_3_35_40_involved_stores</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T3_B_all_merge_4_15_35_involved_stores</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T3_C_all_merge_3_15_35_involved_stores</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       group  store_count\n",
       "0                       T1_A_single_store_TA           21\n",
       "0  T1_B_all_merge_4_40_above_involved_stores           40\n",
       "0  T1_C_all_merge_3_40_above_involved_stores          389\n",
       "0  T1_D_all_merge_4_40_above_involved_stores            3\n",
       "0  T1_E_all_merge_3_40_above_involved_stores           58\n",
       "0     T2_B_all_merge_4_35_40_involved_stores            0\n",
       "0     T2_C_all_merge_3_35_40_involved_stores           27\n",
       "0     T3_B_all_merge_4_15_35_involved_stores            1\n",
       "0     T3_C_all_merge_3_15_35_involved_stores           14"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_count=pd.DataFrame()\n",
    "\n",
    "for col in df_stores_in_each_group.columns.tolist():\n",
    "    list_col=df_stores_in_each_group[col].unique().tolist()\n",
    "    list_col=[x for x in list_col if str(x)!=\"nan\"]\n",
    "    len_col=len(list_col)\n",
    "    df=pd.DataFrame({\"group\":col,\"store_count\":len_col},index=[0])\n",
    "    df_store_count=df_store_count.append(df)\n",
    "df_store_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"GY_TA_combination_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_all_single_store_TA.to_excel(writer,\"T1_df_all_single_store_TA\",index=False)\n",
    "df_B_all_merge_4_40_above.to_excel(writer,\"T1_df_B_all_merge_4\",index=False)\n",
    "df_C_all_merge_3_40_above.to_excel(writer,\"T1_df_C_all_merge_3\",index=False)\n",
    "df_D_all_merge_4_40_above.to_excel(writer,\"T1_df_D_all_merge_4\",index=False)\n",
    "df_E_all_merge_3_40_above.to_excel(writer,\"T1_df_E_all_merge_3\",index=False)\n",
    "\n",
    "df_B_all_merge_4_35_40.to_excel(writer,\"T2_df_B_all_merge_4_15_35\",index=False)\n",
    "df_C_all_merge_3_35_40.to_excel(writer,\"T2_df_C_all_merge_3_15_35\",index=False)\n",
    "\n",
    "df_B_all_merge_4_15_35.to_excel(writer,\"T3_df_B_all_merge_4_15_35\",index=False)\n",
    "df_C_all_merge_3_15_35.to_excel(writer,\"T3_df_C_all_merge_3_15_35\",index=False)\n",
    "\n",
    "df_store_count.to_excel(writer,\"group_store_count\",index=False)\n",
    "\n",
    "df_stores_in_each_group.to_excel(writer,\"defined_stores\",index=False)\n",
    "\n",
    "all_paired_group_store_df.to_excel(writer,\"all_paired_group_store_df\",index=False)\n",
    "remained_stores.to_excel(writer,\"remained_stores\",index=False)\n",
    "new_stores.to_excel(writer,\"new_stores_without_P_S\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected_N_stores_as_initial_aggregated_TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMA_nielsen=pd.read_excel(path_nielsen_zip,\n",
    "                          dtype=str,skiprows=1,usecols=['CODE','NAME','NAME.1'])\n",
    "DMA_nielsen=DMA_nielsen.rename(columns={\"CODE\":\"zip_cd\",\"NAME\":\"DMA\",\"NAME.1\":\"CTY\"})\n",
    "DMA_nielsen=DMA_nielsen.drop_duplicates()\n",
    "zip_DMA=DMA_nielsen.groupby(\"zip_cd\")['DMA'].apply(set).to_frame().reset_index()\n",
    "zip_CTY=DMA_nielsen.groupby(\"zip_cd\")['CTY'].apply(set).to_frame().reset_index()\n",
    "DMA_nielsen=pd.merge(zip_DMA,zip_CTY,on=\"zip_cd\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected T1B - T2C\n",
    "selected_groups=['T1_B_all_merge_4_40_above_involved_stores',\n",
    "                 'T1_C_all_merge_3_40_above_involved_stores',\n",
    "                 'T1_D_all_merge_4_40_above_involved_stores',\n",
    "                 'T1_E_all_merge_3_40_above_involved_stores',\n",
    "                 'T2_B_all_merge_4_35_40_involved_stores',\n",
    "                 'T2_C_all_merge_3_35_40_involved_stores']\n",
    "\n",
    "df_output_N_stores_selected=pd.DataFrame()\n",
    "\n",
    "for group in selected_groups:\n",
    "    store_list=df_stores_in_each_group[group].unique().tolist()\n",
    "    store_list=[x for x in store_list if str(x)!=\"nan\"]\n",
    "    df=pd.DataFrame({\"store_id\":store_list},index=[group]*len(store_list)).reset_index().rename(columns={\"index\":\"group\"})\n",
    "    df_output_N_stores_selected=df_output_N_stores_selected.append(df)\n",
    "df_output_N_stores_selected.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>store_id</th>\n",
       "      <th>address_1</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>DMA</th>\n",
       "      <th>CTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_B_all_merge_4_40_above_involved_stores</td>\n",
       "      <td>8035</td>\n",
       "      <td>350 KAMEHAMEHA HIGHWAY</td>\n",
       "      <td>96782</td>\n",
       "      <td>PEARL CITY</td>\n",
       "      <td>HI</td>\n",
       "      <td>21.387715</td>\n",
       "      <td>-157.955361</td>\n",
       "      <td>{'HONOLULU'}</td>\n",
       "      <td>{'HONOLULU'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1_B_all_merge_4_40_above_involved_stores</td>\n",
       "      <td>8029</td>\n",
       "      <td>86-120 FARRINGTON HIGHWAY SUITE K</td>\n",
       "      <td>96792</td>\n",
       "      <td>WAIANAE</td>\n",
       "      <td>HI</td>\n",
       "      <td>21.437371</td>\n",
       "      <td>-158.185444</td>\n",
       "      <td>{'HONOLULU'}</td>\n",
       "      <td>{'HONOLULU'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       group store_id  \\\n",
       "0  T1_B_all_merge_4_40_above_involved_stores     8035   \n",
       "1  T1_B_all_merge_4_40_above_involved_stores     8029   \n",
       "\n",
       "                           address_1 zip_cd        city state   latitude  \\\n",
       "0             350 KAMEHAMEHA HIGHWAY  96782  PEARL CITY    HI  21.387715   \n",
       "1  86-120 FARRINGTON HIGHWAY SUITE K  96792     WAIANAE    HI  21.437371   \n",
       "\n",
       "    longitude           DMA           CTY  \n",
       "0 -157.955361  {'HONOLULU'}  {'HONOLULU'}  \n",
       "1 -158.185444  {'HONOLULU'}  {'HONOLULU'}  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list=df_store_included_with_dates[['store_num','address_1','zip_cd','city','state','latitude','longitude']]\n",
    "store_list=store_list.rename(columns={\"store_num\":\"store_id\"})\n",
    "store_list['zip_cd']=store_list['zip_cd'].apply(lambda x: x.split(\"-\")[0].zfill(5))\n",
    "df_output_N_stores_selected=pd.merge(df_output_N_stores_selected,store_list,on=\"store_id\",how=\"left\")\n",
    "\n",
    "df_output_N_stores_selected=pd.merge(df_output_N_stores_selected,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "\n",
    "df_output_N_stores_selected['DMA']=df_output_N_stores_selected['DMA'].astype(str)\n",
    "df_output_N_stores_selected['CTY']=df_output_N_stores_selected['CTY'].astype(str)\n",
    "\n",
    "df_output_N_stores_selected.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P_S_zips_by_store_copy=df_P_S_zips_by_store.copy()\n",
    "df_P_S_zips_by_store_copy['All_P&S_zips']=df_P_S_zips_by_store_copy['all_P_zips']+df_P_S_zips_by_store_copy['all_S_zips']\n",
    "df_P_S_zips_by_store_copy['All_P&S_zips_40_miles']=df_P_S_zips_by_store_copy['40_miles_P_zips']+df_P_S_zips_by_store_copy['40_miles_S_zips']\n",
    "df_P_S_zips_by_store_copy=df_P_S_zips_by_store_copy[['store_id','all_P_zips','all_S_zips','All_P&S_zips','40_miles_P_zips','40_miles_S_zips','All_P&S_zips_40_miles']]\n",
    "\n",
    "df_output_N_stores_selected=pd.merge(df_output_N_stores_selected,df_P_S_zips_by_store_copy,on=\"store_id\",how=\"left\")\n",
    "\n",
    "df_output_N_stores_selected['nearest_store']=df_output_N_stores_selected['store_id'].apply(lambda x: find_nearest_store(x)[0])\n",
    "df_output_N_stores_selected['dist_to_nearest_store']=df_output_N_stores_selected['store_id'].apply(lambda x: find_nearest_store(x)[1])\n",
    "\n",
    "df_output_N_stores_selected=pd.merge(df_output_N_stores_selected,store_PS_40_near,on=\"nearest_store\")\n",
    "df_output_N_stores_selected['nearest_intersection_zips']=df_output_N_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['near_store_all_PS_40'])[0],axis=1)\n",
    "df_output_N_stores_selected['nearest_pair_overlap_with_hold']=df_output_N_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['near_store_all_PS_40'])[1],axis=1)\n",
    "df_output_N_stores_selected['nearest_pair_overlap_with_nearest']=df_output_N_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['near_store_all_PS_40'])[2],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_N_stores_selected['min_overlap_pctg']=df_output_N_stores_selected['store_id'].apply(lambda x: find_overlaped_stores(x)[0])\n",
    "df_output_N_stores_selected['min_overlap_store']=df_output_N_stores_selected['store_id'].apply(lambda x: find_overlaped_stores(x)[1])\n",
    "df_output_N_stores_selected['max_overlap_pctg']=df_output_N_stores_selected['store_id'].apply(lambda x: find_overlaped_stores(x)[2])\n",
    "df_output_N_stores_selected['max_overlap_store']=df_output_N_stores_selected['store_id'].apply(lambda x: find_overlaped_stores(x)[3])\n",
    "\n",
    "\n",
    "df_output_N_stores_selected['min_overlap_store']=df_output_N_stores_selected['min_overlap_store'].apply(lambda x: eval(x))\n",
    "df_output_N_stores_selected['max_overlap_store']=df_output_N_stores_selected['max_overlap_store'].apply(lambda x: eval(x))\n",
    "\n",
    "df_output_N_stores_selected['min_paired_store']=df_output_N_stores_selected.apply(lambda x: remove_the_hold_store(x['min_overlap_store'],x['store_id']),axis=1)\n",
    "df_output_N_stores_selected['max_paired_store']=df_output_N_stores_selected.apply(lambda x: remove_the_hold_store(x['max_overlap_store'],x['store_id']),axis=1)\n",
    "\n",
    "df_output_N_stores_selected['min_overlap_store']=df_output_N_stores_selected['min_overlap_store'].astype(str)\n",
    "df_output_N_stores_selected['max_overlap_store']=df_output_N_stores_selected['max_overlap_store'].astype(str)\n",
    "\n",
    "df_output_N_stores_selected['dist_min_overlap_pairs']=df_output_N_stores_selected['min_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "df_output_N_stores_selected['dist_max_overlap_pairs']=df_output_N_stores_selected['max_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "\n",
    "\n",
    "df_output_N_stores_selected=pd.merge(df_output_N_stores_selected,store_PS_40_min,on=\"min_paired_store\")\n",
    "df_output_N_stores_selected=pd.merge(df_output_N_stores_selected,store_PS_40_max,on=\"max_paired_store\")\n",
    "\n",
    "\n",
    "df_output_N_stores_selected['max_intersection_zips']=df_output_N_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['max_store_all_PS_40'])[0],axis=1)\n",
    "df_output_N_stores_selected['max_pair_overlap_with_hold']=df_output_N_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['max_store_all_PS_40'])[1],axis=1)\n",
    "df_output_N_stores_selected['max_pair_overlap_with_max']=df_output_N_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['max_store_all_PS_40'])[2],axis=1)\n",
    "\n",
    "df_output_N_stores_selected['min_intersection_zips']=df_output_N_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['min_store_all_PS_40'])[0],axis=1)\n",
    "df_output_N_stores_selected['min_pair_overlap_with_hold']=df_output_N_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['min_store_all_PS_40'])[1],axis=1)\n",
    "df_output_N_stores_selected['min_pair_overlap_with_min']=df_output_N_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['min_store_all_PS_40'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_B_all_merge_4_40_above_involved_stores 40\n",
      "T1_B_all_merge_4_40_above_involved_stores 40\n",
      "T1_C_all_merge_3_40_above_involved_stores 389\n",
      "T1_C_all_merge_3_40_above_involved_stores 389\n",
      "T1_D_all_merge_4_40_above_involved_stores 3\n",
      "T1_D_all_merge_4_40_above_involved_stores 3\n",
      "T1_E_all_merge_3_40_above_involved_stores 58\n",
      "T1_E_all_merge_3_40_above_involved_stores 58\n",
      "T2_C_all_merge_3_35_40_involved_stores 27\n",
      "T2_C_all_merge_3_35_40_involved_stores 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df_output_N_stores_selected_with_result=pd.DataFrame()\n",
    "for group,df_group in df_output_N_stores_selected.groupby(\"group\"):\n",
    "    print(group,df_group.shape[0])\n",
    "\n",
    "    if (group in ['T1_B_all_merge_4_40_above_involved_stores','T2_B_all_merge_4_35_40_involved_stores']):\n",
    "        df_1=df_group[df_group['min_overlap_pctg']>=0.35]\n",
    "        df_2=df_group[df_group['min_overlap_pctg']<0.35]\n",
    "        \n",
    "        df_1['result_combined_store']=df_1[['store_id','nearest_store','max_paired_store','min_paired_store']].values.tolist()\n",
    "        df_2['result_combined_store']=df_2[['store_id','nearest_store','max_paired_store']].values.tolist()\n",
    "        \n",
    "        df_group=df_1.append(df_2)\n",
    "        \n",
    "    elif (group in ['T1_C_all_merge_3_40_above_involved_stores','T1_D_all_merge_4_40_above_involved_stores','T1_E_all_merge_3_40_above_involved_stores']):\n",
    "        df_group['result_combined_store']=df_group[['store_id','nearest_store','max_paired_store']].values.tolist()\n",
    "        \n",
    "    elif group==\"T2_C_all_merge_3_35_40_involved_stores\":\n",
    "        df_group_max=df_group[(df_group['max_overlap_pctg']>=0.35) & (df_group['max_overlap_pctg']<0.5)]\n",
    "        df_group_min=df_group[(df_group['min_overlap_pctg']>=0.35) & (df_group['min_overlap_pctg']<0.5)]\n",
    "        list_max_group=df_group_max['store_id'].unique().tolist()\n",
    "        list_min_group=df_group_min['store_id'].unique().tolist()\n",
    "        list_both_group=list_max_group+list_min_group\n",
    "        \n",
    "        df_group_others=df_group[~df_group['store_id'].isin(list_both_group)]\n",
    "        \n",
    "        \n",
    "        df_group_max['result_combined_store']=df_group_max[['store_id','nearest_store','max_paired_store']].values.tolist()\n",
    "        df_group_min['result_combined_store']=df_group_min[['store_id','nearest_store','min_paired_store']].values.tolist()\n",
    "        \n",
    "        df_group=df_group_max.append(df_group_min).append(df_group_others)\n",
    "        \n",
    "    print(group,len(df_group))\n",
    "    df_output_N_stores_selected_with_result=df_output_N_stores_selected_with_result.append(df_group)\n",
    "df_output_N_stores_selected_with_result['result_combined_store']=df_output_N_stores_selected_with_result['result_combined_store'].fillna(\"[]\")\n",
    "df_output_N_stores_selected_with_result['result_combined_store']=df_output_N_stores_selected_with_result['result_combined_store'].astype(str)\n",
    "df_output_N_stores_selected_with_result['result_combined_store']=df_output_N_stores_selected_with_result['result_combined_store'].apply(lambda x: sorted(list(set(eval(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_2=col_list.copy()\n",
    "col_list_2.remove(\"dist_group\")\n",
    "\n",
    "col_list_2=col_list_2[:6]+['CTY','DMA']+col_list_2[6:]\n",
    "df_output_N_stores_selected_with_result=df_output_N_stores_selected_with_result[[\"group\"]+col_list_2+[\"result_combined_store\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_N_stores_selected_with_result=df_output_N_stores_selected_with_result.sort_values([\"dist_to_nearest_store\",\"state\",\"CTY\",\"city\"])\n",
    "\n",
    "writer=pd.ExcelWriter(output_folder+\"sorted_N_stores_T1B_T2C_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_output_N_stores_selected_with_result.to_excel(writer,\"sorted_N_stores\",index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_data=df_output_N_stores_selected_with_result[['store_id','result_combined_store']]\n",
    "df_ta_store_result_pairs=pd.DataFrame(columns=['TA','store_id'])\n",
    "df_data=df_data.reset_index()\n",
    "del df_data['index']\n",
    "\n",
    "ta=0\n",
    "for i,row in df_data.iterrows():\n",
    "    location_hold=row['store_id']\n",
    "    location_associatd=row['result_combined_store']\n",
    "    intersection_existing=set(location_associatd).intersection(set(df_ta_store_result_pairs['store_id'].tolist()))\n",
    "    \n",
    "    if len(intersection_existing)==0:\n",
    "        ta+=1\n",
    "        df=pd.DataFrame({\"TA\":[ta]*len(location_associatd),\"store_id\":location_associatd},index=[ta]*len(location_associatd))\n",
    "        df_ta_store_result_pairs=df_ta_store_result_pairs.append(df)\n",
    "    else:\n",
    "        TA_list_overlapped=df_ta_store_result_pairs[df_ta_store_result_pairs['store_id'].isin(intersection_existing)]['TA'].unique().tolist()\n",
    "        grouped_ta=df_ta_store_result_pairs[df_ta_store_result_pairs['TA'].isin(TA_list_overlapped)]\n",
    "        grouped_ta_others=df_ta_store_result_pairs[~df_ta_store_result_pairs['TA'].isin(TA_list_overlapped)]\n",
    "        \n",
    "        grouped_ta['TA']=grouped_ta['TA'].min()\n",
    "        \n",
    "        new_stores_added=[x for x in location_associatd if x not in grouped_ta['store_id'].tolist()]\n",
    "        df=pd.DataFrame({\"TA\":[grouped_ta['TA'].min()]*len(new_stores_added),\"store_id\":new_stores_added},index=[grouped_ta['TA'].min()]*len(new_stores_added))\n",
    "        grouped_ta=grouped_ta.append(df)\n",
    "        df_ta_store_result_pairs=grouped_ta_others.append(grouped_ta)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ta_store_result_pairs=df_ta_store_result_pairs[df_ta_store_result_pairs['store_id'].isin(df_output_N_stores_selected_with_result['store_id'].tolist())]\n",
    "df_ta_store_result_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_N_stores_selected_with_result=pd.merge(df_output_N_stores_selected_with_result,df_ta_store_result_pairs,on=\"store_id\",how=\"left\")\n",
    "\n",
    "summary_df_N_stores=df_output_N_stores_selected_with_result.groupby(\"TA\")['store_id'].count().to_frame().reset_index().sort_values(\"store_id\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_N_stores_selected_with_result=df_output_N_stores_selected_with_result[['TA']+[x for x in df_output_N_stores_selected_with_result.columns.tolist() if x!=\"TA\"]]\n",
    "df_output_N_stores_selected_with_result=df_output_N_stores_selected_with_result.sort_values(['TA','state','CTY'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rename_TA=df_output_N_stores_selected_with_result[['TA']].drop_duplicates()\n",
    "df_rename_TA['new_name']=[x+1 for x in range(len(df_rename_TA))]\n",
    "dict_rename_TA=df_rename_TA.set_index(\"TA\").to_dict()[\"new_name\"]\n",
    "\n",
    "\n",
    "df_output_N_stores_selected_with_result['TA']=df_output_N_stores_selected_with_result['TA'].apply(lambda x: dict_rename_TA[x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"initial_TA_output.xlsx\",engine=\"xlsxwriter\")\n",
    "\n",
    "df_output_N_stores_selected_with_result.to_excel(writer,\"with_TA\",index=False)\n",
    "summary_df_N_stores.to_excel(writer,\"summary\",index=False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(116, 4)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_N_TA_zips=df_output_N_stores_selected_with_result.groupby(\"TA\")['All_P&S_zips_40_miles','All_P&S_zips'].sum().reset_index()\n",
    "\n",
    "df_output_N_TA_zips=df_output_N_TA_zips.rename(columns={\"All_P&S_zips_40_miles\":\"zip_cd_40\",\"All_P&S_zips\":\"zip_cd_all\",\"store_id\":\"store_list\"})\n",
    "df_output_N_TA_zips['zip_cd_40']=df_output_N_TA_zips['zip_cd_40'].apply(lambda x: list(set(x)))\n",
    "df_output_N_TA_zips['zip_cd_all']=df_output_N_TA_zips['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "\n",
    "df_output_N_TA_zips_2=df_output_N_stores_selected_with_result.groupby(\"TA\")['store_id'].apply(list).reset_index()\n",
    "df_output_N_TA_zips_2=df_output_N_TA_zips_2.rename(columns={\"store_id\":\"store_list\"})\n",
    "df_output_N_TA_zips_2['store_list']=df_output_N_TA_zips_2['store_list'].apply(lambda x: list(set(x)))\n",
    "\n",
    "df_output_N_TA_zips=pd.merge(df_output_N_TA_zips,df_output_N_TA_zips_2,on=\"TA\")\n",
    "df_output_N_TA_zips.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Store TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stores=new_stores.reset_index()\n",
    "\n",
    "df_new_store_zips=pd.DataFrame()\n",
    "\n",
    "del new_stores['index']\n",
    "\n",
    "for ind,row in new_stores.iterrows():\n",
    "    store_num=row['store_id']\n",
    "    store_center=[row['latitude'],row['longitude']]\n",
    "    \n",
    "    for zip_cd in zip_centers.keys():\n",
    "        dist=haversine(store_center,zip_centers[zip_cd],unit=\"mi\")\n",
    "        \n",
    "        if dist<=10:\n",
    "\n",
    "            df=pd.DataFrame({\"store_id\":store_num,\"zips_in_10\":zip_cd,\"dist_miles\":dist},index=[store_num])\n",
    "            df_new_store_zips=df_new_store_zips.append(df)\n",
    "        \n",
    "df_new_store_zips.shape\n",
    "\n",
    "# No new stores!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(137, 4)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sing_store_zips_wide=df_all_single_store_TA[['store_id','All_P&S_zips_40_miles','All_P&S_zips']]\n",
    "\n",
    "df_sing_store_zips_wide=df_sing_store_zips_wide.sort_values(\"store_id\")\n",
    "df_sing_store_zips_wide=df_sing_store_zips_wide.rename(columns={\"All_P&S_zips_40_miles\":\"zip_cd_40\",\n",
    "                                                                \"All_P&S_zips\":\"zip_cd_all\",\n",
    "                                                                \"store_id\":\"store_list\"})\n",
    "df_sing_store_zips_wide['store_list']=df_sing_store_zips_wide['store_list'].apply(lambda x: [x])\n",
    "df_sing_store_zips_wide['TA']=[x+1+df_output_N_TA_zips['TA'].max() for x in range(len(df_sing_store_zips_wide))]\n",
    "\n",
    "all_defined_TA=df_output_N_TA_zips.append(df_sing_store_zips_wide)\n",
    "all_defined_stores=all_defined_TA['store_list'].sum()\n",
    "print(len(all_defined_stores))\n",
    "\n",
    "all_defined_TA=all_defined_TA.reset_index()\n",
    "del all_defined_TA['index']\n",
    "\n",
    "all_defined_TA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining stores\n",
    "\n",
    "df_remain_stores=store_list[['store_id']].drop_duplicates()\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['store_id'].isin(all_defined_stores)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remain_stores=pd.merge(df_remain_stores,store_list,on=\"store_id\",how=\"left\")\n",
    "df_remain_stores=pd.merge(df_remain_stores,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "\n",
    "df_remain_stores['DMA']=df_remain_stores['DMA'].astype(str)\n",
    "df_remain_stores['CTY']=df_remain_stores['CTY'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remain_stores=pd.merge(df_remain_stores,df_P_S_zips_by_store_copy,on=\"store_id\",how=\"inner\")\n",
    "\n",
    "df_remain_stores['nearest_store']=df_remain_stores['store_id'].apply(lambda x: find_nearest_store(x)[0])\n",
    "df_remain_stores['dist_to_nearest_store']=df_remain_stores['store_id'].apply(lambda x: find_nearest_store(x)[1])\n",
    "\n",
    "df_remain_stores=pd.merge(df_remain_stores,store_PS_40_near,on=\"nearest_store\")\n",
    "\n",
    "df_remain_stores['nearest_intersection_zips']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['near_store_all_PS_40'])[0],axis=1)\n",
    "df_remain_stores['nearest_pair_overlap_with_hold']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['near_store_all_PS_40'])[1],axis=1)\n",
    "df_remain_stores['nearest_pair_overlap_with_nearest']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['near_store_all_PS_40'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remain_stores['min_overlap_pctg']=df_remain_stores['store_id'].apply(lambda x: find_overlaped_stores(x)[0])\n",
    "df_remain_stores['min_overlap_store']=df_remain_stores['store_id'].apply(lambda x: find_overlaped_stores(x)[1])\n",
    "df_remain_stores['max_overlap_pctg']=df_remain_stores['store_id'].apply(lambda x: find_overlaped_stores(x)[2])\n",
    "df_remain_stores['max_overlap_store']=df_remain_stores['store_id'].apply(lambda x: find_overlaped_stores(x)[3])\n",
    "\n",
    "\n",
    "df_remain_stores['min_overlap_store']=df_remain_stores['min_overlap_store'].apply(lambda x: eval(x))\n",
    "df_remain_stores['max_overlap_store']=df_remain_stores['max_overlap_store'].apply(lambda x: eval(x))\n",
    "\n",
    "df_remain_stores['min_paired_store']=df_remain_stores.apply(lambda x: remove_the_hold_store(x['min_overlap_store'],x['store_id']),axis=1)\n",
    "df_remain_stores['max_paired_store']=df_remain_stores.apply(lambda x: remove_the_hold_store(x['max_overlap_store'],x['store_id']),axis=1)\n",
    "\n",
    "df_remain_stores['min_overlap_store']=df_remain_stores['min_overlap_store'].astype(str)\n",
    "df_remain_stores['max_overlap_store']=df_remain_stores['max_overlap_store'].astype(str)\n",
    "\n",
    "df_remain_stores['dist_min_overlap_pairs']=df_remain_stores['min_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "df_remain_stores['dist_max_overlap_pairs']=df_remain_stores['max_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "\n",
    "\n",
    "df_remain_stores=pd.merge(df_remain_stores,store_PS_40_min,on=\"min_paired_store\")\n",
    "df_remain_stores=pd.merge(df_remain_stores,store_PS_40_max,on=\"max_paired_store\")\n",
    "\n",
    "\n",
    "df_remain_stores['max_intersection_zips']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['max_store_all_PS_40'])[0],axis=1)\n",
    "df_remain_stores['max_pair_overlap_with_hold']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['max_store_all_PS_40'])[1],axis=1)\n",
    "df_remain_stores['max_pair_overlap_with_max']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['max_store_all_PS_40'])[2],axis=1)\n",
    "\n",
    "df_remain_stores['min_intersection_zips']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['min_store_all_PS_40'])[0],axis=1)\n",
    "df_remain_stores['min_pair_overlap_with_hold']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['min_store_all_PS_40'])[1],axis=1)\n",
    "df_remain_stores['min_pair_overlap_with_min']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_40_miles'],x['min_store_all_PS_40'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_remain_stores=df_remain_stores.append(df_new_store_zips_wide_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_covered_TA(zip_list_store):\n",
    "    max_intersect_count=0\n",
    "    max_intersect_list=[]\n",
    "    intersect_TA=0\n",
    "    for ind,row in all_defined_TA.iterrows():\n",
    "        ta_40_zips=row['zip_cd_40']\n",
    "        intersection_zips_P_S_40=list(set(zip_list_store).intersection(set(ta_40_zips)))\n",
    "        intersection_zips_P_S_40_len=len(intersection_zips_P_S_40)\n",
    "        if intersection_zips_P_S_40_len>max_intersect_count:\n",
    "            max_intersect_count=intersection_zips_P_S_40_len\n",
    "            max_intersect_list=intersection_zips_P_S_40\n",
    "            intersect_TA=row['TA']\n",
    "    max_intersect_pctc=max_intersect_count/len(zip_list_store)\n",
    "            \n",
    "    return intersect_TA,max_intersect_list,max_intersect_count,max_intersect_pctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_40']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_all_single_store_TA['dist_group']\n",
    "df_sing_store_zips_wide_copy=df_sing_store_zips_wide.copy()\n",
    "df_sing_store_zips_wide_copy=df_sing_store_zips_wide_copy[['store_list','TA']]\n",
    "df_sing_store_zips_wide_copy['store_id']=df_sing_store_zips_wide_copy['store_list'].apply(lambda x: x[0])\n",
    "df_sing_store_zips_wide_copy=df_sing_store_zips_wide_copy[['store_id',\"TA\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_single_store_TA=pd.merge(df_all_single_store_TA,df_sing_store_zips_wide_copy,on=\"store_id\",how=\"left\")\n",
    "df_all_single_store_TA=df_all_single_store_TA[[\"TA\"]+[x for x in df_all_single_store_TA.columns.tolist() if x!=\"TA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_single_store_TA_cols_1=[x for x in df_output_N_stores_selected_with_result.columns.tolist() if x in df_all_single_store_TA.columns.tolist()]\n",
    "df_all_single_store_TA_cols_2=[x for x in df_all_single_store_TA.columns.tolist() if x not in df_all_single_store_TA_cols_1]\n",
    "df_all_single_store_TA=df_all_single_store_TA[df_all_single_store_TA_cols_1+df_all_single_store_TA_cols_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_remain_stores_cols_1=[x for x in df_output_N_stores_selected_with_result.columns.tolist() if x in df_remain_stores.columns.tolist()]\n",
    "df_remain_stores_cols_2=[x for x in df_remain_stores.columns.tolist() if x not in df_remain_stores_cols_1]\n",
    "df_remain_stores=df_remain_stores[df_remain_stores_cols_1+df_remain_stores_cols_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"GY_remaining_stores_and_defined_TA_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_remain_stores.to_excel(writer,\"df_remain_stores\",index=False)\n",
    "all_defined_TA.to_excel(writer,\"all_defined_TA\",index=False)\n",
    "df_output_N_stores_selected_with_result.to_excel(writer,\"TA_by_store_multiple\",index=False)\n",
    "df_all_single_store_TA.to_excel(writer,\"TA_by_store_single\",index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>zip_cd_40</th>\n",
       "      <th>zip_cd_all</th>\n",
       "      <th>store_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[95024, 94110, 94039, 94582, 95111, 94014, 950...</td>\n",
       "      <td>[70118, 93636, 94035, 33138, 84084, 96088, 941...</td>\n",
       "      <td>[8724, 4861, 1290, 9246]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[30188, 30572, 30035, 30363, 30622, 30329, 306...</td>\n",
       "      <td>[80620, 32444, 12901, 37924, 32408, 20601, 740...</td>\n",
       "      <td>[3610, 2130, 2136, 2121, 2141, 2128, 2126]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[53179, 60466, 53168, 60626, 46383, 60453, 602...</td>\n",
       "      <td>[80212, 55414, 64834, 55418, 03229, 54656, 342...</td>\n",
       "      <td>[1285, 1261, 3602, 1260, 1274, 6120, 1270, 127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[95024, 94110, 94039, 94582, 94026, 95111, 950...</td>\n",
       "      <td>[94035, 64834, 23173, 84084, 94103, 07945, 952...</td>\n",
       "      <td>[8722, 8766, 8773]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA                                          zip_cd_40  \\\n",
       "0   1  [95024, 94110, 94039, 94582, 95111, 94014, 950...   \n",
       "1   2  [30188, 30572, 30035, 30363, 30622, 30329, 306...   \n",
       "2   3  [53179, 60466, 53168, 60626, 46383, 60453, 602...   \n",
       "3   4  [95024, 94110, 94039, 94582, 94026, 95111, 950...   \n",
       "\n",
       "                                          zip_cd_all  \\\n",
       "0  [70118, 93636, 94035, 33138, 84084, 96088, 941...   \n",
       "1  [80620, 32444, 12901, 37924, 32408, 20601, 740...   \n",
       "2  [80212, 55414, 64834, 55418, 03229, 54656, 342...   \n",
       "3  [94035, 64834, 23173, 84084, 94103, 07945, 952...   \n",
       "\n",
       "                                          store_list  \n",
       "0                           [8724, 4861, 1290, 9246]  \n",
       "1         [3610, 2130, 2136, 2121, 2141, 2128, 2126]  \n",
       "2  [1285, 1261, 3602, 1260, 1274, 6120, 1270, 127...  \n",
       "3                                 [8722, 8766, 8773]  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_defined_TA.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23 15:06:52.765132\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iter the balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Iter 1 - >=40% \n",
    "\n",
    "df_remain_stores_Iter1_40=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.4]\n",
    "df_remain_stores_Iter1_40=df_remain_stores_Iter1_40[['store_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_40_miles']]\n",
    "df_remain_stores_Iter1_40=df_remain_stores_Iter1_40.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "df_remain_stores_Iter1_40['store_id']=df_remain_stores_Iter1_40['store_id'].apply(lambda x: [x])\n",
    "df_remain_stores_Iter1_40=df_remain_stores_Iter1_40.groupby(\"TA\")['store_id','All_P&S_zips','All_P&S_zips_40_miles'].sum().reset_index()\n",
    "for col in ['store_id','All_P&S_zips','All_P&S_zips_40_miles']:\n",
    "    df_remain_stores_Iter1_40[col]=df_remain_stores_Iter1_40[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "###\n",
    "all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_40,on=\"TA\",how=\"left\")\n",
    "\n",
    "for col in ['store_id','All_P&S_zips','All_P&S_zips_40_miles']:\n",
    "    all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "    all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "    all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "    \n",
    "all_defined_TA['store_list']=all_defined_TA[['store_list','store_id']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_40']=all_defined_TA[['zip_cd_40','All_P&S_zips_40_miles']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "all_defined_TA['zip_cd_40']=all_defined_TA['zip_cd_40'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_40','zip_cd_all']]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['store_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_40']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Iter 2 - >=30% \n",
    "\n",
    "df_remain_stores_Iter1_40=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.3]\n",
    "df_remain_stores_Iter1_40=df_remain_stores_Iter1_40[['store_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_40_miles']]\n",
    "df_remain_stores_Iter1_40=df_remain_stores_Iter1_40.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "df_remain_stores_Iter1_40['store_id']=df_remain_stores_Iter1_40['store_id'].apply(lambda x: [x])\n",
    "df_remain_stores_Iter1_40=df_remain_stores_Iter1_40.groupby(\"TA\")['store_id','All_P&S_zips','All_P&S_zips_40_miles'].sum().reset_index()\n",
    "for col in ['store_id','All_P&S_zips','All_P&S_zips_40_miles']:\n",
    "    df_remain_stores_Iter1_40[col]=df_remain_stores_Iter1_40[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "###\n",
    "all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_40,on=\"TA\",how=\"left\")\n",
    "\n",
    "for col in ['store_id','All_P&S_zips','All_P&S_zips_40_miles']:\n",
    "    all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "    all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "    all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "    \n",
    "all_defined_TA['store_list']=all_defined_TA[['store_list','store_id']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_40']=all_defined_TA[['zip_cd_40','All_P&S_zips_40_miles']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "all_defined_TA['zip_cd_40']=all_defined_TA['zip_cd_40'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_40','zip_cd_all']]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['store_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_40']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Iter 3 - >=20% \n",
    "\n",
    "df_remain_stores_Iter1_40=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.2]\n",
    "df_remain_stores_Iter1_40=df_remain_stores_Iter1_40[['store_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_40_miles']]\n",
    "df_remain_stores_Iter1_40=df_remain_stores_Iter1_40.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "df_remain_stores_Iter1_40['store_id']=df_remain_stores_Iter1_40['store_id'].apply(lambda x: [x])\n",
    "df_remain_stores_Iter1_40=df_remain_stores_Iter1_40.groupby(\"TA\")['store_id','All_P&S_zips','All_P&S_zips_40_miles'].sum().reset_index()\n",
    "for col in ['store_id','All_P&S_zips','All_P&S_zips_40_miles']:\n",
    "    df_remain_stores_Iter1_40[col]=df_remain_stores_Iter1_40[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "###\n",
    "all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_40,on=\"TA\",how=\"left\")\n",
    "\n",
    "for col in ['store_id','All_P&S_zips','All_P&S_zips_40_miles']:\n",
    "    all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "    all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "    all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "    \n",
    "all_defined_TA['store_list']=all_defined_TA[['store_list','store_id']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_40']=all_defined_TA[['zip_cd_40','All_P&S_zips_40_miles']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "all_defined_TA['zip_cd_40']=all_defined_TA['zip_cd_40'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_40','zip_cd_all']]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['store_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_40']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 41)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>0.2].shape[0]>0:\n",
    "    df_remain_stores_Iter1_40=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.2]\n",
    "    df_remain_stores_Iter1_40=df_remain_stores_Iter1_40[['store_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_40_miles']]\n",
    "    df_remain_stores_Iter1_40=df_remain_stores_Iter1_40.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "    df_remain_stores_Iter1_40['store_id']=df_remain_stores_Iter1_40['store_id'].apply(lambda x: [x])\n",
    "    df_remain_stores_Iter1_40=df_remain_stores_Iter1_40.groupby(\"TA\")['store_id','All_P&S_zips','All_P&S_zips_40_miles'].sum().reset_index()\n",
    "    for col in ['store_id','All_P&S_zips','All_P&S_zips_40_miles']:\n",
    "        df_remain_stores_Iter1_40[col]=df_remain_stores_Iter1_40[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "    ###\n",
    "    all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_40,on=\"TA\",how=\"left\")\n",
    "\n",
    "    for col in ['store_id','All_P&S_zips','All_P&S_zips_40_miles']:\n",
    "        all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "        all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "        all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "\n",
    "    all_defined_TA['store_list']=all_defined_TA[['store_list','store_id']].sum(axis=1)\n",
    "    all_defined_TA['zip_cd_40']=all_defined_TA[['zip_cd_40','All_P&S_zips_40_miles']].sum(axis=1)\n",
    "    all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "    all_defined_TA['zip_cd_40']=all_defined_TA['zip_cd_40'].apply(lambda x: list(set(x)))\n",
    "    all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "    all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_40','zip_cd_all']]\n",
    "\n",
    "    df_remain_stores=df_remain_stores[~df_remain_stores['store_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "    df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "    df_remain_stores['Overlap_zips_with_TA_40']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "    df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "    df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_40_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n",
    "df_remain_stores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_defined_TA['store_count']=all_defined_TA['store_list'].apply(lambda x: len(x))\n",
    "all_defined_TA['store_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"GY_remaining_stores_and_defined_2_TA_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_remain_stores.to_excel(writer,\"df_remain_stores\",index=False)\n",
    "all_defined_TA.to_excel(writer,\"all_defined_TA\",index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_list [<class 'list'>]\n",
      "zip_cd_all [<class 'list'>]\n",
      "zip_cd_40 [<class 'list'>]\n",
      "TA [<class 'int'>]\n",
      "TA [<class 'int'>]\n",
      "store_list [<class 'list'>]\n",
      "zip_cd_40 [<class 'list'>]\n",
      "zip_cd_all [<class 'list'>]\n",
      "store_count [<class 'int'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_remain_stores_single_TA=df_remain_stores[['store_id','All_P&S_zips','All_P&S_zips_40_miles']]\n",
    "df_remain_stores_single_TA['TA']=[all_defined_TA['TA'].max()+x+1 for x in range(len(df_remain_stores_single_TA))]\n",
    "df_remain_stores_single_TA=df_remain_stores_single_TA.rename(columns={\"store_id\":\"store_list\"})\n",
    "df_remain_stores_single_TA=df_remain_stores_single_TA.rename(columns={\"All_P&S_zips_40_miles\":\"zip_cd_40\"})\n",
    "df_remain_stores_single_TA=df_remain_stores_single_TA.rename(columns={\"All_P&S_zips\":\"zip_cd_all\"})\n",
    "df_remain_stores_single_TA['store_list']=df_remain_stores_single_TA['store_list'].apply(lambda x: [x])\n",
    "df_remain_stores_single_TA.head(2)\n",
    "\n",
    "for col in df_remain_stores_single_TA.columns.tolist():\n",
    "    print(col,df_remain_stores_single_TA[col].apply(lambda x: type(x)).unique())\n",
    "    \n",
    "for col in all_defined_TA.columns.tolist():\n",
    "    print(col,all_defined_TA[col].apply(lambda x: type(x)).unique())\n",
    "    \n",
    "all_defined_TA=all_defined_TA.append(df_remain_stores_single_TA)\n",
    "\n",
    "all_defined_TA['store_count']=all_defined_TA['store_list'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_defined_TA['store_count']=all_defined_TA['store_list'].apply(lambda x: len(x))\n",
    "\n",
    "all_defined_TA['temp_1st_store']=all_defined_TA['store_list'].apply(lambda x: \"single_\"+str(x[0]))\n",
    "all_defined_TA['temp_TA_str']=all_defined_TA['TA'].apply(lambda x: \"multiple_\"+str(x))\n",
    "\n",
    "all_defined_TA['ta_name']=np.where(all_defined_TA['store_count']==1,all_defined_TA['temp_1st_store'],all_defined_TA['temp_TA_str'])\n",
    "\n",
    "del all_defined_TA['temp_1st_store']\n",
    "del all_defined_TA['temp_TA_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_store_count_TA=all_defined_TA.groupby(\"store_count\")['TA'].count().to_frame().reset_index().sort_values(\"store_count\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=pd.DataFrame(columns={\"store_id\",\"TA\",\"ta_name\"})\n",
    "\n",
    "for ind,row in all_defined_TA.iterrows():\n",
    "    store_list_in_TA=row['store_list']\n",
    "    TA_num=row['TA']\n",
    "    TA_name=row['ta_name']\n",
    "    df=pd.DataFrame({\"store_id\":store_list_in_TA,\"TA\":[TA_num]*len(store_list_in_TA),\"ta_name\":[TA_name]*len(store_list_in_TA)},index=range(len(store_list_in_TA)))\n",
    "    df_output_by_store=df_output_by_store.append(df)\n",
    "df_output_by_store=df_output_by_store.sort_values([\"TA\",\"store_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401174, 3)\n"
     ]
    }
   ],
   "source": [
    "df_previous_zip_by_store_copy=df_sales_by_zip[df_sales_by_zip['store_id'].isin(df_output_by_store['store_id'].tolist())]\n",
    "df_previous_zip_by_store_copy=df_previous_zip_by_store_copy[['store_id','zip_5','trans_label']]\n",
    "df_previous_zip_by_store_copy=df_previous_zip_by_store_copy[df_previous_zip_by_store_copy['trans_label'].isin([\"P\",\"S\"])]\n",
    "df_previous_zip_by_store_copy=df_previous_zip_by_store_copy.rename(columns={\"zip_5\":\"zip_cd\"})\n",
    "\n",
    "print(df_previous_zip_by_store_copy.shape)\n",
    "\n",
    "df_trans_zips=df_previous_zip_by_store_copy.groupby([\"store_id\",\"trans_label\"])['zip_cd'].apply(list).to_frame().reset_index()\n",
    "\n",
    "df_trans_zips=df_trans_zips.pivot(index=\"store_id\",columns=\"trans_label\",values=\"zip_cd\").reset_index()\n",
    "df_trans_zips=df_trans_zips.rename(columns={\"P\":\"all_trans_P_zips\",\"S\":\"all_trans_S_zips\"})\n",
    "# df_10_zips=df_new_store_zips.groupby(\"store_id\")['zips_in_10'].apply(list).to_frame().reset_index()\n",
    "# df_output_by_store_zips=df_trans_zips.append(df_10_zips)\n",
    "df_output_by_store_zips=df_trans_zips.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=pd.merge(df_output_by_store,store_list,on=\"store_id\",how=\"left\")\n",
    "df_output_by_store=pd.merge(df_output_by_store,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "df_output_by_store=pd.merge(df_output_by_store,df_output_by_store_zips,on=\"store_id\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store['all_trans_P_zips']=df_output_by_store['all_trans_P_zips'].fillna(\"[]\")\n",
    "df_output_by_store['all_trans_S_zips']=df_output_by_store['all_trans_S_zips'].fillna(\"[]\")\n",
    "# df_output_by_store['zips_in_10']=df_output_by_store['zips_in_10'].fillna(\"[]\")\n",
    "\n",
    "df_output_by_store['all_trans_P_zips']=df_output_by_store['all_trans_P_zips'].astype(str)\n",
    "df_output_by_store['all_trans_S_zips']=df_output_by_store['all_trans_S_zips'].astype(str)\n",
    "# df_output_by_store['zips_in_10']=df_output_by_store['zips_in_10'].astype(str)\n",
    "\n",
    "df_output_by_store['all_trans_P_zips']=df_output_by_store['all_trans_P_zips'].apply(lambda x: eval(x))\n",
    "df_output_by_store['all_trans_S_zips']=df_output_by_store['all_trans_S_zips'].apply(lambda x: eval(x))\n",
    "# df_output_by_store['zips_in_10']=df_output_by_store['zips_in_10'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit 40 miles zips to the associated stores\n",
    "df_output_by_store_copy=df_output_by_store.copy()\n",
    "df_output_by_store_copy=df_output_by_store_copy.reset_index()\n",
    "del df_output_by_store_copy['index']\n",
    "\n",
    "location_lat_long_dict=df_output_by_store_copy[['store_id','latitude','longitude']].drop_duplicates()\n",
    "location_lat_long_dict['store_center']=location_lat_long_dict[['latitude','longitude']].values.tolist()\n",
    "location_lat_long_dict=location_lat_long_dict.set_index(\"store_id\")['store_center']\n",
    "\n",
    "\n",
    "df_output_by_store_1=pd.DataFrame()\n",
    "df_output_by_store_copy['trans_P_zips_40_within_TA']=np.nan\n",
    "df_output_by_store_copy['trans_S_zips_40_within_TA']=np.nan\n",
    "\n",
    "for TA,df_group in df_output_by_store_copy.groupby(\"TA\"):\n",
    "    store_list=df_group['store_id'].tolist()\n",
    "    df_group=df_group.reset_index()\n",
    "    del df_group['index']\n",
    "    \n",
    "    for ind,row in df_group.iterrows():\n",
    "        all_P_zips_list=row['all_trans_P_zips']\n",
    "        all_S_zips_list=row['all_trans_S_zips']\n",
    "        P_zips_list_40_in_TA=[]\n",
    "        S_zips_list_40_in_TA=[]\n",
    "        \n",
    "        for zip_P in all_P_zips_list:\n",
    "            if zip_P in zip_centers.keys():\n",
    "                for store in store_list:\n",
    "                    store_center=location_lat_long_dict[store]\n",
    "                    dist=haversine(store_center, zip_centers[zip_P],unit=\"mi\")\n",
    "                    if dist<=num_final_inclusion_dist:\n",
    "                        P_zips_list_40_in_TA=P_zips_list_40_in_TA+[zip_P]\n",
    "                \n",
    "        for zip_S in all_S_zips_list:\n",
    "            if zip_S in zip_centers.keys():\n",
    "                for store in store_list:\n",
    "                    store_center=location_lat_long_dict[store]\n",
    "                    dist=haversine(store_center, zip_centers[zip_S],unit=\"mi\")\n",
    "                    if dist<=num_final_inclusion_dist:\n",
    "                        S_zips_list_40_in_TA=S_zips_list_40_in_TA+[zip_S]\n",
    "                    \n",
    "        P_zips_list_40_in_TA=list(set(P_zips_list_40_in_TA))\n",
    "        S_zips_list_40_in_TA=list(set(S_zips_list_40_in_TA))\n",
    "        \n",
    "        df_group.loc[ind,'trans_P_zips_40_within_TA']=str(P_zips_list_40_in_TA)\n",
    "        df_group.loc[ind,'trans_S_zips_40_within_TA']=str(S_zips_list_40_in_TA)\n",
    "        \n",
    "    df_output_by_store_1=df_output_by_store_1.append(df_group)\n",
    "        \n",
    "df_output_by_store_1['trans_P_zips_40_within_TA']=df_output_by_store_1['trans_P_zips_40_within_TA'].apply(lambda x: eval(x))\n",
    "df_output_by_store_1['trans_S_zips_40_within_TA']=df_output_by_store_1['trans_S_zips_40_within_TA'].apply(lambda x: eval(x))\n",
    "\n",
    "df_output_by_store=df_output_by_store_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=df_output_by_store.reset_index()\n",
    "del df_output_by_store['index']\n",
    "\n",
    "df_output_by_store_zip_long=pd.DataFrame(columns=[\"TA\",\"ta_name\",\"store_id\",'zip_cd','zip_type'])\n",
    "\n",
    "for ind,row in df_output_by_store.iterrows():\n",
    "    TA=row['TA']\n",
    "    ta_name=row['ta_name']\n",
    "    store_id=row['store_id']\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    all_P_zips=row['trans_P_zips_40_within_TA']\n",
    "    all_S_zips=row['trans_S_zips_40_within_TA']\n",
    "    # all_10_zips=row['zips_in_10']\n",
    "    \n",
    "    df_P=pd.DataFrame({\"store_id\":[store_id]*len(all_P_zips),'zip_cd':all_P_zips})\n",
    "    df_P['zip_type']=\"trans_P\"\n",
    "    \n",
    "    df_S=pd.DataFrame({\"store_id\":[store_id]*len(all_S_zips),'zip_cd':all_S_zips})\n",
    "    df_S['zip_type']=\"trans_S\"\n",
    "    \n",
    "    # df_10=pd.DataFrame({\"store_id\":[store_id]*len(all_10_zips),'zip_cd':all_10_zips})\n",
    "    # df_10['zip_type']=\"zips_10\"\n",
    "    \n",
    "    df=df_P.append(df_S)\n",
    "    df['TA']=TA\n",
    "    df['ta_name']=ta_name\n",
    "    df_output_by_store_zip_long=df_output_by_store_zip_long.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>store_list</th>\n",
       "      <th>trans_P_zips</th>\n",
       "      <th>trans_S_zips</th>\n",
       "      <th>store_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>multiple_1</td>\n",
       "      <td>[1290, 4861, 8724, 9246]</td>\n",
       "      <td>[94010, 94025, 94044, 94066, 94080, 94085, 940...</td>\n",
       "      <td>[93901, 93902, 93905, 93906, 93907, 93908, 939...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>multiple_2</td>\n",
       "      <td>[2121, 2124, 2126, 2128, 2130, 2136, 2141, 3610]</td>\n",
       "      <td>[30004, 30008, 30017, 30019, 30024, 30030, 300...</td>\n",
       "      <td>[30002, 30005, 30009, 30010, 30011, 30012, 300...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TA     ta_name                                        store_list  \\\n",
       "0  1  multiple_1                          [1290, 4861, 8724, 9246]   \n",
       "1  2  multiple_2  [2121, 2124, 2126, 2128, 2130, 2136, 2141, 3610]   \n",
       "\n",
       "                                        trans_P_zips  \\\n",
       "0  [94010, 94025, 94044, 94066, 94080, 94085, 940...   \n",
       "1  [30004, 30008, 30017, 30019, 30024, 30030, 300...   \n",
       "\n",
       "                                        trans_S_zips  store_count  \n",
       "0  [93901, 93902, 93905, 93906, 93907, 93908, 939...            4  \n",
       "1  [30002, 30005, 30009, 30010, 30011, 30012, 300...            8  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_TA=df_output_by_store_zip_long.sort_values([\"TA\",'ta_name','zip_type','zip_cd'])\n",
    "df_output_by_TA=df_output_by_TA.drop_duplicates([\"TA\",'ta_name','zip_cd'])\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.groupby([\"TA\",\"ta_name\",\"zip_type\"])['zip_cd'].apply(list).to_frame().reset_index()\n",
    "df_output_by_TA=df_output_by_TA.pivot(index=\"TA\",columns=\"zip_type\",values=\"zip_cd\").reset_index()\n",
    "\n",
    "\n",
    "ta_name=df_output_by_store_zip_long[['TA','ta_name']].drop_duplicates()\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_name,on=\"TA\",how=\"left\")\n",
    "\n",
    "ta_store_list=df_output_by_store.groupby(\"TA\")['store_id'].apply(list).to_frame().reset_index()\n",
    "\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_store_list,on='TA',how=\"left\")\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.rename(columns={\"store_id\":\"store_list\",\"trans_P\":\"trans_P_zips\",\"trans_S\":\"trans_S_zips\"})\n",
    "df_output_by_TA=df_output_by_TA[['TA','ta_name','store_list','trans_P_zips','trans_S_zips']]\n",
    "df_output_by_TA['store_count']=df_output_by_TA['store_list'].apply(lambda x: len(x))\n",
    "\n",
    "df_output_by_TA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge multiple TA with 30% overlap + \n",
    "df_output_by_TA['trans_P_zips']=df_output_by_TA['trans_P_zips'].fillna(\"[]\").astype(str).apply(lambda x: eval(x))\n",
    "df_output_by_TA['trans_S_zips']=df_output_by_TA['trans_S_zips'].fillna(\"[]\").astype(str).apply(lambda x: eval(x))\n",
    "# df_output_by_TA['distance_10_zips']=df_output_by_TA['distance_10_zips'].fillna(\"[]\").astype(str).apply(lambda x: eval(x))\n",
    "\n",
    "\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.reset_index()\n",
    "del df_output_by_TA['index']\n",
    "df_output_by_TA['all_zips']=df_output_by_TA['trans_P_zips']+df_output_by_TA['trans_S_zips'] #+df_output_by_TA['distance_10_zips']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qc_overlap_1=df_output_by_TA[['TA','ta_name','all_zips']].rename(columns={\"TA\":\"TA_1\",\"all_zips\":\"all_zips_1\"})\n",
    "df_qc_overlap_1=df_qc_overlap_1[df_qc_overlap_1['ta_name'].apply(lambda x: x.split(\"_\")[0]==\"multiple\")]\n",
    "df_qc_overlap_1['temp']=1\n",
    "del df_qc_overlap_1['ta_name']\n",
    "\n",
    "df_qc_overlap_2=df_output_by_TA[['TA','ta_name','all_zips']].rename(columns={\"TA\":\"TA_2\",\"all_zips\":\"all_zips_2\"})\n",
    "df_qc_overlap_2=df_qc_overlap_2[df_qc_overlap_2['ta_name'].apply(lambda x: x.split(\"_\")[0]==\"multiple\")]\n",
    "df_qc_overlap_2['temp']=1\n",
    "del df_qc_overlap_2['ta_name']\n",
    "\n",
    "df_qc_overlap=pd.merge(df_qc_overlap_1,df_qc_overlap_2,on=\"temp\",how=\"outer\")\n",
    "df_qc_overlap=df_qc_overlap[df_qc_overlap['TA_1']!=df_qc_overlap['TA_2']]\n",
    "del df_qc_overlap['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intsection_pctg_qc_TA(list_1,list_2):\n",
    "    intersection_list=list(set(list_1).intersection(set(list_2)))\n",
    "    intersection_pctg=len(intersection_list)/len(set(list_1+list_2))\n",
    "    return intersection_pctg\n",
    "\n",
    "df_qc_overlap['intersecion_pctg']=df_qc_overlap.apply(lambda x: intsection_pctg_qc_TA(x['all_zips_1'],x['all_zips_2']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_overlap_high_TA=df_qc_overlap[df_qc_overlap['intersecion_pctg']>0.3]\n",
    "df_overlap_high_TA['pairs']=df_overlap_high_TA[['TA_1','TA_2']].values.tolist()\n",
    "df_overlap_high_TA['pairs']=df_overlap_high_TA['pairs'].apply(lambda x: str(sorted(x)))\n",
    "df_overlap_high_TA=df_overlap_high_TA[['TA_1','TA_2','pairs']].drop_duplicates()\n",
    "\n",
    "df_overlap_high_TA_all_pairs=df_overlap_high_TA['pairs'].unique().tolist()\n",
    "df_overlap_high_TA_all_pairs=[eval(x) for x in df_overlap_high_TA_all_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 1,\n",
       " 114: 4,\n",
       " 22: 2,\n",
       " 81: 22,\n",
       " 64: 5,\n",
       " 73: 6,\n",
       " 12: 7,\n",
       " 19: 8,\n",
       " 77: 11,\n",
       " 66: 13,\n",
       " 72: 66,\n",
       " 89: 72,\n",
       " 97: 66,\n",
       " 67: 16,\n",
       " 71: 67,\n",
       " 27: 17,\n",
       " 78: 27,\n",
       " 41: 21,\n",
       " 76: 21,\n",
       " 29: 23,\n",
       " 96: 78,\n",
       " 44: 37,\n",
       " 93: 45,\n",
       " 43: 42,\n",
       " 91: 43,\n",
       " 111: 52,\n",
       " 82: 55,\n",
       " 107: 56,\n",
       " 104: 59,\n",
       " 99: 68,\n",
       " 80: 75,\n",
       " 110: 98}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_M_M_TA_dict={}\n",
    "for pair_list in df_overlap_high_TA_all_pairs:\n",
    "    merge_M_M_TA_dict.update({pair_list[1]:pair_list[0]}) \n",
    "    \n",
    "merge_M_M_TA_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "del df_output_by_store['ta_name']\n",
    "df_output_by_store_1=df_output_by_store[df_output_by_store['TA'].isin(merge_M_M_TA_dict.keys())]\n",
    "df_output_by_store_2=df_output_by_store[~df_output_by_store['TA'].isin(merge_M_M_TA_dict.keys())]\n",
    "\n",
    "df_output_by_store_1['TA']=df_output_by_store_1['TA'].apply(lambda x: merge_M_M_TA_dict[x])\n",
    "df_output_by_store=df_output_by_store_1.append(df_output_by_store_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_name=df_output_by_store.groupby(\"TA\")['store_id'].apply(list).to_frame().reset_index()\n",
    "df_ta_name['store_count']=df_ta_name['store_id'].apply(lambda x: len(x))\n",
    "df_ta_name=df_ta_name.sort_values(\"store_count\",ascending=False)\n",
    "df_ta_name['TA_num']=[str(x+1) for x in range(len(df_ta_name))]\n",
    "df_ta_name['store_id_0_temp']=df_ta_name['store_id'].apply(lambda x: x[0])\n",
    "df_ta_name['store_id_0_temp']=\"single_\"+df_ta_name['store_id_0_temp']\n",
    "df_ta_name['multiple_temp']=\"multiple_\"+df_ta_name['TA_num']\n",
    "\n",
    "df_ta_name['ta_name']=np.where(df_ta_name['store_count']==1,df_ta_name['store_id_0_temp'],df_ta_name['multiple_temp'])\n",
    "\n",
    "df_ta_name=df_ta_name[['TA','TA_num','ta_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=pd.merge(df_output_by_store,df_ta_name,on=\"TA\",how=\"left\")\n",
    "df_output_by_store=df_output_by_store[['TA_num','ta_name']+[x for x in df_output_by_store.columns.tolist() if x not in ['TA_num','ta_name']]]\n",
    "\n",
    "del df_output_by_store['TA']\n",
    "df_output_by_store['TA_num']=df_output_by_store['TA_num'].astype(int)\n",
    "df_output_by_store=df_output_by_store.sort_values(\"TA_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=df_output_by_store.reset_index()\n",
    "del df_output_by_store['index']\n",
    "\n",
    "df_output_by_store_zip_long=pd.DataFrame(columns=[\"TA_num\",\"ta_name\",\"store_id\",'zip_cd','zip_type'])\n",
    "\n",
    "for ind,row in df_output_by_store.iterrows():\n",
    "    TA=row['TA_num']\n",
    "    ta_name=row['ta_name']\n",
    "    store_id=row['store_id']\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    all_P_zips=row['trans_P_zips_40_within_TA']\n",
    "    all_S_zips=row['trans_S_zips_40_within_TA']\n",
    "    # all_10_zips=row['zips_in_10']\n",
    "    \n",
    "    df_P=pd.DataFrame({\"store_id\":[store_id]*len(all_P_zips),'zip_cd':all_P_zips})\n",
    "    df_P['zip_type']=\"trans_P\"\n",
    "    \n",
    "    df_S=pd.DataFrame({\"store_id\":[store_id]*len(all_S_zips),'zip_cd':all_S_zips})\n",
    "    df_S['zip_type']=\"trans_S\"\n",
    "    \n",
    "    # df_10=pd.DataFrame({\"store_id\":[store_id]*len(all_10_zips),'zip_cd':all_10_zips})\n",
    "    # df_10['zip_type']=\"zips_10\"\n",
    "    \n",
    "    df=df_P.append(df_S)#.append(df_10)\n",
    "    df['TA_num']=TA\n",
    "    df['ta_name']=ta_name\n",
    "    df_output_by_store_zip_long=df_output_by_store_zip_long.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_num</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>store_list</th>\n",
       "      <th>trans_P_zips</th>\n",
       "      <th>trans_S_zips</th>\n",
       "      <th>store_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>multiple_1</td>\n",
       "      <td>[6133, 1260, 1261, 1262, 1263, 1265, 1268, 127...</td>\n",
       "      <td>[60004, 60005, 60007, 60015, 60016, 60018, 600...</td>\n",
       "      <td>[46301, 46303, 46304, 46307, 46310, 46311, 463...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>multiple_2</td>\n",
       "      <td>[6651, 6675, 6663, 6661, 6641, 2537, 6622, 255...</td>\n",
       "      <td>[33018, 33019, 33020, 33022, 33023, 33024, 330...</td>\n",
       "      <td>[33002, 33004, 33008, 33009, 33010, 33012, 330...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TA_num     ta_name                                         store_list  \\\n",
       "0      1  multiple_1  [6133, 1260, 1261, 1262, 1263, 1265, 1268, 127...   \n",
       "1      2  multiple_2  [6651, 6675, 6663, 6661, 6641, 2537, 6622, 255...   \n",
       "\n",
       "                                        trans_P_zips  \\\n",
       "0  [60004, 60005, 60007, 60015, 60016, 60018, 600...   \n",
       "1  [33018, 33019, 33020, 33022, 33023, 33024, 330...   \n",
       "\n",
       "                                        trans_S_zips  store_count  \n",
       "0  [46301, 46303, 46304, 46307, 46310, 46311, 463...           23  \n",
       "1  [33002, 33004, 33008, 33009, 33010, 33012, 330...           19  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_TA=df_output_by_store_zip_long.sort_values([\"TA_num\",'ta_name','zip_type','zip_cd'])\n",
    "df_output_by_TA=df_output_by_TA.drop_duplicates([\"TA_num\",'ta_name','zip_cd'])\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.groupby([\"TA_num\",\"ta_name\",\"zip_type\"])['zip_cd'].apply(list).to_frame().reset_index()\n",
    "df_output_by_TA=df_output_by_TA.pivot(index=\"TA_num\",columns=\"zip_type\",values=\"zip_cd\").reset_index()\n",
    "\n",
    "\n",
    "ta_name=df_output_by_store_zip_long[['TA_num','ta_name']].drop_duplicates()\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_name,on=\"TA_num\",how=\"left\")\n",
    "\n",
    "ta_store_list=df_output_by_store.groupby(\"TA_num\")['store_id'].apply(list).to_frame().reset_index()\n",
    "\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_store_list,on='TA_num',how=\"left\")\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.rename(columns={\"store_id\":\"store_list\",\"trans_P\":\"trans_P_zips\",\"trans_S\":\"trans_S_zips\"})\n",
    "df_output_by_TA=df_output_by_TA[['TA_num','ta_name','store_list','trans_P_zips','trans_S_zips']]\n",
    "df_output_by_TA['store_count']=df_output_by_TA['store_list'].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "df_output_by_TA.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17087, 2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_unique_zips=df_output_by_store_zip_long[['zip_type','zip_cd']].drop_duplicates()\n",
    "df_output_unique_zips=df_output_unique_zips.sort_values(\"zip_type\")\n",
    "df_output_unique_zips=df_output_unique_zips.drop_duplicates(\"zip_cd\")\n",
    "df_output_unique_zips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_lat_long=df_store_included[['store_num','latitude','longitude']].rename(columns={\"store_num\":\"store_id\"})\n",
    "df_output_by_store_zip_long=pd.merge(df_output_by_store_zip_long,location_lat_long,on=\"store_id\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_store_missing=[x for x in df_store_included['store_num'].tolist() if x not in df_output_by_store['store_id'].tolist()]\n",
    "list_store_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_TA['P_zip_counts']=df_output_by_TA['trans_P_zips'].apply(len)\n",
    "df_output_by_TA['S_zip_counts']=df_output_by_TA['trans_S_zips'].apply(len)\n",
    "\n",
    "df_output_by_store['all_P_zip_counts']=df_output_by_store['all_trans_P_zips'].apply(len)\n",
    "df_output_by_store['all_S_zip_counts']=df_output_by_store['all_trans_S_zips'].apply(len)\n",
    "\n",
    "df_output_by_store['mile40_P_zip_counts']=df_output_by_store['trans_P_zips_40_within_TA'].apply(len)\n",
    "df_output_by_store['mile40_S_zip_counts']=df_output_by_store['trans_S_zips_40_within_TA'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1_ta_view=df_output_by_TA['store_list'].sum()\n",
    "list_2_store_view=df_output_by_store['store_id'].unique().tolist()\n",
    "list_3_whole=df_store_included['store_num'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list_3_whole)-set(list_1_ta_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_num</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>store_id</th>\n",
       "      <th>address_1</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>DMA</th>\n",
       "      <th>CTY</th>\n",
       "      <th>all_trans_P_zips</th>\n",
       "      <th>all_trans_S_zips</th>\n",
       "      <th>trans_P_zips_40_within_TA</th>\n",
       "      <th>trans_S_zips_40_within_TA</th>\n",
       "      <th>all_P_zip_counts</th>\n",
       "      <th>all_S_zip_counts</th>\n",
       "      <th>mile40_P_zip_counts</th>\n",
       "      <th>mile40_S_zip_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>26</td>\n",
       "      <td>multiple_26</td>\n",
       "      <td>2393</td>\n",
       "      <td>114 ROLLING HILLS CIRCLE</td>\n",
       "      <td>29640</td>\n",
       "      <td>EASLEY</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.862904</td>\n",
       "      <td>-82.550289</td>\n",
       "      <td>{GREENVLL-SPART-ASHEVLL-AND}</td>\n",
       "      <td>{GREENVILLE, PICKENS}</td>\n",
       "      <td>[29642]</td>\n",
       "      <td>[29640, 29671, 29657, 29673, 29611, 29630, 292...</td>\n",
       "      <td>[29642]</td>\n",
       "      <td>[29693, 29690, 29353, 29605, 28018, 29385, 296...</td>\n",
       "      <td>1</td>\n",
       "      <td>963</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TA_num      ta_name store_id                 address_1 zip_cd    city  \\\n",
       "311      26  multiple_26     2393  114 ROLLING HILLS CIRCLE  29640  EASLEY   \n",
       "\n",
       "    state   latitude  longitude                           DMA  \\\n",
       "311    SC  34.862904 -82.550289  {GREENVLL-SPART-ASHEVLL-AND}   \n",
       "\n",
       "                       CTY all_trans_P_zips  \\\n",
       "311  {GREENVILLE, PICKENS}          [29642]   \n",
       "\n",
       "                                      all_trans_S_zips  \\\n",
       "311  [29640, 29671, 29657, 29673, 29611, 29630, 292...   \n",
       "\n",
       "    trans_P_zips_40_within_TA  \\\n",
       "311                   [29642]   \n",
       "\n",
       "                             trans_S_zips_40_within_TA  all_P_zip_counts  \\\n",
       "311  [29693, 29690, 29353, 29605, 28018, 29385, 296...                 1   \n",
       "\n",
       "     all_S_zip_counts  mile40_P_zip_counts  mile40_S_zip_counts  \n",
       "311               963                    1                  117  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_store[df_output_by_store['store_id']=='2393']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "\n",
      "SELECT t1.installer_store_num, t1.store_num, t1.company_owned_store_ind, t1.zip_cd  from mdb.vw__installer_master as t1\n",
      "left join mdb_cdl.store t2 on t1.store_num=t2.store_num\n",
      "where (open_store_flag='Y' or open_store_flag is null and company_owned_store_ind=\"Y\") or (company_owned_store_ind=\"N\" and t1.close_date is null);\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jliang/.local/lib/python3.7/site-packages/google/cloud/bigquery/client.py:441: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n",
      "  \"Cannot create BigQuery Storage client, the dependency \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all_open_stores.shape (4608, 4)\n",
      "(4608, 4) 4608\n"
     ]
    }
   ],
   "source": [
    "query_string='''\n",
    "SELECT t1.installer_store_num, t1.store_num, t1.company_owned_store_ind, t1.zip_cd  from mdb.vw__installer_master as t1\n",
    "left join mdb_cdl.store t2 on t1.store_num=t2.store_num\n",
    "where (open_store_flag='Y' or open_store_flag is null and company_owned_store_ind=\"Y\") or (company_owned_store_ind=\"N\" and t1.close_date is null);\n",
    "'''\n",
    "\n",
    "print(\"query: \\n%s\"%query_string)\n",
    "df_all_open_stores=client.query(query_string).result().to_dataframe()\n",
    "print(\"df_all_open_stores.shape\",df_all_open_stores.shape)\n",
    "df_all_open_stores['store_num']=df_all_open_stores['store_num'].astype(int).astype(str)\n",
    "df_all_open_stores['zip_cd']=df_all_open_stores['zip_cd'].apply(lambda x: x.split(\"-\")[0].zfill(5))\n",
    "print(df_all_open_stores.shape,df_all_open_stores['installer_store_num'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>company_owned_store_ind</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>non_coor_store_counts</th>\n",
       "      <th>coor_store_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01056</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01089</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "company_owned_store_ind zip_cd  non_coor_store_counts  coor_store_counts\n",
       "0                        01056                      2                  0\n",
       "1                        01089                      1                  0\n",
       "2                        01201                      1                  0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_count_by_zip=df_all_open_stores.groupby([\"zip_cd\",\"company_owned_store_ind\"])['installer_store_num'].count().to_frame().reset_index()\n",
    "df_store_count_by_zip=df_store_count_by_zip.pivot_table(index='zip_cd',columns=\"company_owned_store_ind\",values='installer_store_num').reset_index()\n",
    "df_store_count_by_zip=df_store_count_by_zip.fillna(0)\n",
    "df_store_count_by_zip=df_store_count_by_zip.rename(columns={\"Y\":\"coor_store_counts\",\"N\":\"non_coor_store_counts\"})\n",
    "df_store_count_by_zip['coor_store_counts']=df_store_count_by_zip['coor_store_counts'].astype(int)\n",
    "df_store_count_by_zip['non_coor_store_counts']=df_store_count_by_zip['non_coor_store_counts'].astype(int)\n",
    "\n",
    "df_store_count_by_zip.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_count_by_zip['coor_store_counts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_num</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>store_list</th>\n",
       "      <th>city_list</th>\n",
       "      <th>state_list</th>\n",
       "      <th>trans_P_zips</th>\n",
       "      <th>trans_S_zips</th>\n",
       "      <th>store_count</th>\n",
       "      <th>P_zip_counts</th>\n",
       "      <th>S_zip_counts</th>\n",
       "      <th>count_Coor_store_in_P</th>\n",
       "      <th>count_Noncoor_store_in_P</th>\n",
       "      <th>count_Coor_store_in_S</th>\n",
       "      <th>count_Noncoor_store_in_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>multiple_1</td>\n",
       "      <td>[6133, 1260, 1261, 1262, 1263, 1265, 1268, 127...</td>\n",
       "      <td>['MORTON GROVE', 'HANOVER PARK', 'PLAINFIELD',...</td>\n",
       "      <td>['IL']</td>\n",
       "      <td>[60004, 60005, 60007, 60015, 60016, 60018, 600...</td>\n",
       "      <td>[46301, 46303, 46304, 46307, 46310, 46311, 463...</td>\n",
       "      <td>23</td>\n",
       "      <td>84</td>\n",
       "      <td>493</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>multiple_2</td>\n",
       "      <td>[6651, 6675, 6663, 6661, 6641, 2537, 6622, 255...</td>\n",
       "      <td>['HOLLYWOOD', 'LAKE WORTH', 'HIALEAH', 'NORTH ...</td>\n",
       "      <td>['FL']</td>\n",
       "      <td>[33018, 33019, 33020, 33022, 33023, 33024, 330...</td>\n",
       "      <td>[33002, 33004, 33008, 33009, 33010, 33012, 330...</td>\n",
       "      <td>19</td>\n",
       "      <td>62</td>\n",
       "      <td>240</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TA_num     ta_name                                         store_list  \\\n",
       "0      1  multiple_1  [6133, 1260, 1261, 1262, 1263, 1265, 1268, 127...   \n",
       "1      2  multiple_2  [6651, 6675, 6663, 6661, 6641, 2537, 6622, 255...   \n",
       "\n",
       "                                           city_list state_list  \\\n",
       "0  ['MORTON GROVE', 'HANOVER PARK', 'PLAINFIELD',...     ['IL']   \n",
       "1  ['HOLLYWOOD', 'LAKE WORTH', 'HIALEAH', 'NORTH ...     ['FL']   \n",
       "\n",
       "                                        trans_P_zips  \\\n",
       "0  [60004, 60005, 60007, 60015, 60016, 60018, 600...   \n",
       "1  [33018, 33019, 33020, 33022, 33023, 33024, 330...   \n",
       "\n",
       "                                        trans_S_zips  store_count  \\\n",
       "0  [46301, 46303, 46304, 46307, 46310, 46311, 463...           23   \n",
       "1  [33002, 33004, 33008, 33009, 33010, 33012, 330...           19   \n",
       "\n",
       "   P_zip_counts  S_zip_counts count_Coor_store_in_P count_Noncoor_store_in_P  \\\n",
       "0            84           493                    18                       30   \n",
       "1            62           240                    15                       19   \n",
       "\n",
       "  count_Coor_store_in_S count_Noncoor_store_in_S  \n",
       "0                     6                      108  \n",
       "1                     7                       45  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_TA=df_output_by_TA.reset_index()\n",
    "del df_output_by_TA['index']\n",
    "df_output_by_TA.insert(3,'city_list',np.nan)\n",
    "df_output_by_TA.insert(4,'state_list',np.nan)\n",
    "df_output_by_TA['count_Coor_store_in_P']=np.nan\n",
    "df_output_by_TA['count_Noncoor_store_in_P']=np.nan\n",
    "df_output_by_TA['count_Coor_store_in_S']=np.nan\n",
    "df_output_by_TA['count_Noncoor_store_in_S']=np.nan\n",
    "\n",
    "for ind, row in df_output_by_TA.iterrows():\n",
    "    list_stores=row['store_list']\n",
    "    df_included_store_city=df_store_included[df_store_included['store_num'].isin(list_stores)]\n",
    "    list_cities=list(set(df_included_store_city['city'].tolist()))\n",
    "    list_states=list(set(df_included_store_city['state'].tolist()))\n",
    "    \n",
    "    list_P=row['trans_P_zips']\n",
    "    count_coor_stores_P=df_store_count_by_zip[df_store_count_by_zip['zip_cd'].isin(list_P)]['coor_store_counts'].sum()\n",
    "    count_noncoor_stores_P=df_store_count_by_zip[df_store_count_by_zip['zip_cd'].isin(list_P)]['non_coor_store_counts'].sum()\n",
    "    \n",
    "    list_S=row['trans_S_zips']\n",
    "    count_coor_stores_S=df_store_count_by_zip[df_store_count_by_zip['zip_cd'].isin(list_S)]['coor_store_counts'].sum()\n",
    "    count_noncoor_stores_S=df_store_count_by_zip[df_store_count_by_zip['zip_cd'].isin(list_S)]['non_coor_store_counts'].sum()\n",
    "    \n",
    "    df_output_by_TA.loc[ind,'city_list']=str(list_cities)\n",
    "    df_output_by_TA.loc[ind,'state_list']=str(list_states)\n",
    "    df_output_by_TA.loc[ind,'count_Coor_store_in_P']=str(count_coor_stores_P)\n",
    "    df_output_by_TA.loc[ind,'count_Noncoor_store_in_P']=str(count_noncoor_stores_P)\n",
    "    df_output_by_TA.loc[ind,'count_Coor_store_in_S']=str(count_coor_stores_S)\n",
    "    df_output_by_TA.loc[ind,'count_Noncoor_store_in_S']=str(count_noncoor_stores_S)\n",
    "df_output_by_TA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_TA['city_list']=df_output_by_TA['city_list'].apply(eval)\n",
    "df_output_by_TA['state_list']=df_output_by_TA['state_list'].apply(eval)\n",
    "df_output_by_TA['count_Coor_store_in_P']=df_output_by_TA['count_Coor_store_in_P'].apply(eval)\n",
    "df_output_by_TA['count_Noncoor_store_in_P']=df_output_by_TA['count_Noncoor_store_in_P'].apply(eval)\n",
    "df_output_by_TA['count_Coor_store_in_S']=df_output_by_TA['count_Coor_store_in_S'].apply(eval)\n",
    "df_output_by_TA['count_Noncoor_store_in_S']=df_output_by_TA['count_Noncoor_store_in_S'].apply(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(list_store_missing)==0:\n",
    "    writer=pd.ExcelWriter(output_folder+\"GY_final_TA_updated_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "    df_output_unique_zips.to_excel(writer,\"unique_zips_full_footprint\",index=False)\n",
    "    df_output_by_TA.to_excel(writer,\"view_by_TA\",index=False)\n",
    "    df_output_by_store.to_excel(writer,\"view_by_store\",index=False)\n",
    "    df_output_by_store_zip_long.to_excel(writer,\"view_for_Tableau\",index=False)\n",
    "    writer.save()\n",
    "else:\n",
    "    print(\"checking stores misssing: \\n%s\"%list_store_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_num</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>store_id</th>\n",
       "      <th>address_1</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>DMA</th>\n",
       "      <th>CTY</th>\n",
       "      <th>all_trans_P_zips</th>\n",
       "      <th>all_trans_S_zips</th>\n",
       "      <th>trans_P_zips_40_within_TA</th>\n",
       "      <th>trans_S_zips_40_within_TA</th>\n",
       "      <th>all_P_zip_counts</th>\n",
       "      <th>all_S_zip_counts</th>\n",
       "      <th>mile40_P_zip_counts</th>\n",
       "      <th>mile40_S_zip_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>26</td>\n",
       "      <td>multiple_26</td>\n",
       "      <td>2393</td>\n",
       "      <td>114 ROLLING HILLS CIRCLE</td>\n",
       "      <td>29640</td>\n",
       "      <td>EASLEY</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.862904</td>\n",
       "      <td>-82.550289</td>\n",
       "      <td>{GREENVLL-SPART-ASHEVLL-AND}</td>\n",
       "      <td>{GREENVILLE, PICKENS}</td>\n",
       "      <td>[29642]</td>\n",
       "      <td>[29640, 29671, 29657, 29673, 29611, 29630, 292...</td>\n",
       "      <td>[29642]</td>\n",
       "      <td>[29693, 29690, 29353, 29605, 28018, 29385, 296...</td>\n",
       "      <td>1</td>\n",
       "      <td>963</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TA_num      ta_name store_id                 address_1 zip_cd    city  \\\n",
       "311      26  multiple_26     2393  114 ROLLING HILLS CIRCLE  29640  EASLEY   \n",
       "\n",
       "    state   latitude  longitude                           DMA  \\\n",
       "311    SC  34.862904 -82.550289  {GREENVLL-SPART-ASHEVLL-AND}   \n",
       "\n",
       "                       CTY all_trans_P_zips  \\\n",
       "311  {GREENVILLE, PICKENS}          [29642]   \n",
       "\n",
       "                                      all_trans_S_zips  \\\n",
       "311  [29640, 29671, 29657, 29673, 29611, 29630, 292...   \n",
       "\n",
       "    trans_P_zips_40_within_TA  \\\n",
       "311                   [29642]   \n",
       "\n",
       "                             trans_S_zips_40_within_TA  all_P_zip_counts  \\\n",
       "311  [29693, 29690, 29353, 29605, 28018, 29385, 296...                 1   \n",
       "\n",
       "     all_S_zip_counts  mile40_P_zip_counts  mile40_S_zip_counts  \n",
       "311               963                    1                  117  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_store[df_output_by_store['store_id']=='2393']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
