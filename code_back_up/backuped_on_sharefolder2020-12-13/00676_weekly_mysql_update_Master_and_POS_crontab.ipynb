{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/celery/BL_MySQL/Weekly_Update_MySQL'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import logging\n",
    "import sqlalchemy\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='/home/jian/celery/BL_MySQL/Weekly_Update_MySQL/weekly_mysql_update_Master_and_POSItem.log',level=\"INFO\")\n",
    "\n",
    "def recursive_file_gen(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root,file)\n",
    "            \n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py:166: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tables_in_BigLots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BL_POS_Item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BL_POS_Subclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BL_Rewards_Master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pred_CRM_table</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tables_in_BigLots\n",
       "0        BL_POS_Item\n",
       "1    BL_POS_Subclass\n",
       "2  BL_Rewards_Master\n",
       "3     Pred_CRM_table"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplerows=None\n",
    "\n",
    "\n",
    "existing_tables=pd.read_sql(\"show tables;\",con=BL_engine)\n",
    "existing_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max(sign_up_date)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  max(sign_up_date)\n",
       "0        2019-12-28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date_already_in_SQL=pd.read_sql(\"select max(sign_up_date) from BL_Rewards_Master;\", con=BL_engine)\n",
    "max_date_already_in_SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'2019-12-22'\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_week_start=str(max_date_already_in_SQL.iloc[0,0]-datetime.timedelta(days=6))\n",
    "last_week_start=\"'\"+last_week_start+\"'\"\n",
    "last_week_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sign_up_date</th>\n",
       "      <th>day_counts</th>\n",
       "      <th>unique_new_sign_ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-22</td>\n",
       "      <td>1</td>\n",
       "      <td>26447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>1</td>\n",
       "      <td>25051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>1</td>\n",
       "      <td>22263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>1</td>\n",
       "      <td>7355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>1</td>\n",
       "      <td>18856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>16996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>17715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sign_up_date  day_counts  unique_new_sign_ups\n",
       "0   2019-12-22           1                26447\n",
       "1   2019-12-23           1                25051\n",
       "2   2019-12-24           1                22263\n",
       "3   2019-12-25           1                 7355\n",
       "4   2019-12-26           1                18856\n",
       "5   2019-12-27           1                16996\n",
       "6   2019-12-28           1                17715"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_last_week_in_SQL=pd.read_sql(\"select sign_up_date, \\\n",
    "count(distinct sign_up_date) as day_counts, \\\n",
    "count(distinct customer_id_hashed) as unique_new_sign_ups \\\n",
    "from BL_Rewards_Master \\\n",
    "where sign_up_date>=%s \\\n",
    "group by sign_up_date;\" % last_week_start,con=BL_engine)\n",
    "\n",
    "df_last_week_in_SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134683"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_last_week_in_SQL['unique_new_sign_ups'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer_id_hashed',\n",
       " 'email_address_hash',\n",
       " 'sign_up_date',\n",
       " 'sign_up_channel',\n",
       " 'sign_up_location',\n",
       " 'customer_zip_code',\n",
       " 'transaction_count',\n",
       " 'transaction_amount',\n",
       " 'experian_multi_cluster',\n",
       " 'experian_demo_cluster',\n",
       " 'purchase_channel',\n",
       " 'email_unsubscribe_indicator',\n",
       " 'email_undeliverable_indicator',\n",
       " 'file_path']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list=pd.read_sql(\"select * from BL_Rewards_Master limit 1;\",con=BL_engine)\n",
    "col_list=col_list.columns.tolist()\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jian/BigLots/MediaStorm_2020-01-04/MediaStormMasterWeekly20200107-113348-460.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_item_POS_plain=list(recursive_file_gen(\"/home/jian/BigLots/\"))\n",
    "files_item_POS_plain=[x for x in files_item_POS_plain if x[-4:]==\".txt\" and \"master\" in x.lower() and \"/MediaStorm_\" in x]\n",
    "files_item_POS_plain=[x for x in files_item_POS_plain if x.split(\"/MediaStorm_\")[1][:10]>str(max_date_already_in_SQL.iloc[0,0])]\n",
    "files_item_POS_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaStormMasterWeekly20200107-113348-460.txt 2020-01-07 17:26:53.602858 False\n",
      "(115863, 14)\n"
     ]
    }
   ],
   "source": [
    "df_new_sign_ups=pd.DataFrame()\n",
    "\n",
    "for file in files_item_POS_plain:\n",
    "    df=pd.read_csv(file,dtype=str,nrows=samplerows,sep=\"|\")\n",
    "    print(os.path.basename(file),datetime.datetime.now(),df.columns.tolist()==col_list)\n",
    "    df['file_path']=file\n",
    "    df_new_sign_ups=df_new_sign_ups.append(df)\n",
    "    \n",
    "print(df_new_sign_ups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataframe column value types\n",
    "\n",
    "df_new_sign_ups['sign_up_date']=pd.to_datetime(df_new_sign_ups['sign_up_date'],format=\"%Y-%m-%d\").dt.date\n",
    "\n",
    "#\n",
    "df_new_sign_ups['sign_up_location']=df_new_sign_ups['sign_up_location'].fillna(-999).astype(int)\n",
    "df_new_sign_ups['sign_up_location']=df_new_sign_ups['sign_up_location'].replace(-999,np.nan)\n",
    "\n",
    "df_new_sign_ups['transaction_count']=df_new_sign_ups['transaction_count'].astype(float)\n",
    "df_new_sign_ups['transaction_amount']=df_new_sign_ups['transaction_amount'].astype(float)\n",
    "df_new_sign_ups['experian_multi_cluster']=df_new_sign_ups['experian_multi_cluster'].astype(float)\n",
    "df_new_sign_ups['experian_demo_cluster']=df_new_sign_ups['experian_demo_cluster'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check headers:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"check headers: \",df_new_sign_ups.columns.tolist()==col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_new_sign_ups.shape (115863, 14)\n",
      "df_new_sign_ups['customer_id_hashed'].nunique() 115863\n",
      "df_new_sign_ups['email_address_hash'].nunique() 115863\n"
     ]
    }
   ],
   "source": [
    "print(\"df_new_sign_ups.shape\",df_new_sign_ups.shape)\n",
    "print(\"df_new_sign_ups['customer_id_hashed'].nunique()\",df_new_sign_ups['customer_id_hashed'].nunique())\n",
    "print(\"df_new_sign_ups['email_address_hash'].nunique()\",df_new_sign_ups['email_address_hash'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_sign_ups.to_sql(\"BL_Rewards_Master\",if_exists='append', con=BL_engine, index=False,chunksize=300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC Master rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_last_date_in_sql '2019-12-29'\n"
     ]
    }
   ],
   "source": [
    "new_last_date_in_sql=pd.read_sql(\"select max(sign_up_date) from BL_Rewards_Master;\", con=BL_engine)\n",
    "new_last_date_in_sql=str(new_last_date_in_sql.iloc[0,0]-datetime.timedelta(days=6))\n",
    "new_last_date_in_sql=\"'\"+new_last_date_in_sql+\"'\"\n",
    "print(\"new_last_date_in_sql\",new_last_date_in_sql)\n",
    "new_ids_updated_this_week=pd.read_sql(\"select sign_up_date, \\\n",
    "count(distinct sign_up_date) as day_counts, \\\n",
    "count(distinct customer_id_hashed) as unique_new_sign_ups \\\n",
    "from BL_Rewards_Master \\\n",
    "where sign_up_date>=%s \\\n",
    "group by sign_up_date;\" % new_last_date_in_sql,con=BL_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sign_up_date</th>\n",
       "      <th>day_counts</th>\n",
       "      <th>unique_new_sign_ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>15964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>13808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>12405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>19543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>18168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>19291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>16684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sign_up_date  day_counts  unique_new_sign_ups\n",
       "0   2019-12-29           1                15964\n",
       "1   2019-12-30           1                13808\n",
       "2   2019-12-31           1                12405\n",
       "3   2020-01-01           1                19543\n",
       "4   2020-01-02           1                18168\n",
       "5   2020-01-03           1                19291\n",
       "6   2020-01-04           1                16684"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ids_updated_this_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QC the txt count new ids == MySQL new rows:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"QC the txt count new ids == MySQL new rows: \",df_new_sign_ups.shape[0]==new_ids_updated_this_week['unique_new_sign_ups'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update POS Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max(transaction_dt)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  max(transaction_dt)\n",
       "0          2019-12-28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date_already_in_SQL=pd.read_sql(\"select max(transaction_dt) from BL_POS_Item;\", con=BL_engine)\n",
    "max_date_already_in_SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'2019-12-22'\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_week_start=str(max_date_already_in_SQL.iloc[0,0]-datetime.timedelta(days=6))\n",
    "last_week_start=\"'\"+last_week_start+\"'\"\n",
    "last_week_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_dt</th>\n",
       "      <th>weekly_sales</th>\n",
       "      <th>day_counts</th>\n",
       "      <th>unique_shoppers</th>\n",
       "      <th>store_count_include_6990</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-22</td>\n",
       "      <td>27677400.15</td>\n",
       "      <td>1</td>\n",
       "      <td>353809</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>29795055.18</td>\n",
       "      <td>1</td>\n",
       "      <td>392662</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>28576709.46</td>\n",
       "      <td>1</td>\n",
       "      <td>364284</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>156.43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>19008999.40</td>\n",
       "      <td>1</td>\n",
       "      <td>286458</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>15527399.48</td>\n",
       "      <td>1</td>\n",
       "      <td>248281</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>16458419.28</td>\n",
       "      <td>1</td>\n",
       "      <td>250426</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_dt  weekly_sales  day_counts  unique_shoppers  \\\n",
       "0     2019-12-22   27677400.15           1           353809   \n",
       "1     2019-12-23   29795055.18           1           392662   \n",
       "2     2019-12-24   28576709.46           1           364284   \n",
       "3     2019-12-25        156.43           1                2   \n",
       "4     2019-12-26   19008999.40           1           286458   \n",
       "5     2019-12-27   15527399.48           1           248281   \n",
       "6     2019-12-28   16458419.28           1           250426   \n",
       "\n",
       "   store_count_include_6990  \n",
       "0                      1420  \n",
       "1                      1421  \n",
       "2                      1421  \n",
       "3                         1  \n",
       "4                      1421  \n",
       "5                      1421  \n",
       "6                      1421  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_week_sales_already_in_SQL=pd.read_sql(\"select transaction_dt, \\\n",
    "sum(item_transaction_amt) as weekly_sales, \\\n",
    "count(distinct transaction_dt) as day_counts, \\\n",
    "count(distinct customer_id_hashed) as unique_shoppers, \\\n",
    "count(distinct location_id) as store_count_include_6990 \\\n",
    "from BL_POS_Item \\\n",
    "where transaction_dt>=%s \\\n",
    "group by transaction_dt;\" % last_week_start,con=BL_engine)\n",
    "\n",
    "max_week_sales_already_in_SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jian/BigLots/MediaStorm_2020-01-04/MediaStormDailySales20200107-112859-015.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_item_POS_plain=list(recursive_file_gen(\"/home/jian/BigLots/\"))\n",
    "files_item_POS_plain=[x for x in files_item_POS_plain if x[-4:]==\".txt\" and \"dailysales\" in x.lower() and \"/MediaStorm_\" in x]\n",
    "files_item_POS_plain=[x for x in files_item_POS_plain if x.split(\"/MediaStorm_\")[1][:10]>str(max_date_already_in_SQL.iloc[0,0])]\n",
    "files_item_POS_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['location_id',\n",
       " 'transaction_dt',\n",
       " 'transaction_id',\n",
       " 'customer_id_hashed',\n",
       " 'class_code_id',\n",
       " 'subclass_id',\n",
       " 'item_id',\n",
       " 'item_transaction_units',\n",
       " 'item_transaction_amt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list=pd.read_sql(\"select * from BL_POS_Item limit 1;\",con=BL_engine)\n",
    "col_list=col_list.columns.tolist()\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_POS_df_clean_type(df):\n",
    "    # All fields to keep as str not changed\n",
    "    df['location_id']=df['location_id'].astype(int)\n",
    "    df['transaction_dt']=pd.to_datetime(df['transaction_dt'],format=\"%Y-%m-%d\").dt.date\n",
    "    # df['transaction_id']=df['transaction_id'].astype(str) varchar(16)\n",
    "    # df['customer_id_hashed']=   char(64)\n",
    "    # df['class_code_id']=df['class_code_id'].astype(str) varchar(16)\n",
    "    # df['subclass_id']=df['subclass_id'].astype(str) varchar(16)\n",
    "    # df['item_id']=df['item_id'].astype(str) varchar(16)\n",
    "    df['item_transaction_units']=df['item_transaction_units'].astype(int)\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    \n",
    "    # printthe len of str cols\n",
    "    # print('transaction_id',df['transaction_id'].apply(len).max())\n",
    "    # print('class_code_id',df['class_code_id'].apply(len).max())\n",
    "    # print('subclass_id',df['subclass_id'].apply(len).max())\n",
    "    # print('item_id',df['item_id'].apply(len).max())\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['location_id',\n",
       " 'transaction_dt',\n",
       " 'transaction_id',\n",
       " 'customer_id_hashed',\n",
       " 'class_code_id',\n",
       " 'subclass_id',\n",
       " 'item_id',\n",
       " 'item_transaction_units',\n",
       " 'item_transaction_amt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_table(files_item_POS_plain[0],dtype=str,sep=\"|\",nrows=1)\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 2020-01-07 17:48:47.826678 MediaStormDailySales20200107-112859-015.txt\n",
      "(14906032, 9) 2019-12-29 2020-01-04\n"
     ]
    }
   ],
   "source": [
    "samplerows=None\n",
    "\n",
    "for file in files_item_POS_plain:\n",
    "    df=pd.read_table(file,dtype=str,sep=\"|\",nrows=samplerows)\n",
    "    print(df.columns.tolist()==col_list, datetime.datetime.now(), os.path.basename(file))\n",
    "    print(df.shape,df['transaction_dt'].min(),df['transaction_dt'].max())\n",
    "    \n",
    "    logging.info(str(df.columns.tolist()==col_list)+\", \"+str(datetime.datetime.now())+\", \"+str(os.path.basename(file)))\n",
    "    logging.info(str(df.shape)+\", \"+str(df['transaction_dt'].min())+\", \"+str(df['transaction_dt'].max()))\n",
    "    \n",
    "    df=item_POS_df_clean_type(df)\n",
    "    df.to_sql('BL_POS_Item',if_exists='append',con=BL_engine,index=False,\n",
    "              dtype={\n",
    "                  'location_id':sqlalchemy.types.INTEGER(),\n",
    "                  'transaction_dt':sqlalchemy.Date(),\n",
    "                  'transaction_id':sqlalchemy.types.VARCHAR(length=16),\n",
    "                  'customer_id_hashed':sqlalchemy.types.VARCHAR(length=64),\n",
    "                  'class_code_id':sqlalchemy.types.VARCHAR(length=16),\n",
    "                  'subclass_id':sqlalchemy.types.VARCHAR(length=16),\n",
    "                  'item_id':sqlalchemy.types.VARCHAR(length=16),\n",
    "                  'item_transaction_units':sqlalchemy.types.INTEGER(),\n",
    "                  'item_transaction_amt':sqlalchemy.types.DECIMAL(precision=10,scale=2,asdecimal=True)\n",
    "                    }\n",
    "             )\n",
    "print(\"All_Done: \",datetime.datetime.now())\n",
    "logging.info(\"All_Done: \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_table(files_item_POS_plain[0],dtype=str,sep=\"|\",nrows=None)\n",
    "df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "print(df['item_transaction_amt'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date_already_in_SQL=pd.read_sql(\"select max(transaction_dt) from BL_POS_Item;\", con=BL_engine)\n",
    "last_week_start_after_updating=str(max_date_already_in_SQL.iloc[0,0]-datetime.timedelta(days=6))\n",
    "last_week_start_after_updating=\"'\"+last_week_start_after_updating+\"'\"\n",
    "print(last_week_start_after_updating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_week_sales_already_in_SQL=pd.read_sql(\"select transaction_dt, \\\n",
    "sum(item_transaction_amt) as weekly_sales, \\\n",
    "count(distinct transaction_dt) as day_counts, \\\n",
    "count(distinct customer_id_hashed) as unique_shoppers, \\\n",
    "count(distinct location_id) as store_count_include_6990 \\\n",
    "from BL_POS_Item \\\n",
    "where transaction_dt>=%s \\\n",
    "group by transaction_dt;\" % last_week_start_after_updating,con=BL_engine)\n",
    "\n",
    "summary_week_sales_already_in_SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"QC last week sales inline with txt file: \",summary_week_sales_already_in_SQL['weekly_sales'].sum()==summary_week_sales_already_in_SQL['weekly_sales'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
