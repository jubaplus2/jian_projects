{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/Projects/SunnyD/Allocate_DMA_spend_to_IRI/Update_2020_Joann_Request'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YouTube',\n",
       " 'summary',\n",
       " 'total cost',\n",
       " 'DTV',\n",
       " 'DTV cost',\n",
       " 'DTV total imp',\n",
       " 'ct-need to cleanDMA',\n",
       " 'untitled 3cost',\n",
       " 'untitled 7im',\n",
       " 'ALLeee',\n",
       " 'Snap',\n",
       " 'data',\n",
       " 'mapping_naming',\n",
       " 'coefficient',\n",
       " 'Digital Clicks',\n",
       " 'SUNNYD - Digital Spend by Day b']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel_File=pd.ExcelFile(\"./SUNNYD - Digital Deliveries by Day by Market_0113.xlsx\")\n",
    "Excel_File.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# update dma naming\\n\\nDMA_name_mapping=json.load(open(\"/home/jian/Docs/Geo_mapping/dma_map_latest.json\",\"r\"))\\nprint(len(DMA_name_mapping))\\njoann_updating=Excel_File.parse(\\'mapping_naming\\',dtype=str)\\njoann_updating=joann_updating[~joann_updating[\\'dirty_name\\'].isin(DMA_name_mapping.keys())]\\njoann_updating_dict=joann_updating.set_index(\"dirty_name\").to_dict()[\\'clean_name\\']\\n\\nprint(len(joann_updating_dict))\\nDMA_name_mapping.update(joann_updating_dict)\\nprint(len(DMA_name_mapping))\\n\\nwith open(\"/home/jian/Docs/Geo_mapping/dma_map_latest.json\", \\'w\\') as outfile:  \\n    json.dump(DMA_name_mapping, outfile)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# update dma naming\n",
    "\n",
    "DMA_name_mapping=json.load(open(\"/home/jian/Docs/Geo_mapping/dma_map_latest.json\",\"r\"))\n",
    "print(len(DMA_name_mapping))\n",
    "joann_updating=Excel_File.parse('mapping_naming',dtype=str)\n",
    "joann_updating=joann_updating[~joann_updating['dirty_name'].isin(DMA_name_mapping.keys())]\n",
    "joann_updating_dict=joann_updating.set_index(\"dirty_name\").to_dict()['clean_name']\n",
    "\n",
    "print(len(joann_updating_dict))\n",
    "DMA_name_mapping.update(joann_updating_dict)\n",
    "print(len(DMA_name_mapping))\n",
    "\n",
    "with open(\"/home/jian/Docs/Geo_mapping/dma_map_latest.json\", 'w') as outfile:  \n",
    "    json.dump(DMA_name_mapping, outfile)\n",
    "'''\n",
    "\n",
    "# 1612\n",
    "# 108\n",
    "# 1720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMA_name_mapping=json.load(open(\"/home/jian/Docs/Geo_mapping/dma_map_latest.json\",\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53494, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Media</th>\n",
       "      <th>clean_DMA</th>\n",
       "      <th>Impression</th>\n",
       "      <th>Click</th>\n",
       "      <th>Cost</th>\n",
       "      <th>cleaned date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hulu</td>\n",
       "      <td>Abilene-Sweetwater, TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hulu</td>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Media                    clean_DMA  Impression  Click  Cost cleaned date\n",
       "0  Hulu       Abilene-Sweetwater, TX         0.0      0   0.0   2019-10-18\n",
       "1  Hulu  Albany-Schenectady-Troy, NY         0.0      0   0.0   2019-10-18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data=Excel_File.parse('data',dtype=str)\n",
    "df_data['cleaned date']=pd.to_datetime(df_data['cleaned date']).dt.date\n",
    "df_data['Impression']=df_data['Impression'].fillna(0).astype(float)\n",
    "df_data['Click']=df_data['Click'].fillna(0).astype(int)\n",
    "df_data['Cost']=df_data['Cost'].fillna(0).astype(float)\n",
    "print(df_data.shape)\n",
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the Snapchat data based on new file\n",
    "df_data_snap=df_data[df_data['Media']==\"Snapchat\"]\n",
    "df_data=df_data[df_data['Media']!=\"Snapchat\"]\n",
    "\n",
    "df_snapchat_new=pd.read_csv(\"./SunnyD Fall FY'20 Snap_Spend by DMA_1.16.20.csv\",dtype=str,\n",
    "                            usecols=['cleaned DMA','Impressions','Swipe Ups','Spend'])\n",
    "df_snapchat_new['Impressions']=df_snapchat_new['Impressions'].astype(int)\n",
    "df_snapchat_new['Swipe Ups']=df_snapchat_new['Swipe Ups'].astype(int)\n",
    "df_snapchat_new['Spend']=df_snapchat_new['Spend'].astype(float)\n",
    "\n",
    "\n",
    "df_snapchat_new=df_snapchat_new.rename(columns={\"Impressions\":\"new_impr\",\"Swipe Ups\":\"new_click\",\"Spend\":\"new_cost\"})\n",
    "df_snapchat_new=df_snapchat_new.groupby(\"cleaned DMA\")['new_impr','new_click','new_cost'].sum().reset_index()\n",
    "df_snapchat_new['impr_pctg']=df_snapchat_new['new_impr']/df_snapchat_new['new_impr'].sum()\n",
    "df_snapchat_new['click_pctg']=df_snapchat_new['new_click']/df_snapchat_new['new_click'].sum()\n",
    "df_snapchat_new['cost_pctg']=df_snapchat_new['new_cost']/df_snapchat_new['new_cost'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_snapchat_ratio=df_snapchat_new[['cleaned DMA','impr_pctg','click_pctg','cost_pctg']]\n",
    "df_snapchat_ratio['clean_DMA']=df_snapchat_ratio['cleaned DMA'].copy()\n",
    "df_snapchat_ratio['merge_key']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18352805.0\n",
      "112417\n",
      "42081.38999999999\n",
      "18352805.0\n",
      "112417.0\n",
      "42081.39\n"
     ]
    }
   ],
   "source": [
    "del df_data_snap['clean_DMA']\n",
    "df_data_snap['merge_key']=1\n",
    "print(df_data_snap['Impression'].sum())\n",
    "print(df_data_snap['Click'].sum())\n",
    "print(df_data_snap['Cost'].sum())\n",
    "\n",
    "df_data_snap=pd.merge(df_data_snap,df_snapchat_ratio,on=\"merge_key\",how=\"left\")\n",
    "df_data_snap['new_impr_by_dma']=df_data_snap['Impression']*df_data_snap['impr_pctg']\n",
    "df_data_snap['new_click_by_dma']=df_data_snap['Click']*df_data_snap['click_pctg']\n",
    "df_data_snap['new_cost_by_dma']=df_data_snap['Cost']*df_data_snap['cost_pctg']\n",
    "\n",
    "del df_data_snap['Impression']\n",
    "del df_data_snap['Click']\n",
    "del df_data_snap['Cost']\n",
    "\n",
    "df_data_snap=df_data_snap.rename(columns={\"new_impr_by_dma\":\"Impression\",\"new_click_by_dma\":\"Click\",\"new_cost_by_dma\":\"Cost\"})\n",
    "\n",
    "print(df_data_snap['Impression'].sum())\n",
    "print(df_data_snap['Click'].sum())\n",
    "print(df_data_snap['Cost'].sum())\n",
    "\n",
    "\n",
    "df_data_snap=df_data_snap[df_data.columns.tolist()]\n",
    "df_data=df_data.append(df_data_snap)\n",
    "\n",
    "# Snapchat already updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Media</th>\n",
       "      <th>clean_DMA</th>\n",
       "      <th>Impression</th>\n",
       "      <th>Click</th>\n",
       "      <th>Cost</th>\n",
       "      <th>cleaned date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snapchat</td>\n",
       "      <td>Albany, GA</td>\n",
       "      <td>96.576694</td>\n",
       "      <td>0.619329</td>\n",
       "      <td>0.150699</td>\n",
       "      <td>2019-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snapchat</td>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>86.450250</td>\n",
       "      <td>0.287546</td>\n",
       "      <td>0.121902</td>\n",
       "      <td>2019-10-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Media                    clean_DMA  Impression     Click      Cost  \\\n",
       "0  Snapchat                   Albany, GA   96.576694  0.619329  0.150699   \n",
       "1  Snapchat  Albany-Schenectady-Troy, NY   86.450250  0.287546  0.121902   \n",
       "\n",
       "  cleaned date  \n",
       "0   2019-10-22  \n",
       "1   2019-10-22  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_snap.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Media</th>\n",
       "      <th>clean_DMA</th>\n",
       "      <th>Impression</th>\n",
       "      <th>Click</th>\n",
       "      <th>Cost</th>\n",
       "      <th>cleaned date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hulu</td>\n",
       "      <td>Abilene-Sweetwater, TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hulu</td>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Media                    clean_DMA  Impression  Click  Cost cleaned date\n",
       "0  Hulu       Abilene-Sweetwater, TX         0.0    0.0   0.0   2019-10-18\n",
       "1  Hulu  Albany-Schenectady-Troy, NY         0.0    0.0   0.0   2019-10-18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56893, 7)\n"
     ]
    }
   ],
   "source": [
    "df_buy_type=Excel_File.parse('summary',dtype=str)\n",
    "df_buy_type=df_buy_type[['Media','Media buy']].drop_duplicates().rename(columns={\"Media buy\":\"buy_type\"})\n",
    "df_data=pd.merge(df_data,df_buy_type,on=\"Media\",how=\"left\")\n",
    "print(df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsegment Pre-Roll TTD', 'Pandora', 'Facebook', 'DTV']\n",
      "(56893, 7)\n",
      "['National', 'Zip', 'DMA']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Media</th>\n",
       "      <th>clean_DMA</th>\n",
       "      <th>Impression</th>\n",
       "      <th>Click</th>\n",
       "      <th>Cost</th>\n",
       "      <th>cleaned date</th>\n",
       "      <th>buy_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hulu</td>\n",
       "      <td>Abilene-Sweetwater, TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>National</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hulu</td>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>National</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Media                    clean_DMA  Impression  Click  Cost cleaned date  \\\n",
       "0  Hulu       Abilene-Sweetwater, TX         0.0    0.0   0.0   2019-10-18   \n",
       "1  Hulu  Albany-Schenectady-Troy, NY         0.0    0.0   0.0   2019-10-18   \n",
       "\n",
       "   buy_type  \n",
       "0  National  \n",
       "1  National  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_data[pd.isnull(df_data['buy_type'])]['Media'].unique().tolist())\n",
    "\n",
    "del df_data['buy_type']\n",
    "df_data['Media']=df_data['Media'].replace(\"Microsegment Pre-Roll TTD\",\"Microsegment Video/Display\")\n",
    "df_data['Media']=df_data['Media'].replace(\"Pandora\",\"Pandora/Soundcloud\")\n",
    "df_data['Media']=df_data['Media'].replace(\"Facebook\",\"Facebook/Instagram\")\n",
    "df_data['Media']=df_data['Media'].replace(\"DTV\",\"DirecTV\")\n",
    "df_data=pd.merge(df_data,df_buy_type,on=\"Media\",how=\"left\")\n",
    "print(df_data.shape)\n",
    "\n",
    "print(df_data['buy_type'].unique().tolist())\n",
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net_to_gross_factor=Excel_File.parse(\"coefficient\")\n",
    "df_net_to_gross_factor['Media']=df_net_to_gross_factor['Media'].replace(\"DTV\",\"DirecTV\")\n",
    "df_net_to_gross_factor['Media']=df_net_to_gross_factor['Media'].replace(\"Microsegment Pre-Roll TTD\",\"Microsegment Video/Display\")\n",
    "df_net_to_gross_factor['Media']=df_net_to_gross_factor['Media'].replace(\"Pandora\",\"Pandora/Soundcloud\")\n",
    "df_net_to_gross_factor['Media']=df_net_to_gross_factor['Media'].replace(\"Facebook\",\"Facebook/Instagram\")\n",
    "\n",
    "\n",
    "df_net_to_gross_factor=df_net_to_gross_factor[['Media','coefficient']]\n",
    "df_net_to_gross_factor=pd.merge(df_net_to_gross_factor,df_buy_type,on=\"Media\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_DMA</th>\n",
       "      <th>IRI Market</th>\n",
       "      <th>Pctg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene-Sweetwater, TX</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albany, GA</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>0.796801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>NEW ENGLAND</td>\n",
       "      <td>0.029085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>0.174114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Wilmington, NC</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Yakima-Pasco-Richland-Kennewick, WA</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Youngstown, OH</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Yuma, AZ-El Centro, CA</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Zanesville, OH</td>\n",
       "      <td>COLUMBUS</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               clean_DMA   IRI Market      Pctg\n",
       "0                 Abilene-Sweetwater, TX    NO MARKET  1.000000\n",
       "1                             Albany, GA    NO MARKET  1.000000\n",
       "2            Albany-Schenectady-Troy, NY       ALBANY  0.796801\n",
       "3            Albany-Schenectady-Troy, NY  NEW ENGLAND  0.029085\n",
       "4            Albany-Schenectady-Troy, NY    NO MARKET  0.174114\n",
       "..                                   ...          ...       ...\n",
       "322                       Wilmington, NC    NO MARKET  1.000000\n",
       "323  Yakima-Pasco-Richland-Kennewick, WA    NO MARKET  1.000000\n",
       "324                       Youngstown, OH    NO MARKET  1.000000\n",
       "325               Yuma, AZ-El Centro, CA    NO MARKET  1.000000\n",
       "326                       Zanesville, OH     COLUMBUS  1.000000\n",
       "\n",
       "[327 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2019 mapping \n",
    "\n",
    "allocation_pctg=pd.read_csv(\"/home/jian/Projects/SunnyD/Otherinput/DMA_to_IRI_Pctg/from_DMA_to_IRI_based_on_common_population.csv\",dtype=str)\n",
    "allocation_pctg=allocation_pctg[['DMA','IRI Market','Pctg']]\n",
    "allocation_pctg['Pctg']=allocation_pctg['Pctg'].apply(lambda x: float(x))\n",
    "allocation_pctg['clean_DMA']=allocation_pctg['DMA'].apply(lambda x: DMA_name_mapping[x])\n",
    "allocation_pctg=allocation_pctg[['clean_DMA','IRI Market','Pctg']]\n",
    "allocation_pctg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_pop:  339192928.3000005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_DMA</th>\n",
       "      <th>IRI Market</th>\n",
       "      <th>Pctg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene-Sweetwater, TX</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albany, GA</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>0.796801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>NEW ENGLAND</td>\n",
       "      <td>0.029085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany-Schenectady-Troy, NY</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>0.174114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>xx</td>\n",
       "      <td>WICHITA</td>\n",
       "      <td>0.002469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anchorage, AK</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fairbanks, AK</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Juneau, AK</td>\n",
       "      <td>NO MARKET</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      clean_DMA   IRI Market      Pctg\n",
       "0        Abilene-Sweetwater, TX    NO MARKET  1.000000\n",
       "1                    Albany, GA    NO MARKET  1.000000\n",
       "2   Albany-Schenectady-Troy, NY       ALBANY  0.796801\n",
       "3   Albany-Schenectady-Troy, NY  NEW ENGLAND  0.029085\n",
       "4   Albany-Schenectady-Troy, NY    NO MARKET  0.174114\n",
       "..                          ...          ...       ...\n",
       "64                           xx      WICHITA  0.002469\n",
       "0                 Anchorage, AK    NO MARKET  1.000000\n",
       "1                 Fairbanks, AK    NO MARKET  1.000000\n",
       "2                  Honolulu, HI    NO MARKET  1.000000\n",
       "3                    Juneau, AK    NO MARKET  1.000000\n",
       "\n",
       "[396 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update_national_pctg\n",
    "\n",
    "df_pop_by_iri=pd.read_csv(\"/home/jian/Projects/SunnyD/Otherinput/Population_by_IRI/SunnyD_population by IRI with duplication_JL_2018-09-21.csv\")\n",
    "df_pop_by_iri.head(2)\n",
    "\n",
    "df_pop_by_iri=df_pop_by_iri.groupby(\"IRI Market\")['POP18'].sum().to_frame().reset_index()\n",
    "total_pop=df_pop_by_iri['POP18'].sum() # with dup\n",
    "print(\"total_pop: \",total_pop)\n",
    "\n",
    "df_pop_by_iri['Pctg']=df_pop_by_iri['POP18']/total_pop\n",
    "df_pop_by_iri.head(2)\n",
    "# df_pop_by_iri['Pctg'].sum()\n",
    "df_pop_by_iri['clean_DMA']=\"xx\"\n",
    "df_pop_by_iri=df_pop_by_iri[['clean_DMA','IRI Market','Pctg']]\n",
    "\n",
    "allocation_pctg=allocation_pctg.append(df_pop_by_iri)\n",
    "\n",
    "\n",
    "# update AK HI DMAs\n",
    "\n",
    "df_ak_hi=pd.DataFrame({\"clean_DMA\":['Anchorage, AK', 'Fairbanks, AK', 'Honolulu, HI', 'Juneau, AK']})\n",
    "df_ak_hi['IRI Market']=\"NO MARKET\"\n",
    "df_ak_hi['Pctg']=1\n",
    "\n",
    "allocation_pctg=allocation_pctg.append(df_ak_hi)\n",
    "allocation_pctg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hulu', 'InMarket', 'Microsegment Video/Display',\n",
       "       'Pandora/Soundcloud', 'Twitch', 'YouTube', 'Facebook/Instagram'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[df_data['clean_DMA']==\"xx\"]['Media'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10745, 7)\n",
      "['Hulu' 'DirecTV']\n",
      "df_1['Impression'].sum() 50255409.0\n",
      "df_1['Click'].sum() 0.0\n",
      "df_1['Cost'].sum() 505573.99\n",
      "/n\n",
      "df_1['IRI_Impression'].sum() 50255409.00000001\n",
      "df_1['IRI_Click'].sum() 0.0\n",
      "df_1['IRI_Cost'].sum() 505573.99\n"
     ]
    }
   ],
   "source": [
    "# 1. National buy\n",
    "df_1=df_data[df_data['buy_type']==\"National\"]\n",
    "print(df_1.shape)\n",
    "print(df_1['Media'].unique())\n",
    "\n",
    "print(\"df_1['Impression'].sum()\",df_1['Impression'].sum())\n",
    "print(\"df_1['Click'].sum()\",df_1['Click'].sum())\n",
    "print(\"df_1['Cost'].sum()\",df_1['Cost'].sum())\n",
    "\n",
    "# Anyway need to allocate all 211 DMAs\n",
    "'''\n",
    "df_1=df_1[df_1[['Impression','Click','Cost']].sum(axis=1)>0]\n",
    "print(df_1.shape)\n",
    "'''\n",
    "df_1=pd.merge(df_1,allocation_pctg,on=\"clean_DMA\",how=\"left\")\n",
    "df_1['IRI_Impression']=df_1['Impression']*df_1['Pctg']\n",
    "df_1['IRI_Click']=df_1['Click']*df_1['Pctg']\n",
    "df_1['IRI_Cost']=df_1['Cost']*df_1['Pctg']\n",
    "df_1=df_1.groupby([\"IRI Market\",\"Media\",\"buy_type\",\"cleaned date\"])['IRI_Impression','IRI_Click','IRI_Cost'].sum().reset_index()\n",
    "\n",
    "print(\"/n\")\n",
    "print(\"df_1['IRI_Impression'].sum()\",df_1['IRI_Impression'].sum())\n",
    "print(\"df_1['IRI_Click'].sum()\",df_1['IRI_Click'].sum())\n",
    "print(\"df_1['IRI_Cost'].sum()\",df_1['IRI_Cost'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18624, 7)\n",
      "['Pandora/Soundcloud' 'Twitch' 'Snapchat']\n",
      "df_2['Impression'].sum() 26898779.0\n",
      "df_2['Click'].sum() 138184.0\n",
      "df_2['Cost'].sum() 262178.57\n",
      "After/n\n",
      "df_2['IRI_Impression'].sum() 26898779.0\n",
      "df_2['IRI_Click'].sum() 138184.0\n",
      "df_2['IRI_Cost'].sum() 262178.57000000007\n"
     ]
    }
   ],
   "source": [
    "# 2. DMA buy\n",
    "df_2=df_data[df_data['buy_type']==\"DMA\"]\n",
    "print(df_2.shape)\n",
    "print(df_2['Media'].unique())\n",
    "\n",
    "print(\"df_2['Impression'].sum()\",df_2['Impression'].sum())\n",
    "print(\"df_2['Click'].sum()\",df_2['Click'].sum())\n",
    "print(\"df_2['Cost'].sum()\",df_2['Cost'].sum())\n",
    "\n",
    "df_2=pd.merge(df_2,allocation_pctg,on=\"clean_DMA\",how=\"left\")\n",
    "df_2['IRI_Impression']=df_2['Impression']*df_2['Pctg']\n",
    "df_2['IRI_Click']=df_2['Click']*df_2['Pctg']\n",
    "df_2['IRI_Cost']=df_2['Cost']*df_2['Pctg']\n",
    "df_2=df_2.groupby([\"IRI Market\",\"Media\",\"buy_type\",\"cleaned date\"])['IRI_Impression','IRI_Click','IRI_Cost'].sum().reset_index()\n",
    "\n",
    "print(\"After/n\")\n",
    "print(\"df_2['IRI_Impression'].sum()\",df_2['IRI_Impression'].sum())\n",
    "print(\"df_2['IRI_Click'].sum()\",df_2['IRI_Click'].sum())\n",
    "print(\"df_2['IRI_Cost'].sum()\",df_2['IRI_Cost'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27524, 7)\n",
      "['InMarket' 'Microsegment Video/Display' 'YouTube' 'Facebook/Instagram']\n",
      "df_3['Impression'].sum() 67745643.0\n",
      "df_3['Click'].sum() 114068.0\n",
      "df_3['Cost'].sum() 347375.010000178\n",
      "(27524, 7)\n",
      "df_3['Impression'].sum() 67745643.0\n",
      "df_3['Click'].sum() 114068.0\n",
      "df_3['Cost'].sum() 347375.010000178\n",
      "After/n\n",
      "df_3['IRI_Impression'].sum() 67745642.99999999\n",
      "df_3['IRI_Click'].sum() 114068.0\n",
      "df_3['IRI_Cost'].sum() 347375.010000178\n"
     ]
    }
   ],
   "source": [
    "# 3. Zip buy\n",
    "\n",
    "\n",
    "# Step1: get the mapping without \"NO MARKET\"\n",
    "df_3=df_data[df_data['buy_type']==\"Zip\"]\n",
    "print(df_3.shape)\n",
    "print(df_3['Media'].unique())\n",
    "\n",
    "print(\"df_3['Impression'].sum()\",df_3['Impression'].sum())\n",
    "print(\"df_3['Click'].sum()\",df_3['Click'].sum())\n",
    "print(\"df_3['Cost'].sum()\",df_3['Cost'].sum())\n",
    "\n",
    "df_3=pd.merge(df_3,allocation_pctg,on=\"clean_DMA\",how=\"left\")\n",
    "\n",
    "# remove if No Market, and rolling to 100% for those in IRI\n",
    "df_3_DMA_IRI=df_3[['clean_DMA','IRI Market','Pctg']].drop_duplicates()\n",
    "df_3_DMA_IRI=df_3_DMA_IRI[df_3_DMA_IRI['IRI Market']!=\"NO MARKET\"]\n",
    "df_3_DMA_IRI_pair_adj=df_3_DMA_IRI.groupby(['clean_DMA'])['Pctg'].sum().to_frame().reset_index()\n",
    "df_3_DMA_IRI_pair_adj['adj']=1/df_3_DMA_IRI_pair_adj['Pctg']\n",
    "df_3_DMA_IRI_pair_adj=df_3_DMA_IRI_pair_adj[['clean_DMA','adj']]\n",
    "df_3_DMA_IRI=pd.merge(df_3_DMA_IRI,df_3_DMA_IRI_pair_adj,on=\"clean_DMA\",how=\"left\")\n",
    "df_3_DMA_IRI['Pctg']=df_3_DMA_IRI['Pctg']*df_3_DMA_IRI['adj']\n",
    "\n",
    "del df_3_DMA_IRI['adj']\n",
    "\n",
    "df_3_DMA_IRI\n",
    "\n",
    "# Step2: use the new mapping table\n",
    "df_3=df_data[df_data['buy_type']==\"Zip\"]\n",
    "print(df_3.shape)\n",
    "\n",
    "print(\"df_3['Impression'].sum()\",df_3['Impression'].sum())\n",
    "print(\"df_3['Click'].sum()\",df_3['Click'].sum())\n",
    "print(\"df_3['Cost'].sum()\",df_3['Cost'].sum())\n",
    "\n",
    "df_3=pd.merge(df_3,df_3_DMA_IRI,on=\"clean_DMA\",how=\"left\")\n",
    "\n",
    "# Step3: even though zip buy, but soem DMAs shown with 0 overlap with DMA, have to fill na with \"NO MARKET\"\n",
    "df_3['IRI Market']=df_3['IRI Market'].fillna(\"NO MARKET\")\n",
    "df_3['Pctg']=df_3['Pctg'].fillna(1)\n",
    "\n",
    "\n",
    "df_3['IRI_Impression']=df_3['Impression']*df_3['Pctg']\n",
    "df_3['IRI_Click']=df_3['Click']*df_3['Pctg']\n",
    "df_3['IRI_Cost']=df_3['Cost']*df_3['Pctg']\n",
    "df_3=df_3.groupby([\"IRI Market\",\"Media\",\"buy_type\",\"cleaned date\"])['IRI_Impression','IRI_Click','IRI_Cost'].sum().reset_index()\n",
    "\n",
    "print(\"After/n\")\n",
    "print(\"df_3['IRI_Impression'].sum()\",df_3['IRI_Impression'].sum())\n",
    "print(\"df_3['IRI_Click'].sum()\",df_3['IRI_Click'].sum())\n",
    "print(\"df_3['IRI_Cost'].sum()\",df_3['IRI_Cost'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18424, 7)\n",
      "(18424, 8)\n"
     ]
    }
   ],
   "source": [
    "df_output=pd.concat([df_1,df_2,df_3])\n",
    "print(df_output.shape)\n",
    "df_output=pd.merge(df_output,df_net_to_gross_factor,on=[\"Media\",'buy_type'],how=\"left\")\n",
    "print(df_output.shape)\n",
    "\n",
    "df_output['IRI_Gross_Cost']=df_output['IRI_Cost']*df_output['coefficient']\n",
    "df_output.to_csv(\"./SunnyD_allocated_DMA_to_IRI_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
