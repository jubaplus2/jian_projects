{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-04 15:22:44.752689\n",
      "/home/jian/Projects/Big_Lots/Analysis/2019_Q3/Columbus_Day_Result\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "print(os.getcwd())\n",
    "\n",
    "# 10/10/2019 – 10/19/2019\n",
    "# 10/04/2018 – 10/13/2018\n",
    "\n",
    "# vs the compariable days last year \n",
    "# changed to 1 week earlier last year 2018, run on 2019-11-04\n",
    "# no need for the pre-campaign period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recurisve_file_gen(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jian/BigLots/2019_by_weeks/MediaStorm_2019-10-12/MediaStormDailySales20191015-111135-657.txt',\n",
       " '/home/jian/BigLots/2019_by_weeks/MediaStorm_2019-10-19/MediaStormDailySales20191022-111240-145.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sales_file=list(recurisve_file_gen(\"/home/jian/BigLots/\"))\n",
    "list_sales_file=[x for x in list_sales_file if \"daily\" in x.lower()]\n",
    "list_sales_file=[x for x in list_sales_file if x[-4:]==\".txt\"]\n",
    "list_sales_file=[x for x in list_sales_file if \"2019-\" in x]\n",
    "list_sales_file=[x for x in list_sales_file if x.split(\"MediaStorm_\")[1][:10]>=\"2019-10-10\"]\n",
    "list_sales_file=[x for x in list_sales_file if x.split(\"MediaStorm_\")[1][:10]<=\"2019-10-19\"]\n",
    "list_sales_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/MediaStormDailySalesHistory20181006.txt',\n",
       " '/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/MediaStormDailySalesHistory20181013.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sales_file_2018=glob.glob(\"/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/*.txt\")\n",
    "list_sales_file_2018=[x for x in list_sales_file_2018 if x.split(\"/MediaStormDailySalesHistory\")[1][:8]>=\"20181004\"]\n",
    "list_sales_file_2018=[x for x in list_sales_file_2018 if x.split(\"/MediaStormDailySalesHistory\")[1][:8]<=\"20181013\"]\n",
    "list_sales_file_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-04 15:31:02.809489\n",
      "2019-11-04 15:36:10.728691\n"
     ]
    }
   ],
   "source": [
    "df_sales_2019=pd.DataFrame()\n",
    "for file in list_sales_file:\n",
    "    df=pd.read_table(file,dtype=str,sep=\"|\")\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    \n",
    "    df['rewards_label']=np.where(pd.isnull(df['customer_id_hashed']),\"NonRewards\",\"Rewards\")\n",
    "    #\n",
    "    df_sales=df.groupby([\"location_id\",\"transaction_dt\",\"rewards_label\"])['item_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"item_transaction_amt\":\"sales\"})\n",
    "    #\n",
    "    df_trans=df[['location_id','transaction_dt','transaction_id','customer_id_hashed','rewards_label']].drop_duplicates()\n",
    "    df_trans['trans']=1\n",
    "    df_trans=df_trans.groupby([\"location_id\",\"transaction_dt\",\"rewards_label\"])['trans'].sum().to_frame().reset_index()\n",
    "    \n",
    "    df=pd.merge(df_sales,df_trans,on=[\"location_id\",\"transaction_dt\",\"rewards_label\"],how=\"outer\")\n",
    "    df_sales_2019=df_sales_2019.append(df)\n",
    "    print(datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/MediaStormDailySalesHistory20181006.txt',\n",
       " '/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/MediaStormDailySalesHistory20181013.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sales_file_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-04 15:43:54.908065\n",
      "2019-11-04 15:44:46.078380\n"
     ]
    }
   ],
   "source": [
    "df_sales_2018=pd.DataFrame()\n",
    "for file in list_sales_file_2018:\n",
    "    df=pd.read_table(file,dtype=str,sep=\"|\")\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    \n",
    "    df['rewards_label']=np.where(pd.isnull(df['customer_id_hashed']),\"NonRewards\",\"Rewards\")\n",
    "    #\n",
    "    df_sales=df.groupby([\"location_id\",\"transaction_dt\",\"rewards_label\"])['item_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"item_transaction_amt\":\"sales\"})\n",
    "    #\n",
    "    df_trans=df[['location_id','transaction_dt','transaction_id','customer_id_hashed','rewards_label']].drop_duplicates()\n",
    "    df_trans['trans']=1\n",
    "    df_trans=df_trans.groupby([\"location_id\",\"transaction_dt\",\"rewards_label\"])['trans'].sum().to_frame().reset_index()\n",
    "    \n",
    "    df=pd.merge(df_sales,df_trans,on=[\"location_id\",\"transaction_dt\",\"rewards_label\"],how=\"outer\")\n",
    "    df_sales_2018=df_sales_2018.append(df)\n",
    "    print(datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_test_date_2019: [datetime.date(2019, 10, 10), datetime.date(2019, 10, 11), datetime.date(2019, 10, 12), datetime.date(2019, 10, 13), datetime.date(2019, 10, 14), datetime.date(2019, 10, 15), datetime.date(2019, 10, 16), datetime.date(2019, 10, 17), datetime.date(2019, 10, 18), datetime.date(2019, 10, 19)]\n",
      "list_test_date_2018: [datetime.date(2018, 10, 4), datetime.date(2018, 10, 5), datetime.date(2018, 10, 6), datetime.date(2018, 10, 7), datetime.date(2018, 10, 8), datetime.date(2018, 10, 9), datetime.date(2018, 10, 10), datetime.date(2018, 10, 11), datetime.date(2018, 10, 12), datetime.date(2018, 10, 13)]\n"
     ]
    }
   ],
   "source": [
    "list_test_date_2019=[datetime.date(2019,10,10)+datetime.timedelta(days=x) for x in range(10)]\n",
    "\n",
    "list_test_date_2018=[x-datetime.timedelta(days=(52+1)*7) for x in list_test_date_2019]\n",
    "\n",
    "print(\"list_test_date_2019:\",list_test_date_2019)\n",
    "print(\"list_test_date_2018:\",list_test_date_2018)\n",
    "\n",
    "#\n",
    "df_test_19=pd.DataFrame({\"transaction_dt\":list_test_date_2019},index=['campaign']*len(list_test_date_2019)).reset_index()\n",
    "df_test_19['year']=2019\n",
    "\n",
    "df_test_18=pd.DataFrame({\"transaction_dt\":list_test_date_2018},index=['campaign']*len(list_test_date_2018)).reset_index()\n",
    "df_test_18['year']=2018\n",
    "\n",
    "\n",
    "#\n",
    "df_date_type=pd.concat([df_test_19,df_test_18]).rename(columns={\"index\":\"date_type\"})\n",
    "df_date_type['transaction_dt']=df_date_type['transaction_dt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sales_2018=pd.merge(df_sales_2018,df_date_type,on=\"transaction_dt\",how=\"left\")\n",
    "df_sales_2018=df_sales_2018[pd.notnull(df_sales_2018['date_type'])]\n",
    "\n",
    "df_sales_2019=pd.merge(df_sales_2019,df_date_type,on=\"transaction_dt\",how=\"left\")\n",
    "df_sales_2019=df_sales_2019[pd.notnull(df_sales_2019['date_type'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_compariable=df_sales_2018.append(df_sales_2019)[['location_id','year','date_type','transaction_dt']].drop_duplicates()\n",
    "df_compariable=df_compariable.groupby(['location_id','year','date_type'])['transaction_dt'].nunique().to_frame().reset_index()\n",
    "df_compariable_overall=df_compariable.groupby(['location_id'])['transaction_dt'].sum().to_frame().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Test', 'Control']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_file=pd.ExcelFile(\"./BL_2019Q3_Labor_Day_IVL4_Test_SOTF_Stores_8.20.19_from_BL.xlsx\")\n",
    "excel_file.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test=excel_file.parse(\"Test\",dtype=str,skiprows=3,usecols=[\"Store#\",\"SOTF ?\"])\n",
    "df_test=df_test[pd.notnull(df_test['Store#'])]\n",
    "df_test=df_test.rename(columns={\"SOTF ?\":\"SOTF\",\"Store#\":\"location_id\"})\n",
    "df_test=df_test[['location_id','SOTF']]\n",
    "df_test['Store_Type']=\"Test_Store\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_control=excel_file.parse(\"Control\",dtype=str,skiprows=2,usecols=[\"Store#\",\"SOTF ?\"])\n",
    "df_control=df_control[pd.notnull(df_control['Store#'])]\n",
    "df_control=df_control.rename(columns={\"SOTF ?\":\"SOTF\",\"Store#\":\"location_id\"})\n",
    "df_control=df_control[['location_id','SOTF']]\n",
    "df_control['Store_Type']=\"Control_Store\"\n",
    "\n",
    "# note in the excel\n",
    "df_control=df_control[df_control['location_id']!=\"1012\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((190, 3), 190)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_type=df_test.append(df_control)\n",
    "df_store_type.shape,df_store_type['location_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sales_both=df_sales_2019.append(df_sales_2018)\n",
    "df_sales_both=pd.merge(df_sales_both,df_store_type,on=\"location_id\",how=\"left\")\n",
    "df_sales_both['Store_Type']=np.where(pd.notnull(df_sales_both['Store_Type']),df_sales_both['Store_Type'],\n",
    "                                    np.where(df_sales_both['location_id']==\"6990\",\"Online\",\"Balance\")\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Balance', 'Control_Store', 'Test_Store', 'Online'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_both['Store_Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"./BL_ColumnsDay_Test_Performance_JL_updated_on_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_sales_both.to_excel(writer,\"sales_data\",index=False)\n",
    "df_compariable_overall.to_excel(writer,\"df_compariable_overall\",index=False)\n",
    "df_compariable.to_excel(writer,\"df_compariable\",index=False)\n",
    "df_store_type.to_excel(writer,\"df_store_type\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
