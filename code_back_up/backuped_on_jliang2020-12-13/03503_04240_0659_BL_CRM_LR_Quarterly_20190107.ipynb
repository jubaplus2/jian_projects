{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To check the 1st date of SP's transaction \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import hashlib\n",
    "import gc\n",
    "import glob\n",
    "logging.basicConfig(filename='crmnewscore.log', level=logging.INFO)\n",
    "logging.info('Started')\n",
    "\n",
    "samplerows = None\n",
    "activemos = '2017-12-29'\n",
    "lapsed = '2017-06-29'\n",
    "lastdate = '2018-12-29'\n",
    "\n",
    "\n",
    "folder_write = '/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/checking_crm_newscore_20190107/'\n",
    "try:\n",
    "    os.stat(folder_write)\n",
    "except:\n",
    "    os.mkdir(folder_write)\n",
    "    \n",
    "# Adding control members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2019-01-17 12:49:32.748316\n",
      "2 2019-01-17 12:50:32.686746\n",
      "3 2019-01-17 12:51:46.645242\n",
      "4 2019-01-17 12:53:50.134908\n",
      "5 2019-01-17 12:54:56.633023\n",
      "6 2019-01-17 12:56:00.733586\n",
      "7 2019-01-17 12:58:01.969982\n",
      "8 2019-01-17 13:00:01.684056\n",
      "9 2019-01-17 13:10:12.721372\n",
      "10 2019-01-17 13:23:06.747699\n",
      "11 2019-01-17 13:33:32.820782\n",
      "12 2019-01-17 13:36:16.045250\n",
      "13 2019-01-17 13:40:53.715065\n",
      "14 2019-01-17 13:49:49.256555\n",
      "15 2019-01-17 13:56:51.173385\n",
      "Deduped 2019-01-17 14:12:22.989323\n"
     ]
    }
   ],
   "source": [
    "#To check the 1st date\n",
    "\n",
    "chunksize_num = 10**7\n",
    "filename='/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/crm_newscore_0922/combinedtransactions_0922.csv'\n",
    "dftrans_before_20180922=pd.DataFrame()\n",
    "count_i=0\n",
    "\n",
    "for chunk in pd.read_csv(filename, chunksize=chunksize_num,dtype=str):\n",
    "    chunk['total_transaction_amt']=chunk['total_transaction_amt'].astype(float)\n",
    "    chunk['total_transaction_units']=chunk['total_transaction_units'].astype(float)\n",
    "    chunk = chunk[['customer_id_hashed','transaction_date','transaction_time',\n",
    "                   'transaction_id','location_id','total_transaction_units',\n",
    "                   'total_transaction_amt']].drop_duplicates()\n",
    "    dftrans_before_20180922=dftrans_before_20180922.append(chunk)\n",
    "    count_i+=1\n",
    "    print(count_i,datetime.datetime.now())\n",
    "    \n",
    "\n",
    "'''\n",
    "dftrans_before_20180922 = pd.read_csv('/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/crm_newscore_0922/combinedtransactions_0922.csv',dtype=str)\n",
    "#dftrans = dftrans[dftrans['transaction_date']>=lapsed]\n",
    "dftrans_before_20180922['total_transaction_amt']=dftrans_before_20180922['total_transaction_amt'].astype(float)\n",
    "dftrans_before_20180922['total_transaction_units']=dftrans_before_20180922['total_transaction_units'].astype(float)\n",
    "\n",
    "dftrans_before_20180922 = dftrans_before_20180922[['customer_id_hashed','transaction_date','transaction_time',\n",
    "                   'transaction_id','location_id','total_transaction_units',\n",
    "                   'total_transaction_amt']].drop_duplicates()\n",
    "'''\n",
    "\n",
    "del chunk\n",
    "\n",
    "dftrans_before_20180922=dftrans_before_20180922.drop_duplicates()\n",
    "\n",
    "print(\"Deduped\",datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "\n",
    "weeks_after_20180922=[datetime.date(2018,9,29)+datetime.timedelta(days=x*7) for x in range(999)]\n",
    "possible_recent_folders=[\"/home/jian/BigLots/MediaStorm_\"+str(x)+\"/\" for x in weeks_after_20180922]\n",
    "recent_file_list=[]\n",
    "for dirc in possible_recent_folders:\n",
    "    list_recent=[x for x in list(recursive_file_gen(dirc)) if (\"DailySales\" in x) & (\".txt\" in x) ]\n",
    "    recent_file_list=recent_file_list+list_recent\n",
    "recent_file_df=pd.DataFrame({\"path\":recent_file_list,\"date\":[datetime.datetime.strptime(x.split(\"DailySales\")[1][:8],\"%Y%m%d\").date()-datetime.timedelta(days=3) for x in recent_file_list]},index=[x for x in range(len(recent_file_list))])\n",
    "\n",
    "\n",
    "list_1_after_201806=[x for x in list(recursive_file_gen(\"/home/jian/BigLots/2018_by_weeks/\")) if (\"DailySales\" in x) & (\".txt\" in x) ]\n",
    "folder_date=[datetime.datetime.strptime(x.split(\"/\")[len(x.split(\"/\"))-2].split(\"_\")[1],\"%Y-%m-%d\").date() for x in list_1_after_201806]\n",
    "df_1_after_201806=pd.DataFrame({\"date\":folder_date,\"path\":list_1_after_201806},index=[x for x in range(len(list_1_after_201806))])\n",
    "df_1_after_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "df_1_after_201806=df_1_after_201806.sort_values(\"date\").reset_index()\n",
    "del df_1_after_201806['index']\n",
    "new_dailysales_files=df_1_after_201806.append(recent_file_df)\n",
    "\n",
    "new_dailysales_files=new_dailysales_files[new_dailysales_files['date']>datetime.date(2018,9,22)]\n",
    "new_dailysales_files=new_dailysales_files[new_dailysales_files['date']<=datetime.date(2018,12,29)]\n",
    "\n",
    "print(len(new_dailysales_files))\n",
    "new_dailysales_files=new_dailysales_files['path'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-09-29/MediaStormDailySales20181002-113621-096.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-10-06/MediaStormDailySales20181009-120942-538.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-10-13/MediaStormDailySales20181016-120059-769.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-10-20/MediaStormDailySales20181023-113036-640.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-10-27/MediaStormDailySales20181030-112403-266.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-11-03/MediaStormDailySales20181106-113148-519.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-11-10/MediaStormDailySales20181110.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-11-17/MediaStormDailySales20181120-113127-574.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-11-24/MediaStormDailySales20181127-115851-687.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-12-01/MediaStormDailySales20181204-113208-042.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-12-08/MediaStormDailySales20181211-115638-766.txt',\n",
       " '/home/jian/BigLots/MediaStorm_2018-12-15/MediaStormDailySales20181218-112627-166.txt',\n",
       " '/home/jian/BigLots/MediaStorm_2018-12-22/MediaStormDailySales20181225-112126-218.txt',\n",
       " '/home/jian/BigLots/MediaStorm_2018-12-29/MediaStormDailySales20190101-113809-353.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dailysales_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 14\n",
      "1 done 2019-01-17 14:13:22.048161\n",
      "2 done 2019-01-17 14:14:21.367281\n",
      "3 done 2019-01-17 14:14:59.648293\n",
      "4 done 2019-01-17 14:15:45.503732\n",
      "5 done 2019-01-17 14:16:35.916216\n",
      "6 done 2019-01-17 14:17:28.580887\n",
      "7 done 2019-01-17 14:18:25.035073\n",
      "8 done 2019-01-17 14:19:30.540994\n",
      "9 done 2019-01-17 14:21:00.269744\n",
      "10 done 2019-01-17 14:22:30.249166\n",
      "11 done 2019-01-17 14:24:08.629091\n",
      "12 done 2019-01-17 14:25:48.781103\n",
      "13 done 2019-01-17 14:27:47.376541\n",
      "14 done 2019-01-17 14:29:13.889194\n"
     ]
    }
   ],
   "source": [
    "combined_rewards_transaction_after_20180922_agg=pd.DataFrame() \n",
    "count_i=1\n",
    "print(\"Total Files: \"+str(len(new_dailysales_files)))\n",
    "for file_daily in new_dailysales_files:\n",
    "    df=pd.read_table(file_daily,nrows = None,sep= '|',dtype =str)\n",
    "    df['subclass_transaction_amt']=df['subclass_transaction_amt'].astype(float)\n",
    "    df['subclass_transaction_units']=df['subclass_transaction_units'].astype(float)\n",
    "    df=df[~pd.isnull(df['customer_id_hashed'])]\n",
    "    df_sales=df.groupby(['location_id','transaction_dt','customer_id_hashed'])['subclass_transaction_amt','subclass_transaction_units'].sum().reset_index().rename(columns={\"subclass_transaction_amt\":\"total_transaction_amt\",\"subclass_transaction_units\":\"total_transaction_units\"})\n",
    "    df_trans=df[['location_id','transaction_dt','transaction_id','customer_id_hashed']].drop_duplicates().groupby(['location_id','transaction_dt','customer_id_hashed'])['transaction_id'].count().to_frame().reset_index().rename(columns={\"transaction_id\":\"transactions\"})\n",
    "    df=pd.merge(df_sales,df_trans,on=['location_id','transaction_dt','customer_id_hashed'],how=\"left\")\n",
    "    combined_rewards_transaction_after_20180922_agg=combined_rewards_transaction_after_20180922_agg.append(df)\n",
    "    print(count_i,\"done\",datetime.datetime.now())\n",
    "    count_i+=1\n",
    "    \n",
    "combined_rewards_transaction_after_20180922_agg=combined_rewards_transaction_after_20180922_agg.rename(columns={\"transaction_dt\":\"transaction_date\"})\n",
    "\n",
    "# combined_rewards_transaction_after_20180922_agg.to_csv(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/combined_agged_rewards_transactions_20180929_20181229.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>total_transaction_amt</th>\n",
       "      <th>total_transaction_units</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-23</td>\n",
       "      <td>034490071a1e00504095560cdaf61f1847460791d3699b...</td>\n",
       "      <td>11.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-09-23</td>\n",
       "      <td>051fb5a4679d93c4b3a8a1a9ae34c9ba81509196edc99a...</td>\n",
       "      <td>6.35</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id transaction_date  \\\n",
       "0           1       2018-09-23   \n",
       "1           1       2018-09-23   \n",
       "\n",
       "                                  customer_id_hashed  total_transaction_amt  \\\n",
       "0  034490071a1e00504095560cdaf61f1847460791d3699b...                  11.30   \n",
       "1  051fb5a4679d93c4b3a8a1a9ae34c9ba81509196edc99a...                   6.35   \n",
       "\n",
       "   total_transaction_units  transactions  \n",
       "0                      4.0             1  \n",
       "1                      6.0             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_rewards_transaction_after_20180922_agg.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the store for an id\n",
    "\n",
    "df_2018_transaction_by_id_1=dftrans_before_20180922[dftrans_before_20180922['transaction_date'].apply(lambda x: x[:4]==\"2018\")]\n",
    "df_2018_transaction_by_id_1=df_2018_transaction_by_id_1[df_2018_transaction_by_id_1['total_transaction_amt']>0]\n",
    "df_2018_transaction_by_id_1=df_2018_transaction_by_id_1.groupby(['customer_id_hashed','location_id'])['total_transaction_amt'].count().to_frame().reset_index()\n",
    "df_2018_transaction_by_id_1=df_2018_transaction_by_id_1.rename(columns={\"total_transaction_amt\":\"trans\"})\n",
    "\n",
    "\n",
    "df_2018_transaction_by_id_2=combined_rewards_transaction_after_20180922_agg[combined_rewards_transaction_after_20180922_agg['total_transaction_amt']>0]\n",
    "df_2018_transaction_by_id_2=df_2018_transaction_by_id_2.groupby(['customer_id_hashed','location_id'])['transactions'].sum().to_frame().reset_index().rename(columns={\"transactions\":\"trans\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2018_transaction_by_id=df_2018_transaction_by_id_1.append(df_2018_transaction_by_id_2)\n",
    "df_2018_transaction_by_id=df_2018_transaction_by_id.groupby(['customer_id_hashed','location_id'])['trans'].sum().to_frame().reset_index()\n",
    "df_2018_transaction_by_id=df_2018_transaction_by_id.sort_values(['customer_id_hashed','trans'],ascending=[True,False]).drop_duplicates(['customer_id_hashed'])\n",
    "df_2018_transaction_by_id.to_csv(folder_write+\"id_by_store_based_on_2018_trans.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>location_id</th>\n",
       "      <th>trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000135f48c68690ad3d5fc9ada41bb5cd687452007e8...</td>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001dadc0265bf9d250566d74e0006323f18b5826641...</td>\n",
       "      <td>4061</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed location_id  trans\n",
       "0  00000135f48c68690ad3d5fc9ada41bb5cd687452007e8...        1292      1\n",
       "3  000001dadc0265bf9d250566d74e0006323f18b5826641...        4061      3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_2018_transaction_by_id_1\n",
    "del df_2018_transaction_by_id_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-06-26\n",
      "2018-12-29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###get recency\n",
    "dfrecency=combined_rewards_transaction_after_20180922_agg[['customer_id_hashed','transaction_date']].append(dftrans_before_20180922[['customer_id_hashed','transaction_date']]) #Allready combined\n",
    "dfrecency = dfrecency[['customer_id_hashed','transaction_date']].drop_duplicates()\n",
    "print (min(dfrecency['transaction_date']))\n",
    "print (max(dfrecency['transaction_date']))\n",
    "dfrecency = dfrecency.sort_values(['transaction_date'],ascending = False)\n",
    "dfrecency = dfrecency.drop_duplicates('customer_id_hashed')\n",
    "dfrecency.to_csv(folder_write + 'dfrecency.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfrecency['transaction_date'] = pd.to_datetime(dfrecency['transaction_date'])\n",
    "dfrecency['recency'] =  datetime.datetime.strptime(str(lastdate), '%Y-%m-%d').date() - dfrecency['transaction_date']\n",
    "dfrecency['recency'] = dfrecency['recency'].apply(lambda x:x.days)\n",
    "dfrecency['recency'] = np.ceil((dfrecency['recency']+1)/30)\n",
    "\n",
    "dfrecency = dfrecency[['customer_id_hashed','recency']]\n",
    "dfrecency = dfrecency.drop_duplicates('customer_id_hashed')\n",
    "dfrecency.to_csv(folder_write + 'dfrecency2.csv',index = False)\n",
    "\n",
    "dfrecency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfiddetail = pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/combined_masterids_up_to_20181229_JL.csv',nrows = samplerows)\n",
    "dfiddetail = dfiddetail.drop_duplicates('customer_id_hashed')\n",
    "dfiddetail2 = pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/MediaStorm_Lapsed_Reward_Member_Master_from2014-08-26to2017-02-26.zip',\n",
    "                     nrows = samplerows,dtype = 'str',sep = '|',\n",
    "                       usecols = ['customer_id_hashed','email_address_hash','customer_zip_code'])\n",
    "dfiddetail = dfiddetail.append(dfiddetail2,ignore_index = True)\n",
    "dfiddetail = dfiddetail.drop_duplicates('customer_id_hashed')\n",
    "dfiddetail = dfiddetail.drop_duplicates('email_address_hash')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftrans_before_20180922['transactions'] = 1\n",
    "dftrans_before_20180922 = dftrans_before_20180922[['customer_id_hashed','total_transaction_amt',\n",
    "                   'total_transaction_units','transactions']].groupby(['customer_id_hashed']).sum().reset_index()\n",
    "combined_rewards_transaction_after_20180922_agg=combined_rewards_transaction_after_20180922_agg[['customer_id_hashed','total_transaction_amt',\n",
    "                   'total_transaction_units','transactions']].groupby(['customer_id_hashed']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftrans_before_20180922=dftrans_before_20180922.append(combined_rewards_transaction_after_20180922_agg) #Allready combined\n",
    "dftrans_before_20180922 = dftrans_before_20180922[['customer_id_hashed','total_transaction_amt',\n",
    "                   'total_transaction_units','transactions']].groupby(['customer_id_hashed']).sum().reset_index()\n",
    "\n",
    "dftotal=dftrans_before_20180922\n",
    "\n",
    "\n",
    "dftotal = pd.merge(dftotal,dfrecency,on = 'customer_id_hashed',how='outer')\n",
    "del dfrecency\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftotal = dftotal.sort_values(['transactions','recency','total_transaction_amt'],ascending = [0,1,0])\n",
    "dftotal.reset_index(drop = True, inplace = True)\n",
    "dftotal.reset_index(inplace = True)\n",
    "dftotal = dftotal.rename(columns = {'index':'Transindex'})\n",
    "\n",
    "dftotal = dftotal.sort_values(['total_transaction_amt','recency','transactions'],ascending = [0,1,0])\n",
    "dftotal.reset_index(drop = True, inplace = True)\n",
    "dftotal.reset_index(inplace = True)\n",
    "dftotal = dftotal.rename(columns = {'index':'Amtindex'})\n",
    "\n",
    "dftotal = dftotal.sort_values(['recency','transactions','total_transaction_amt'],ascending = [1,0,0])\n",
    "dftotal.reset_index(drop = True, inplace = True)\n",
    "dftotal.reset_index(inplace = True)\n",
    "dftotal = dftotal.rename(columns = {'index':'recencyindex'})\n",
    "\n",
    "c_ids = len(dftotal.index)\n",
    "logging.info('total customers from transaction and amt: ')\n",
    "logging.info(c_ids)\n",
    "c_ids = np.ceil(c_ids/5.0)\n",
    "\n",
    "dftotal['Transindex'] = np.ceil((dftotal['Transindex']+1)/c_ids)\n",
    "dftotal['Amtindex'] = np.ceil((dftotal['Amtindex']+1)/c_ids)\n",
    "dftotal['recencyindex'] = np.ceil((dftotal['recencyindex']+1)/c_ids)\n",
    "\n",
    "dftotal['RFM'] = dftotal['recencyindex']*100 + dftotal['Transindex']*10 + dftotal['Amtindex']\n",
    "dftotal = dftotal.sort_values(['RFM','recency','transactions',\n",
    "                               'total_transaction_amt'],ascending = [1,1,0,0])\n",
    "dftotal.reset_index(drop = True, inplace = True)\n",
    "dftotal.reset_index(inplace = True)\n",
    "dftotal = dftotal.rename(columns = {'index':'frmindex'})\n",
    "c_ids = len(dftotal.index)\n",
    "c_ids = np.ceil(c_ids/10.0)\n",
    "dftotal['frmindex'] = np.ceil((dftotal['frmindex']+1)/c_ids)\n",
    "\n",
    "dftotal.to_csv(folder_write + 'dfrfm.csv',index = False)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "dftotal = pd.read_csv(folder_write + 'dfrfm.csv')\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "dftotal = dftotal[['customer_id_hashed','frmindex']]\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "dfrecency = pd.read_csv(folder_write + 'dfrecency.csv')\n",
    "dfrecency['active'] = np.where(dfrecency['transaction_date']>=activemos,'active',\n",
    "                    np.where(dfrecency['transaction_date']>=lapsed,'lapsed','other'))\n",
    "dfrecency['active'].unique()\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "dftotal = pd.merge(dftotal,dfrecency[['customer_id_hashed','active']],on = 'customer_id_hashed')\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "dfiddetail['customer_zip_code'] = dfiddetail['customer_zip_code'].astype('str')\n",
    "dfiddetail['customer_zip_code'] = dfiddetail['customer_zip_code'].str[0:5]\n",
    "dfiddetail['customer_zip_code'].fillna('00000',inplace = True)\n",
    "dfiddetail['customer_zip_code'] = dfiddetail['customer_zip_code'].apply(lambda x:x.zfill(5))\n",
    "print(len(dfiddetail.index))\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "print(\"totalids_trans:\",len(dftotal.index))\n",
    "dftotal = pd.merge(dftotal,dfiddetail,on = 'customer_id_hashed')\n",
    "print(\"totalids_trans_mergewithmaster:\",len(dftotal.index))\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "zipmap = pd.read_csv('/home/jian/Projects/Big_Lots/New_TA/zips_in_new_ta/zip_with_ta_dma.csv',dtype = 'str')\n",
    "zipmap['zipcodegroup'] = zipmap['revenue_flag']\n",
    "zipmap = zipmap[['zip','zipcodegroup']].drop_duplicates('zip')\n",
    "zipmap.columns = ['customer_zip_code','zipcodegroup']\n",
    "dftotal = pd.merge(dftotal,zipmap,on ='customer_zip_code',how = 'left' )\n",
    "print(dftotal['zipcodegroup'].unique())\n",
    "dftotal['zipcodegroup'].fillna('T',inplace = True)\n",
    "print(dftotal['zipcodegroup'].unique())\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "dftotal.to_csv(folder_write + 'dfrfm_wemail.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# detailed_scores_df=pd.read_csv(folder_write + 'dfrfm_wemail.csv',dtype=str)\n",
    "detailed_scores_df=dftotal\n",
    "detailed_scores_df['frmindex']=detailed_scores_df['frmindex'].apply(lambda x: str(int(float(x))).zfill(2))\n",
    "detailed_scores_df['customer_zip_code']=detailed_scores_df['customer_zip_code'].apply(lambda x: x.zfill(5))\n",
    "detailed_scores_df['frmindex']=detailed_scores_df['frmindex'].apply(lambda x:\"D\"+x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# To be deleted\\nimport pandas as pd\\ndetailed_scores_df=pd.read_csv(folder_write + 'dfrfm_wemail.csv',dtype=str)\\n\\ndetailed_scores_df.groupby(['zipcodegroup'])['customer_id_hashed'].count().to_frame().reset_index()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# To be deleted\n",
    "import pandas as pd\n",
    "detailed_scores_df=pd.read_csv(folder_write + 'dfrfm_wemail.csv',dtype=str)\n",
    "\n",
    "detailed_scores_df.groupby(['zipcodegroup'])['customer_id_hashed'].count().to_frame().reset_index()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "control_file_list=glob.glob(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/upload_newscore_0922/*.csv\")\n",
    "control_file_list=[x for x in control_file_list if \"C_\" in x]\n",
    "print(len(control_file_list))\n",
    "\n",
    "old_control_df=pd.DataFrame()\n",
    "for file_path in control_file_list:\n",
    "    df=pd.read_csv(file_path,dtype=str)\n",
    "    old_control_df=old_control_df.append(df)\n",
    "    \n",
    "len(old_control_df['customer_id_hashed'].unique())\n",
    "\n",
    "# Random 500000 ids as control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del old_control_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2019-01-17 11:23:46.639555\n",
      "2 2019-01-17 11:23:48.224337\n",
      "3 2019-01-17 11:23:49.963513\n",
      "4 2019-01-17 11:23:52.130970\n",
      "5 2019-01-17 11:23:54.260448\n",
      "6 2019-01-17 11:23:56.401059\n",
      "7 2019-01-17 11:23:58.224527\n",
      "8 2019-01-17 11:24:00.060439\n",
      "9 2019-01-17 11:24:01.875253\n",
      "10 2019-01-17 11:24:03.793053\n",
      "11 2019-01-17 11:24:05.792031\n",
      "12 2019-01-17 11:24:07.853883\n",
      "13 2019-01-17 11:24:09.988217\n",
      "14 2019-01-17 11:24:12.199976\n",
      "15 2019-01-17 11:24:14.248272\n",
      "16 2019-01-17 11:24:16.330673\n",
      "17 2019-01-17 11:24:18.434372\n",
      "18 2019-01-17 11:24:20.578801\n",
      "19 2019-01-17 11:24:22.737708\n",
      "20 2019-01-17 11:24:24.942990\n",
      "21 2019-01-17 11:24:27.225624\n",
      "22 2019-01-17 11:24:29.586495\n",
      "23 2019-01-17 11:24:31.837453\n",
      "24 2019-01-17 11:24:34.126162\n",
      "25 2019-01-17 11:24:36.809908\n",
      "26 2019-01-17 11:24:39.751901\n",
      "27 2019-01-17 11:24:42.536332\n",
      "28 2019-01-17 11:24:45.223852\n",
      "29 2019-01-17 11:24:47.964946\n",
      "30 2019-01-17 11:24:50.785773\n",
      "31 2019-01-17 11:24:53.537397\n",
      "32 2019-01-17 11:24:56.266120\n",
      "33 2019-01-17 11:24:58.958613\n",
      "34 2019-01-17 11:25:01.670770\n",
      "35 2019-01-17 11:25:04.373708\n",
      "36 2019-01-17 11:25:07.009579\n",
      "37 2019-01-17 11:25:10.669409\n",
      "38 2019-01-17 11:25:14.724441\n",
      "39 2019-01-17 11:25:18.162005\n",
      "40 2019-01-17 11:25:21.670524\n",
      "41 2019-01-17 11:25:25.147431\n",
      "42 2019-01-17 11:25:28.577298\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "total_rows=len(detailed_scores_df)\n",
    "\n",
    "test_all_df=pd.DataFrame()\n",
    "control_all_df=pd.DataFrame()\n",
    "\n",
    "i_counter=0\n",
    "\n",
    "for comb,group in detailed_scores_df.groupby(['active','zipcodegroup','frmindex']):\n",
    "    random_list=random.sample(range(len(group)), int(np.round(len(group)/total_rows*500000)))\n",
    "\n",
    "    group=group.reset_index()\n",
    "    del group['index']\n",
    "    group=group.reset_index()\n",
    "    df_control=group[group['index'].isin(random_list)]\n",
    "    df_test=group[~group['index'].isin(random_list)]\n",
    "    \n",
    "    test_all_df=test_all_df.append(df_test)\n",
    "    control_all_df=control_all_df.append(df_control)\n",
    "    i_counter+=1\n",
    "    print(i_counter,datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_all_df['segment']=\"T_\"+test_all_df['active']+\"_chain_\"+test_all_df['zipcodegroup']+\"_\"+test_all_df['frmindex']+\"_2019Q1\"\n",
    "control_all_df['segment']=\"C_\"+control_all_df['active']+\"_chain_\"+control_all_df['zipcodegroup']+\"_\"+control_all_df['frmindex']+\"_2019Q1\"\n",
    "\n",
    "\n",
    "test_all_df['HML_group']=np.where(test_all_df['frmindex'].isin(['D01','D02','D03']),\"H\",\n",
    "                                 np.where(test_all_df['frmindex'].isin(['D04','D05','D06']),\"M\",\"L\"))\n",
    "control_all_df['HML_group']=np.where(control_all_df['frmindex'].isin(['D01','D02','D03']),\"H\",\n",
    "                                 np.where(control_all_df['frmindex'].isin(['D04','D05','D06']),\"M\",\"L\"))\n",
    "\n",
    "test_all_df['segment_new']=\"T_\"+test_all_df['active']+test_all_df['zipcodegroup']+\"_\"+test_all_df['HML_group']+\"_2019Q1\"\n",
    "control_all_df['segment_new']=\"C_\"+control_all_df['active']+control_all_df['zipcodegroup']+\"_\"+control_all_df['HML_group']+\"_2019Q1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_all_df.to_csv(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/crm_newscore_20190107/all_test.csv\",index=False)\n",
    "control_all_df.to_csv(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/crm_newscore_20190107/all_control.csv\",index=False)\n",
    "\n",
    "folder_write_inner = '/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/crm_newscore_20190107/by_group/'\n",
    "try:\n",
    "    os.stat(folder_write_inner)\n",
    "except:\n",
    "    os.mkdir(folder_write_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2019-01-17 11:38:18.450303\n",
      "2 2019-01-17 11:38:26.170574\n",
      "3 2019-01-17 11:38:35.170873\n",
      "4 2019-01-17 11:38:42.044620\n",
      "5 2019-01-17 11:38:50.695546\n",
      "6 2019-01-17 11:38:57.581566\n",
      "7 2019-01-17 11:39:02.339104\n",
      "8 2019-01-17 11:39:06.218479\n",
      "9 2019-01-17 11:39:08.795167\n",
      "10 2019-01-17 11:39:10.933404\n",
      "11 2019-01-17 11:39:13.120461\n",
      "12 2019-01-17 11:39:15.299168\n",
      "13 2019-01-17 11:39:17.533514\n",
      "14 2019-01-17 11:39:19.385378\n",
      "15 2019-01-17 11:39:20.485718\n",
      "16 2019-01-17 11:39:21.463754\n",
      "17 2019-01-17 11:39:22.279139\n",
      "18 2019-01-17 11:39:23.155093\n",
      "19 2019-01-17 11:39:23.942558\n",
      "20 2019-01-17 11:39:24.872037\n",
      "21 2019-01-17 11:39:25.838834\n",
      "22 2019-01-17 11:39:26.790691\n",
      "23 2019-01-17 11:39:27.299259\n",
      "24 2019-01-17 11:39:27.889435\n",
      "25 2019-01-17 11:39:32.141296\n",
      "26 2019-01-17 11:39:36.524750\n",
      "27 2019-01-17 11:39:37.647353\n",
      "28 2019-01-17 11:39:38.321829\n",
      "29 2019-01-17 11:39:39.349712\n",
      "30 2019-01-17 11:39:40.543704\n",
      "31 2019-01-17 11:39:40.821287\n",
      "32 2019-01-17 11:39:40.998980\n",
      "33 2019-01-17 11:39:41.485993\n",
      "34 2019-01-17 11:39:42.224325\n",
      "35 2019-01-17 11:39:42.371212\n",
      "36 2019-01-17 11:39:42.475716\n",
      "37 2019-01-17 11:39:50.006412\n",
      "38 2019-01-17 11:39:58.282594\n",
      "39 2019-01-17 11:40:00.482275\n",
      "40 2019-01-17 11:40:02.713942\n",
      "41 2019-01-17 11:40:03.785929\n",
      "42 2019-01-17 11:40:04.912620\n"
     ]
    }
   ],
   "source": [
    "i_counter=0\n",
    "for seg,group in test_all_df.groupby(['segment']):\n",
    "    group=group[['customer_id_hashed','email_address_hash','segment']]\n",
    "    group.to_csv(folder_write_inner+seg+\".csv\",index=False)\n",
    "    i_counter+=1\n",
    "    print(i_counter,datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2019-01-17 11:40:06.719322\n",
      "2 2019-01-17 11:40:06.906427\n",
      "3 2019-01-17 11:40:07.113988\n",
      "4 2019-01-17 11:40:07.266616\n",
      "5 2019-01-17 11:40:07.467941\n",
      "6 2019-01-17 11:40:07.626507\n",
      "7 2019-01-17 11:40:07.727921\n",
      "8 2019-01-17 11:40:07.808633\n",
      "9 2019-01-17 11:40:07.854179\n",
      "10 2019-01-17 11:40:07.899033\n",
      "11 2019-01-17 11:40:07.945304\n",
      "12 2019-01-17 11:40:07.985915\n",
      "13 2019-01-17 11:40:08.032385\n",
      "14 2019-01-17 11:40:08.074066\n",
      "15 2019-01-17 11:40:08.099599\n",
      "16 2019-01-17 11:40:08.123096\n",
      "17 2019-01-17 11:40:08.142270\n",
      "18 2019-01-17 11:40:08.165594\n",
      "19 2019-01-17 11:40:08.187836\n",
      "20 2019-01-17 11:40:08.210726\n",
      "21 2019-01-17 11:40:08.232505\n",
      "22 2019-01-17 11:40:08.254725\n",
      "23 2019-01-17 11:40:08.268687\n",
      "24 2019-01-17 11:40:08.283985\n",
      "25 2019-01-17 11:40:08.386008\n",
      "26 2019-01-17 11:40:08.487732\n",
      "27 2019-01-17 11:40:08.514707\n",
      "28 2019-01-17 11:40:08.531700\n",
      "29 2019-01-17 11:40:08.557099\n",
      "30 2019-01-17 11:40:08.586050\n",
      "31 2019-01-17 11:40:08.595026\n",
      "32 2019-01-17 11:40:08.600859\n",
      "33 2019-01-17 11:40:08.613816\n",
      "34 2019-01-17 11:40:08.632488\n",
      "35 2019-01-17 11:40:08.637758\n",
      "36 2019-01-17 11:40:08.641924\n",
      "37 2019-01-17 11:40:08.813858\n",
      "38 2019-01-17 11:40:08.992403\n",
      "39 2019-01-17 11:40:09.038929\n",
      "40 2019-01-17 11:40:09.085609\n",
      "41 2019-01-17 11:40:09.109384\n",
      "42 2019-01-17 11:40:09.134584\n"
     ]
    }
   ],
   "source": [
    "i_counter=0\n",
    "for seg,group in control_all_df.groupby(['segment']):\n",
    "    group=group[['customer_id_hashed','email_address_hash','segment']]\n",
    "    group.to_csv(folder_write_inner+seg+\".csv\",index=False)\n",
    "    i_counter+=1\n",
    "    print(i_counter,datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_test=test_all_df.groupby([''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the primary store for each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active</th>\n",
       "      <th>frmindex</th>\n",
       "      <th>zipcodegroup</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>active</td>\n",
       "      <td>D01</td>\n",
       "      <td>P</td>\n",
       "      <td>1929287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>active</td>\n",
       "      <td>D01</td>\n",
       "      <td>S</td>\n",
       "      <td>351683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>active</td>\n",
       "      <td>D01</td>\n",
       "      <td>T</td>\n",
       "      <td>140943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>active</td>\n",
       "      <td>D02</td>\n",
       "      <td>P</td>\n",
       "      <td>1668107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>active</td>\n",
       "      <td>D02</td>\n",
       "      <td>S</td>\n",
       "      <td>383989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>active</td>\n",
       "      <td>D02</td>\n",
       "      <td>T</td>\n",
       "      <td>179731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>active</td>\n",
       "      <td>D03</td>\n",
       "      <td>P</td>\n",
       "      <td>1860610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>active</td>\n",
       "      <td>D03</td>\n",
       "      <td>S</td>\n",
       "      <td>389090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>active</td>\n",
       "      <td>D03</td>\n",
       "      <td>T</td>\n",
       "      <td>159799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>active</td>\n",
       "      <td>D04</td>\n",
       "      <td>P</td>\n",
       "      <td>1367382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>active</td>\n",
       "      <td>D04</td>\n",
       "      <td>S</td>\n",
       "      <td>350901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>active</td>\n",
       "      <td>D04</td>\n",
       "      <td>T</td>\n",
       "      <td>180095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>active</td>\n",
       "      <td>D05</td>\n",
       "      <td>P</td>\n",
       "      <td>1804669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>active</td>\n",
       "      <td>D05</td>\n",
       "      <td>S</td>\n",
       "      <td>409036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>active</td>\n",
       "      <td>D05</td>\n",
       "      <td>T</td>\n",
       "      <td>178342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>active</td>\n",
       "      <td>D06</td>\n",
       "      <td>P</td>\n",
       "      <td>1435411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>active</td>\n",
       "      <td>D06</td>\n",
       "      <td>S</td>\n",
       "      <td>365309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>active</td>\n",
       "      <td>D06</td>\n",
       "      <td>T</td>\n",
       "      <td>185566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>active</td>\n",
       "      <td>D07</td>\n",
       "      <td>P</td>\n",
       "      <td>889970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>active</td>\n",
       "      <td>D07</td>\n",
       "      <td>S</td>\n",
       "      <td>211824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>active</td>\n",
       "      <td>D07</td>\n",
       "      <td>T</td>\n",
       "      <td>102543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>active</td>\n",
       "      <td>D08</td>\n",
       "      <td>P</td>\n",
       "      <td>736091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>active</td>\n",
       "      <td>D08</td>\n",
       "      <td>S</td>\n",
       "      <td>194208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>active</td>\n",
       "      <td>D08</td>\n",
       "      <td>T</td>\n",
       "      <td>119155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D07</td>\n",
       "      <td>P</td>\n",
       "      <td>906436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D07</td>\n",
       "      <td>S</td>\n",
       "      <td>214688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D07</td>\n",
       "      <td>T</td>\n",
       "      <td>100951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D08</td>\n",
       "      <td>P</td>\n",
       "      <td>930498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D08</td>\n",
       "      <td>S</td>\n",
       "      <td>248458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D08</td>\n",
       "      <td>T</td>\n",
       "      <td>152793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D09</td>\n",
       "      <td>P</td>\n",
       "      <td>223913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D09</td>\n",
       "      <td>S</td>\n",
       "      <td>55490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D09</td>\n",
       "      <td>T</td>\n",
       "      <td>29259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D10</td>\n",
       "      <td>P</td>\n",
       "      <td>140231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D10</td>\n",
       "      <td>S</td>\n",
       "      <td>36603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lapsed</td>\n",
       "      <td>D10</td>\n",
       "      <td>T</td>\n",
       "      <td>21796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>other</td>\n",
       "      <td>D09</td>\n",
       "      <td>P</td>\n",
       "      <td>1548647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>other</td>\n",
       "      <td>D09</td>\n",
       "      <td>S</td>\n",
       "      <td>379854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>other</td>\n",
       "      <td>D09</td>\n",
       "      <td>T</td>\n",
       "      <td>193645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>other</td>\n",
       "      <td>D10</td>\n",
       "      <td>P</td>\n",
       "      <td>1607539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>other</td>\n",
       "      <td>D10</td>\n",
       "      <td>S</td>\n",
       "      <td>412630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>other</td>\n",
       "      <td>D10</td>\n",
       "      <td>T</td>\n",
       "      <td>211940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    active frmindex zipcodegroup    count\n",
       "0   active      D01            P  1929287\n",
       "1   active      D01            S   351683\n",
       "2   active      D01            T   140943\n",
       "3   active      D02            P  1668107\n",
       "4   active      D02            S   383989\n",
       "5   active      D02            T   179731\n",
       "6   active      D03            P  1860610\n",
       "7   active      D03            S   389090\n",
       "8   active      D03            T   159799\n",
       "9   active      D04            P  1367382\n",
       "10  active      D04            S   350901\n",
       "11  active      D04            T   180095\n",
       "12  active      D05            P  1804669\n",
       "13  active      D05            S   409036\n",
       "14  active      D05            T   178342\n",
       "15  active      D06            P  1435411\n",
       "16  active      D06            S   365309\n",
       "17  active      D06            T   185566\n",
       "18  active      D07            P   889970\n",
       "19  active      D07            S   211824\n",
       "20  active      D07            T   102543\n",
       "21  active      D08            P   736091\n",
       "22  active      D08            S   194208\n",
       "23  active      D08            T   119155\n",
       "24  lapsed      D07            P   906436\n",
       "25  lapsed      D07            S   214688\n",
       "26  lapsed      D07            T   100951\n",
       "27  lapsed      D08            P   930498\n",
       "28  lapsed      D08            S   248458\n",
       "29  lapsed      D08            T   152793\n",
       "30  lapsed      D09            P   223913\n",
       "31  lapsed      D09            S    55490\n",
       "32  lapsed      D09            T    29259\n",
       "33  lapsed      D10            P   140231\n",
       "34  lapsed      D10            S    36603\n",
       "35  lapsed      D10            T    21796\n",
       "36   other      D09            P  1548647\n",
       "37   other      D09            S   379854\n",
       "38   other      D09            T   193645\n",
       "39   other      D10            P  1607539\n",
       "40   other      D10            S   412630\n",
       "41   other      D10            T   211940"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_summary=detailed_scores_df.groupby(['active','frmindex','zipcodegroup'])['email_address_hash'].count().to_frame().reset_index().rename(columns={\"email_address_hash\":\"count\"})\n",
    "count_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(detailed_scores_df['customer_id_hashed'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(detailed_scores_df['email_address_hash'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(control_file_list[0],dtype=str)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
