{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/JayLiang/Desktop/Media Storm/PEI/CallAway/SEM_ Optimization/Summary_Non_Brand_Callaway_From_2017-04-02_To_2017-09-20.xlsx\n"
     ]
    }
   ],
   "source": [
    "end_date = \"2017-09-20\"\n",
    "start_date = \"2017-04-02\"\n",
    "\n",
    "Save_Path='/Users/JayLiang/Desktop/Media Storm/PEI/CallAway/SEM_ Optimization/Summary_Non_Brand_Callaway'+'_From_'+str(start_date)+'_To_'+str(end_date)+'.xlsx'\n",
    "print(Save_Path)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 6\n",
    "import os\n",
    "import argparse\n",
    "import httplib2\n",
    "import pprint\n",
    "import time\n",
    "import datetime\n",
    "from io import StringIO\n",
    "\n",
    "from apiclient.discovery import build\n",
    "from oauth2client import GOOGLE_TOKEN_URI\n",
    "from oauth2client.client import OAuth2Credentials\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "\n",
    "def create_credentials():\n",
    "    \"\"\"Create Google OAuth2 credentials.\n",
    "\n",
    "    Args:\n",
    "        client_id: Client id of a Google Cloud console project.\n",
    "        client_secret: Client secret of a Google Cloud console project.\n",
    "        refresh_token: A refresh token authorizing the Google Cloud console project\n",
    "          to access the DS data of some Google user.\n",
    "    Returns:\n",
    "        OAuth2Credentials\n",
    "    \"\"\"\n",
    "    return OAuth2Credentials(access_token=None,\n",
    "                           client_id='549790627766-qnth4m8qvuimg87pnsp4b82lhte7dk5a.apps.googleusercontent.com',\n",
    "                           client_secret='Vta4lQLOL49vVYvktkcPGRNb',\n",
    "                           refresh_token='1/ab7pCGMu3K5AveG0UOUpQ0J08vCp6uM357O8qmoPDMs',\n",
    "                           token_expiry=None,\n",
    "                           token_uri=\"https://accounts.google.com/o/oauth2/token\",\n",
    "                           user_agent=None)\n",
    "\n",
    "def get_service(credentials):\n",
    "    \"\"\"Set up a new DoubleClick Search service.\n",
    "\n",
    "    Args:\n",
    "        credentials: An OAuth2Credentials generated with create_credentials, or\n",
    "        flows in the oatuh2client.client package.\n",
    "    Returns:\n",
    "        An authorized Doubleclicksearch serivce.\n",
    "    \"\"\"\n",
    "    # Use the authorize() function of OAuth2Credentials to apply necessary credential\n",
    "    # headers to all requests.\n",
    "    http = credentials.authorize(http = httplib2.Http())\n",
    "\n",
    "    # Construct the service object for the interacting with the DoubleClick Search API.\n",
    "    service = build('doubleclicksearch', 'v2', http=http)\n",
    "    return service\n",
    "\n",
    "def poll_report(service, report_id):\n",
    "    \"\"\"Poll the API with the reportId until the report is ready, up to ten times.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        report_id: The ID DS has assigned to a report.\n",
    "    Returns:\n",
    "        pd.DataFrame, report file\n",
    "    \"\"\"\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            request = service.reports().get(reportId=report_id)\n",
    "            json_data = request.execute()\n",
    "            if json_data['isReportReady']:\n",
    "                pprint.pprint('The report is ready.')\n",
    "\n",
    "                # For large reports, DS automatically fragments the report into multiple\n",
    "                # files. The 'files' property in the JSON object that DS returns contains\n",
    "                # the list of URLs for file fragment. To download a report, DS needs to\n",
    "                # know the report ID and the index of a file fragment.\n",
    "                report = pd.DataFrame()\n",
    "                for i in range(len(json_data['files'])):\n",
    "                    pprint.pprint('Downloading fragment ' + str(i) + ' for report ' + report_id)\n",
    "                    report = report.append(download_files(service, report_id, str(i)), ignore_index = True) # See Download the report.\n",
    "                return report\n",
    "\n",
    "            else:\n",
    "                pprint.pprint('Report is not ready. I will try again.')\n",
    "                time.sleep(10)\n",
    "        except HttpError as e:\n",
    "            error = simplejson.loads(e.content)['error']['errors'][0]\n",
    "\n",
    "            # See Response Codes\n",
    "            pprint.pprint('HTTP code %d, reason %s' % (e.resp.status, error['reason']))\n",
    "            break\n",
    "        \n",
    "def download_files(service, report_id, report_fragment):\n",
    "    \"\"\"Generate and print sample report.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        report_id: The ID DS has assigned to a report.\n",
    "        report_fragment: The 0-based index of the file fragment from the files array.\n",
    "    Returns:\n",
    "        pd.DataFrame report file\n",
    "    \"\"\"\n",
    "    request = service.reports().getFile(reportId=report_id, reportFragment=report_fragment)\n",
    "    return pd.read_csv(StringIO(request.execute().decode('utf-8')))\n",
    "\n",
    "def request_report(service, start_date, end_date, columns):\n",
    "    \"\"\"Request sample report and print the report ID that DS returns. See Set Up Your Application.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        columns: list of columns will be in the report\n",
    "    Returns:\n",
    "        The report id.\n",
    "    \"\"\"\n",
    "    request = service.reports().request(\n",
    "        body={\n",
    "                \"reportScope\": {\n",
    "                    \"agencyId\": \"20100000000000932\",\n",
    "                    \"advertiserId\": \"21700000001406447\", # Callaway Apparel - Perry Ellis International\n",
    "                    #\"engineAccountId\": \"700000001564770\" # Google - Callaway Apparel\n",
    "                    #\"advertiserId\": \"21700000001131725\", # Celebrity Cruise\n",
    "                    #\"engineAccountId\": \"700000001217833\" # Celebrity Cruise\n",
    "                    #\"engineAccountId\": \"700000001561242\" # Celebrity Cruise - Juba Plus\n",
    "                },\n",
    "                \"reportType\": \"keyword\",\n",
    "                \"columns\": [{'columnName': column} for column in columns],   \n",
    "                \"timeRange\" : {\n",
    "                    \"startDate\" : start_date,\n",
    "                    \"endDate\" : end_date\n",
    "                    },\n",
    "                \n",
    "                #\"filters\": [\n",
    "                #    {\n",
    "                #        \"column\" : { \"columnName\": \"keywordLabels\" },\n",
    "                #        \"operator\" : \"containsElement\",\n",
    "                #        \"values\" : [\"JubaNovTest\",]\n",
    "                #    }\n",
    "                #],\n",
    "                \n",
    "                \"downloadFormat\": \"csv\",\n",
    "                \"maxRowsPerFile\": 100000000,\n",
    "                \"statisticsCurrency\": \"agency\",\n",
    "                \"verifySingleTimeZone\": \"false\",\n",
    "                \"includeRemovedEntities\": \"false\"\n",
    "            }\n",
    "    )\n",
    "    json_data = request.execute()\n",
    "    return json_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-04-02 2017-09-20\n",
      "'Report is not ready. I will try again.'\n",
      "'Report is not ready. I will try again.'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAn2uX-JzaliyAJ'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAnprS8PRUyWKne'\n"
     ]
    }
   ],
   "source": [
    "# download reports\n",
    "creds = create_credentials()\n",
    "\n",
    "service = get_service(creds)\n",
    "\n",
    "\n",
    "print(start_date, end_date)\n",
    "REPORTID_nonHVA = request_report(service, start_date, end_date, \n",
    "                                 ['campaign', 'adGroup', 'keywordText', 'keywordMatchType', 'status', \n",
    "                                  'effectiveKeywordMaxCpc', 'keywordMaxCpc', 'topOfPageBidCurrent',\n",
    "                                  'topOfPageBidAvg', 'impr', 'clicks', 'cost', \n",
    "                                  'avgCpc', 'avgPos', 'dfaRevenue'])\n",
    "REPORTID_HVA = request_report(service, start_date, end_date, \n",
    "                              ['campaign', 'adGroup', 'keywordText', 'keywordMatchType', \n",
    "                               'floodlightActivity', 'dfaActions'])\n",
    "\n",
    "non_hva = poll_report(service, REPORTID_nonHVA)\n",
    "hva = poll_report(service, REPORTID_HVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_hva_and_non_hva(hva, non_hva):\n",
    "    '''merge two reports downloaded by download_reports().\n",
    "    Args:\n",
    "        hva: pd.DataFrame\n",
    "        non_hva: pd.DataFrame\n",
    "        columns_hva: list of string\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    '''   \n",
    "    columns_hva= ['Callaway - Big & Tall', 'Callaway - Clearance,Callaway - Unsubscribe - HVA 2', \n",
    "                'Callaway - Search - HVA2', 'Callaway - Big & Tall_Belts', 'Callaway - Big & Tall_Outerwear', \n",
    "                'Callaway - Big & Tall_Pants-Shorts', 'Callaway - Big & Tall_Polos', \n",
    "                'Callaway - Clearance_Big & Tall Clearance', 'Callaway - Clearance_Mens Clearance', \n",
    "                'Callaway - Clearance_Womens Clearance', 'Callaway - Features_Best-Sellers', \n",
    "                'Callaway - Features_Callaway X', 'Callaway - Features_New Arrivals', \n",
    "                'Callaway - Features_Opti-Series', 'Callaway - Men Golf Shoes', 'Callaway - Men_Belts', \n",
    "                'Callaway - Men_Outerwear', 'Callaway - Men_Pants', 'Callaway - Men_Polos', \n",
    "                'Callaway - Men_Shorts', 'Callaway - Men_Standard Collection', 'Callaway - Products - Belts', \n",
    "                'Callaway - Products - Jacket', 'Callaway - Products - Jackets', \n",
    "                'Callaway - Products - Men Golf Shoes', 'Callaway - Products - Pants', \n",
    "                'Callaway - Products - Polo', 'Callaway - Products - Polos', 'Callaway - Products - Short', \n",
    "                'Callaway - Products - Shorts', 'Callaway - Products - Skorts', 'Callaway - Products - Sweaters', \n",
    "                'Callaway - Products - Vests', 'Callaway - Products - Women Golf Shoes', \n",
    "                'Callaway - Women Golf Shoes', 'Callaway - Women_Belts', 'Callaway - Women_Outerwear', \n",
    "                'Callaway - Women_Pants', 'Callaway - Women_Polos', 'Callaway - Women_Skorts & Shorts', \n",
    "                'Callaway - Women_Standard Collection',\n",
    "                'Callaway - Add to Cart - HVA 3', 'Callaway - Order Status (Orders)', 'Callaway - Billing_Payment',\n",
    "                'Callaway - Check Out', 'Callaway - Order Review', 'Callaway - Paypal', 'Callaway - Secure Checkout',\n",
    "                'Callaway - Shipping']\n",
    "    \n",
    "    result = pd.DataFrame(columns=['campaign', 'adGroup', 'keywordText', 'keywordMatchType']+columns_hva)\n",
    "    \n",
    "    for (campaign, ad_group, keyword, keyword_match_type), group in hva.groupby(['campaign', 'adGroup', \n",
    "                                                                                 'keywordText', 'keywordMatchType']):\n",
    "        df = pd.DataFrame([{\n",
    "            'campaign': campaign,\n",
    "            'adGroup': ad_group,\n",
    "            'keywordText' : keyword,\n",
    "            'keywordMatchType': keyword_match_type\n",
    "        }])\n",
    "\n",
    "        for column in columns_hva:\n",
    "            if column in group['floodlightActivity'].values:\n",
    "                df[column] = group[group['floodlightActivity'] == column]['dfaActions'].values[0]\n",
    "            else:\n",
    "                df[column] = 0\n",
    "                \n",
    "        result = result.append(df, ignore_index = True)\n",
    "\n",
    "    # combine hva and non_hva\n",
    "    merged = non_hva.merge(result, \n",
    "                           on = ['campaign', 'adGroup', 'keywordText', 'keywordMatchType'], \n",
    "                           how = 'left')\n",
    "\n",
    "    # generate baseline and resid compare\n",
    "    merged = merged.fillna(value = 0)\n",
    "    \n",
    "    # generate new fields\n",
    "    merged['HVA'] = merged[columns_hva].sum(axis=1).apply(int)   \n",
    "    merged['ROI'] = merged['dfaRevenue'] / merged['cost']\n",
    "    merged['ROI'] = merged['ROI'].fillna(0)\n",
    "    return merged[['campaign', 'adGroup', 'keywordText', 'keywordMatchType', \n",
    "                   'status', 'keywordMaxCpc', 'effectiveKeywordMaxCpc', \n",
    "                   'topOfPageBidCurrent', 'topOfPageBidAvg', 'impr', 'clicks', \n",
    "                   'HVA', 'avgCpc', 'avgPos', 'cost', 'dfaRevenue', 'ROI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_Non-Brand_Callaway Apparel_Big & Tall Clothing_EST-2773 1486\n",
      "B_Non-Brand_Callaway Apparel_Big & Tall Clothing_EST-2773 931\n",
      "Y_Non-Brand_Callaway Apparel_Big & Tall Clothing_EST-2773 446\n",
      "G_Non-Brand_Callaway Apparel_Mens Clothing_EST-2773 1446\n",
      "B_Non-Brand_Callaway Apparel_Mens Clothing_EST-2773 1012\n",
      "Y_Non-Brand_Callaway Apparel_Mens Clothing_EST-2773 434\n",
      "G_Non-Brand_Callaway Apparel_Womens Clothing_EST-2773 1325\n",
      "B_Non-Brand_Callaway Apparel_Womens Clothing_EST-2773 793\n",
      "Y_Non-Brand_Callaway Apparel_Womens Clothing_EST-2773 463\n"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter(Save_Path, engine='xlsxwriter')\n",
    "campaigns = {\n",
    "    'G_Non-Brand BigTall': 'G_Non-Brand_Callaway Apparel_Big & Tall Clothing_EST-2773',\n",
    "    'B_Non-Brand BigTall': 'B_Non-Brand_Callaway Apparel_Big & Tall Clothing_EST-2773',\n",
    "    'Y_Non-Brand BigTall': 'Y_Non-Brand_Callaway Apparel_Big & Tall Clothing_EST-2773',\n",
    "    \n",
    "    'G_Non-Brand Men': 'G_Non-Brand_Callaway Apparel_Mens Clothing_EST-2773',\n",
    "    'B_Non-Brand Men': 'B_Non-Brand_Callaway Apparel_Mens Clothing_EST-2773',\n",
    "    'Y_Non-Brand Men': 'Y_Non-Brand_Callaway Apparel_Mens Clothing_EST-2773',\n",
    "    \n",
    "    'G_Non-Brand Women': 'G_Non-Brand_Callaway Apparel_Womens Clothing_EST-2773',\n",
    "    'B_Non-Brand Women': 'B_Non-Brand_Callaway Apparel_Womens Clothing_EST-2773',\n",
    "    'Y_Non-Brand women': 'Y_Non-Brand_Callaway Apparel_Womens Clothing_EST-2773'\n",
    "}\n",
    "\n",
    "List=[]\n",
    "\n",
    "for tab in campaigns:\n",
    "    CAMPAIGN = campaigns[tab]\n",
    "    hva_1 = hva[hva['campaign'] == CAMPAIGN]\n",
    "    non_hva_1 = non_hva[non_hva['campaign'] == CAMPAIGN]\n",
    "    print(CAMPAIGN, len(hva_1))\n",
    "    df = merge_hva_and_non_hva(hva_1, non_hva_1)\n",
    "    df = df[(df['keywordText'] != 'Display Network Stats') & (df['status'] == 'Active')]\n",
    "\n",
    "    if len(df)==0:\n",
    "        df['group'] = None\n",
    "\n",
    "    elif len(df['ROI'].unique())==1 and df['ROI'].unique()[0]==0 and len(df['HVA'].unique())==1 and df['HVA'].unique()[0]==0:\n",
    "        df['group'] = None\n",
    "\n",
    "    else:\n",
    "        # group1\n",
    "        df.loc[(df['ROI'] > 0)&(df['clicks'] < 30), 'group'] = 'group1_lowClick'\n",
    "        df.loc[(df['ROI'] > 0)&(df['clicks'] >= 30), 'group'] = 'group1'\n",
    "\n",
    "        # group2\n",
    "        HVA_mean = df['HVA'].mean()\n",
    "        if HVA_mean < 10:\n",
    "            HVA_mean = df[df['HVA'] > 0]['HVA'].mean()\n",
    "        impr_75 = sorted(list(df['impr']))[int(len(df)*3/4)]\n",
    "\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] >= HVA_mean)&\n",
    "               (df['clicks'] >= 30)&\n",
    "               (df['impr']>=impr_75), 'group'] = 'group2'\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] >= HVA_mean)&\n",
    "               (df['clicks'] >= 30)&\n",
    "               (df['impr']<impr_75), 'group'] = 'group2_highImpr'\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] >= HVA_mean)&\n",
    "               (df['clicks'] < 30), 'group'] = 'group2_lowClick'\n",
    "\n",
    "        impr_mean = df[df['group'].isnull()]['impr'].mean() #Not allocated group 'impr' mean\n",
    "\n",
    "        # group3\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] >= impr_mean)&\n",
    "               (df['cost'] > 0)&\n",
    "               (df['clicks'] >= 30), 'group'] = 'group3'\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] >= impr_mean)&\n",
    "               (df['cost'] > 0)&\n",
    "               (df['clicks'] < 30), 'group'] = 'group3_lowClick'\n",
    "\n",
    "        # group4\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] >= impr_mean)&\n",
    "               (df['avgPos'] <= 2)&\n",
    "               (df['cost'] == 0), 'group'] = 'group4'\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] >= impr_mean)&\n",
    "               (df['avgPos'] > 2)&\n",
    "               (df['cost'] == 0), 'group'] = 'group4_lowPosition'\n",
    "\n",
    "        # group5\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] < impr_mean)&\n",
    "               (df['clicks'] >= 30), 'group'] = 'group5'\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] < impr_mean)&\n",
    "               (df['clicks'] < 30), 'group'] = 'group5_lowClick'\n",
    "\n",
    "\n",
    "        applications_SEM = {\n",
    "            'group1': 'Maintain',\n",
    "            'group1_lowClick': 'keep_running',\n",
    "            'group2': '75% Desktop, 25% Mobile',\n",
    "            'group2_highImpr': 'Type= Exact, add ngatiove KWs',\n",
    "            'group2_lowClick': 'keep_running',\n",
    "            'group3': 'pause/ Add to sitelinkes in other ad-groups',\n",
    "            'group3_lowClick': 'keep_running',\n",
    "            'group4': 'keep_running',\n",
    "            'group4_lowPosition': 'improve position to 1-2 (increase CPC)',\n",
    "            'group5': 'pause',\n",
    "            'group5_lowClick': 'keep_running'}\n",
    "\n",
    "        applications_FB_Programatic = {\n",
    "            'group1': 'Add Products',\n",
    "            'group1_lowClick': 'keep_running',\n",
    "            'group2': 'Add Products',\n",
    "            'group2_highImpr': 'Add Products',\n",
    "            'group2_lowClick': 'keep_running',\n",
    "            'group3': 'n.a',\n",
    "            'group3_lowClick': 'keep_running',\n",
    "            'group4': 'n.a',\n",
    "            'group4_lowPosition': 'n.a',\n",
    "            'group5': 'n.a',\n",
    "            'group5_lowClick': 'keep_running'}\n",
    "\n",
    "        applications_PLA = {\n",
    "            'group1': 'Maintain/add Products',\n",
    "            'group1_lowClick': 'keep_running',\n",
    "            'group2': 'Filter by Zips',\n",
    "            'group2_highImpr': 'Add Products',\n",
    "            'group2_lowClick': 'keep_running',\n",
    "            'group3': 'pause',\n",
    "            'group3_lowClick': 'keep_running',\n",
    "            'group4': 'keep running',\n",
    "            'group4_lowPosition': 'improve position to 1-2 (increase CPC)',\n",
    "            'group5': 'n.a',\n",
    "            'group5_lowClick': 'keep_running'}\n",
    "        applications_Display = {\n",
    "            'group1': 'Add Products',\n",
    "            'group1_lowClick': 'keep_running',\n",
    "            'group2': 'Filter by Zips/100% Desktop',\n",
    "            'group2_highImpr': 'n.a',\n",
    "            'group2_lowClick': 'keep_running',\n",
    "            'group3': 'n.a.',\n",
    "            'group3_lowClick': 'keep_running',\n",
    "            'group4': 'n.a',\n",
    "            'group4_lowPosition': 'n.a',\n",
    "            'group5': 'n.a',\n",
    "            'group5_lowClick': 'keep_running'}\n",
    "        criterion = {\n",
    "            'group1': 'ROI > 0',\n",
    "            'group1_lowClick': 'clicks are too low to drive conclusion',\n",
    "            'group2': 'ROI = 0, high HVA',\n",
    "            'group2_highImpr': 'ROI = 0, high HVA, high impression',\n",
    "            'group2_lowClick': 'clicks are too low to drive conclusion',\n",
    "            'group3': 'ROI = 0, low HVA, high impression, cost > 0',\n",
    "            'group3_lowClick': 'clicks are too low to drive conclusion',\n",
    "            'group4': 'ROI = 0, low HVA, high impression, cost = 0, position already high',\n",
    "            'group4_lowPosition': 'ROI = 0, low HVA, high impression, cost = 0, low position',\n",
    "            'group5': 'ROI = 0, low HVA, low impression',\n",
    "            'group5_lowClick': 'clicks are too low to drive conclusion'}\n",
    "\n",
    "        df['criterion'] = df['group'].apply(lambda x: criterion[x])\n",
    "        df['applications_FB_Programatic'] = df['group'].apply(lambda x: applications_FB_Programatic[x])\n",
    "        df['applications_SEM'] = df['group'].apply(lambda x: applications_SEM[x])\n",
    "        df['applications_PLA'] = df['group'].apply(lambda x: applications_PLA[x])\n",
    "        df['applications_Display'] = df['group'].apply(lambda x: applications_Display[x])\n",
    "\n",
    "    df.sort_values('group', inplace=True)\n",
    "    List.append(df)\n",
    "    df.to_excel(writer, sheet_name=tab, index=False)\n",
    "\n",
    "    \n",
    "#####\n",
    "\n",
    "new_df = []\n",
    "for i in range(len(List)):\n",
    "    if i%3 == 0:\n",
    "        newdf = pd.concat([List[i],List[i+1],List[i+2]])\n",
    "        new_df.append(newdf)\n",
    "\n",
    "newnew_df = []        \n",
    "for summ in new_df:\n",
    "    summ['Engine']=summ['campaign'].apply(lambda x: x[0])\n",
    "    summ = pd.pivot_table(summ[['campaign','Engine','group','keywordText']],index = ['campaign','Engine','group'], aggfunc = 'count' )\n",
    "    summ.columns =summ.columns.get_level_values(0)\n",
    "    summ.reset_index(inplace=True)\n",
    "    summ['SEM RECOMMENDATION'] = summ['group'].apply(lambda x : applications_SEM[x])\n",
    "    summ['FB/PROGRAMMATIC'] = summ['group'].apply(lambda x : applications_FB_Programatic[x])\n",
    "    summ['PLA RECOMMENDATION'] = summ['group'].apply(lambda x : applications_PLA[x])\n",
    "    summ['Display RECOMMENDATION'] = summ['group'].apply(lambda x : applications_Display[x])\n",
    "    newnew_df.append(summ)\n",
    "    \n",
    "summary = pd.concat(newnew_df)\n",
    "summary_2=summary.pivot_table(summary[['campaign','Engine','SEM RECOMMENDATION','FB/PROGRAMMATIC','PLA RECOMMENDATION','Display RECOMMENDATION','keywordText']],index = ['campaign','Engine','SEM RECOMMENDATION','FB/PROGRAMMATIC','PLA RECOMMENDATION','Display RECOMMENDATION'], aggfunc = 'sum' )\n",
    "summary_2.columns=summary_2.columns.get_level_values(0)\n",
    "summary_2.reset_index(inplace=True)\n",
    "summary_2['campaign']=summary_2['campaign'].apply(lambda x: x[29:(len(x)-9)])\n",
    "summary_2.sort_values(['campaign','Engine'], inplace=True)\n",
    "summary_2=summary_2[['campaign', 'Engine', 'keywordText', 'SEM RECOMMENDATION', 'FB/PROGRAMMATIC',\n",
    "       'PLA RECOMMENDATION', 'Display RECOMMENDATION']]\n",
    "Engine_Rep_dict={'G':\"Google\",\"B\":\"Bing\",\"Y\":'Yahoo'}\n",
    "summary_2['Engine']=summary_2['Engine'].apply(lambda x:Engine_Rep_dict[x])\n",
    "summary_2.to_excel(writer, sheet_name='summary', index=False)\n",
    "\n",
    "\n",
    "####\n",
    "new_kws = pd.read_csv('/Users/JayLiang/Desktop/Media Storm/PEI/CallAway/SEM_ Optimization/Callaway new kw list.csv')\n",
    "new_kws = new_kws[new_kws['Brand Nonbrand'] == 'Nonbrand']\n",
    "new_kws = new_kws.drop_duplicates(['Campaign', 'New KW'])\n",
    "\n",
    "curr_kws = non_hva[non_hva['campaign'].isin(campaigns.values())][[\n",
    "        'campaign', 'adGroup', 'keywordText', 'keywordMatchType', \n",
    "        'keywordMaxCpc', 'effectiveKeywordMaxCpc', 'topOfPageBidCurrent', \n",
    "        'topOfPageBidAvg', 'status', 'impr', 'clicks', 'cost', 'dfaRevenue'\n",
    "    ]].copy()\n",
    "\n",
    "campaign_abbr = {\n",
    "    'B_Non-Brand_Callaway Apparel_Big & Tall Clothing_EST-2773': 'Big Tall',\n",
    "    'G_Non-Brand_Callaway Apparel_Big & Tall Clothing_EST-2773': 'Big Tall',\n",
    "    'Y_Non-Brand_Callaway Apparel_Big & Tall Clothing_EST-2773': 'Big Tall',\n",
    "    'B_Non-Brand_Callaway Apparel_Mens Clothing_EST-2773': 'Men',\n",
    "    'G_Non-Brand_Callaway Apparel_Mens Clothing_EST-2773': 'Men',\n",
    "    'Y_Non-Brand_Callaway Apparel_Mens Clothing_EST-2773': 'Men',\n",
    "    'G_Non-Brand_Callaway Apparel_Womens Clothing_EST-2773': 'Women',\n",
    "    'B_Non-Brand_Callaway Apparel_Womens Clothing_EST-2773': 'Women',\n",
    "    'Y_Non-Brand_Callaway Apparel_Womens Clothing_EST-2773': 'Women'\n",
    "}\n",
    "\n",
    "curr_kws['campaign_abbr'] = curr_kws['campaign'].apply(lambda x: campaign_abbr[x])\n",
    "curr_kws['ROI'] = (curr_kws['dfaRevenue'] / curr_kws['cost']).fillna(0)\n",
    "\n",
    "curr_kws = curr_kws.merge(new_kws, left_on=['campaign_abbr', 'keywordText'], right_on=['Campaign', 'New KW'], how='left')\n",
    "\n",
    "action_to_new_kw_provided = curr_kws[curr_kws['New KW'].notnull()].copy()\n",
    "\n",
    "def insight(row):\n",
    "    if row['status'] == 'Paused':\n",
    "        if row['clicks'] < 30:\n",
    "            return 'status was Paused, clicks < 30'\n",
    "        elif row['ROI'] == 0:\n",
    "            return 'status was Paused, clicks >=30, ROI = 0, keep Paused'\n",
    "        else:\n",
    "            return 'status was Paused, clicks >= 30, ROI > 0'\n",
    "        \n",
    "    elif row['clicks'] < 30:\n",
    "        return 'status was activate, clicks < 30'\n",
    "    elif row['ROI'] == 0:\n",
    "        return 'status was activate, clicks >= 30, ROI = 0'\n",
    "    else:\n",
    "        return 'status was activate, clicks >= 30, ROI > 0'\n",
    "\n",
    "def action(row):\n",
    "    if row['status'] == 'Paused':\n",
    "        if row['ROI'] == 0 and row['clicks'] >=30:\n",
    "            return 'No Action'\n",
    "        else:\n",
    "            return 'Activate'\n",
    "    elif row['clicks'] < 30:\n",
    "        return 'No Action'\n",
    "    elif row['ROI'] == 0:\n",
    "        return 'Paused'\n",
    "    else:\n",
    "        return 'No Action'\n",
    "    \n",
    "action_to_new_kw_provided['insight'] = action_to_new_kw_provided.apply(lambda row: insight(row), axis=1)       \n",
    "action_to_new_kw_provided['Strategy'] = action_to_new_kw_provided.apply(lambda row: action(row), axis=1)\n",
    "\n",
    "paused_kw_not_in_new_list = curr_kws[curr_kws['New KW'].isnull()].copy()  \n",
    "paused_kw_not_in_new_list = paused_kw_not_in_new_list[paused_kw_not_in_new_list['status'] == 'Paused']\n",
    "paused_kw_not_in_new_list['insight'] = paused_kw_not_in_new_list.apply(lambda row: insight(row), axis=1)\n",
    "paused_kw_not_in_new_list['Strategy'] = paused_kw_not_in_new_list.apply(lambda row: action(row), axis=1)\n",
    "\n",
    "del action_to_new_kw_provided['Campaign']\n",
    "del action_to_new_kw_provided['New KW']\n",
    "del action_to_new_kw_provided['campaign_abbr']\n",
    "del action_to_new_kw_provided['Brand Nonbrand']\n",
    "action_to_new_kw_provided.to_excel(writer, sheet_name='action_to_new_kw_provided', index=False)\n",
    "\n",
    "del paused_kw_not_in_new_list['Campaign']\n",
    "del paused_kw_not_in_new_list['New KW']\n",
    "del paused_kw_not_in_new_list['campaign_abbr']\n",
    "del paused_kw_not_in_new_list['Brand Nonbrand']\n",
    "paused_kw_not_in_new_list.to_excel(writer, sheet_name='paused_kw_not_in_new_list', index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "writer.save()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
