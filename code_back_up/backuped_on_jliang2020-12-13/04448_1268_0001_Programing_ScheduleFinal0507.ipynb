{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Charts start here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import datetime\n",
    "import function3036\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "startdate = 20170918\n",
    "enddate = 20170924\n",
    "cableid = '006196'\n",
    "cablename = 'LIF  '\n",
    "folderpath = '/home/nielsen/NielsenEngine/ProgramSchedule/output0918/'\n",
    "engine = create_engine('mysql://linked_admin:EyAeRxy4PH3Ut5L8@localhost/linked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = datetime.datetime.strptime(str(startdate), '%Y%m%d').date()\n",
    "end_date = datetime.datetime.strptime(str(enddate), '%Y%m%d').date()\n",
    "end_date = end_date + datetime.timedelta(days=3)\n",
    "try:\n",
    "    os.stat(folderpath)\n",
    "except:\n",
    "    os.mkdir(folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "type36 = pd.read_sql((\"select * from minuteviewing_cwk where NetworkName=%(n0)s \\\n",
    "                       and Date>=%(sd0)s\\\n",
    "                       and Date<=%(ed0)s\\\n",
    "                       and playbacksegments != 'Live7D'\\\n",
    "                       and playbacksegments != 'Live3D'\"),\n",
    "                       params={'n0':cablename,'sd0':start_date,'ed0':end_date},\n",
    "                       con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type36['playbacksegments'] = np.where(type36['playbacksegments'] == 'Live', \n",
    "                                      'Live', 'Shifted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demographics(Startdate,Enddate):\n",
    "    Startdate=datetime.datetime.strptime(str(Startdate), '%Y%m%d').date()\n",
    "    startdate=Startdate+datetime.timedelta(days=(6-Startdate.weekday()))\n",
    "    Enddate=datetime.datetime.strptime(str(Enddate), '%Y%m%d').date()\n",
    "    enddate=Enddate+datetime.timedelta(days=(6-Enddate.weekday()))\n",
    "    directory=pd.read_csv('/home/nielsen/Nielsen_Directory_Server/NielsenDirectoryServer.csv')\n",
    "    directory['Week']=pd.to_datetime(directory['Week'])\n",
    "    directory=directory.sort_values('Week',ascending=0)\n",
    "    names2024=directory[(directory['Week']<=enddate)&(directory['Week']>=startdate)&(directory['Table']=='EHH')]\n",
    "    names2024=names2024['FilePath']\n",
    "    df2=pd.DataFrame()\n",
    "    type24=pd.DataFrame()\n",
    "    for i in names2024:\n",
    "        df2=pd.read_csv(i,sep='\\t')\n",
    "        df2.columns=['all']\n",
    "        df2['type']=df2['all'].str[0:2]\n",
    "        df2=df2[df2['type']=='24']\n",
    "        df2['HHID']=df2['all'].str[13:20]\n",
    "        df2['PersonID']=df2['all'].str[20:22]\n",
    "        df2['Age']=df2['all'].str[38:41].astype('int')\n",
    "        df2['Gender']=df2['all'].str[41:42]\n",
    "        df2['starteffetivedate']=df2['all'].str[22:30].astype('int')\n",
    "        df2=df2.drop_duplicates()   \n",
    "        type24=type24.append(df2,ignore_index=True)\n",
    "    type24=type24.sort_values('starteffetivedate',ascending=0)\n",
    "    type24=type24.drop_duplicates(['HHID','PersonID']) \n",
    "    type24=type24[['HHID','PersonID','Age','Gender']]   \n",
    "    return type24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo = demographics(startdate,enddate)\n",
    "#demo = demo[(demo['Age'].isin(range(25,55)))&(demo['Gender']=='F')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo.reset_index(drop = True, inplace = True)\n",
    "#demo['HHID_PersonID'] = demo['HHID'] + '_' + demo['PersonID']\n",
    "#demo = demo[['HHID_PersonID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type36 = pd.merge(type36,demo, on='HHID_PersonID')\n",
    "#type36.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####run this when reprocessed\n",
    "type30 = function3036.get_type30withreprocess(cableid,startdate,enddate)\n",
    "type30 = type30[type30['CableID']==cableid]\n",
    "type30['ProgramDate'] = pd.to_datetime(type30['ProgramDate'])\n",
    "type30=type30.sort_values(['ProgramDate','BroadcastStartTime'],ascending=True)\n",
    "type30=type30.reset_index(drop=True)\n",
    "type30.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type30 = function3036.get_type30(cableid,startdate,enddate)\n",
    "type30['ProgramDate'] = pd.to_datetime(type30['ProgramDate'])\n",
    "type30=type30.sort_values(['ProgramDate','BroadcastStartTime'],ascending=True)\n",
    "type30=type30.reset_index(drop=True)\n",
    "type30.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type30['premieretype'] = np.where(type30['PremiereIndicator']==1,' :PREMIERE',\n",
    "                                 np.where(type30['RepeatIndicator']==0,' :MAINEP',' :REAIR'))\n",
    "type30['ProgramName'] = np.where(type30['Programtypesummarycode'] =='FF',\n",
    "                                    'MOVIES: ' + type30['EpisodeName'] + type30['premieretype'],\n",
    "                                    type30['ProgramName'] + type30['premieretype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.merge(type36,type30,on=['NetworkName','ProgramID', 'TelecastN'])\n",
    "dfall['Date'] = pd.to_datetime(dfall['Date'])\n",
    "dfall = dfall[dfall['ProgramDate']<=dfall['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "###calculate leadin programs\n",
    "type30leadin1 = type30[['index','NetworkName','ProgramID',\n",
    "                        'TelecastN','BroadcastStartTime','ProgramDate']]\n",
    "type30leadin1.loc[:,'index'] = type30leadin1['index']+1\n",
    "type30leadin1perday = type30leadin1[['index','BroadcastStartTime','ProgramDate']]\n",
    "type30leadin1perday = type30leadin1perday.sort_values(['ProgramDate',\n",
    "                                                       'BroadcastStartTime'],ascending=[1,0])\n",
    "type30leadin1perday = type30leadin1perday.drop_duplicates(['ProgramDate'])\n",
    "type30leadin1perday = type30leadin1perday[['index','BroadcastStartTime']]\n",
    "type30leadin1perday.columns = ['index','remove']\n",
    "type30leadin1 = pd.merge(type30leadin1,type30leadin1perday,on='index',how='left')\n",
    "type30leadin1 = type30leadin1.fillna(0)\n",
    "type30leadin1 = type30leadin1[type30leadin1['remove'] == 0]\n",
    "type30leadin1 = type30leadin1[['index','NetworkName','ProgramID','TelecastN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfleadin = pd.merge(type36[['HHID_PersonID','NetworkName',\n",
    "                            'ProgramID', 'TelecastN']],\n",
    "                    type30leadin1,on=['NetworkName','ProgramID', 'TelecastN'])#,'playbacksegments'\n",
    "dfleadin = dfleadin[['HHID_PersonID','NetworkName',\n",
    "                     'index']].drop_duplicates()#,'playbacksegments'\n",
    "dfleadin['leadin'] = 1\n",
    "dfexclleadin = pd.merge(dfall,\n",
    "                        dfleadin,\n",
    "                        on=['HHID_PersonID','NetworkName',\n",
    "                            'index'],\n",
    "                        how='left')#,'playbacksegments'\n",
    "dfexclleadin['leadin'].fillna(0,inplace = True)\n",
    "dfexclleadin = dfexclleadin[dfexclleadin['leadin'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfintab = dfall[['HHID_PersonID','PersonIntab',\n",
    "                 'Date']].drop_duplicates(['HHID_PersonID','Date'])\n",
    "dfintab = dfintab.groupby('HHID_PersonID').mean()\n",
    "dfintab.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def programgainlost(qualifiedmins, dfminsall, dfintab):\n",
    "    df = dfminsall[dfminsall['mins']>=qualifiedmins]\n",
    "    dftotal = df[['HHID_PersonID', 'NetworkName',\n",
    "                  'ProgramID','TelecastN']].drop_duplicates()\n",
    "    dftotal = pd.merge(dftotal,dfintab, on= 'HHID_PersonID' )\n",
    "    dftotal = dftotal.groupby(['NetworkName',\n",
    "                               'ProgramID','TelecastN']).sum()\n",
    "    dftotal.columns =['UniqueReach_'+str(qualifiedmins)]\n",
    "    dftotal.reset_index(inplace = True)\n",
    "    dftotal2 = df[['HHID_PersonID', 'NetworkName',\n",
    "                   'ProgramID','TelecastN','playbacksegments']].drop_duplicates()\n",
    "    dftotal2 = pd.merge(dftotal2,dfintab, on= 'HHID_PersonID' )\n",
    "    dftotal2 = dftotal2.groupby(['NetworkName',\n",
    "              'ProgramID','TelecastN','playbacksegments']).sum().unstack('playbacksegments')\n",
    "    dftotal2.columns =['UniqueLiveReach_'+str(qualifiedmins),\n",
    "                       'UniqueShiftedReach_'+str(qualifiedmins)]\n",
    "    dftotal2.reset_index(inplace = True)\n",
    "    dftotal2.fillna(0,inplace = True)\n",
    "    gain = df[['HHID_PersonID','Date','Time','NetworkName']]\n",
    "    gain.loc[:,'gain'] = 1\n",
    "    gain.loc[:,'Time'] = np.where(gain['Time']%100 == 59,\n",
    "                                gain['Time'] + 41,\n",
    "                                gain['Time'] + 1)\n",
    "    gain = pd.merge(df[['HHID_PersonID','Date','Time',\n",
    "                        'NetworkName','ProgramID','TelecastN']], gain, \n",
    "                    on = ['HHID_PersonID','Date','Time','NetworkName'],\n",
    "                    how = 'left')\n",
    "    gain.fillna(0, inplace = True)\n",
    "    gain = gain[gain['gain'] == 0]\n",
    "    gain = gain.drop_duplicates(['NetworkName','ProgramID',\n",
    "                                 'TelecastN','HHID_PersonID'])\n",
    "    gain = pd.merge(gain,dfintab, on= 'HHID_PersonID' )\n",
    "    gain = gain[['NetworkName','ProgramID',\n",
    "                 'TelecastN','PersonIntab']].groupby(['NetworkName','ProgramID',\n",
    "                 'TelecastN']).sum()\n",
    "    gain.columns =['Gain_'+str(qualifiedmins)]\n",
    "    gain.reset_index(inplace = True)\n",
    "    lost = df[['HHID_PersonID','NetworkName','ProgramID','TelecastN','ViewEndTime','EpisodeDuration']]\n",
    "    lost = lost.sort_values(['HHID_PersonID','NetworkName','ProgramID','TelecastN','ViewEndTime'],\n",
    "                            ascending = [1,1,1,1,0])\n",
    "    lost = lost.drop_duplicates(['HHID_PersonID','NetworkName','ProgramID','TelecastN'])\n",
    "    lost = lost[lost['ViewEndTime']!=lost['EpisodeDuration']]\n",
    "    lost = pd.merge(lost,dfintab, on= 'HHID_PersonID' )\n",
    "    lost = lost[['NetworkName','ProgramID',\n",
    "                 'TelecastN','PersonIntab']].groupby(['NetworkName','ProgramID',\n",
    "                 'TelecastN']).sum()\n",
    "    lost.columns =['Lost_'+str(qualifiedmins)]\n",
    "    lost.reset_index(inplace = True)\n",
    "    finalreport = pd.merge(dftotal, dftotal2,\n",
    "                           on = ['NetworkName','ProgramID','TelecastN'],\n",
    "                           how='outer')\n",
    "    finalreport = pd.merge(finalreport, gain,\n",
    "                           on = ['NetworkName','ProgramID','TelecastN'],\n",
    "                           how='outer')\n",
    "    finalreport = pd.merge(finalreport, lost, \n",
    "                           on = ['NetworkName','ProgramID','TelecastN'],\n",
    "                           how='outer')\n",
    "    finalreport.fillna(0, inplace = True)\n",
    "    finalreport.loc[:,'Lost_' + str(qualifiedmins)] = -finalreport['Lost_' + str(qualifiedmins)]\n",
    "    finalreport.loc[:,'Net_' + str(qualifiedmins)] = finalreport['Gain_' + str(qualifiedmins)] +\\\n",
    "                                               finalreport['Lost_' + str(qualifiedmins)]\n",
    "    return finalreport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "function3036.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  gain['gain'] = 1\n",
      "function3036.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  gain['Time'] + 1)\n",
      "function3036.py:129: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  lost['Time'] + 1)\n"
     ]
    }
   ],
   "source": [
    "###get metrics for live\n",
    "df1 = function3036.programoutput('Live',1,dfall)\n",
    "df6 = function3036.programoutput('Live',6,dfall)\n",
    "dflive = pd.merge(df1, df6, on=['Date','Time','NetworkName', 'ProgramID',\n",
    "                              'TelecastN'],how='outer')\n",
    "newcol = ['Date', 'Time', 'NetworkName', 'ProgramID', 'TelecastN']\n",
    "for i in dflive.columns[5:13]:\n",
    "    j = i + '_Live'\n",
    "    newcol.append(j)\n",
    "dflive.columns = newcol\n",
    "del(df1,df6)\n",
    "###get metrics for shifted\n",
    "df1 = function3036.programoutput('Shifted',1,dfall)\n",
    "df6 = function3036.programoutput('Shifted',6,dfall)\n",
    "dfshifted = pd.merge(df1, df6, on=['Date','Time','NetworkName', 'ProgramID',\n",
    "                              'TelecastN'],how='outer')\n",
    "newcol = ['Date', 'Time', 'NetworkName', 'ProgramID', 'TelecastN']\n",
    "for i in dfshifted.columns[5:13]:\n",
    "    j = i + '_Shifted'\n",
    "    newcol.append(j)\n",
    "dfshifted.columns = newcol\n",
    "del(df1,df6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###add program information\n",
    "dflive2 = pd.merge(dflive, \n",
    "                      type30[['NetworkName', 'ProgramID','TelecastN',\n",
    "                             'ProgramName','EpisodeName','EpisodeDuration',\n",
    "                             'PremiereIndicator','RepeatIndicator','ProgramDate',\n",
    "                             'BroadcastStartTime','BroadcastEndTime']],\n",
    "                      on=['NetworkName', 'ProgramID','TelecastN'])\n",
    "dfshifted2 = pd.merge(dfshifted, \n",
    "                      type30[['NetworkName', 'ProgramID','TelecastN',\n",
    "                             'ProgramName','EpisodeName','EpisodeDuration',\n",
    "                             'PremiereIndicator','RepeatIndicator','ProgramDate',\n",
    "                             'BroadcastStartTime','BroadcastEndTime']],\n",
    "                      on=['NetworkName', 'ProgramID','TelecastN'])\n",
    "dflive2.fillna(0,inplace = True)\n",
    "dfshifted2.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "####combine live and shifted\n",
    "dfshifted.fillna(0,inplace = True)\n",
    "dfcombined = dfshifted.groupby(['Date', 'Time','NetworkName']).sum()\n",
    "dfcombined.reset_index(inplace = True)\n",
    "dfcombined = pd.merge(dflive,dfcombined,on=['Date', 'Time','NetworkName'],how='outer')\n",
    "dfcombined.fillna(0,inplace = True)\n",
    "\n",
    "dfcombined['dayofweek'] = pd.to_datetime(dfcombined['Date'])\n",
    "days = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}\n",
    "dfcombined['dayofweek'] = dfcombined['dayofweek'].dt.dayofweek\n",
    "dfcombined['dayofweek'] = dfcombined['dayofweek'].apply(lambda x: days[x])\n",
    "dfcombined['DateTime'] = None\n",
    "dfcombined = dfcombined[['Date', 'Time', 'dayofweek', 'DateTime',\n",
    "       'Reach_1_Live', 'Gain_1_Live', 'Lost_1_Live', 'Net_1_Live',\n",
    "       'Reach_6_Live', 'Gain_6_Live', 'Lost_6_Live', 'Net_6_Live',\n",
    "       'Reach_1_Shifted', 'Gain_1_Shifted', 'Lost_1_Shifted',\n",
    "       'Net_1_Shifted', 'Reach_6_Shifted', 'Gain_6_Shifted',\n",
    "       'Lost_6_Shifted', 'Net_6_Shifted', 'NetworkName','ProgramID', 'TelecastN']]\n",
    "dfcombined = pd.merge(dfcombined, \n",
    "                      type30[['NetworkName', 'ProgramID','TelecastN',\n",
    "                             'ProgramName','EpisodeName','EpisodeDuration',\n",
    "                             'PremiereIndicator','RepeatIndicator','ProgramDate',\n",
    "                             'BroadcastStartTime','BroadcastEndTime','Programtypesummarycode']],\n",
    "                      on=['NetworkName', 'ProgramID','TelecastN'],how='left')\n",
    "#dfcombined['ProgramName'] = np.where(dfcombined['Programtypesummarycode'] =='FF',\n",
    "#                                    'MOVIES: ' + dfcombined['EpisodeName'],\n",
    "#                                    dfcombined['ProgramName'])\n",
    "del dfcombined['Programtypesummarycode']\n",
    "\n",
    "dfcombined = dfcombined.sort_values(['Date', 'Time'])\n",
    "dfcombined['Date'] = dfcombined['Date'].astype('str')\n",
    "dfcombined['Time'] = dfcombined['Time'].astype('str')\n",
    "dfcombined['Time'] = dfcombined['Time'].apply(lambda x:x.zfill(4))\n",
    "dfcombined['Time'] = dfcombined['Time'].str[0:2] + ':' \\\n",
    "                      + dfcombined['Time'].str[2:4]\n",
    "dfcombined['DateTime'] = dfcombined['Date'].str[5:10] + ' ' \\\n",
    "                      + dfcombined['Time'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###create program schedule\n",
    "type30['dayofweek'] = pd.to_datetime(type30['ProgramDate'])\n",
    "days = {0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\n",
    "type30['dayofweek'] = type30['dayofweek'].dt.dayofweek\n",
    "type30['dayofweek'] = type30['dayofweek'].apply(lambda x: days[x])\n",
    "\n",
    "schedule = pd.DataFrame()\n",
    "dfschedule = type30.sort_values(['ProgramDate','BroadcastStartTime'])\n",
    "dfschedule['BroadcastStartTime'] = dfschedule['BroadcastStartTime'].astype('str')\n",
    "dfschedule['BroadcastStartTime'] = dfschedule['BroadcastStartTime'].apply(lambda x:x.zfill(4))\n",
    "dfschedule['BroadcastStartTime'] = dfschedule['BroadcastStartTime'].str[0:2] + ':' \\\n",
    "                      + dfschedule['BroadcastStartTime'].str[2:4]\n",
    "#dfschedule['ProgramName'] = np.where(dfschedule['Programtypesummarycode'] =='FF',\n",
    "#                                    'MOVIES: ' + dfschedule['EpisodeName'],\n",
    "#                                    dfschedule['ProgramName'])\n",
    "for i in ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']:\n",
    "    dfday = dfschedule[dfschedule['dayofweek']==i]\n",
    "    a = max(dfday['ProgramDate'])\n",
    "    a = str(a)[0:10]\n",
    "    dfday = dfday[['BroadcastStartTime','ProgramName']]\n",
    "    dfday.columns = [i, a]\n",
    "    dfday = dfday.reset_index(drop=True)\n",
    "    schedule = pd.concat([schedule, dfday], axis=1)\n",
    "schedule.fillna('',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "####create table for the charts\n",
    "dfsummary1 = pd.merge(dflive,dfshifted,on=['Date','Time','NetworkName', 'ProgramID',\n",
    "                              'TelecastN'],how='outer')\n",
    "dfsummary1.fillna(0,inplace = True)\n",
    "dfsummary1 = pd.merge(dfsummary1, \n",
    "                      type30[['NetworkName', 'ProgramID','TelecastN',\n",
    "                             'ProgramName','Programtypesummarycode','EpisodeName']],\n",
    "                      on=['NetworkName', 'ProgramID','TelecastN'])\n",
    "#dfsummary1['ProgramName'] = np.where(dfsummary1['Programtypesummarycode'] =='FF',\n",
    "#                                    'MOVIES: ' + dfsummary1['EpisodeName'],\n",
    "#                                    dfsummary1['ProgramName'])\n",
    "dfsummary1 = dfsummary1[['Date','Time','ProgramName','Reach_1_Live',\n",
    "                         'Reach_1_Shifted']]\n",
    "dfsummary1.columns = ['Date','Time','ProgramName','_Live',\n",
    "                         '_Shifted']\n",
    "dfsummary1['Date'] = dfsummary1['Date'].astype('str')\n",
    "dfsummary1['Time'] = dfsummary1['Time'].astype('str')\n",
    "dfsummary1['Time'] = dfsummary1['Time'].apply(lambda x:x.zfill(4))\n",
    "dfsummary1['Time'] = dfsummary1['Time'].str[0:2] + ':' \\\n",
    "                      + dfsummary1['Time'].str[2:4]\n",
    "dfsummary1['DateTime'] = dfsummary1['Date'].str[5:10] + ' ' \\\n",
    "                      + dfsummary1['Time'].astype('str')\n",
    "dfsummary1 = dfsummary1.groupby(['Date','Time',\n",
    "                                 'DateTime','ProgramName']).sum().unstack('ProgramName')\n",
    "dfsummary1.columns = dfsummary1.columns.get_level_values(1) + dfsummary1.columns.get_level_values(0)\n",
    "dfsummary1.fillna(0,inplace = True)\n",
    "dfsummary1.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###get info for excel\n",
    "mindate = min(type30['ProgramDate'])\n",
    "mindate = str(mindate)[0:10]\n",
    "maxdate = max(type30['ProgramDate'])\n",
    "maxdate = str(maxdate)[0:10]\n",
    "maxrows = len(dfcombined.index)\n",
    "\n",
    "rowindex = dfcombined[['Date']]\n",
    "rowindex = rowindex.reset_index(drop=True)\n",
    "rowindex = rowindex.drop_duplicates()\n",
    "rowindex.reset_index(inplace = True)\n",
    "\n",
    "programindex = {}\n",
    "j=-1\n",
    "for i in dfsummary1.columns:\n",
    "    j=j+1\n",
    "    programindex[i] = j\n",
    "    \n",
    "#####save the files to excel\n",
    "writer = pd.ExcelWriter(folderpath+'ProgramOutput1 '+mindate+'_LIF.xlsx',\n",
    "                        engine='xlsxwriter',\n",
    "                        datetime_format='yyyy-mm-dd',\n",
    "                        date_format='yyyy-mm-dd')\n",
    "dflive2.to_excel(writer,'live', index=False)\n",
    "dfshifted2.to_excel(writer,'shifted', index=False)\n",
    "dfcombined.to_excel(writer,'combined', index=False)\n",
    "schedule.to_excel(writer,'Charts', index=False, startrow=2)\n",
    "dfsummary1.to_excel(writer,'promgrams', index=False)\n",
    "\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['combined']\n",
    "# update combined format\n",
    "format1 = workbook.add_format({'num_format': '#,##0'})\n",
    "format2 = workbook.add_format({'num_format': '#,##0,\"K\"'})\n",
    "worksheet.set_column('E:T', None, format1)\n",
    "\n",
    "worksheet = writer.sheets['promgrams']\n",
    "worksheet.set_column('D:DZ', None, format1)\n",
    "\n",
    "#adding charts start here\n",
    "worksheet = writer.sheets['Charts']\n",
    "bold = workbook.add_format({'bold': True})\n",
    "worksheet.write(0, 0, mindate + ' - ' + maxdate, bold)\n",
    "worksheet.set_column('B:B', 25, None)\n",
    "worksheet.set_column('D:D', 25, None)\n",
    "worksheet.set_column('F:F', 25, None)\n",
    "worksheet.set_column('H:H', 25, None)\n",
    "worksheet.set_column('J:J', 25, None)\n",
    "worksheet.set_column('L:L', 25, None)\n",
    "worksheet.set_column('N:N', 25, None)\n",
    "\n",
    "# Create a 1mins+chart\n",
    "chartloc = len(schedule.index) + 4\n",
    "\n",
    "chart1plus = workbook.add_chart({'type': 'line'})\n",
    "chart1plus.add_series({\n",
    "        'name':       ['combined', 0, 4],\n",
    "        'categories': ['combined', 1, 3, maxrows, 3],\n",
    "        'values':     ['combined', 1, 4, maxrows, 4]})\n",
    "chart1plus.add_series({\n",
    "        'name':       ['combined', 0, 12],\n",
    "        'categories': ['combined', 1, 3, maxrows, 3],\n",
    "        'values':     ['combined', 1, 12, maxrows, 12]})\n",
    "chart1plus.set_x_axis({'name': 'Time'})\n",
    "chart1plus.set_y_axis({'name': 'Persons', 'major_gridlines': {'visible': True}})\n",
    "\n",
    "chart1plus.set_size({'width': 1280, 'height': 576})\n",
    "chart1plus.set_title({'name': '1Mins+ Reach'})\n",
    "chart1plus.set_legend({'position': 'bottom'})\n",
    "worksheet.insert_chart('B'+str(chartloc), chart1plus) \n",
    "\n",
    "# Create a 6mins+chart\n",
    "chartloc = chartloc + 30\n",
    "chart6plus = workbook.add_chart({'type': 'line'})\n",
    "chart6plus.add_series({\n",
    "        'name':       ['combined', 0, 8],\n",
    "        'categories': ['combined', 1, 3, maxrows, 3],\n",
    "        'values':     ['combined', 1, 8, maxrows, 8]})\n",
    "chart6plus.add_series({\n",
    "        'name':       ['combined', 0, 16],\n",
    "        'categories': ['combined', 1, 3, maxrows, 3],\n",
    "        'values':     ['combined', 1, 16, maxrows, 16]})\n",
    "chart6plus.set_x_axis({'name': 'Time'})\n",
    "chart6plus.set_y_axis({'name': 'Persons', 'major_gridlines': {'visible': True}})\n",
    "chart6plus.set_size({'width': 1280, 'height': 576})\n",
    "chart6plus.set_title({'name': '6Mins+ Reach'})\n",
    "chart6plus.set_legend({'position': 'bottom'})\n",
    "worksheet.insert_chart('B'+str(chartloc), chart6plus) \n",
    "\n",
    "setmaxaxis = (np.floor(max(dfcombined['Reach_1_Live'])/200000)+1)*200000\n",
    "###create daily Programs Chart\n",
    "days = {0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\n",
    "for i in range(7):\n",
    "    dayrow_0 = rowindex['index'][i]+1\n",
    "    if (i==6)&(len(rowindex)==7):\n",
    "        dayrow_1 = len(dfcombined)\n",
    "    else:\n",
    "        dayrow_1 = rowindex['index'][(i+1)]\n",
    "    dayofweek = days[i]\n",
    "    chartloc = chartloc + 30\n",
    "    pgrams = dfschedule[dfschedule['dayofweek']==dayofweek]\n",
    "    pgrams = pgrams[['ProgramName']].drop_duplicates()\n",
    "    chartdaily = workbook.add_chart({'type': 'line'})\n",
    "    for i in pgrams['ProgramName']:\n",
    "        colloc_live =  programindex[i+'_Live']\n",
    "        colloc_shifted =  programindex[i+'_Shifted']\n",
    "        chartdaily.add_series({\n",
    "            'name':       ['promgrams', 0, colloc_live],\n",
    "            'categories': ['promgrams', dayrow_0, 2, dayrow_1, 2],\n",
    "            'values':     ['promgrams', dayrow_0, colloc_live, dayrow_1, colloc_live]})\n",
    "        chartdaily.add_series({\n",
    "            'name':       ['promgrams', 0, colloc_shifted],\n",
    "            'categories': ['promgrams', dayrow_0, 2, dayrow_1, 2],\n",
    "            'values':     ['promgrams', dayrow_0, colloc_shifted, dayrow_1, colloc_shifted]})\n",
    "    chartdaily.set_y_axis({'name': 'Persons', \n",
    "                           'major_gridlines': {'visible': True},\n",
    "                           'max': setmaxaxis,'min': 0})\n",
    "    chartdaily.set_size({'width': 1280, 'height': 576})\n",
    "    chartdaily.set_title({'name': dayofweek + ' Programs'})\n",
    "    chartdaily.set_legend({'position': 'bottom'})\n",
    "    worksheet.insert_chart('B'+str(chartloc), chartdaily)\n",
    "    \n",
    "setmaxaxis = (np.floor(max(dfcombined['Gain_1_Live'])/50000)+1)*50000\n",
    "setminaxis = (np.floor(min(dfcombined['Lost_1_Live']+1)/50000))*50000\n",
    "###create gain Chart\n",
    "days = {0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\n",
    "for i in range(7):\n",
    "    dayrow_0 = rowindex['index'][i]+1\n",
    "    if (i==6)&(len(rowindex)==7):\n",
    "        dayrow_1 = len(dfcombined)\n",
    "    else:\n",
    "        dayrow_1 = rowindex['index'][(i+1)]\n",
    "    dayofweek = days[i]\n",
    "    chartloc = chartloc + 30\n",
    "    chartgain = workbook.add_chart({'type': 'column'})\n",
    "    chartgain.add_series({\n",
    "        'name':       ['combined', 0, 5],\n",
    "        'categories': ['combined', dayrow_0, 3, dayrow_1, 3],\n",
    "        'values':     ['combined', dayrow_0, 5, dayrow_1, 5],\n",
    "        'gap':        20})\n",
    "    chartgain.add_series({\n",
    "        'name':       ['combined', 0, 6],\n",
    "        'categories': ['combined', dayrow_0, 3, dayrow_1, 3],\n",
    "        'values':     ['combined', dayrow_0, 6, dayrow_1, 6],\n",
    "        'gap':        20})\n",
    "    chartgain.set_y_axis({'name': 'Persons', \n",
    "                          'major_gridlines': {'visible': True},\n",
    "                          'max': setmaxaxis,'min': setminaxis,\n",
    "                          'major_unit': 25000,\n",
    "                          'label_position': 'low'})\n",
    "    chartgain.set_size({'width': 1280, 'height': 576})\n",
    "    chartgain.set_title({'name': dayofweek + ' Gain/Lost 1Mins+'})\n",
    "    chartgain.set_legend({'position': 'bottom'})\n",
    "    worksheet.insert_chart('B'+str(chartloc), chartgain)\n",
    "    chartloc = chartloc + 30\n",
    "    chartnet = workbook.add_chart({'type': 'column'})\n",
    "    chartnet.add_series({\n",
    "        'name':       ['combined', 0, 7],\n",
    "        'categories': ['combined', dayrow_0, 3, dayrow_1, 3],\n",
    "        'values':     ['combined', dayrow_0, 7, dayrow_1, 7],\n",
    "        'gap':        20})\n",
    "    chartnet.set_y_axis({'name': 'Persons', \n",
    "                         'major_gridlines': {'visible': True},\n",
    "                         'max': setmaxaxis,'min': setminaxis,\n",
    "                         'major_unit': 25000,\n",
    "                         'label_position': 'low'})\n",
    "    chartnet.set_size({'width': 1280, 'height': 576})\n",
    "    chartnet.set_title({'name': dayofweek + ' Net 1Mins+'})\n",
    "    chartnet.set_legend({'position': 'bottom'})\n",
    "    worksheet.insert_chart('B'+str(chartloc), chartnet)\n",
    "\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def programgainlost(qualifiedmins, dfminsall, dfintab):\n",
    "    df = dfminsall[dfminsall['mins']>=qualifiedmins]\n",
    "    dftotal = df[['HHID_PersonID', 'NetworkName',\n",
    "                  'ProgramID','TelecastN']].drop_duplicates()\n",
    "    dftotal = pd.merge(dftotal,dfintab, on= 'HHID_PersonID' )\n",
    "    dftotal = dftotal.groupby(['NetworkName',\n",
    "                               'ProgramID','TelecastN']).sum()\n",
    "    dftotal.columns =['UniqueReach_'+str(qualifiedmins)]\n",
    "    dftotal.reset_index(inplace = True)\n",
    "    dftotal2 = df[['HHID_PersonID', 'NetworkName',\n",
    "                   'ProgramID','TelecastN','playbacksegments']].drop_duplicates()\n",
    "    dftotal2 = pd.merge(dftotal2,dfintab, on= 'HHID_PersonID' )\n",
    "    dftotal2 = dftotal2.groupby(['NetworkName',\n",
    "              'ProgramID','TelecastN','playbacksegments']).sum().unstack('playbacksegments')\n",
    "    dftotal2.columns =['UniqueLiveReach_'+str(qualifiedmins),\n",
    "                       'UniqueShiftedReach_'+str(qualifiedmins)]\n",
    "    dftotal2.reset_index(inplace = True)\n",
    "    dftotal2.fillna(0,inplace = True)\n",
    "    gain = df[['HHID_PersonID','Date','Time','NetworkName']]\n",
    "    gain.loc[:,'gain'] = 1\n",
    "    gain.loc[:,'Time'] = np.where(gain['Time']%100 == 59,\n",
    "                                gain['Time'] + 41,\n",
    "                                gain['Time'] + 1)\n",
    "    gain = pd.merge(df[['HHID_PersonID','Date','Time',\n",
    "                        'NetworkName','ProgramID','TelecastN']], gain, \n",
    "                    on = ['HHID_PersonID','Date','Time','NetworkName'],\n",
    "                    how = 'left')\n",
    "    gain.fillna(0, inplace = True)\n",
    "    gain = gain[gain['gain'] == 0]\n",
    "    gain = gain.drop_duplicates(['NetworkName','ProgramID',\n",
    "                                 'TelecastN','HHID_PersonID'])\n",
    "    gain = pd.merge(gain,dfintab, on= 'HHID_PersonID' )\n",
    "    gain = gain[['NetworkName','ProgramID',\n",
    "                 'TelecastN','PersonIntab']].groupby(['NetworkName','ProgramID',\n",
    "                 'TelecastN']).sum()\n",
    "    gain.columns =['Gain_'+str(qualifiedmins)]\n",
    "    gain.reset_index(inplace = True)\n",
    "    lost = df[['HHID_PersonID','NetworkName','ProgramID','TelecastN','ViewEndTime','EpisodeDuration']]\n",
    "    lost = lost.sort_values(['HHID_PersonID','NetworkName','ProgramID','TelecastN','ViewEndTime'],\n",
    "                            ascending = [1,1,1,1,0])\n",
    "    lost = lost.drop_duplicates(['HHID_PersonID','NetworkName','ProgramID','TelecastN'])\n",
    "    lost = lost[lost['ViewEndTime']!=lost['EpisodeDuration']]\n",
    "    lost = pd.merge(lost,dfintab, on= 'HHID_PersonID' )\n",
    "    lost = lost[['NetworkName','ProgramID',\n",
    "                 'TelecastN','PersonIntab']].groupby(['NetworkName','ProgramID',\n",
    "                 'TelecastN']).sum()\n",
    "    lost.columns =['Lost_'+str(qualifiedmins)]\n",
    "    lost.reset_index(inplace = True)\n",
    "    finalreport = pd.merge(dftotal, dftotal2,\n",
    "                           on = ['NetworkName','ProgramID','TelecastN'],\n",
    "                           how='outer')\n",
    "    finalreport = pd.merge(finalreport, gain,\n",
    "                           on = ['NetworkName','ProgramID','TelecastN'],\n",
    "                           how='outer')\n",
    "    finalreport = pd.merge(finalreport, lost, \n",
    "                           on = ['NetworkName','ProgramID','TelecastN'],\n",
    "                           how='outer')\n",
    "    finalreport.fillna(0, inplace = True)\n",
    "    finalreport.loc[:,'Lost_' + str(qualifiedmins)] = -finalreport['Lost_' + str(qualifiedmins)]\n",
    "    finalreport.loc[:,'Net_' + str(qualifiedmins)] = finalreport['Gain_' + str(qualifiedmins)] +\\\n",
    "                                               finalreport['Lost_' + str(qualifiedmins)]\n",
    "    return finalreport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pandas/core/indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    }
   ],
   "source": [
    "####create summary table for excel \n",
    "df1 = programgainlost(1, dfall, dfintab)\n",
    "df6 = programgainlost(6, dfall, dfintab)#function3036.\n",
    "dfwleadin = pd.merge(df1, df6, on=['NetworkName', 'ProgramID',\n",
    "                     'TelecastN'],how='outer')\n",
    "del (df1, df6)\n",
    "\n",
    "df1 = programgainlost(1, dfexclleadin, dfintab)#function3036.\n",
    "df6 = programgainlost(6, dfexclleadin, dfintab)#function3036.\n",
    "dfnl = pd.merge(df1, df6, on=['NetworkName', 'ProgramID',\n",
    "                     'TelecastN'],how='outer')\n",
    "newcol = ['NetworkName', 'ProgramID', 'TelecastN']\n",
    "for i in dfnl.columns[3:15]:\n",
    "    j = i + '_nl'\n",
    "    newcol.append(j)\n",
    "dfnl.columns = newcol\n",
    "del (df1, df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsummary1 = pd.merge(dfwleadin,dfnl,on=['NetworkName', 'ProgramID',\n",
    "                      'TelecastN'],how='outer')\n",
    "dfsummary1.fillna(0,inplace = True)\n",
    "\n",
    "dfsummary1 = pd.merge(dfsummary1, \n",
    "                      type30[['NetworkName', 'ProgramID','TelecastN',\n",
    "                             'ProgramName','EpisodeName','EpisodeDuration',\n",
    "                             'PremiereIndicator','RepeatIndicator','ProgramDate',\n",
    "                             'BroadcastStartTime','BroadcastEndTime',\n",
    "                             'Programtypesummarycode']],\n",
    "                      on=['NetworkName', 'ProgramID','TelecastN'])\n",
    "#dfsummary1['ProgramName'] = np.where(dfsummary1['Programtypesummarycode'] =='FF',\n",
    "#                                    'MOVIES: ' + dfsummary1['EpisodeName'],\n",
    "#                                   dfsummary1['ProgramName'])\n",
    "\n",
    "dfsummary1 = dfsummary1[['NetworkName', 'ProgramID','TelecastN',\n",
    "                         'ProgramName','EpisodeName','EpisodeDuration',\n",
    "                         'PremiereIndicator','RepeatIndicator','ProgramDate',\n",
    "                         'BroadcastStartTime','BroadcastEndTime',\n",
    "                         'UniqueReach_1','UniqueLiveReach_1','UniqueShiftedReach_1','Net_1',\n",
    "                         'UniqueReach_6','UniqueLiveReach_6','UniqueShiftedReach_6','Net_6',\n",
    "                         'UniqueReach_1_nl','UniqueLiveReach_1_nl','UniqueShiftedReach_1_nl','Net_1_nl',\n",
    "                         'UniqueReach_6_nl','UniqueLiveReach_6_nl','UniqueShiftedReach_6_nl','Net_6_nl']]\n",
    "dfsummary1['TotalRatio6_1'] = dfsummary1['UniqueReach_6']/dfsummary1['UniqueReach_1']\n",
    "dfsummary1 = dfsummary1.sort_values(['ProgramDate','ProgramName','BroadcastStartTime'],\n",
    "                                    ascending = True)\n",
    "dfsummary1['DayofWeek'] = dfsummary1['ProgramDate'].dt.dayofweek\n",
    "days2 = {0:'Monday',1:'Tuesday',2:'Wednesday',3:'Thursday',4:'Friday',5:'Saturday',6:'Sunday'}\n",
    "dfsummary1['DayofWeek'] = dfsummary1['DayofWeek'].apply(lambda x: days2[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfall['ProgramFinal'] = dfall['ProgramName']\n",
    "#np.where(dfall['Programtypesummarycode'] =='FF',\n",
    "#                                    'MOVIES: ' + dfall['EpisodeName'],\n",
    "#                                    dfall['ProgramName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfexclleadin['ProgramFinal'] = dfexclleadin['ProgramName']\n",
    "#np.where(dfexclleadin['Programtypesummarycode'] =='FF',\n",
    "#'MOVIES: ' + dfexclleadin['EpisodeName'],\n",
    "#                                   dfexclleadin['ProgramName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "###select fringe program from summary1\n",
    "dfsummary1fringe = dfsummary1[(dfsummary1['BroadcastStartTime']>=1600)&(dfsummary1['BroadcastStartTime']<2200)]\n",
    "dfsummary1fringe['ProgramName'] = dfsummary1fringe['DayofWeek'] +':'+ dfsummary1fringe['ProgramName']\n",
    "dfsummary1fringe.loc[:,'ProgramDate'] = dfsummary1fringe['ProgramDate'].astype('str')\n",
    "dfsummary1fringe.loc[:,'BroadcastStartTime'] = dfsummary1fringe['BroadcastStartTime'].astype('str')\n",
    "dfsummary1fringe.loc[:,'BroadcastStartTime'] = dfsummary1fringe['BroadcastStartTime'].apply(lambda x:x.zfill(4))\n",
    "dfsummary1fringe.loc[:,'BroadcastStartTime'] = dfsummary1fringe['BroadcastStartTime'].str[0:2] + ':' \\\n",
    "                      + dfsummary1fringe['BroadcastStartTime'].str[2:4]\n",
    "dfsummary1fringe.loc[:,'ProgramDateTime'] = dfsummary1fringe['ProgramDate'].str[5:10] + ' ' \\\n",
    "                      + dfsummary1fringe['BroadcastStartTime'].astype('str')\n",
    "dfsummary1fringe.loc[:,'BroadcastEndTime'] = dfsummary1fringe['BroadcastEndTime'].astype('str')\n",
    "dfsummary1fringe.loc[:,'BroadcastEndTime'] = dfsummary1fringe['BroadcastEndTime'].apply(lambda x:x.zfill(4))\n",
    "dfsummary1fringe.loc[:,'BroadcastEndTime'] = dfsummary1fringe['BroadcastEndTime'].str[0:2] + ':' \\\n",
    "                      + dfsummary1fringe['BroadcastEndTime'].str[2:4]\n",
    "    \n",
    "programlist = dfsummary1fringe[['ProgramName']]\n",
    "programlist = programlist.reset_index(drop = True)\n",
    "programlist.reset_index(inplace = True)\n",
    "programlist = programlist.drop_duplicates('ProgramName')\n",
    "programlist.columns = ['rowindex','ProgramName']\n",
    "programlist = programlist.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(folderpath+'ProgramOutput2 '+mindate+'_LIF.xlsx',\n",
    "                        engine='xlsxwriter',\n",
    "                        datetime_format='yyyy-mm-dd',\n",
    "                        date_format='yyyy-mm-dd')\n",
    "dfsummary1.to_excel(writer,'Episode & Telecast', index=False)\n",
    "dfsummary1fringe.to_excel(writer,'FringeTelecast', index=False)\n",
    "\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Episode & Telecast']\n",
    "\n",
    "format1 = workbook.add_format({'num_format': '#,##0'})\n",
    "format2 = workbook.add_format({'text_wrap' : True})\n",
    "format3 = workbook.add_format({'num_format': '0.0%' , 'bg_color': '#D6EAF8'})\n",
    "format4 = workbook.add_format({'num_format': '#,##0,\"K\"', 'bg_color': '#FCF3CF'})\n",
    "\n",
    "worksheet.set_column('L:AA', 12, format1)\n",
    "worksheet.set_row(0,None, format2)\n",
    "worksheet.set_column('AB:AB', None, format3)\n",
    "worksheet.set_column('I:I', 12, None)\n",
    "\n",
    "worksheet = writer.sheets['FringeTelecast']\n",
    "worksheet.set_column('L:AA', 12, format4)\n",
    "worksheet.set_row(0,None, format2)\n",
    "worksheet.set_column('AB:AB', None, format3)\n",
    "\n",
    "\n",
    "worksheet = workbook.add_worksheet('Shows Detail Charts')\n",
    "\n",
    "chartloc = 2\n",
    "for i in range(len(programlist.index)):\n",
    "    dayrow_0 = programlist['rowindex'][i]+1\n",
    "    if i!=(len(programlist.index) - 1):\n",
    "        dayrow_1 = programlist['rowindex'][(i+1)]\n",
    "    else:\n",
    "        dayrow_1 = len(dfsummary1fringe)-1\n",
    "    programname = programlist['ProgramName'][i]\n",
    "    ###reach chart\n",
    "    chartreach = workbook.add_chart({'type': 'column', 'subtype': 'stacked'})\n",
    "    chartreach.add_series({\n",
    "        'name':       'Live 1+',\n",
    "        'categories': ['FringeTelecast', dayrow_0, 29, dayrow_1, 29],\n",
    "        'values':     ['FringeTelecast', dayrow_0, 12, dayrow_1, 12],\n",
    "        'data_labels': {'value': True}})\n",
    "    chartreach.add_series({\n",
    "        'name':       'Shifted 1+',\n",
    "        'categories': ['FringeTelecast', dayrow_0, 29, dayrow_1, 29],\n",
    "        'values':     ['FringeTelecast', dayrow_0, 13, dayrow_1, 13],\n",
    "        'data_labels': {'value': True}})\n",
    "    chartreach.set_y_axis({'name': 'Total Reach 1Mins+', \n",
    "                           'major_gridlines': {'visible': False},\n",
    "                           'min': 0})\n",
    "    chartreach.set_size({'width': 560, 'height': 476})\n",
    "    chartreach.set_title({'name': programname + ' Total Reach 1Mins+'})\n",
    "    chartreach.set_legend({'position': 'bottom'})\n",
    "    worksheet.insert_chart('B'+str(chartloc), chartreach)\n",
    "    ###reach chart6\n",
    "    chartreach6 = workbook.add_chart({'type': 'column', 'subtype': 'stacked'})\n",
    "    chartreach6.add_series({\n",
    "        'name':       'Live 6+',\n",
    "        'categories': ['FringeTelecast', dayrow_0, 29, dayrow_1, 29],\n",
    "        'values':     ['FringeTelecast', dayrow_0, 16, dayrow_1, 16],\n",
    "        'data_labels': {'value': True}})\n",
    "    chartreach6.add_series({\n",
    "        'name':       'Shifted 6+',\n",
    "        'categories': ['FringeTelecast', dayrow_0, 29, dayrow_1, 29],\n",
    "        'values':     ['FringeTelecast', dayrow_0, 17, dayrow_1, 17],\n",
    "        'data_labels': {'value': True}})\n",
    "    chartreach6.set_y_axis({'name': 'Total Reach 6Mins+', \n",
    "                            'major_gridlines': {'visible': False},\n",
    "                            'min': 0})\n",
    "    chartreach6.set_size({'width': 560, 'height': 476})\n",
    "    chartreach6.set_title({'name': programname + ' Total Reach 6Mins+'})\n",
    "    chartreach6.set_legend({'position': 'bottom'})\n",
    "    worksheet.insert_chart('L'+str(chartloc), chartreach6)\n",
    "    ###ratio\n",
    "    chartratio = workbook.add_chart({'type': 'column'})\n",
    "    chartratio.add_series({\n",
    "        'name':       'Total Ratio 6+/1+',\n",
    "        'categories': ['FringeTelecast', dayrow_0, 29, dayrow_1, 29],\n",
    "        'values':     ['FringeTelecast', dayrow_0, 27, dayrow_1, 27],\n",
    "        'data_labels': {'value': True}})    \n",
    "    chartratio.set_y_axis({'major_gridlines': {'visible': False},\n",
    "                           'min': 0})\n",
    "    chartratio.set_size({'width': 560, 'height': 476})\n",
    "    chartratio.set_title({'name': programname + ' Total Ratio 6+/1+'})\n",
    "    chartratio.set_legend({'position': 'bottom'})\n",
    "    worksheet.insert_chart('U'+str(chartloc), chartratio)\n",
    "    ###net\n",
    "    chartnet = workbook.add_chart({'type': 'column'})\n",
    "    chartnet.add_series({\n",
    "        'name':       'Total Net 1Min+',\n",
    "        'categories': ['FringeTelecast', dayrow_0, 29, dayrow_1, 29],\n",
    "        'values':     ['FringeTelecast', dayrow_0, 14, dayrow_1, 14],\n",
    "        'data_labels': {'value': True}})\n",
    "    chartnet.add_series({\n",
    "        'name':       'Total Net 1Min+ Excl. Leadin',\n",
    "        'categories': ['FringeTelecast', dayrow_0, 29, dayrow_1, 29],\n",
    "        'values':     ['FringeTelecast', dayrow_0, 22, dayrow_1, 22],\n",
    "        'data_labels': {'value': True}}) \n",
    "    chartnet.set_y_axis({'major_gridlines': {'visible': False},\n",
    "                         #'min': 0\n",
    "                         })\n",
    "    chartnet.set_size({'width': 560, 'height': 476})\n",
    "    chartnet.set_title({'name': programname + ' Total Net'})\n",
    "    chartnet.set_legend({'position': 'bottom'})\n",
    "    worksheet.insert_chart('AD'+str(chartloc), chartnet)\n",
    "    chartloc = chartloc + 26\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getaffinity(dfall,dfintab,colname):\n",
    "    dfsub1 = dfall[['HHID_PersonID',colname]].drop_duplicates()\n",
    "    dfsub1['Metric'] = 'Reach'\n",
    "    dfsub1 = pd.merge(dfsub1,dfintab,on='HHID_PersonID')\n",
    "    dfsuball = dfsub1.groupby([colname]).sum()\n",
    "    dfsuball.reset_index(inplace=True)\n",
    "    dfsub2 = dfall[['HHID_PersonID',colname]].drop_duplicates()    \n",
    "    dfsub2.columns = ['HHID_PersonID','y']\n",
    "    dfsub = pd.merge(dfsub1,dfsub2,on='HHID_PersonID')\n",
    "    dfsub = dfsub.groupby(['Metric',colname,'y']).sum().unstack('y')\n",
    "    dfsub.columns = dfsub.columns.get_level_values(1)\n",
    "    dfsub.reset_index(inplace=True)\n",
    "    dfsubpct = pd.merge(dfsub,dfsuball,on=i)\n",
    "    colrank = []\n",
    "    for a in dfsub.columns:\n",
    "        colrank.append(a)\n",
    "    cols = dfsub1[[colname]].drop_duplicates()\n",
    "    for j in cols[colname]:\n",
    "        dfsubpct[j]=dfsubpct[j]/dfsubpct['PersonIntab']\n",
    "    del dfsubpct['PersonIntab']\n",
    "    dfsubpct['Metric'] = 'Percent Reach'\n",
    "    dfaffinity = dfsub.append(dfsubpct,ignore_index=True)\n",
    "    dfaffinity = dfaffinity[colrank]\n",
    "    return dfaffinity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall['Hour'] = dfall['Hour'].astype('str')\n",
    "dfall['Hour'] = dfall['Hour'].apply(lambda x:x.zfill(2))\n",
    "dfall['Hour'] = dfall['Hour']+ ':00'\n",
    "dfexclleadin['Hour'] = dfexclleadin['Hour'].astype('str')\n",
    "dfexclleadin['Hour'] = dfexclleadin['Hour'].apply(lambda x:x.zfill(2))\n",
    "dfexclleadin['Hour'] = dfexclleadin['Hour']+ ':00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "type30['ProgramFinal'] = type30['ProgramName']\n",
    "#np.where(type30['Programtypesummarycode'] =='FF',\n",
    "#                                    'MOVIES: ' + type30['EpisodeName'],\n",
    "#                                    type30['ProgramName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "showrank = type30[['ProgramFinal']].drop_duplicates()\n",
    "showrank = showrank.reset_index(drop = True)\n",
    "showrank.reset_index(inplace = True)\n",
    "showrank.columns = ['programrank','ProgramFinal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showrankrow = ['Metric','ProgramFinal']\n",
    "for i in showrank['ProgramFinal']:\n",
    "    showrankrow.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfall['ProgramTelecast'] = dfall['ProgramDate'].astype('str') + ' ' + dfall['ProgramFinal']\n",
    "dfexclleadin['ProgramTelecast'] = dfexclleadin['ProgramDate'].astype('str') + ' ' + dfexclleadin['ProgramFinal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricrank = {'Percent Reach 1Mins +': 1,\n",
    " 'Percent Reach 6Mins +': 3,\n",
    " 'Percent Reach Excl. Leadin 1Mins +': 5,\n",
    " 'Percent Reach Excl. Leadin 6Mins +': 7,\n",
    " 'Reach 1Mins +': 0,\n",
    " 'Reach 6Mins +': 2,\n",
    " 'Reach Excl. Leadin 1Mins +': 4,\n",
    " 'Reach Excl. Leadin 6Mins +': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfintab = dfall[['HHID_PersonID','PersonIntab','Date']].drop_duplicates()\n",
    "dfintab = dfintab.groupby('HHID_PersonID').mean()\n",
    "dfintab.reset_index(inplace = True)\n",
    "df26plus = dfall[dfall['mins']>=6]\n",
    "dfexclleadin6plus = dfexclleadin[dfexclleadin['mins']>=6]\n",
    "\n",
    "for i in ['ProgramFinal','Day','Hour']:#: \n",
    "    dfreach1 = getaffinity(dfall,dfintab,i)\n",
    "    dfreach1['Metric'] = dfreach1['Metric'] + ' 1Mins +'\n",
    "    colrank = []\n",
    "    for a in dfreach1.columns:\n",
    "        colrank.append(a)    \n",
    "    dfreach6 = getaffinity(df26plus,dfintab,i)\n",
    "    dfreach6['Metric'] = dfreach6['Metric'] + ' 6Mins +'\n",
    "    dfreach1nl = getaffinity(dfexclleadin,dfintab,i)\n",
    "    dfreach1nl['Metric'] = dfreach1nl['Metric'] + ' Excl. Leadin 1Mins +'\n",
    "    dfreach6nl = getaffinity(dfexclleadin6plus,dfintab,i)\n",
    "    dfreach6nl['Metric'] = dfreach6nl['Metric'] + ' Excl. Leadin 6Mins +'\n",
    "    dfaffinity = dfreach1.append(dfreach6,ignore_index=True)\n",
    "    dfaffinity = dfaffinity.append(dfreach1nl,ignore_index=True)\n",
    "    dfaffinity = dfaffinity.append(dfreach6nl,ignore_index=True)\n",
    "    del (dfreach1,dfreach6,dfreach1nl,dfreach6nl)\n",
    "    dfaffinity = dfaffinity[colrank]\n",
    "    dfaffinity.fillna(0,inplace = True)  \n",
    "    if i =='ProgramFinal':\n",
    "        dfaffinity = pd.merge(dfaffinity,showrank,on='ProgramFinal')\n",
    "        dfaffinity['metricrank'] = dfaffinity['Metric'].apply(lambda x : metricrank[x])\n",
    "        dfaffinity = dfaffinity.sort_values(['metricrank','programrank'], ascending = True)\n",
    "        dfaffinity = dfaffinity[showrankrow]\n",
    "    dfaffinity = dfaffinity.reset_index(drop = True)\n",
    "    affinityrank = dfaffinity[['Metric']]\n",
    "    affinityrank = affinityrank.reset_index(drop = True)\n",
    "    affinityrank.reset_index(inplace = True)\n",
    "    affinityrank.columns = ['rankindex','Metric']\n",
    "    affinityrank = affinityrank.drop_duplicates('Metric')\n",
    "    affinityrank = affinityrank.reset_index(drop = True)\n",
    "    dfaffinity.to_excel(writer,'Affinity_'+i, index=False)\n",
    "    worksheet = writer.sheets['Affinity_'+i]\n",
    "    worksheet.set_column('A:B', 15, None)\n",
    "    for j in range(8):\n",
    "        if j%2 ==0:\n",
    "            for k in range((affinityrank['rankindex'][j]),(affinityrank['rankindex'][j+1])):\n",
    "                worksheet.set_row(k+1,None, format4)\n",
    "        elif j==7:\n",
    "            for k in range((affinityrank['rankindex'][7]),len(dfaffinity.index)):\n",
    "                worksheet.set_row(k+1,None, format3)\n",
    "        else:\n",
    "            for k in range((affinityrank['rankindex'][j]),(affinityrank['rankindex'][j+1])):\n",
    "                worksheet.set_row(k+1,None, format3)\n",
    "    worksheet = workbook.add_worksheet('Affinity_'+i+'Charts')\n",
    "    chartloc = 2\n",
    "    cols = len(dfaffinity.columns) -1\n",
    "    affinityrank2 = dfaffinity[['Metric',i]]\n",
    "    affinityrank2 = affinityrank2.reset_index(drop = True)\n",
    "    affinityrank2.reset_index(inplace = True)\n",
    "    affinityrank2.columns = ['rankindex','Metric',i]\n",
    "    affinityrank3 = affinityrank2[affinityrank2['Metric'] == 'Reach Excl. Leadin 6Mins +']\n",
    "    for j in affinityrank3[i]:\n",
    "        rown1 = affinityrank2['rankindex'][(affinityrank2[i]==j)&(affinityrank2['Metric'] == 'Reach 6Mins +')].index.tolist()\n",
    "        rown2 = affinityrank2['rankindex'][(affinityrank2[i]==j)&(affinityrank2['Metric'] == 'Reach Excl. Leadin 6Mins +')].index.tolist()\n",
    "        rown1c = affinityrank2['rankindex'][(affinityrank2[i]==j)&(affinityrank2['Metric'] == 'Percent Reach 6Mins +')].index.tolist()\n",
    "        rown2c = affinityrank2['rankindex'][(affinityrank2[i]==j)&(affinityrank2['Metric'] == 'Percent Reach Excl. Leadin 6Mins +')].index.tolist()\n",
    "        rown1 = rown1[0] + 1\n",
    "        rown2 = rown2[0] + 1\n",
    "        rown1c = rown1c[0] + 1\n",
    "        rown2c = rown2c[0] + 1\n",
    "        chartcount = workbook.add_chart({'type': 'column'})\n",
    "        chartcount.add_series({\n",
    "            'name':       'Reach 6+',\n",
    "            'categories': ['Affinity_'+i, 0, 2, 0, cols],\n",
    "            'values':     ['Affinity_'+i, rown1, 2, rown1, cols],\n",
    "            #'data_labels': {'value': True}\n",
    "            })\n",
    "        chartcount.add_series({\n",
    "            'name':       'Reach 6+ Excl. Leandin',\n",
    "            'categories': ['Affinity_'+i, 0, 2, 0, cols],\n",
    "            'values':     ['Affinity_'+i, rown2, 2, rown2, cols],\n",
    "            #'data_labels': {'value': True}\n",
    "            })\n",
    "        chartcount.set_y_axis({'major_gridlines': {'visible': False}})\n",
    "        chartcount.set_size({'width': 560, 'height': 476})\n",
    "        chartcount.set_title({'name': 'Affinity '+dfaffinity[i][(rown1-1)]})\n",
    "        chartcount.set_legend({'position': 'bottom'})\n",
    "        worksheet.insert_chart('B'+str(chartloc), chartcount) \n",
    "        ##pct\n",
    "        chartcountc = workbook.add_chart({'type': 'column'})\n",
    "        chartcountc.add_series({\n",
    "            'name':       'pct Reach 6+',\n",
    "            'categories': ['Affinity_'+i, 0, 2, 0, cols],\n",
    "            'values':     ['Affinity_'+i, rown1c, 2, rown1c, cols],\n",
    "            #'data_labels': {'value': True}\n",
    "            })\n",
    "        chartcountc.add_series({\n",
    "            'name':       'pct Reach 6+ Excl. Leandin',\n",
    "            'categories': ['Affinity_'+i, 0, 2, 0, cols],\n",
    "            'values':     ['Affinity_'+i, rown2c, 2, rown2c, cols],\n",
    "            #'data_labels': {'value': True}\n",
    "            })\n",
    "        chartcountc.set_y_axis({'major_gridlines': {'visible': True},\n",
    "                                'max': 1})\n",
    "        chartcountc.set_size({'width': 560, 'height': 476})\n",
    "        chartcountc.set_title({'name': 'Affinity Pct ' + dfaffinity[i][(rown1-1)]})\n",
    "        chartcountc.set_legend({'position': 'bottom'})\n",
    "        worksheet.insert_chart('L'+str(chartloc), chartcountc)       \n",
    "        chartloc = chartloc + 30   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "type30['ProgramID_TelecastN'] = type30['ProgramID'] +'_' + type30['TelecastN']\n",
    "df_combinedall = pd.DataFrame()\n",
    "for i in range(10,24): \n",
    "    fringep_start17 = type30[['ProgramID_TelecastN','BroadcastStartTime','BroadcastEndTime','ProgramDate']]\n",
    "    fringep_start17 = fringep_start17[((fringep_start17['BroadcastStartTime']>=i*100)&\\\n",
    "                                  (fringep_start17['BroadcastStartTime']<=2400))]    \n",
    "    fringep_start171 = fringep_start17[(fringep_start17['BroadcastStartTime'].isin(range(i*100,(i+1)*100)))]\n",
    "    if len(fringep_start171.index)>0:\n",
    "        df1 = pd.merge(fringep_start171[['ProgramID_TelecastN','ProgramDate','BroadcastStartTime']],\n",
    "                       dfall[['HHID_PersonID','ProgramID_TelecastN','mins']],\n",
    "                       on = 'ProgramID_TelecastN')\n",
    "        df1_6plus = df1[df1['mins']>=6]\n",
    "        df1_6plus = df1_6plus.drop_duplicates(['HHID_PersonID','ProgramID_TelecastN'])\n",
    "        df1 = df1.drop_duplicates(['HHID_PersonID','ProgramID_TelecastN'])\n",
    "        df2 = pd.merge(fringep_start17,\n",
    "                       dfall[['HHID_PersonID','ProgramID_TelecastN','mins','ProgramFinal']],\n",
    "                       on = 'ProgramID_TelecastN')\n",
    "        df2_6plus = df2[df2['mins']>=6]\n",
    "        df2_6plus = df2_6plus.drop_duplicates(['HHID_PersonID','ProgramID_TelecastN'])\n",
    "        df2 = df2.drop_duplicates(['HHID_PersonID','ProgramID_TelecastN'])\n",
    "        df2 =  pd.merge(df1,df2,on =['ProgramDate','HHID_PersonID'])\n",
    "        df2 = df2[df2['BroadcastStartTime_x']<=df2['BroadcastStartTime_y']]\n",
    "        df2 = df2[['HHID_PersonID','ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                   'BroadcastEndTime','ProgramFinal']].drop_duplicates()\n",
    "        df2 = pd.merge(df2,dfintab,on = 'HHID_PersonID')\n",
    "        df2 = df2.groupby(['ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                   'BroadcastEndTime','ProgramFinal']).sum()\n",
    "        df2.columns = ['UniqueReach1+']\n",
    "        df2.reset_index(inplace = True)\n",
    "        df2_6plus =  pd.merge(df1_6plus,df2_6plus,on =['ProgramDate','HHID_PersonID'])\n",
    "        df2_6plus = df2_6plus[df2_6plus['BroadcastStartTime_x']<=df2_6plus['BroadcastStartTime_y']]\n",
    "        df2_6plus = df2_6plus[['HHID_PersonID','ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                   'BroadcastEndTime','ProgramFinal']].drop_duplicates()\n",
    "        df2_6plus = pd.merge(df2_6plus,dfintab,on = 'HHID_PersonID')\n",
    "        df2_6plus = df2_6plus.groupby(['ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                   'BroadcastEndTime','ProgramFinal']).sum()\n",
    "        df2_6plus.columns = ['UniqueReach6+']\n",
    "        df2_6plus.reset_index(inplace = True)\n",
    "        df1 = pd.merge(df1,dfintab,on = 'HHID_PersonID')\n",
    "        df1 = df1[['ProgramDate','BroadcastStartTime','PersonIntab']].groupby(['ProgramDate','BroadcastStartTime']).sum()\n",
    "        df1.columns = ['total1mins']\n",
    "        df1_6plus = pd.merge(df1_6plus,dfintab,on = 'HHID_PersonID')\n",
    "        df1_6plus = df1_6plus[['ProgramDate','BroadcastStartTime','PersonIntab']].groupby(['ProgramDate','BroadcastStartTime']).sum()\n",
    "        df1_6plus.columns = ['total6mins']\n",
    "        df1.reset_index(inplace = True)\n",
    "        df1_6plus.reset_index(inplace = True)\n",
    "        df1el = pd.merge(fringep_start171[['ProgramID_TelecastN','ProgramDate','BroadcastStartTime']],\n",
    "                       dfexclleadin[['HHID_PersonID','ProgramID_TelecastN','mins']],\n",
    "                       on = 'ProgramID_TelecastN')\n",
    "        df1el_6plus = df1el[df1el['mins']>=6]\n",
    "        df1el_6plus = df1el_6plus.drop_duplicates(['HHID_PersonID','ProgramID_TelecastN'])\n",
    "        df1el = df1el.drop_duplicates(['HHID_PersonID','ProgramID_TelecastN'])\n",
    "        df2el = pd.merge(fringep_start17,\n",
    "                       dfexclleadin[['HHID_PersonID','ProgramID_TelecastN','mins','ProgramFinal']],\n",
    "                       on = 'ProgramID_TelecastN')\n",
    "        df2el_6plus = df2el[df2el['mins']>=6]\n",
    "        df2el_6plus = df2el_6plus.drop_duplicates(['HHID_PersonID','ProgramID_TelecastN'])\n",
    "        df2el = df2el.drop_duplicates(['HHID_PersonID','ProgramID_TelecastN'])\n",
    "        df2el =  pd.merge(df1el,df2el,on =['ProgramDate','HHID_PersonID'])\n",
    "        df2el = df2el[df2el['BroadcastStartTime_x']<=df2el['BroadcastStartTime_y']]\n",
    "        df2el = df2el[['HHID_PersonID','ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                   'BroadcastEndTime','ProgramFinal']].drop_duplicates()\n",
    "        df2el = pd.merge(df2el,dfintab,on = 'HHID_PersonID')\n",
    "        df2el = df2el.groupby(['ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                   'BroadcastEndTime','ProgramFinal']).sum()\n",
    "        df2el.columns = ['UniqueNewReach1+']\n",
    "        df2el.reset_index(inplace = True)\n",
    "        df2el_6plus =  pd.merge(df1el_6plus,df2el_6plus,on =['ProgramDate','HHID_PersonID'])\n",
    "        df2el_6plus = df2el_6plus[df2el_6plus['BroadcastStartTime_x']<=df2el_6plus['BroadcastStartTime_y']]\n",
    "        df2el_6plus = df2el_6plus[['HHID_PersonID','ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                   'BroadcastEndTime','ProgramFinal']].drop_duplicates()\n",
    "        df2el_6plus = pd.merge(df2el_6plus,dfintab,on = 'HHID_PersonID')\n",
    "        df2el_6plus = df2el_6plus.groupby(['ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                   'BroadcastEndTime','ProgramFinal']).sum()\n",
    "        df2el_6plus.columns = ['UniqueNewReach6+']\n",
    "        df2el_6plus.reset_index(inplace = True)\n",
    "        df_combined = pd.merge(df2,df2_6plus,on =['ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                           'BroadcastEndTime','ProgramFinal'],how= 'outer')\n",
    "        df_combined = pd.merge(df_combined,df2el,on =['ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                           'BroadcastEndTime','ProgramFinal'],how= 'outer')\n",
    "        df_combined = pd.merge(df_combined,df2el_6plus,on =['ProgramDate','BroadcastStartTime_x','BroadcastStartTime_y',\n",
    "                           'BroadcastEndTime','ProgramFinal'],how= 'outer')\n",
    "        df_combined = df_combined.rename(columns = {'BroadcastStartTime_x':'BroadcastStartTime'})\n",
    "        df_combined = pd.merge(df_combined,df1,on =['ProgramDate','BroadcastStartTime'],how= 'outer')\n",
    "        df_combined = pd.merge(df_combined,df1_6plus,on =['ProgramDate','BroadcastStartTime'],how= 'outer')\n",
    "        df_combined.fillna(0,inplace = True)\n",
    "        df_combined['pcttotal'] = df_combined['UniqueReach1+']/df_combined['total1mins']\n",
    "        df_combined['UniqueReach6+pcttotal'] = df_combined['UniqueReach6+']/df_combined['total1mins']\n",
    "        #\n",
    "        df_combined['UniqueNewReach1+pcttotal'] = df_combined['UniqueNewReach1+']/df_combined['total1mins']\n",
    "        df_combined['Rollingpcttotal'] = df_combined['UniqueNewReach1+']/df_combined['UniqueReach1+']\n",
    "        #\n",
    "        df_combined['UniqueNewReach6+pcttotal'] = df_combined['UniqueNewReach6+']/df_combined['total6mins']\n",
    "        df_combined['Rollingpcttotal6'] = df_combined['UniqueNewReach6+']/df_combined['UniqueReach6+']\n",
    "        #\n",
    "        df_combined['UniqueLeadinReach1+'] = df_combined['UniqueReach1+'] - df_combined['UniqueNewReach1+']\n",
    "        df_combined['UniqueLeadinReach1+pcttotal'] = df_combined['UniqueLeadinReach1+']/df_combined['total1mins']\n",
    "        df_combined['UniqueLeadinReach1+Rollingpcttotal'] = df_combined['UniqueLeadinReach1+']/df_combined['UniqueReach1+']\n",
    "        #\n",
    "        df_combined['UniqueLeadinReach6+'] = df_combined['UniqueReach6+'] - df_combined['UniqueNewReach6+']\n",
    "        df_combined['UniqueLeadinReach6+pcttotal'] = df_combined['UniqueLeadinReach6+']/df_combined['total6mins']\n",
    "        df_combined['UniqueLeadinReach6+Rollingpcttotal'] = df_combined['UniqueLeadinReach6+']/df_combined['UniqueReach6+']\n",
    "        df_combined = df_combined.rename(columns = {'BroadcastStartTime':'BaseStartTime'})\n",
    "        df_combined = df_combined.rename(columns = {'BroadcastStartTime_y':'BroadcastStartTime'})\n",
    "        df_combined.fillna(0,inplace = True)\n",
    "        df_combined = df_combined[['ProgramDate', 'BaseStartTime', 'BroadcastStartTime',\n",
    "                                   'BroadcastEndTime', 'ProgramFinal','UniqueReach1+','pcttotal',\n",
    "                                   'UniqueReach6+','UniqueReach6+pcttotal','UniqueNewReach1+',\n",
    "                                   'UniqueNewReach1+pcttotal', 'Rollingpcttotal',\n",
    "                                   'UniqueNewReach6+','UniqueNewReach6+pcttotal', 'Rollingpcttotal6',\n",
    "                                   'UniqueLeadinReach1+', 'UniqueLeadinReach1+pcttotal',\n",
    "                                   'UniqueLeadinReach1+Rollingpcttotal', 'UniqueLeadinReach6+',\n",
    "                                   'UniqueLeadinReach6+pcttotal', 'UniqueLeadinReach6+Rollingpcttotal']]\n",
    "        df_combinedall = df_combinedall.append(df_combined,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(folderpath+'ProgramOutput3 '+mindate+'.xlsx',\n",
    "                        engine='xlsxwriter',\n",
    "                        datetime_format='yyyy-mm-dd',\n",
    "                        date_format='yyyy-mm-dd')\n",
    "df_combinedall.to_excel(writer,'Audience Retention', index=False)\n",
    "\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Audience Retention']\n",
    "\n",
    "format1 = workbook.add_format({'num_format': '#,##0'})\n",
    "format2 = workbook.add_format({'text_wrap' : True})\n",
    "format3 = workbook.add_format({'num_format': '0.0%'})\n",
    "\n",
    "worksheet.set_row(0,None, format2)\n",
    "worksheet.set_column('F:U', 12, format1)\n",
    "worksheet.set_column('G:G', None, format3)\n",
    "worksheet.set_column('I:I', None, format3)\n",
    "worksheet.set_column('K:L', None, format3)\n",
    "worksheet.set_column('N:O', None, format3)\n",
    "worksheet.set_column('Q:R', None, format3)\n",
    "worksheet.set_column('T:U', None, format3)\n",
    "worksheet.set_column('A:A', 12, None)\n",
    "worksheet.set_column('E:E', 16, None)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fringep_start17 = type30[['ProgramID','TelecastN','ProgramName','BroadcastStartTime','BroadcastEndTime','ProgramDate']]\n",
    "fringep_start17 = fringep_start17[((fringep_start17['BroadcastStartTime']>=1000)&\\\n",
    "                                  (fringep_start17['BroadcastStartTime']<=2400))|\\\n",
    "                                 ((fringep_start17['BroadcastEndTime']>=1000)&\\\n",
    "                                  (fringep_start17['BroadcastEndTime']<=2400))]\n",
    "\n",
    "fringep_start17['ProgramID_TelecastN'] = fringep_start17['ProgramID'] +'_' +\\\n",
    "                                         fringep_start17['TelecastN']\n",
    "fringep_start17_1 = fringep_start17.drop_duplicates('ProgramDate')\n",
    "fringep_start17_1list = []\n",
    "for i in fringep_start17_1['ProgramID_TelecastN']:\n",
    "    fringep_start17_1list.append(i)\n",
    "fringep_start17list = []\n",
    "for i in fringep_start17['ProgramID_TelecastN']:\n",
    "    fringep_start17list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fringep_start17_1 = dfall[dfall['ProgramID_TelecastN'].isin(fringep_start17_1list)]\n",
    "fringep_start17_1 = fringep_start17_1[['HHID_PersonID',\n",
    "                                       'ProgramDate']].drop_duplicates()\n",
    "fringep_start17_1 = pd.merge(fringep_start17_1,dfintab, on = 'HHID_PersonID')\n",
    "\n",
    "fringep_start17_1.columns  = ['HHID_PersonID','ProgramDate','uniquereach1']\n",
    "\n",
    "fringep_start17 = dfall[dfall['ProgramID_TelecastN'].isin(fringep_start17list)]\n",
    "fringep_start17 = fringep_start17.drop_duplicates(['ProgramDate','BroadcastStartTime',\n",
    "                                    'BroadcastEndTime', 'ProgramFinal','HHID_PersonID'])\n",
    "fringep_start17 = pd.merge(fringep_start17,\n",
    "                           fringep_start17_1,\n",
    "                           on =['HHID_PersonID','ProgramDate'] )\n",
    "fringep_start17 = fringep_start17[['ProgramDate','BroadcastStartTime',\n",
    "                                    'BroadcastEndTime', 'ProgramFinal',\n",
    "                                    'uniquereach1']].groupby(['ProgramDate','BroadcastStartTime',\n",
    "                                    'BroadcastEndTime', 'ProgramFinal']).sum()\n",
    "fringep_start17.reset_index(inplace = True)\n",
    "fringep_start17_1 = fringep_start17_1.groupby('ProgramDate').sum()\n",
    "fringep_start17_1.columns  = ['sumintab']\n",
    "fringep_start17_1.reset_index(inplace = True)\n",
    "fringep_start17 = pd.merge(fringep_start17,\n",
    "                           fringep_start17_1,\n",
    "                           on =['ProgramDate'] )\n",
    "fringep_start17['pcttotal'] = fringep_start17['uniquereach1']/fringep_start17['sumintab']\n",
    "del fringep_start17['sumintab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fringep_start18 = type30[['ProgramID','TelecastN','ProgramName','BroadcastStartTime','BroadcastEndTime','ProgramDate']]\n",
    "fringep_start18 = fringep_start18[((fringep_start18['BroadcastStartTime']>=1800)&\\\n",
    "                                  (fringep_start18['BroadcastStartTime']<=2200))|\\\n",
    "                                 ((fringep_start18['BroadcastEndTime']>=1800)&\\\n",
    "                                  (fringep_start18['BroadcastEndTime']<=2200))]\n",
    "\n",
    "fringep_start18['ProgramID_TelecastN'] = fringep_start18['ProgramID'] +'_' +\\\n",
    "                                         fringep_start18['TelecastN']\n",
    "fringep_start18_1 = fringep_start18.drop_duplicates('ProgramDate')\n",
    "fringep_start18_1list = []\n",
    "for i in fringep_start18_1['ProgramID_TelecastN']:\n",
    "    fringep_start18_1list.append(i)\n",
    "fringep_start18list = []\n",
    "for i in fringep_start18['ProgramID_TelecastN']:\n",
    "    fringep_start18list.append(i)\n",
    "\n",
    "fringep_start18_1 = dfall[dfall['ProgramID_TelecastN'].isin(fringep_start18_1list)]\n",
    "fringep_start18_1 = fringep_start18_1[['HHID_PersonID',\n",
    "                                       'ProgramDate']].drop_duplicates()\n",
    "fringep_start18_1 = pd.merge(fringep_start18_1,dfintab, on = 'HHID_PersonID')\n",
    "\n",
    "fringep_start18_1.columns  = ['HHID_PersonID','ProgramDate','uniquereach1']\n",
    "\n",
    "fringep_start18 = dfall[dfall['ProgramID_TelecastN'].isin(fringep_start18list)]\n",
    "fringep_start18 = fringep_start18.drop_duplicates(['ProgramDate','BroadcastStartTime',\n",
    "                                    'BroadcastEndTime', 'ProgramFinal','HHID_PersonID'])\n",
    "fringep_start18 = pd.merge(fringep_start18,\n",
    "                           fringep_start18_1,\n",
    "                           on =['HHID_PersonID','ProgramDate'] )\n",
    "fringep_start18 = fringep_start18[['ProgramDate','BroadcastStartTime',\n",
    "                                    'BroadcastEndTime', 'ProgramFinal',\n",
    "                                    'uniquereach1']].groupby(['ProgramDate','BroadcastStartTime',\n",
    "                                    'BroadcastEndTime', 'ProgramFinal']).sum()\n",
    "fringep_start18.reset_index(inplace = True)\n",
    "fringep_start18_1 = fringep_start18_1.groupby('ProgramDate').sum()\n",
    "fringep_start18_1.columns  = ['sumintab']\n",
    "fringep_start18_1.reset_index(inplace = True)\n",
    "fringep_start18 = pd.merge(fringep_start18,\n",
    "                           fringep_start18_1,\n",
    "                           on =['ProgramDate'] )\n",
    "fringep_start18['pcttotal'] = fringep_start18['uniquereach1']/fringep_start18['sumintab']\n",
    "del fringep_start18['sumintab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(folderpath+'ProgramOutput3 '+mindate+'.xlsx',\n",
    "                        engine='xlsxwriter',\n",
    "                        datetime_format='yyyy-mm-dd',\n",
    "                        date_format='yyyy-mm-dd')\n",
    "fringep_start17.to_excel(writer,'Audience Retention', index=False)\n",
    "fringep_start18.to_excel(writer,'Audience Retention', index=False, startcol=7)\n",
    "\n",
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['Audience Retention']\n",
    "\n",
    "format1 = workbook.add_format({'num_format': '#,##0'})\n",
    "format2 = workbook.add_format({'text_wrap' : True})\n",
    "format3 = workbook.add_format({'num_format': '0.0%'})\n",
    "\n",
    "worksheet.set_row(0,None, format2)\n",
    "worksheet.set_column('E:E', 12, format1)\n",
    "worksheet.set_column('F:F', None, format3)\n",
    "\n",
    "worksheet.set_column('L:L', 12, format1)\n",
    "worksheet.set_column('M:M', None, format3)\n",
    "worksheet.set_column('A:A', 12, None)\n",
    "worksheet.set_column('H:H', 12, None)\n",
    "worksheet.set_column('D:D', 16, None)\n",
    "worksheet.set_column('K:K', 16, None)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
