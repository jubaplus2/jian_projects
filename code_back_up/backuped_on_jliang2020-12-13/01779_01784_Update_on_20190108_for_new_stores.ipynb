{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/Projects/Smoothie_King/TA/New_TA_20190108'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine_zips_with_any_intersection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from haversine import haversine\n",
    "import zipcodes\n",
    "import googlemaps\n",
    "import os\n",
    "import zipcodes\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_centers=json.load(open(\"/home/jian/Docs/Geo_mapping/center_of_rentrak_zip.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pandas/core/frame.py:4528: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  other.index).difference(self.columns).tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(905, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0930 closed as in the email \"SK stores missing sales data\"\n",
    "store_list=pd.read_excel(\"/home/jian/Projects/Smoothie_King/TA/New_TA_20190108/StoreList_20190107.xlsx\",dtype=str)\n",
    "store_list=store_list[~pd.isnull(store_list['storenumber'])]\n",
    "closed_stores=store_list[store_list['status']==\"Closed\"]\n",
    "store_list=store_list[store_list['status']!=\"Closed\"]\n",
    "store_list=store_list[store_list['storenumber']!=\"0930\"]\n",
    "closed_stores=closed_stores.append(store_list['storenumber']==\"0930\")\n",
    "store_list=store_list[store_list['storenumber']!=\"nan\"].reset_index()\n",
    "del store_list['index']\n",
    "\n",
    "store_list['Latitude']=store_list['Latitude'].astype(float)\n",
    "store_list['Longitude']=store_list['Longitude'].astype(float)\n",
    "store_list['zip']=store_list['zip'].apply(lambda x: x.split(\"-\")[0])\n",
    "\n",
    "store_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_lat_lng_store=store_list[pd.isnull(store_list['Latitude']) | pd.isnull(store_list['Longitude'])]\n",
    "store_list_with_latlng=store_list[~pd.isnull(store_list['Latitude']) & ~pd.isnull(store_list['Longitude'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Google \"10560 Westheimer Road, Houston, TX, 77042\"\n",
    "# Get 29.737266,-95.5651062\n",
    "non_lat_lng_store['Latitude']=29.737266\n",
    "non_lat_lng_store['Longitude']=-95.5651062\n",
    "\n",
    "store_list=non_lat_lng_store.append(store_list_with_latlng).reset_index()\n",
    "store_list=store_list.sort_values(['index'])\n",
    "del store_list['index']\n",
    "store_list=store_list.drop_duplicates() #Remove dup row 0443\n",
    "\n",
    "store_list=store_list.reset_index()\n",
    "del store_list['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manually update the zip for the 11 stores\n",
    "store_zip_dic_updated={}\n",
    "store_zip_dic_updated.update({\"1333\":\"36695\"})\n",
    "store_zip_dic_updated.update({\"1349\":\"07747\"})\n",
    "store_zip_dic_updated.update({\"1436\":\"78411\"})\n",
    "\n",
    "store_zip_dic_updated.update({\"1245\":\"68133\"})\n",
    "store_zip_dic_updated.update({\"1152\":\"70810\"})\n",
    "store_zip_dic_updated.update({\"1282\":\"70803\"})\n",
    "\n",
    "store_zip_dic_updated.update({\"1386\":\"62711\"})\n",
    "store_zip_dic_updated.update({\"1467\":\"63146\"})\n",
    "store_zip_dic_updated.update({\"1252\":\"73013\"})\n",
    "\n",
    "store_zip_dic_updated.update({\"1397\":\"28054\"})\n",
    "store_zip_dic_updated.update({\"1653\":\"46074\"})\n",
    "\n",
    "store_zip_dic_updated.update({\"1390\":\"39440\"}) # Changed\n",
    "store_zip_dic_updated.update({\"1464\":\"07901\"}) # Changed\n",
    "\n",
    "store_zip_dic_updated.update({\"0989\":\"70130\"}) # Changed\n",
    "store_zip_dic_updated.update({\"1457\":\"08873\"}) # Changed\n",
    "store_zip_dic_updated.update({\"1432\":\"30281\"}) # Changed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "store_without_zips=store_list[store_list['storenumber'].isin(store_zip_dic_updated.keys())]\n",
    "store_with_zips=store_list[~store_list['storenumber'].isin(store_zip_dic_updated.keys())]\n",
    "store_without_zips['zip']=store_without_zips['storenumber'].apply(lambda x: store_zip_dic_updated[x])\n",
    "\n",
    "store_list=store_with_zips.append(store_without_zips).reset_index()\n",
    "store_list=store_list.sort_values(['index'])\n",
    "del store_list['index']\n",
    "store_list=store_list.reset_index()\n",
    "del store_list['index']\n",
    "\n",
    "store_zip5_dic=store_list.set_index(['storenumber'])['zip'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_store_zip_to_store_loc=store_list.copy()\n",
    "check_store_zip_to_store_loc=check_store_zip_to_store_loc.reset_index()\n",
    "check_store_zip_to_store_loc['orignal_dist']=np.nan\n",
    "del check_store_zip_to_store_loc['index']\n",
    "for i in range(len(check_store_zip_to_store_loc)):\n",
    "    store_zip=check_store_zip_to_store_loc['zip'][i]\n",
    "    store_lat=check_store_zip_to_store_loc['Latitude'][i]\n",
    "    store_lng=check_store_zip_to_store_loc['Longitude'][i]\n",
    "    if store_zip in zip_centers.keys():\n",
    "        dist_org=haversine(zip_centers[store_zip],[store_lat,store_lng],miles=True)\n",
    "    else:\n",
    "        dist_org=np.nan\n",
    "    check_store_zip_to_store_loc['orignal_dist'][i]=dist_org\n",
    "    \n",
    "check_store_zip_to_store_loc=check_store_zip_to_store_loc.sort_values(['orignal_dist'],ascending=False)\n",
    "check_store_zip_to_store_loc_revise=check_store_zip_to_store_loc[check_store_zip_to_store_loc['orignal_dist']>=20]\n",
    "check_store_zip_to_store_loc_revise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manually google the 14 address for lat lng\n",
    "to_update_lat_lng_dict={}\n",
    "to_update_lat_lng_dict.update({\"1385\":[32.552785,-83.6603137]}) #770 Hwy 96, Bonaire, GA, 31005\n",
    "to_update_lat_lng_dict.update({\"1149\":[30.0818157,-95.5229529]}) #21630 Kuykendahl Rd. Suite 405, Spring, TX, 77388\n",
    "to_update_lat_lng_dict.update({\"1587\":[35.9632665,-78.9601981]}) #4215 University Dr, Suite 100, Durham, NC, 27707\n",
    "to_update_lat_lng_dict.update({\"1382\":[34.0897496,-81.1726416]}) #945-G Lake Murray Blvd, Irmo, SC, 29063\n",
    "# to_update_lat_lng_dict.update({\"1171\":[32.2832495,-90.0270132]}) #201 Woodgate Drive S, Brandon, MS, 39402, Correct\n",
    "to_update_lat_lng_dict.update({\"0262NT\":[29.7181022,-95.3408497]}) #University of Houston, Houston, TX, 77004  ########## 4500 University Dr, Houston, TX 77004\n",
    "\n",
    "to_update_lat_lng_dict.update({\"1363\":[35.7489926,-81.336297]}) #225 12th Ave. NE, Hickory, NC, 28601\n",
    "# to_update_lat_lng_dict.update({\"1358\":[35.8363716,-78.6454606]}) #4120 Main at North Hills St. Suite 110, Raleigh, NC, 27403, Correct\n",
    "to_update_lat_lng_dict.update({\"1464\":[40.717702,-74.3630287]}) #462 Springfield Ave, Summit, NJ, 08053\n",
    "# to_update_lat_lng_dict.update({\"1673\":[34.7840431,-86.9484213]}) #1260 US Highway 72 E, Suite 1, Athens, AL, 35661, Correct\n",
    "# to_update_lat_lng_dict.update({\"1303\":[34.0211345,-84.3198411]}) #1530 Old Alabama Road, Suite 180, Roswell, GA, 30094, Correct\n",
    "to_update_lat_lng_dict.update({\"1190\":[33.8056582,-84.5279771]}) #1025 Veterans Memorial Hwy SE, Bldg 710, Mableton, GA, 30126\n",
    "to_update_lat_lng_dict.update({\"0116\":[29.8767939,-95.6450357]}) #6810 Hwy 6N, Houston, TX, 77084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "store_list_keep=store_list[~store_list['storenumber'].isin(to_update_lat_lng_dict.keys())]\n",
    "store_list_revised=store_list[store_list['storenumber'].isin(to_update_lat_lng_dict.keys())]\n",
    "store_list_revised['Latitude']=store_list_revised['storenumber'].apply(lambda x: to_update_lat_lng_dict[x][0])\n",
    "store_list_revised['Longitude']=store_list_revised['storenumber'].apply(lambda x: to_update_lat_lng_dict[x][1])\n",
    "\n",
    "store_list=store_list_keep.append(store_list_revised).reset_index()\n",
    "store_list=store_list.sort_values(['index'])\n",
    "del store_list['index']\n",
    "store_list=store_list.reset_index()\n",
    "del store_list['index']\n",
    "\n",
    "store_lat_dic=store_list.set_index(['storenumber'])['Latitude'].to_dict()\n",
    "store_lng_dic=store_list.set_index(['storenumber'])['Longitude'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_zips_3_miles_long=pd.DataFrame()\n",
    "store_zips_3_miles_dic={}\n",
    "for store_number in store_list['storenumber'].tolist():\n",
    "    store_center=[store_lat_dic[store_number],store_lng_dic[store_number]]\n",
    "    store_zip_list=[store_zip5_dic[store_number]]\n",
    "    df=pd.DataFrame({\"store_number\":store_number,\"zip_code\":store_zip_list,\"distance\":\"store_zip\"},index=[0])\n",
    "    for zip_cd in zip_centers.keys():\n",
    "        dist=haversine(store_center,zip_centers[zip_cd],miles=True)\n",
    "        if dist<=3:\n",
    "            store_zip_list=store_zip_list+[zip_cd]\n",
    "            df=df.append(pd.DataFrame({\"store_number\":store_number,\"zip_code\":zip_cd,\"distance\":dist},index=[0]))\n",
    "    \n",
    "    store_zips_3_miles_long=store_zips_3_miles_long.append(df)\n",
    "    store_zip_list=list(set(store_zip_list))\n",
    "    store_zips_3_miles_dic.update({store_number:store_zip_list})\n",
    "store_list['zip_cd_list']=store_list['storenumber'].apply(lambda x: store_zips_3_miles_dic[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_list_changed=store_list[(store_list['storenumber'].isin(store_zip_dic_updated.keys())) | (store_list['storenumber'].isin(to_update_lat_lng_dict.keys()))]\n",
    "writer=pd.ExcelWriter(\"/home/jian/Projects/Smoothie_King/TA/New_TA_20190108/revised_addresses_info_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "store_list_changed.to_excel(writer,\"store_list_changed\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>store_number</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>store_zip</td>\n",
       "      <td>1128</td>\n",
       "      <td>75219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.09968</td>\n",
       "      <td>1128</td>\n",
       "      <td>75250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    distance store_number zip_code\n",
       "0  store_zip         1128    75219\n",
       "0    2.09968         1128    75250"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_zips_3_miles_long.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['storenumber',\n",
       " 'Address',\n",
       " 'city',\n",
       " 'state',\n",
       " 'zip',\n",
       " 'StoreOpenDate',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'Ownership',\n",
       " 'Franchisee_Name',\n",
       " 'IPAddress',\n",
       " 'DriveThru',\n",
       " 'status',\n",
       " 'StoreCloseDate',\n",
       " 'zip_cd_list']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create TA from Zip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=store_list[['storenumber','Address','city','state','zip','StoreOpenDate','Latitude','Longitude','Ownership',\n",
    "           'Franchisee_Name','IPAddress','DriveThru','status','StoreCloseDate','zip_cd_list']]\n",
    "data=data.sort_values('storenumber')\n",
    "data=data.rename(columns={\"zip_cd_list\":\"zips_3_miles\",\"zip\":\"revised_store_zip\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['TA']=np.nan\n",
    "data['TA']=1\n",
    "data=data.reset_index()\n",
    "del data['index']\n",
    "df_TA_zips=pd.DataFrame({\"store\":[data['storenumber'][0]]*len(data['zips_3_miles'][0]),\"zip\":data['zips_3_miles'][0],\"TA\":[1]*len(data['zips_3_miles'][0])},index=[1]*len(data['zips_3_miles'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "TA_counter=1\n",
    "\n",
    "for i in range(1,len(data)):\n",
    "    intersection_zip=list(set(data['zips_3_miles'][i]).intersection(set(df_TA_zips['zip'].unique().tolist())))\n",
    "    if len(intersection_zip)==0:\n",
    "        TA_counter+=1\n",
    "        df_TA_zips=df_TA_zips.append(pd.DataFrame({\"store\":[data['storenumber'][i]]*len(data['zips_3_miles'][i]),\"zip\":data['zips_3_miles'][i],\"TA\":[TA_counter]*len(data['zips_3_miles'][i])},index=[i]*len(data['zips_3_miles'][i]))).drop_duplicates()\n",
    "        \n",
    "    else:\n",
    "        df_intersection=df_TA_zips[df_TA_zips['zip'].isin(intersection_zip)]\n",
    "        group_df_intersection=df_intersection.groupby(['TA'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False)\n",
    "        selected_TA=group_df_intersection['TA'][0] \n",
    "        \n",
    "        df_TA_zips_0=df_TA_zips[~df_TA_zips['TA'].isin(set(group_df_intersection['TA']))]\n",
    "        df_TA_zips_1=df_TA_zips[df_TA_zips['TA'].isin(group_df_intersection['TA'].tolist())]\n",
    "        df_TA_zips_1['TA']=selected_TA\n",
    "        df_TA_zips=df_TA_zips_0.append(df_TA_zips_1).append(pd.DataFrame({\"store\":[data['storenumber'][i]]*len(data['zips_3_miles'][i]),\"zip\":data['zips_3_miles'][i],\"TA\":[selected_TA]*len(data['zips_3_miles'][i])},index=[i]*len(data['zips_3_miles'][i]))).drop_duplicates()\n",
    "        \n",
    "dict_TA_zips=df_TA_zips.set_index('zip').to_dict()['TA']\n",
    "dict_TA_store=df_TA_zips.set_index('store').to_dict()['TA']\n",
    "data['TA']=data['storenumber'].apply(lambda x: dict_TA_store[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904, 16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TA'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ta_num_unique=data[['TA']].drop_duplicates().reset_index()\n",
    "del df_ta_num_unique['index']\n",
    "df_ta_num_unique['new_TA']=[x+1 for x in range(len(df_ta_num_unique))]\n",
    "\n",
    "dict_ta_num_unique=df_ta_num_unique.set_index(['TA']).to_dict()['new_TA']\n",
    "data['TA']=data['TA'].apply(lambda x: dict_ta_num_unique[x])\n",
    "df_TA_zips['TA']=df_TA_zips['TA'].apply(lambda x: dict_ta_num_unique[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "summary_store=data.groupby(\"TA\")['storenumber'].count().to_frame().reset_index().rename(columns={\"storenumber\":\"store_count\"})\n",
    "summary_zip=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].count().to_frame().reset_index().rename(columns={\"zip\":\"zip_count\"})\n",
    "# summary_store_2=df_TA_zips[['TA','store']].drop_duplicates().groupby(\"TA\")['store'].count().to_frame().reset_index().rename(columns={\"store\":\"store_count_2\"})\n",
    "summary_store_list=data.groupby(\"TA\")['storenumber'].apply(list).to_frame().reset_index().rename(columns={\"storenumber\":\"store_list\"})\n",
    "summary_zip_list=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].apply(list).to_frame().reset_index().rename(columns={\"zip\":\"zip_list\"})\n",
    "\n",
    "\n",
    "\n",
    "summary_by_TA=pd.merge(summary_store,summary_zip,on=\"TA\",how=\"outer\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,summary_store_list,on=\"TA\",how=\"outer\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,summary_zip_list,on=\"TA\",how=\"outer\")\n",
    "\n",
    "# summary=pd.merge(summary,summary_store_2,on=\"TA\",how=\"outer\")\n",
    "TA_Store_zip_list=data.groupby(['TA'])['revised_store_zip'].apply(set).to_frame().reset_index().rename(columns={\"revised_store_zip\":\"store_zip_list\"})\n",
    "summary_by_TA=pd.merge(summary_by_TA,TA_Store_zip_list,on=\"TA\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_by_store_count=summary_by_TA.groupby(['store_count'])['TA'].count().to_frame().reset_index().rename(columns={\"TA\":\"TA_count\"})\n",
    "summary_by_store_list=summary_by_TA.groupby(['store_count'])['TA'].apply(list).to_frame().reset_index().rename(columns={\"TA\":\"TA_list\"})\n",
    "summary_by_store_count=pd.merge(summary_by_store_count,summary_by_store_list,on=\"store_count\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'str'>], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TA_zips['zip'].apply(lambda x: type(x)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_zip_dist_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_zip_dist_in_TA['index']\n",
    "\n",
    "output_distance_zip_in_TA=pd.DataFrame()\n",
    "counter_k=0\n",
    "zip_not_found_list=[]\n",
    "\n",
    "\n",
    "for ta,group in df_zip_dist_in_TA.groupby(['TA']):\n",
    "    group=group.reset_index()\n",
    "    del group['index']\n",
    "    \n",
    "    if len(group)>1:\n",
    "    \n",
    "        dist_list=[]\n",
    "\n",
    "        for i in range(len(group)):\n",
    "            zip_hold=group['zip'][i]\n",
    "\n",
    "            if zip_hold not in zip_centers.keys():\n",
    "                try:\n",
    "                    zip_hold_center=(zipcodes.matching(zip_hold)[0]['lat'],zipcodes.matching(zip_hold)[0]['long'])\n",
    "                except:\n",
    "                    print(\"zip not found hold, \",zip_hold)\n",
    "                    zip_not_found_list=zip_not_found_list+[zip_hold]\n",
    "\n",
    "            else:\n",
    "                zip_hold_center=zip_centers[zip_hold]\n",
    "\n",
    "            for j in range(i+1,len(group)):\n",
    "                zip_var=group['zip'][j]\n",
    "                if zip_var not in zip_centers.keys():\n",
    "                    try:\n",
    "                        zip_var_center=(zipcodes.matching(zip_var)[0]['lat'],zipcodes.matching(zip_var)[0]['long'])\n",
    "                    except:\n",
    "                        print(\"zip not found var, \",zip_hold)\n",
    "                        zip_not_found_list=zip_not_found_list+[zip_var]\n",
    "\n",
    "                else:\n",
    "                    zip_var_center=zip_centers[zip_var]\n",
    "\n",
    "                try:\n",
    "                    dist=haversine(zip_hold_center,zip_var_center,miles=True)\n",
    "                except:\n",
    "                    dist=np.nan\n",
    "\n",
    "                dist_list=dist_list+[dist]\n",
    "        df=pd.DataFrame({\"TA\":ta,\"dist_min\":min(dist_list),\"dist_max\":max(dist_list),\"dist_median\":np.median(dist_list),\"All_dist\":[dist_list]},index=[counter_k])\n",
    "        counter_k+=1\n",
    "        output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "    else:\n",
    "        df=pd.DataFrame({\"TA\":ta,\"dist_min\":0,\"dist_max\":0,\"dist_median\":0,\"All_dist\":\"single_zip\"},index=[counter_k])\n",
    "        output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>zip</th>\n",
       "      <th>DMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>70087</td>\n",
       "      <td>NEW ORLEANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>70031</td>\n",
       "      <td>NEW ORLEANS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA    zip          DMA\n",
       "0   3  70087  NEW ORLEANS\n",
       "1   3  70031  NEW ORLEANS"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_DMA=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",dtype=str,skiprows=1)\n",
    "zip_DMA=zip_DMA.iloc[:,[0,2]]\n",
    "zip_DMA.columns=['zip','DMA']\n",
    "\n",
    "df_city_state_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_city_state_in_TA['index']\n",
    "\n",
    "def city_of_zip(x):\n",
    "    try:\n",
    "        city=zipcodes.matching(x)[0]['city']\n",
    "    except:\n",
    "        city=np.nan\n",
    "    return city\n",
    "\n",
    "def state_of_zip(x):\n",
    "    try:\n",
    "        state=zipcodes.matching(x)[0]['state']\n",
    "    except:\n",
    "        state=np.nan\n",
    "    return state\n",
    "    \n",
    "df_city_state_in_TA['city']=df_city_state_in_TA['zip'].apply(lambda x: city_of_zip(x))\n",
    "df_city_state_in_TA['state']=df_city_state_in_TA['zip'].apply(lambda x: state_of_zip(x))\n",
    "df_city_state_in_TA['city']=df_city_state_in_TA['city']+\" (\"+df_city_state_in_TA['state']+\")\"\n",
    "\n",
    "df_DMA_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_DMA_in_TA['index']\n",
    "df_DMA_in_TA=pd.merge(df_DMA_in_TA,zip_DMA,on=\"zip\",how=\"left\")\n",
    "df_DMA_in_TA.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_city_TA_list=df_city_state_in_TA.groupby(['TA'])['city'].apply(set).to_frame().reset_index()\n",
    "df_city_TA_list=df_city_TA_list.rename(columns={\"city\":\"city_list\"})\n",
    "df_state_TA_list=df_city_state_in_TA.groupby(['TA'])['state'].apply(set).to_frame().reset_index()\n",
    "df_state_TA_list=df_state_TA_list.rename(columns={\"state\":\"state_list\"})\n",
    "df_DMA_TA_list=df_DMA_in_TA.groupby(['TA'])['DMA'].apply(set).to_frame().reset_index()\n",
    "df_DMA_TA_list=df_DMA_TA_list.rename(columns={\"DMA\":\"DMA_list\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "manually_city_dict_of_zip={\"29486\":\"Summerville\"}\n",
    "manually_state_dict_of_zip={\"29486\":\"SC\"}\n",
    "df_city_state_in_TA['city'][df_city_state_in_TA['zip']=='29486']=manually_city_dict_of_zip['29486']\n",
    "df_city_state_in_TA['state'][df_city_state_in_TA['zip']=='29486']=manually_state_dict_of_zip['29486']\n",
    "\n",
    "removed_2_zips_df=df_city_state_in_TA[pd.isnull(df_city_state_in_TA['city'])]\n",
    "df_city_state_in_TA=df_city_state_in_TA[~pd.isnull(df_city_state_in_TA['city'])]\n",
    "# zip \"08644\",\"76190\" removed to determine cities/states because of not existing as in https://www.unitedstateszipcodes.org/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter_k=1\n",
    "df_primary_city_state=pd.DataFrame()\n",
    "df_primary_DMA=pd.DataFrame()\n",
    "for ta,group in df_city_state_in_TA.groupby(['TA']):\n",
    "    df_city=group.groupby(['city'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_city['index']\n",
    "    primary_city=df_city['city'][0]\n",
    "    \n",
    "    df_state=group.groupby(['state'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_state['index']\n",
    "    primary_state=df_state['state'][0]\n",
    "    \n",
    "    df=pd.DataFrame({\"TA\":ta,\"Primary_City\":primary_city,\"Primary_State\":primary_state},index=[counter_k])\n",
    "    counter_k+=1\n",
    "    df_primary_city_state=df_primary_city_state.append(df)\n",
    "\n",
    "    \n",
    "for ta,group in df_DMA_in_TA.groupby(['TA']):\n",
    "    df_DMA=group.groupby(['DMA'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_DMA['index']\n",
    "    primary_DMA=df_DMA['DMA'][0]\n",
    "    \n",
    "    df=pd.DataFrame({\"TA\":ta,\"Primary_DMA\":primary_DMA},index=[counter_k])\n",
    "    counter_k+=1\n",
    "    df_primary_DMA=df_primary_DMA.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_by_TA=pd.merge(summary_by_TA,df_city_TA_list,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_state_TA_list,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_DMA_TA_list,on=\"TA\",how=\"left\")\n",
    "\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_primary_city_state,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_primary_DMA,on=\"TA\",how=\"left\")\n",
    "\n",
    "summary_by_TA=pd.merge(summary_by_TA,output_distance_zip_in_TA,on=\"TA\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Latitude']=data['Latitude'].astype(float)\n",
    "data['Longitude']=data['Longitude'].astype(float)\n",
    "data['TA']=data['TA'].astype(str)\n",
    "summary_by_TA['TA']=summary_by_TA['TA'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_by_TA['ratio_max_media']=summary_by_TA['dist_max']/summary_by_TA['dist_median']\n",
    "\n",
    "summary_by_TA_to_revise=summary_by_TA[(summary_by_TA['ratio_max_media']>2) &\\\n",
    "                                      (summary_by_TA['store_count']>=2) &\\\n",
    "                                     (summary_by_TA['dist_max']>12)]\n",
    "summary_by_TA_to_keep=summary_by_TA[(summary_by_TA['ratio_max_media']<=2) |\\\n",
    "                                      (summary_by_TA['store_count']<2) |\\\n",
    "                                     (summary_by_TA['dist_max']<=12)]\n",
    "summary_by_TA_to_revise=summary_by_TA_to_revise.reset_index()\n",
    "del summary_by_TA_to_revise['index']\n",
    "\n",
    "summary_by_TA_to_keep=summary_by_TA_to_keep.reset_index()\n",
    "del summary_by_TA_to_keep['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary_by_TA['TA'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'str'>], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_by_TA['TA'].apply(lambda x: type(x)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_by_TA['TA'].astype(int).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loop_counter=0\n",
    "while len(summary_by_TA_to_revise)>0:\n",
    "    loop_counter+=1\n",
    "    if loop_counter>30:\n",
    "        break\n",
    "    \n",
    "    summary_by_TA_to_revise=summary_by_TA_to_revise.reset_index()\n",
    "    del summary_by_TA_to_revise['index']\n",
    "\n",
    "    summary_by_TA_to_keep=summary_by_TA_to_keep.reset_index()\n",
    "    del summary_by_TA_to_keep['index']\n",
    "\n",
    "    data_keep=data[data['TA'].isin(summary_by_TA_to_keep['TA'])]\n",
    "    data_revise=data[~data['TA'].isin(summary_by_TA_to_keep['TA'])]\n",
    "    data_revise=data_revise.reset_index()\n",
    "    del data_revise['index']\n",
    "\n",
    "\n",
    "    store_lat_dict=data_revise.set_index(['storenumber']).to_dict()['Latitude']\n",
    "    store_lng_dict=data_revise.set_index(['storenumber']).to_dict()['Longitude']\n",
    "\n",
    "\n",
    "    store_sub_df=pd.DataFrame()\n",
    "    for i in range(len(summary_by_TA_to_revise)):\n",
    "        TA=summary_by_TA_to_revise['TA'][i]\n",
    "        store_list=summary_by_TA_to_revise['store_list'][i].copy()\n",
    "        initial_dist=0\n",
    "        store_pair=[np.nan,np.nan]\n",
    "        while len(store_list)>=2:\n",
    "            store_hold=store_list[0]\n",
    "            store_list.remove(store_hold)\n",
    "            store_hold_center=[store_lat_dict[store_hold],store_lng_dict[store_hold]]\n",
    "            for store_var in store_list:\n",
    "                store_var_center=[store_lat_dict[store_var],store_lng_dict[store_var]]\n",
    "                dist=haversine(store_hold_center,store_var_center,miles=True)\n",
    "                if dist>initial_dist:\n",
    "                    initial_dist=dist\n",
    "                    store_pair=[store_hold,store_var]\n",
    "        store_a=store_pair[0]\n",
    "        store_b=store_pair[1]\n",
    "\n",
    "        store_a_center=[store_lat_dict[store_a],store_lng_dict[store_a]]\n",
    "        store_b_center=[store_lat_dict[store_b],store_lng_dict[store_b]]\n",
    "        store_list=summary_by_TA_to_revise['store_list'][i].copy()\n",
    "        for store in store_list:\n",
    "            store_center=[store_lat_dict[store],store_lng_dict[store]]\n",
    "            dist_a=haversine(store_a_center,store_center,miles=True)\n",
    "            dist_b=haversine(store_b_center,store_center,miles=True)\n",
    "            if dist_a<dist_b:\n",
    "                sub_group=\"a\"\n",
    "            else:\n",
    "                sub_group=\"b\"\n",
    "            df=pd.DataFrame({\"storenumber\":store,\"TA\":TA,\"sub_group\":sub_group},index=[store])\n",
    "            store_sub_df=store_sub_df.append(df)\n",
    "    \n",
    "    store_sub_df['TA']=store_sub_df['TA'].astype(str)\n",
    "    store_sub_df['TA']=store_sub_df['TA']+\"_\"+store_sub_df['sub_group']\n",
    "    store_sub_df=store_sub_df[['storenumber','TA']]\n",
    "    store_sub_df_dic=store_sub_df.set_index(['storenumber']).to_dict()['TA']\n",
    "                    \n",
    "    data_revise['TA']=data_revise['storenumber'].apply(lambda x: store_sub_df_dic[x])\n",
    "    data=data_keep.append(data_revise)\n",
    "    data=data.sort_values(['storenumber'])\n",
    "    data=data.reset_index()\n",
    "    del data['index']\n",
    "    data['TA']=data['TA'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "    df_TA_zips=pd.DataFrame()\n",
    "    for i in range(len(data)):\n",
    "        df=pd.DataFrame({\"store\":[data['storenumber'][i]]*len(data['zips_3_miles'][i]),\n",
    "                         \"TA\":[data['TA'][i]]*len(data['zips_3_miles'][i]),\n",
    "                         \"zip\":data['zips_3_miles'][i]},index=data['zips_3_miles'][i])\n",
    "        df_TA_zips=df_TA_zips.append(df)\n",
    "\n",
    "\n",
    "    summary_store=data.groupby(\"TA\")['storenumber'].count().to_frame().reset_index().rename(columns={\"storenumber\":\"store_count\"})\n",
    "    summary_zip=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].count().to_frame().reset_index().rename(columns={\"zip\":\"zip_count\"})\n",
    "    summary_store_list=data.groupby(\"TA\")['storenumber'].apply(list).to_frame().reset_index().rename(columns={\"storenumber\":\"store_list\"})\n",
    "    summary_zip_list=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].apply(list).to_frame().reset_index().rename(columns={\"zip\":\"zip_list\"})\n",
    "\n",
    "    summary_by_TA=pd.merge(summary_store,summary_zip,on=\"TA\",how=\"outer\")\n",
    "    summary_by_TA=pd.merge(summary_by_TA,summary_store_list,on=\"TA\",how=\"outer\")\n",
    "    summary_by_TA=pd.merge(summary_by_TA,summary_zip_list,on=\"TA\",how=\"outer\")\n",
    "\n",
    "    # summary=pd.merge(summary,summary_store_2,on=\"TA\",how=\"outer\")\n",
    "    TA_Store_zip_list=data.groupby(['TA'])['revised_store_zip'].apply(set).to_frame().reset_index().rename(columns={\"zip_code\":\"store_zip_list\"})\n",
    "    summary_by_TA=pd.merge(summary_by_TA,TA_Store_zip_list,on=\"TA\",how=\"left\")\n",
    "\n",
    "\n",
    "    summary_by_store_count=summary_by_TA.groupby(['store_count'])['TA'].count().to_frame().reset_index().rename(columns={\"TA\":\"TA_count\"})\n",
    "    summary_by_store_list=summary_by_TA.groupby(['store_count'])['TA'].apply(list).to_frame().reset_index().rename(columns={\"TA\":\"TA_list\"})\n",
    "    summary_by_store_count=pd.merge(summary_by_store_count,summary_by_store_list,on=\"store_count\",how=\"outer\")\n",
    "\n",
    "    df_zip_dist_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "    del df_zip_dist_in_TA['index']\n",
    "\n",
    "    output_distance_zip_in_TA=pd.DataFrame()\n",
    "    counter_k=0\n",
    "    for ta,group in df_zip_dist_in_TA.groupby(['TA']):\n",
    "        group=group.reset_index()\n",
    "        del group['index']\n",
    "\n",
    "        if len(group)>1:\n",
    "\n",
    "            dist_list=[]\n",
    "\n",
    "            for i in range(len(group)):\n",
    "                zip_hold=group['zip'][i]\n",
    "\n",
    "                if zip_hold not in zip_centers.keys():\n",
    "                    try:\n",
    "                        zip_hold_center=(zipcodes.matching(zip_hold)[0]['lat'],zipcodes.matching(zip_hold)[0]['long'])\n",
    "                    except:\n",
    "                        print(\"zip not found, \",zip_hold)\n",
    "\n",
    "                else:\n",
    "                    zip_hold_center=zip_centers[zip_hold]\n",
    "\n",
    "                for j in range(i+1,len(group)):\n",
    "                    zip_var=group['zip'][j]\n",
    "                    if zip_var not in zip_centers.keys():\n",
    "                        try:\n",
    "                            zip_var_center=(zipcodes.matching(zip_var)[0]['lat'],zipcodes.matching(zip_var)[0]['long'])\n",
    "                        except:\n",
    "                            print(\"zip not found, \",zip_hold)\n",
    "\n",
    "                    else:\n",
    "                        zip_var_center=zip_centers[zip_var]\n",
    "\n",
    "                    try:\n",
    "                        dist=haversine(zip_hold_center,zip_var_center,miles=True)\n",
    "                    except:\n",
    "                        dist=np.nan\n",
    "\n",
    "                    dist_list=dist_list+[dist]\n",
    "            df=pd.DataFrame({\"TA\":ta,\"dist_min\":min(dist_list),\"dist_max\":max(dist_list),\"dist_median\":np.median(dist_list),\"All_dist\":[dist_list]},index=[counter_k])\n",
    "            counter_k+=1\n",
    "            output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "        else:\n",
    "            df=pd.DataFrame({\"TA\":ta,\"dist_min\":0,\"dist_max\":0,\"dist_median\":0,\"All_dist\":\"single_zip\"},index=[counter_k])\n",
    "            output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "\n",
    "    zip_DMA=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",dtype=str,skiprows=1)\n",
    "    zip_DMA=zip_DMA.iloc[:,[0,2]]\n",
    "    zip_DMA.columns=['zip','DMA']\n",
    "\n",
    "    df_city_state_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "    del df_city_state_in_TA['index']\n",
    "\n",
    "    def city_of_zip(x):\n",
    "        try:\n",
    "            city=zipcodes.matching(x)[0]['city']\n",
    "        except:\n",
    "            city=np.nan\n",
    "        return city\n",
    "\n",
    "    def state_of_zip(x):\n",
    "        try:\n",
    "            state=zipcodes.matching(x)[0]['state']\n",
    "        except:\n",
    "            state=np.nan\n",
    "        return state\n",
    "\n",
    "    df_city_state_in_TA['city']=df_city_state_in_TA['zip'].apply(lambda x: city_of_zip(x))\n",
    "    df_city_state_in_TA['state']=df_city_state_in_TA['zip'].apply(lambda x: state_of_zip(x))\n",
    "    \n",
    "    manually_city_dict_of_zip={\"29486\":\"Summerville\"}\n",
    "    manually_state_dict_of_zip={\"29486\":\"SC\"}\n",
    "    df_city_state_in_TA['city'][df_city_state_in_TA['zip']=='29486']=manually_city_dict_of_zip['29486']\n",
    "    df_city_state_in_TA['state'][df_city_state_in_TA['zip']=='29486']=manually_state_dict_of_zip['29486']\n",
    "\n",
    "    removed_2_zips_df=df_city_state_in_TA[pd.isnull(df_city_state_in_TA['city'])]\n",
    "    df_city_state_in_TA=df_city_state_in_TA[~pd.isnull(df_city_state_in_TA['city'])]\n",
    "    \n",
    "    df_city_state_in_TA['city']=df_city_state_in_TA['city']+\" (\"+df_city_state_in_TA['state']+\")\"\n",
    "\n",
    "    df_DMA_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "    del df_DMA_in_TA['index']\n",
    "    df_DMA_in_TA=pd.merge(df_DMA_in_TA,zip_DMA,on=\"zip\",how=\"left\")\n",
    "\n",
    "    df_city_TA_list=df_city_state_in_TA.groupby(['TA'])['city'].apply(set).to_frame().reset_index()\n",
    "    df_city_TA_list=df_city_TA_list.rename(columns={\"city\":\"city_list\"})\n",
    "    df_state_TA_list=df_city_state_in_TA.groupby(['TA'])['state'].apply(set).to_frame().reset_index()\n",
    "    df_state_TA_list=df_state_TA_list.rename(columns={\"state\":\"state_list\"})\n",
    "    df_DMA_TA_list=df_DMA_in_TA.groupby(['TA'])['DMA'].apply(set).to_frame().reset_index()\n",
    "    df_DMA_TA_list=df_DMA_TA_list.rename(columns={\"DMA\":\"DMA_list\"})\n",
    "\n",
    "    counter_k\n",
    "    df_primary_city_state=pd.DataFrame()\n",
    "    df_primary_DMA=pd.DataFrame()\n",
    "    \n",
    "    df_city_state_in_TA\n",
    "    for ta,group in df_city_state_in_TA.groupby(['TA']):\n",
    "        df_city=group.groupby(['city'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "        del df_city['index']\n",
    "        primary_city=df_city['city'][0]\n",
    "\n",
    "        df_state=group.groupby(['state'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "        del df_state['index']\n",
    "        primary_state=df_state['state'][0]\n",
    "\n",
    "        df=pd.DataFrame({\"TA\":ta,\"Primary_City\":primary_city,\"Primary_State\":primary_state},index=[counter_k])\n",
    "        counter_k+=1\n",
    "        df_primary_city_state=df_primary_city_state.append(df)\n",
    "\n",
    "\n",
    "    for ta,group in df_DMA_in_TA.groupby(['TA']):\n",
    "        df_DMA=group.groupby(['DMA'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "        del df_DMA['index']\n",
    "        primary_DMA=df_DMA['DMA'][0]\n",
    "\n",
    "        df=pd.DataFrame({\"TA\":ta,\"Primary_DMA\":primary_DMA},index=[counter_k])\n",
    "        counter_k+=1\n",
    "        df_primary_DMA=df_primary_DMA.append(df)\n",
    "\n",
    "    summary_by_TA=pd.merge(summary_by_TA,df_city_TA_list,on=\"TA\",how=\"left\")\n",
    "    summary_by_TA=pd.merge(summary_by_TA,df_state_TA_list,on=\"TA\",how=\"left\")\n",
    "    summary_by_TA=pd.merge(summary_by_TA,df_DMA_TA_list,on=\"TA\",how=\"left\")\n",
    "\n",
    "    summary_by_TA=pd.merge(summary_by_TA,df_primary_city_state,on=\"TA\",how=\"left\")\n",
    "    summary_by_TA=pd.merge(summary_by_TA,df_primary_DMA,on=\"TA\",how=\"left\")\n",
    "\n",
    "    summary_by_TA=pd.merge(summary_by_TA,output_distance_zip_in_TA,on=\"TA\",how=\"left\")\n",
    "    summary_by_TA['Initial_TA']=summary_by_TA['TA'].apply(lambda x: int(x.split(\"_\")[0]))\n",
    "    summary_by_TA=summary_by_TA.sort_values(['Initial_TA','TA'])\n",
    "\n",
    "    summary_by_TA['ratio_max_media']=summary_by_TA['dist_max']/summary_by_TA['dist_median']\n",
    "\n",
    "    summary_by_TA_to_revise=summary_by_TA[(summary_by_TA['ratio_max_media']>2) &\\\n",
    "                                          (summary_by_TA['store_count']>=2) &\\\n",
    "                                         (summary_by_TA['dist_max']>12)]\n",
    "    summary_by_TA_to_keep=summary_by_TA[(summary_by_TA['ratio_max_media']<=2) |\\\n",
    "                                          (summary_by_TA['store_count']<2) |\\\n",
    "                                         (summary_by_TA['dist_max']<=12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "summary_by_TA_output=pd.DataFrame()\n",
    "summary_by_TA=summary_by_TA.sort_values(['Initial_TA'])\n",
    "for old_ta,group in summary_by_TA.groupby(['Initial_TA']):\n",
    "    if len(group)>1:\n",
    "        group['TA']=[str(old_ta).zfill(3)+\"_\"+str(x+1) for x in range(len(group))]\n",
    "    else:\n",
    "        group['TA']=str(old_ta).zfill(3)\n",
    "    summary_by_TA_output=summary_by_TA_output.append(group)\n",
    "ta_store_list_dic=summary_by_TA_output.set_index(['TA']).to_dict()['store_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_to_new_ta_dict={}\n",
    "for new_ta in ta_store_list_dic.keys():\n",
    "    length=len(ta_store_list_dic[new_ta])\n",
    "    df=pd.DataFrame({\"store\":ta_store_list_dic[new_ta],\"new_ta\":[new_ta]*length},index=[x for x in range(length)])\n",
    "    df_dict=df.set_index(['store']).to_dict()['new_ta']\n",
    "    store_to_new_ta_dict.update(df_dict)\n",
    "len(store_to_new_ta_dict)    \n",
    "data['TA']=data['storenumber'].apply(lambda x: store_to_new_ta_dict[x])\n",
    "df_TA_zips['TA']=df_TA_zips['store'].apply(lambda x: store_to_new_ta_dict[x])\n",
    "\n",
    "summary_by_store_count=summary_by_TA_output.groupby(['store_count'])['TA'].count().to_frame().reset_index().rename(columns={\"TA\":\"TA_count\"})\n",
    "summary_by_store_list=summary_by_TA_output.groupby(['store_count'])['TA'].apply(list).to_frame().reset_index().rename(columns={\"TA\":\"TA_list\"})\n",
    "summary_by_store_count=pd.merge(summary_by_store_count,summary_by_store_list,on=\"store_count\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_for_tableau=data[['storenumber','revised_store_zip','city','state','Latitude','Longitude','TA']]\n",
    "for col in data_for_tableau.columns.tolist()[1:6]:\n",
    "    data_for_tableau=data_for_tableau.rename(columns={col:\"store_\"+col})\n",
    "data_for_tableau=data_for_tableau.append(df_TA_zips[['TA','zip']])\n",
    "data_for_tableau['store_Latitude']=data_for_tableau['store_Latitude'].fillna(0)\n",
    "data_for_tableau['store_Longitude']=data_for_tableau['store_Longitude'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"/home/jian/Projects/Smoothie_King/TA/New_TA_20190108/SmoothieKing_TA_of_3_miles_zips_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "summary_by_TA_output.to_excel(writer,\"summary_by_TA\",index=False)\n",
    "data['storenumber']=data['storenumber'].replace(\"0262NT\",\"0262\")\n",
    "data['storenumber']=data['storenumber'].astype(int)\n",
    "data=data.sort_values(['storenumber'])\n",
    "data['storenumber']=data['storenumber'].astype(str)\n",
    "data['storenumber']=data['storenumber'].apply(lambda x: x.zfill(4))\n",
    "data['storenumber']=data['storenumber'].replace(\"0262\",\"0262NT\")\n",
    "\n",
    "data.to_excel(writer,\"output_TA_by_store\",index=False)\n",
    "df_TA_zips.to_excel(writer,\"zip_TA\",index=False)\n",
    "data_for_tableau.to_excel(writer,\"data_for_tableau\",index=False)\n",
    "summary_by_store_count.to_excel(writer,\"summary_by_store_count\",index=False)\n",
    "closed_stores.to_excel(writer,\"closed_stores\",index=False)\n",
    "overwrite_zip_stores=store_list_changed.copy()\n",
    "overwrite_zip_stores.to_excel(writer,\"stores_info_changed\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
