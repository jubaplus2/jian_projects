{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIdeas:\\n\\n1. XX & YY seperately deal with, with different weight of probabilities\\n2. use the last transactions, and each item in the last basket with equal weight\\n3. Remove the already purchased items\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ideas:\n",
    "\n",
    "1. XX & YY seperately deal with, with different weight of probabilities\n",
    "2. use the last transactions, and each item in the last basket with equal weight\n",
    "3. Remove the already purchased items\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import logging\n",
    "import json\n",
    "os.getcwd()\n",
    "logging.basicConfig(filename='Multiprocessing.log', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Antai_AE_round1_submit_20190715.csv',\n",
       " 'Antai_AE_round1_test_20190626.csv',\n",
       " 'Antai_AE_round1_item_attr_20190626.zip',\n",
       " 'Antai_AE_round1_train_20190626.zip']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/home/jian/Projects/Big_Lots/Analysis/2019_Q2/Planner_Requests/temp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_R1_item_attr=pd.read_csv(\\'C:\\\\Users\\\\jlian\\\\OneDrive\\\\Desktop\\\\Tianchi_201908_Antai\\\\data\\\\Antai_AE_round1_item_attr_20190626.zip\\',\\n                           dtype=str,compression=\"zip\",sep=\",\")\\nprint(df_R1_item_attr.shape)\\ndf_R1_item_attr.tail(3)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_R1_item_attr=pd.read_csv('C:\\\\Users\\\\jlian\\\\OneDrive\\\\Desktop\\\\Tianchi_201908_Antai\\\\data\\\\Antai_AE_round1_item_attr_20190626.zip',\n",
    "                           dtype=str,compression=\"zip\",sep=\",\")\n",
    "print(df_R1_item_attr.shape)\n",
    "df_R1_item_attr.tail(3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_R1_submit_example=pd.read_csv(\\'C:\\\\Users\\\\jlian\\\\OneDrive\\\\Desktop\\\\Tianchi_201908_Antai\\\\data\\\\Antai_AE_round1_submit_20190715.csv\\',\\n                           dtype=str,sep=\",\")\\nprint(df_R1_submit_example.shape)\\ndf_R1_submit_example.head(3)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_R1_submit_example=pd.read_csv('C:\\\\Users\\\\jlian\\\\OneDrive\\\\Desktop\\\\Tianchi_201908_Antai\\\\data\\\\Antai_AE_round1_submit_20190715.csv',\n",
    "                           dtype=str,sep=\",\")\n",
    "print(df_R1_submit_example.shape)\n",
    "df_R1_submit_example.head(3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12868509, 5)\n",
      "809213\n",
      "2018-07-13 05:54:54\n",
      "2018-08-31 23:59:57\n"
     ]
    }
   ],
   "source": [
    "df_R1_train=pd.read_csv('/home/jian/Projects/Big_Lots/Analysis/2019_Q2/Planner_Requests/temp/data/Antai_AE_round1_train_20190626.zip',\n",
    "                           dtype=str,sep=\",\")\n",
    "print(df_R1_train.shape)\n",
    "print(df_R1_train['buyer_admin_id'].nunique())\n",
    "\n",
    "print(df_R1_train['create_order_time'].min())\n",
    "print(df_R1_train['create_order_time'].max())\n",
    "df_R1_train.head(3)\n",
    "df_R1_train['irank']=df_R1_train['irank'].astype(int)\n",
    "df_R1_train=df_R1_train.sort_values([\"buyer_admin_id\",\"irank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "(12565734, 5)\n"
     ]
    }
   ],
   "source": [
    "count_by_id=df_R1_train.groupby('buyer_admin_id')['irank'].count().to_frame().reset_index().sort_values(\"irank\",ascending=False)\n",
    "count_by_id_exclude=count_by_id[count_by_id['irank']>=2000]\n",
    "list_id_excluded=count_by_id_exclude['buyer_admin_id'].unique().tolist()\n",
    "print(len(list_id_excluded))\n",
    "df_R1_train=df_R1_train[~df_R1_train['buyer_admin_id'].isin(list_id_excluded)]\n",
    "print(df_R1_train.shape)\n",
    "\n",
    "train_item_all=df_R1_train['item_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809081\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "df_id_countries=df_R1_train.groupby(['buyer_admin_id'])['buyer_country_id'].nunique().to_frame().reset_index().sort_values(\"buyer_country_id\")\n",
    "df_id_xx_and_yy=df_id_countries[df_id_countries['buyer_country_id']==2]\n",
    "df_id_1_country=df_id_countries[df_id_countries['buyer_country_id']==1]\n",
    "\n",
    "id_list_1_country=df_id_1_country['buyer_admin_id'].tolist()\n",
    "id_list_2_countries=df_id_xx_and_yy['buyer_admin_id'].tolist()\n",
    "\n",
    "print(len(id_list_1_country))\n",
    "print(len(id_list_2_countries))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2222893, 5)\n",
      "(10342841, 5)\n"
     ]
    }
   ],
   "source": [
    "df_R1_train_YY=df_R1_train[((df_R1_train['buyer_country_id']==\"yy\") & (df_R1_train['buyer_admin_id'].isin(id_list_1_country)))]\n",
    "id_list_YY=df_R1_train_YY['buyer_admin_id'].tolist()\n",
    "## XX & YY combined in to XX only\n",
    "df_R1_train_XX=df_R1_train[~df_R1_train['buyer_admin_id'].isin(id_list_YY)]\n",
    "\n",
    "print(df_R1_train_YY.shape)\n",
    "print(df_R1_train_XX.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_R1_test=pd.read_csv('./data/Antai_AE_round1_test_20190626.csv',\n",
    "                           dtype=str,sep=\",\")\n",
    "df_R1_test['irank']=df_R1_test['irank'].astype(int)\n",
    "df_R1_test_yy_only=df_R1_test[~df_R1_test['buyer_admin_id'].isin(df_R1_train_XX['buyer_admin_id'].tolist())]\n",
    "\n",
    "df_R1_train_YY=df_R1_train_YY.append(df_R1_test_yy_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_R1_train_YY=df_R1_train_YY.sort_values(['buyer_admin_id','create_order_time'],ascending=[True,True])\n",
    "# del df_R1_train_YY['irank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-09 13:08:02.319890\n",
      "2019-08-09 13:13:10.745775\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "df_temp=df_R1_train_YY[['buyer_admin_id','create_order_time']].drop_duplicates()\n",
    "new_rank=[]\n",
    "for buyer_id,df_group in df_temp.groupby(\"buyer_admin_id\"):\n",
    "    new_rank=new_rank+[x+1 for x in range(len(df_group))]\n",
    "        \n",
    "df_temp['new_rank']=new_rank\n",
    "df_R1_train_YY=pd.merge(df_R1_train_YY,df_temp,on=['buyer_admin_id','create_order_time'])\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_YY_id_purchased_count=df_R1_train_YY.groupby(\"item_id\")['buyer_admin_id'].nunique().to_frame().reset_index().sort_values(\"buyer_admin_id\",ascending=False)\n",
    "item_list_hold_YY=df_YY_id_purchased_count[df_YY_id_purchased_count['buyer_admin_id']>=28]['item_id'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# new rank: the higher, the later\n",
    "# the same for same time \n",
    "df_R1_train_YY_iterration=df_R1_train_YY[['buyer_admin_id','item_id','new_rank']]\n",
    "df_R1_train_YY_iterration['count']=1\n",
    "df_R1_train_YY_iterration=df_R1_train_YY_iterration.groupby(['buyer_admin_id','item_id','new_rank'])['count'].sum().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(item_list_hold_YY) 4088\n"
     ]
    }
   ],
   "source": [
    "print(\"len(item_list_hold_YY)\",len(item_list_hold_YY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4088"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_list_hold_YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processors=25\n",
    "\n",
    "len_per_subset=int(np.ceil(len(item_list_hold_YY)/processors))\n",
    "list_of_list_25_subset=[]\n",
    "for i in range(25):\n",
    "    lower_boundry=i*len_per_subset\n",
    "    upper_boundry=(i+1)*len_per_subset\n",
    "    list_of_list_25_subset=list_of_list_25_subset+[item_list_hold_YY[lower_boundry:upper_boundry]]\n",
    "len(list_of_list_25_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dict_of_list_prod_prob_YY(list_input):\n",
    "    dict_output={}\n",
    "    for item in list_input:\n",
    "\n",
    "        df_subset_of_item=df_R1_train_YY_iterration.loc[df_R1_train_YY_iterration['item_id']==item,['buyer_admin_id','new_rank']].drop_duplicates()\n",
    "        len_to_exclude=len(df_subset_of_item)\n",
    "        \n",
    "        df_subset_of_item_2=df_subset_of_item.copy()\n",
    "        df_subset_of_item_2['new_rank']=df_subset_of_item_2['new_rank'].apply(lambda x: x+1)\n",
    "        df_subset_of_item=df_subset_of_item.append(df_subset_of_item_2)\n",
    "\n",
    "        df_subset_of_item=pd.merge(df_subset_of_item,df_R1_train_YY_iterration,on=['buyer_admin_id','new_rank'],how=\"left\")\n",
    "        df_subset_of_item=df_subset_of_item[pd.notnull(df_subset_of_item['item_id'])]\n",
    "\n",
    "        total_others=len(df_subset_of_item)-len_to_exclude\n",
    "        if total_others>0:\n",
    "            df_subset_of_item=df_subset_of_item.groupby(\"item_id\")['count'].sum().to_frame().reset_index()\n",
    "            df_subset_of_item['count']=np.where(df_subset_of_item['item_id']==item,df_subset_of_item['count']-len_to_exclude,df_subset_of_item['count'])\n",
    "            df_subset_of_item['prob']=df_subset_of_item['count']/total_others\n",
    "            df_subset_of_item=df_subset_of_item.sort_values(\"prob\",ascending=False).head(30)\n",
    "            dict_1_item=df_subset_of_item.set_index(\"item_id\").to_dict()['prob']\n",
    "        else:\n",
    "            dict_1_item={}\n",
    "        dict_output.update({item:dict_1_item})\n",
    "    return dict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Start of YY dict creation: \"+str(datetime.datetime.now()))\n",
    "from multiprocessing import Pool\n",
    "p = Pool(processors)\n",
    "result=p.map(get_dict_of_list_prod_prob_YY, list_of_list_25_subset)\n",
    "overall_output={}\n",
    "for res in result:\n",
    "    overall_output.update(res)\n",
    "\n",
    "p.close()\n",
    "p.join()\n",
    "\n",
    "logging.info(\"Done of YY dict creation: \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del result\n",
    "gc.collect()\n",
    "\n",
    "json.dump(overall_output, open('./dict_YY_prodcut.json', 'w'))\n",
    "logging.info(\"Done of YY dict writing: \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-09 14:56:51.989444\n",
      "2019-08-09 14:57:06.345520\n",
      "2019-08-09 14:57:07.573930\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "df_R1_train_XX=df_R1_train_XX.sort_values(['buyer_admin_id','create_order_time'],ascending=[True,True])\n",
    "\n",
    "df_temp=df_R1_train_XX[['buyer_admin_id','create_order_time']].drop_duplicates()\n",
    "new_rank=[]\n",
    "for buyer_id,df_group in df_temp.groupby(\"buyer_admin_id\"):\n",
    "    new_rank.extend([x+1 for x in range(len(df_group))])\n",
    "        \n",
    "df_temp['new_rank']=new_rank\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "df_R1_train_XX=pd.merge(df_R1_train_XX,df_temp,on=['buyer_admin_id','create_order_time'])\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "logging.info(\"Done of XX df sorting rerank: \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(item_list_hold_XX) 1581\n"
     ]
    }
   ],
   "source": [
    "df_XX_id_purchased_count=df_R1_train_XX.groupby(\"item_id\")['buyer_admin_id'].nunique().to_frame().reset_index().sort_values(\"buyer_admin_id\",ascending=False)\n",
    "item_list_hold_XX=df_XX_id_purchased_count[df_XX_id_purchased_count['buyer_admin_id']>=28]['item_id'].tolist()\n",
    "print(\"len(item_list_hold_XX)\",len(item_list_hold_XX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_per_subset=int(np.ceil(len(item_list_hold_XX)/processors))\n",
    "list_of_list_25_subset=[]\n",
    "for i in range(25):\n",
    "    lower_boundry=i*len_per_subset\n",
    "    upper_boundry=(i+1)*len_per_subset\n",
    "    list_of_list_25_subset=list_of_list_25_subset+[item_list_hold_XX[lower_boundry:upper_boundry]]\n",
    "len(list_of_list_25_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_R1_train_XX_iterration=df_R1_train_XX[['buyer_admin_id','item_id','new_rank']]\n",
    "df_R1_train_XX_iterration['count']=1\n",
    "df_R1_train_XX_iterration=df_R1_train_XX_iterration.groupby(['buyer_admin_id','item_id','new_rank'])['count'].sum().to_frame().reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dict_of_list_prod_prob_XX(list_input):\n",
    "    dict_output={}\n",
    "    for item in list_input:\n",
    "\n",
    "        df_subset_of_item=df_R1_train_XX_iterration.loc[df_R1_train_XX_iterration['item_id']==item,['buyer_admin_id','new_rank']].drop_duplicates()\n",
    "        len_to_exclude=len(df_subset_of_item)\n",
    "        \n",
    "        df_subset_of_item_2=df_subset_of_item.copy()\n",
    "        df_subset_of_item_2['new_rank']=df_subset_of_item_2['new_rank'].apply(lambda x: x+1)\n",
    "        df_subset_of_item=df_subset_of_item.append(df_subset_of_item_2)\n",
    "\n",
    "        df_subset_of_item=pd.merge(df_subset_of_item,df_R1_train_XX_iterration,on=['buyer_admin_id','new_rank'],how=\"left\")\n",
    "        df_subset_of_item=df_subset_of_item[pd.notnull(df_subset_of_item['item_id'])]\n",
    "\n",
    "        total_others=len(df_subset_of_item)-len_to_exclude\n",
    "        if total_others>0:\n",
    "            df_subset_of_item=df_subset_of_item.groupby(\"item_id\")['count'].sum().to_frame().reset_index()\n",
    "            df_subset_of_item['count']=np.where(df_subset_of_item['item_id']==item,df_subset_of_item['count']-len_to_exclude,df_subset_of_item['count'])\n",
    "            df_subset_of_item['prob']=df_subset_of_item['count']/total_others\n",
    "            df_subset_of_item=df_subset_of_item.sort_values(\"prob\",ascending=False).head(30)\n",
    "            dict_1_item=df_subset_of_item.set_index(\"item_id\").to_dict()['prob']\n",
    "        else:\n",
    "            dict_1_item={}\n",
    "        dict_output.update({item:dict_1_item})\n",
    "    return dict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Start of XX dict creating: \"+str(datetime.datetime.now()))\n",
    "\n",
    "p = Pool(processors)\n",
    "result=p.map(get_dict_of_list_prod_prob_XX, list_of_list_25_subset)\n",
    "overall_output={}\n",
    "for res in result:\n",
    "    overall_output.update(res)\n",
    "\n",
    "p.close()\n",
    "p.join()\n",
    "\n",
    "logging.info(\"Done of XX dict creation: \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dump(overall_output, open('./dict_XX_prodcut.json', 'w'))\n",
    "logging.info(\"Done of XX dict writing: \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
