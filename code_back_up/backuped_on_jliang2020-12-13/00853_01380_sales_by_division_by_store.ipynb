{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-23 22:02:34.204017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "def recursive_file_gen(root_folder):\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            yield os.path.join(root,file)\n",
    "\n",
    "start_date=datetime.date(2017,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jian/BigLots/2019_by_weeks/MediaStorm_2019-02-16/MediaStormDailySales20190219-113605-481.txt\n"
     ]
    }
   ],
   "source": [
    "all_POS_1_item_weekly=list(recursive_file_gen(\"/home/jian/BigLots/\"))\n",
    "all_POS_1_item_weekly=[x for x in all_POS_1_item_weekly if \"/MediaStorm_20\" in x and \"Daily\" in x]\n",
    "all_POS_1_item_weekly.sort()\n",
    "all_POS_1_item_weekly=[x for x in all_POS_1_item_weekly if x.split(\"/MediaStorm_\")[1][:10]>=\"2019-02-16\"] #hard-code\n",
    "print(all_POS_1_item_weekly[0])\n",
    "df_file_1=pd.DataFrame({\"file_path\":all_POS_1_item_weekly})\n",
    "df_file_1['week_end_dt']=df_file_1['file_path'].apply(lambda x: x.split(\"/MediaStorm_\")[1][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/MediaStormDailySalesHistory20180811.txt\n",
      "/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/MediaStormDailySalesHistory20190209.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>week_end_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jian/BigLots/hist_daily_data_itemlevel_d...</td>\n",
       "      <td>2018-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jian/BigLots/hist_daily_data_itemlevel_d...</td>\n",
       "      <td>2018-08-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path week_end_dt\n",
       "0  /home/jian/BigLots/hist_daily_data_itemlevel_d...  2018-08-11\n",
       "1  /home/jian/BigLots/hist_daily_data_itemlevel_d...  2018-08-18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_POS_2_item_hist=glob.glob(\"/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/*.txt\")\n",
    "all_POS_2_item_hist.sort()\n",
    "print(all_POS_2_item_hist[0])\n",
    "print(all_POS_2_item_hist[-1])\n",
    "df_file_2=pd.DataFrame({\"file_path\":all_POS_2_item_hist})\n",
    "df_file_2['week_end_dt']=df_file_2['file_path'].apply(lambda x: x.split(\"/MediaStormDailySalesHistory\")[1][:10])\n",
    "df_file_2['week_end_dt']=df_file_2['week_end_dt'].apply(lambda x: os.path.basename(x)[:4]+\"-\"+os.path.basename(x)[4:6]+\"-\"+os.path.basename(x)[6:8])\n",
    "df_file_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jian/BigLots/hist_daily_data_subclasslevel/MediaStormDailySales_week_ending_2017-02-11.txt\n",
      "/home/jian/BigLots/hist_daily_data_subclasslevel/MediaStormDailySales_week_ending_2018-06-09.txt\n"
     ]
    }
   ],
   "source": [
    "all_POS_3_subclass_hist=glob.glob(\"/home/jian/BigLots/hist_daily_data_subclasslevel/*.txt\")\n",
    "all_POS_3_subclass_hist.sort()\n",
    "all_POS_3_subclass_hist=[x for x in all_POS_3_subclass_hist if x.split(\"ySales_week_ending_\")[1][:10]>=str(start_date)]\n",
    "all_POS_3_subclass_hist=[x for x in all_POS_3_subclass_hist if x.split(\"ySales_week_ending_\")[1][:10]<=\"2018-08-04\"]\n",
    "print(all_POS_3_subclass_hist[0])\n",
    "print(all_POS_3_subclass_hist[-1])\n",
    "df_file_3=pd.DataFrame({\"file_path\":all_POS_3_subclass_hist})\n",
    "df_file_3['week_end_dt']=df_file_3['file_path'].apply(lambda x: x.split(\"MediaStormDailySales_week_ending_\")[1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-06-16/MediaStormDailySales.txt\n",
      "/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-08-04/MediaStormDailySales20180807-111637-702.txt\n"
     ]
    }
   ],
   "source": [
    "all_POS_4_subclass_weekly=list(recursive_file_gen(\"/home/jian/BigLots/\"))\n",
    "all_POS_4_subclass_weekly=[x for x in all_POS_4_subclass_weekly if \"/MediaStorm_20\" in x and \"Daily\" in x]\n",
    "all_POS_4_subclass_weekly=[x for x in all_POS_4_subclass_weekly if \"/MediaStorm_20\" in x and \".txt\" in x]\n",
    "\n",
    "all_POS_4_subclass_weekly.sort()\n",
    "all_POS_4_subclass_weekly=[x for x in all_POS_4_subclass_weekly if x.split(\"/MediaStorm_\")[1][:10]>=\"2018-06-09\"] #hard-code\n",
    "all_POS_4_subclass_weekly=[x for x in all_POS_4_subclass_weekly if x.split(\"/MediaStorm_\")[1][:10]<=\"2018-08-04\"] #hard-code\n",
    "print(all_POS_4_subclass_weekly[0])\n",
    "print(all_POS_4_subclass_weekly[-1])\n",
    "df_file_4=pd.DataFrame({\"file_path\":all_POS_4_subclass_weekly})\n",
    "df_file_4['week_end_dt']=df_file_4['file_path'].apply(lambda x: x.split(\"/MediaStorm_\")[1][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 2)\n",
      "162\n",
      "2017-02-11 2020-03-14\n"
     ]
    }
   ],
   "source": [
    "df_all_sales=pd.concat([df_file_1,df_file_2,df_file_3,df_file_4])\n",
    "df_all_sales=df_all_sales.sort_values(\"week_end_dt\")\n",
    "df_all_sales=df_all_sales.reset_index()\n",
    "del df_all_sales['index']\n",
    "print(df_all_sales.shape)\n",
    "print(df_all_sales['week_end_dt'].nunique())\n",
    "print(df_all_sales['week_end_dt'].min(),df_all_sales['week_end_dt'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sales['date']=df_all_sales['week_end_dt'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "df_all_sales['diff_week_counts']=df_all_sales['date'].apply(lambda x: int((x-datetime.date(2017,2,5)).days/7)+1)\n",
    "df_all_sales['diff_year_counts']=df_all_sales['date'].apply(lambda x: int(int((x-datetime.date(2017,2,5)).days/7)/52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_sales['Quarter']=df_all_sales['diff_week_counts'].apply(lambda x: int(x/13)%4+1)\n",
    "df_all_sales['Year']=df_all_sales['diff_year_counts'].apply(lambda x: 2017+x)\n",
    "df_all_sales['quarter_str']=df_all_sales[['Year','Quarter']].values.tolist()\n",
    "df_all_sales['quarter_str']=df_all_sales['quarter_str'].apply(lambda x: str(x[0])+\"_Q\"+str(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version. Use                 named aggregation instead.\n",
      "\n",
      "    >>> grouper.agg(name_1=func_1, name_2=func_2)\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>quarter_str</th>\n",
       "      <th colspan=\"3\" halign=\"left\">week_end_dt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017_Q1</td>\n",
       "      <td>2017-02-11</td>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017_Q2</td>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017_Q3</td>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>2017-10-28</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017_Q4</td>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>2018-01-27</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018_Q1</td>\n",
       "      <td>2018-02-10</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018_Q2</td>\n",
       "      <td>2018-05-05</td>\n",
       "      <td>2018-07-28</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018_Q3</td>\n",
       "      <td>2018-08-04</td>\n",
       "      <td>2018-10-27</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018_Q4</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019_Q1</td>\n",
       "      <td>2019-02-09</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019_Q2</td>\n",
       "      <td>2019-05-04</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019_Q3</td>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>2019-10-26</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019_Q4</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020_Q1</td>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quarter_str week_end_dt                  \n",
       "                       min         max count\n",
       "0      2017_Q1  2017-02-11  2018-02-03    13\n",
       "1      2017_Q2  2017-05-06  2017-07-29    13\n",
       "2      2017_Q3  2017-08-05  2017-10-28    13\n",
       "3      2017_Q4  2017-11-04  2018-01-27    13\n",
       "4      2018_Q1  2018-02-10  2019-02-02    13\n",
       "5      2018_Q2  2018-05-05  2018-07-28    13\n",
       "6      2018_Q3  2018-08-04  2018-10-27    13\n",
       "7      2018_Q4  2018-11-03  2019-01-26    13\n",
       "8      2019_Q1  2019-02-09  2020-02-01    13\n",
       "9      2019_Q2  2019-05-04  2019-07-27    13\n",
       "10     2019_Q3  2019-08-03  2019-10-26    13\n",
       "11     2019_Q4  2019-11-02  2020-01-25    13\n",
       "12     2020_Q1  2020-02-08  2020-03-14     6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sales.groupby(\"quarter_str\")['week_end_dt'].agg({\"week_end_dt\":['min','max','count']}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>week_end_dt</th>\n",
       "      <th>date</th>\n",
       "      <th>diff_week_counts</th>\n",
       "      <th>diff_year_counts</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>quarter_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jian/BigLots/hist_daily_data_subclasslev...</td>\n",
       "      <td>2017-02-11</td>\n",
       "      <td>2017-02-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017_Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jian/BigLots/hist_daily_data_subclasslev...</td>\n",
       "      <td>2017-02-18</td>\n",
       "      <td>2017-02-18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017_Q1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path week_end_dt        date  \\\n",
       "0  /home/jian/BigLots/hist_daily_data_subclasslev...  2017-02-11  2017-02-11   \n",
       "1  /home/jian/BigLots/hist_daily_data_subclasslev...  2017-02-18  2017-02-18   \n",
       "\n",
       "   diff_week_counts  diff_year_counts  Quarter  Year quarter_str  \n",
       "0                 1                 0        1  2017     2017_Q1  \n",
       "1                 2                 0        1  2017     2017_Q1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_sales.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-23 22:02:35.104513 2017-02-11\n",
      "2020-03-23 22:02:40.298684 2017-04-22\n",
      "2020-03-23 22:02:42.686944 done of quater:  2017_Q1\n",
      "2020-03-23 22:02:46.795547 2017-06-24\n",
      "2020-03-23 22:02:50.711227 done of quater:  2017_Q2\n",
      "2020-03-23 22:02:53.353816 2017-09-02\n",
      "2020-03-23 22:02:59.102360 done of quater:  2017_Q3\n",
      "2020-03-23 22:03:00.226662 2017-11-11\n",
      "2020-03-23 22:03:05.955275 2018-01-20\n",
      "2020-03-23 22:03:07.982135 done of quater:  2017_Q4\n",
      "2020-03-23 22:03:13.380260 2018-04-07\n",
      "2020-03-23 22:03:17.512768 done of quater:  2018_Q1\n",
      "2020-03-23 22:03:21.132771 2018-06-09\n",
      "2020-03-23 22:03:27.371181 done of quater:  2018_Q2\n",
      "2020-03-23 22:03:29.335839 2018-08-18\n",
      "2020-03-23 22:03:36.100856 2018-10-27\n",
      "2020-03-23 22:03:37.883232 done of quater:  2018_Q3\n",
      "2020-03-23 22:03:44.720571 2019-01-05\n",
      "2020-03-23 22:03:48.806136 done of quater:  2018_Q4\n",
      "2020-03-23 22:03:53.995126 2019-03-23\n",
      "2020-03-23 22:04:00.625605 done of quater:  2019_Q1\n",
      "2020-03-23 22:04:03.680538 2019-05-25\n",
      "2020-03-23 22:04:12.918143 done of quater:  2019_Q2\n",
      "2020-03-23 22:04:13.690316 2019-08-03\n",
      "2020-03-23 22:04:21.267324 2019-10-12\n",
      "2020-03-23 22:04:24.861312 done of quater:  2019_Q3\n",
      "2020-03-23 22:04:31.042002 2019-12-21\n",
      "2020-03-23 22:04:36.863559 done of quater:  2019_Q4\n",
      "2020-03-23 22:04:40.928675 2020-03-07\n",
      "2020-03-23 22:04:42.413817 done of quater:  2020_Q1\n"
     ]
    }
   ],
   "source": [
    "# samplerows=100000\n",
    "samplerows=None\n",
    "df_prod_taxonomy=pd.read_table(\"/home/jian/BigLots/static_files/ProductTaxonomy/MediaStormProductTaxonomy20200301-134228-899.txt\",\n",
    "                               sep=\"|\",dtype=str,usecols=['division_id','class_code_id','subclass_id']).drop_duplicates()\n",
    "df_output_by_week_store=pd.DataFrame()\n",
    "dict_output_by_week_shoppers=dict()\n",
    "df_output_by_quater_shoppers=pd.DataFrame()\n",
    "\n",
    "i=0\n",
    "for quarter,df_file_group in df_all_sales.groupby(\"quarter_str\"):\n",
    "    df_quarter_shopper=pd.DataFrame()\n",
    "    for ind,row in df_file_group.iterrows():\n",
    "        file_path=row['file_path']\n",
    "        week_end_dt=row['week_end_dt']\n",
    "        try:\n",
    "            df=pd.read_table(file_path,sep=\"|\",dtype=str,nrows=samplerows,\n",
    "                             usecols=['location_id','transaction_dt','transaction_id','customer_id_hashed','class_code_id','subclass_id','subclass_transaction_units','subclass_transaction_amt'])\n",
    "            df=df.rename(columns={\"subclass_transaction_units\":\"units\",\"subclass_transaction_amt\":\"sales\"})\n",
    "        except:\n",
    "            try:\n",
    "                df=pd.read_table(file_path,sep=\"|\",dtype=str,nrows=samplerows,\n",
    "                                 usecols=['location_id','transaction_dt','transaction_id','customer_id_hashed','class_code_id','subclass_id','item_transaction_units','item_transaction_amt'])\n",
    "                df=df.rename(columns={\"item_transaction_units\":\"units\",\"item_transaction_amt\":\"sales\"})\n",
    "            except:\n",
    "                print(file_path)\n",
    "                break\n",
    "        df['units']=df['units'].astype(int)\n",
    "        df['sales']=df['sales'].astype(float)\n",
    "        df=pd.merge(df,df_prod_taxonomy,on=['class_code_id','subclass_id'],how=\"left\")\n",
    "        df['division_id']=df['division_id'].fillna(\"others\")\n",
    "        df_rewards=df[pd.notnull(df['customer_id_hashed'])]\n",
    "        df_nonrewards=df[pd.isnull(df['customer_id_hashed'])]\n",
    "\n",
    "        df_rewards_sales=df_rewards.groupby([\"location_id\",'division_id'])['sales','units'].sum().reset_index()\n",
    "        df_rewards_sales=df_rewards_sales.rename(columns={\"sales\":\"rewards_sales\",\"units\":\"rewards_units\"})\n",
    "        df_rewards_trans=df_rewards[['location_id','transaction_dt','transaction_id','customer_id_hashed','division_id']].drop_duplicates()\n",
    "        df_rewards_trans=df_rewards_trans.groupby([\"location_id\",'division_id'])['transaction_id'].count().to_frame().reset_index()\n",
    "        df_rewards_trans=df_rewards_trans.rename(columns={\"transaction_id\":\"rewards_trans\"})\n",
    "        df_rewards_shoppers=df_rewards.groupby([\"location_id\",'division_id'])['customer_id_hashed'].nunique().to_frame().reset_index()\n",
    "        df_rewards_shoppers=df_rewards_shoppers.rename(columns={\"customer_id_hashed\":\"unique_shoppers\"})\n",
    "\n",
    "        df_nonrewards_sales=df_nonrewards.groupby([\"location_id\",'division_id'])['sales','units'].sum().reset_index()\n",
    "        df_nonrewards_sales=df_nonrewards_sales.rename(columns={\"sales\":\"nonrewards_sales\",\"units\":\"nonrewards_units\"})\n",
    "        df_nonrewards_trans=df_rewards[['location_id','transaction_dt','transaction_id','customer_id_hashed','division_id']].drop_duplicates()\n",
    "        df_nonrewards_trans=df_nonrewards_trans.groupby([\"location_id\",'division_id'])['transaction_id'].count().to_frame().reset_index()\n",
    "        df_nonrewards_trans=df_nonrewards_trans.rename(columns={\"transaction_id\":\"nonrewards_trans\"})\n",
    "\n",
    "        df_by_store=pd.merge(df_rewards_sales,df_rewards_trans,on=[\"location_id\",'division_id'],how=\"outer\")\n",
    "        df_by_store=pd.merge(df_by_store,df_rewards_shoppers,on=[\"location_id\",'division_id'],how=\"outer\")\n",
    "        df_by_store=pd.merge(df_by_store,df_nonrewards_sales,on=[\"location_id\",'division_id'],how=\"outer\")\n",
    "        df_by_store=pd.merge(df_by_store,df_nonrewards_trans,on=[\"location_id\",'division_id'],how=\"outer\")\n",
    "        df_by_store=df_by_store.fillna(0)\n",
    "        df_by_store.insert(0,\"week_end_dt\",[week_end_dt]*len(df_by_store))\n",
    "        df_by_store.insert(0,\"quarter\",[quarter]*len(df_by_store))\n",
    "\n",
    "        df_output_by_week_store=df_output_by_week_store.append(df_by_store)\n",
    "\n",
    "        shoppers_week=df_rewards['customer_id_hashed'].nunique()\n",
    "        dict_output_by_week_shoppers.update({week_end_dt:shoppers_week})\n",
    "        df_quarter_shopper=df_quarter_shopper.append(df_rewards[['division_id','customer_id_hashed']].drop_duplicates())\n",
    "        i+=1\n",
    "        if i%10==1:\n",
    "            print(datetime.datetime.now(),week_end_dt)\n",
    "            \n",
    "    df_id_quarter_shopper=df_quarter_shopper.groupby(['division_id'])['customer_id_hashed'].nunique().to_frame().reset_index()\n",
    "    df_id_quarter_shopper['quarter']='quarter'\n",
    "    df_output_by_quater_shoppers=df_output_by_quater_shoppers.append(df_id_quarter_shopper)\n",
    "    print(datetime.datetime.now(),\"done of quater: \",quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shopper_weekly=pd.DataFrame(dict_output_by_week_shoppers,index=[0]).T.reset_index()\n",
    "df_shopper_weekly.columns=['week_end_dt','shopper_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>division_id</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>198992</td>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5045</td>\n",
       "      <td>quarter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  division_id  customer_id_hashed  quarter\n",
       "0           1              198992  quarter\n",
       "1          10                5045  quarter"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_quater_shoppers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>week_end_dt</th>\n",
       "      <th>location_id</th>\n",
       "      <th>division_id</th>\n",
       "      <th>rewards_sales</th>\n",
       "      <th>rewards_units</th>\n",
       "      <th>rewards_trans</th>\n",
       "      <th>unique_shoppers</th>\n",
       "      <th>nonrewards_sales</th>\n",
       "      <th>nonrewards_units</th>\n",
       "      <th>nonrewards_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017_Q1</td>\n",
       "      <td>2017-02-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81.63</td>\n",
       "      <td>55.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>67.73</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017_Q1</td>\n",
       "      <td>2017-02-11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41.50</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>69.17</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017_Q1</td>\n",
       "      <td>2017-02-11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quarter week_end_dt location_id division_id  rewards_sales  rewards_units  \\\n",
       "0  2017_Q1  2017-02-11           1           1          81.63           55.0   \n",
       "1  2017_Q1  2017-02-11           1           2          41.50           23.0   \n",
       "2  2017_Q1  2017-02-11           1           3           2.00            2.0   \n",
       "\n",
       "   rewards_trans  unique_shoppers  nonrewards_sales  nonrewards_units  \\\n",
       "0           31.0             31.0             67.73              40.0   \n",
       "1           14.0             14.0             69.17              39.0   \n",
       "2            1.0              1.0              0.00               0.0   \n",
       "\n",
       "   nonrewards_trans  \n",
       "0              31.0  \n",
       "1              14.0  \n",
       "2               1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_week_store.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_quarter_agg=df_output_by_week_store.groupby(['quarter','division_id'])['rewards_sales','rewards_units','rewards_trans',\n",
    "                                                                                'nonrewards_sales','nonrewards_units','nonrewards_trans'].sum().reset_index()\n",
    "df_output_quarter_store_count=df_output_by_week_store.groupby(['quarter','division_id'])['location_id'].nunique().to_frame().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_quarter_agg=pd.merge(df_output_quarter_agg,df_output_by_quater_shoppers,on=['quarter','division_id'],how=\"left\")\n",
    "df_output_quarter_agg=pd.merge(df_output_quarter_agg,df_output_quarter_store_count,on=['quarter','division_id'],how=\"left\")\n",
    "df_output_quarter_agg=df_output_quarter_agg.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>division_id</th>\n",
       "      <th>quarter</th>\n",
       "      <th>week_end_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017_Q1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017_Q2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id division_id  quarter  week_end_dt\n",
       "0           1           1  2017_Q1           13\n",
       "1           1           1  2017_Q2           13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_available=df_output_by_week_store.groupby(['location_id','division_id','quarter'])['week_end_dt'].count().to_frame().reset_index()\n",
    "df_store_available.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_output_by_week_store.shape (1536994, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"df_output_by_week_store.shape\",df_output_by_week_store.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"./BL_divsion_sales_2_years_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_output_quarter_agg.to_excel(writer,\"performace\",index=False)\n",
    "df_store_available.to_excel(writer,\"store_weeks_available\",index=False)\n",
    "writer.save()\n",
    "\n",
    "df_output_by_week_store.to_csv(\"./BL_2_years_sales_by_store_division_week_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
