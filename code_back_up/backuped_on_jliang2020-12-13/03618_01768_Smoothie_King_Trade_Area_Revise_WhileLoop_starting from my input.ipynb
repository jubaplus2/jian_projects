{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine_zips_with_any_intersection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from haversine import haversine\n",
    "import zipcodes\n",
    "import geocoder\n",
    "Bing_key = \"Avga1gIvFuPIXtcrunxy_sYkQkrLSKTb9XKFrUAb6nnfzG4eC6SwuuznZAw-byWJ\"\n",
    "\n",
    "# https://www.unitedstateszipcodes.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_centers=json.load(open(\"/home/jian/Docs/Geo_mapping/center_of_rentrak_zip.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5389565450652434"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haversine(zip_centers['78734'],[30.34570611,-97.96602215],miles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata=pd.read_csv(\"/home/jian/Projects/Smoothie_King/TA/data_from_Jay/zip_within_3_mile.csv\",dtype=str)\\ndata[\\'zip_code\\']=data[\\'zip_code\\'].apply(lambda x: x.zfill(5))\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data=pd.read_csv(\"/home/jian/Projects/Smoothie_King/TA/data_from_Jay/zip_within_3_mile.csv\",dtype=str)\n",
    "data['zip_code']=data['zip_code'].apply(lambda x: x.zfill(5))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_list=pd.read_excel(\"/home/jian/Projects/Smoothie_King/TA/StoreList.xlsx\",dtype=str)\n",
    "closed_stores=store_list[store_list['status']==\"Closed\"].reset_index()\n",
    "\n",
    "store_list=store_list[store_list['status']!=\"Closed\"].reset_index()\n",
    "del store_list['index']\n",
    "store_list['zip']=store_list['zip'].apply(lambda x: x.zfill(5))\n",
    "store_list['storenumber']=store_list['storenumber'].astype(int)\n",
    "store_list=store_list.sort_values(['storenumber'])\n",
    "store_list['storenumber']=store_list['storenumber'].astype(str)\n",
    "store_list=store_list.reset_index()\n",
    "del store_list['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "store_list['Bing_LatLng']=np.nan\n",
    "store_list['Bing_Address']=np.nan\n",
    "for i in range(len(store_list)):\n",
    "    if store_list['Latitude'][i]==\"nan\":\n",
    "        search_key=store_list['Address'][i]+\", \"+store_list['city'][i]+\", \"+store_list['state'][i]+\", \"+store_list['zip'][i]\n",
    "        \n",
    "        response=geocoder.bing(search_key,key=Bing_key)\n",
    "        if len(response)>0:\n",
    "            lat_lng=response.latlng\n",
    "            store_list['Latitude'][i]=lat_lng[0]\n",
    "            store_list['Longitude'][i]=lat_lng[1]\n",
    "            store_list['Bing_LatLng'][i]=\"Bing\"\n",
    "            store_list['Bing_Address'][i]=response.address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "store_list['Zip_of_LatLng']=np.nan\n",
    "store_list['Zip_of_Address']=np.nan\n",
    "\n",
    "# Manually change of the lat/long for store 1670\n",
    "store_list['Latitude'][store_list['Latitude']==\"nan\"]=39.9353979\n",
    "store_list['Longitude'][store_list['Longitude']==\"nan\"]=-91.3444578\n",
    "\n",
    "for i in range(len(store_list)):\n",
    "\n",
    "    coor_pair=[float(store_list['Latitude'][i]),float(store_list['Longitude'][i])]\n",
    "    response=geocoder.bing(coor_pair,key=Bing_key,method='reverse')\n",
    "    postal_reverse_latlng=response.postal\n",
    "    store_list['Zip_of_LatLng'][i]=postal_reverse_latlng\n",
    "\n",
    "    search_key=store_list['Address'][i]+\", \"+store_list['city'][i]+\", \"+store_list['state'][i]+\", \"+store_list['zip'][i]\n",
    "    response=geocoder.bing(search_key,key=Bing_key)\n",
    "    postal_reverse_add=response.postal\n",
    "    store_list['Zip_of_Address'][i]=postal_reverse_add\n",
    "    \n",
    "store_list['Zip_of_LatLng']=store_list['Zip_of_LatLng'].apply(lambda x: str(x).split(\".\")[0].zfill(5))\n",
    "store_list['Zip_of_Address']=store_list['Zip_of_Address'].apply(lambda x: str(x).split(\".\")[0].zfill(5))\n",
    "store_list['store_zip']=store_list['zip'].apply(lambda x: x.split(\"-\")[0].zfill(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check=store_list[(store_list['Zip_of_LatLng']!=store_list['store_zip']) &\\\n",
    "                 (store_list['Zip_of_Address']!=store_list['store_zip']) &\\\n",
    "                 (store_list['zip']!='00nan') &\\\n",
    "                 ((store_list['Zip_of_LatLng']!='00nan') | (store_list['Zip_of_Address']!='00nan'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['402', '595', '953', '1279', '58', '387', '1464', '1252', '1282', '1386', '989', '1132', '1384', '1432', '1125'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manually_revise_zip={\"402\":\"36832\",\"595\":\"75201\",\"953\":\"27707\",\"1279\":\"70808\",\"58\":\"33618\",\"387\":\"77478\",\n",
    "                     \"1464\":\"07901\",\"1252\":\"73013\",\"1282\":\"70803\",\"1386\":\"62711\",\"989\":\"70130\",\"1132\":\"31605\",\n",
    "                     \"1384\":\"30075\",\"1432\":\"30281\",\"1125\":\"33136\"}\n",
    "manually_revise_zip.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "store_list=store_list.reset_index()\n",
    "del store_list['index']\n",
    "store_list['revised_store_zip']=np.nan\n",
    "for i in range(len(store_list)):\n",
    "    if (store_list['storenumber'][i] in manually_revise_zip.keys()):\n",
    "        store_list['revised_store_zip'][i]=manually_revise_zip[store_list['storenumber'][i]]\n",
    "    elif ((store_list['Zip_of_LatLng'][i]==\"00nan\") & (store_list['Zip_of_Address'][i]==\"00nan\")):\n",
    "        store_list['revised_store_zip'][i]=store_list['store_zip'][i]        \n",
    "    elif ((store_list['store_zip'][i]==store_list['Zip_of_LatLng'][i]) |\\\n",
    "          (store_list['store_zip'][i]==store_list['Zip_of_Address'][i])):\n",
    "        store_list['revised_store_zip'][i]=store_list['store_zip'][i]\n",
    "    elif (store_list['Zip_of_LatLng'][i]==store_list['Zip_of_Address'][i]):\n",
    "        store_list['revised_store_zip'][i]=store_list['Zip_of_LatLng'][i]\n",
    "store_list['revised_store_zip']=store_list['revised_store_zip'].apply(lambda x: str(int(x)).zfill(5))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storenumber</th>\n",
       "      <th>Address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>StoreOpenDate</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Ownership</th>\n",
       "      <th>Franchisee_Name</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>DriveThru</th>\n",
       "      <th>status</th>\n",
       "      <th>StoreCloseDate</th>\n",
       "      <th>Bing_LatLng</th>\n",
       "      <th>Bing_Address</th>\n",
       "      <th>Zip_of_LatLng</th>\n",
       "      <th>Zip_of_Address</th>\n",
       "      <th>store_zip</th>\n",
       "      <th>revised_store_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [storenumber, Address, city, state, zip, StoreOpenDate, Latitude, Longitude, Ownership, Franchisee_Name, IPAddress, DriveThru, status, StoreCloseDate, Bing_LatLng, Bing_Address, Zip_of_LatLng, Zip_of_Address, store_zip, revised_store_zip]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list[pd.isnull(store_list['revised_store_zip'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storenumber</th>\n",
       "      <th>Address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>StoreOpenDate</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Ownership</th>\n",
       "      <th>Franchisee_Name</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>DriveThru</th>\n",
       "      <th>status</th>\n",
       "      <th>StoreCloseDate</th>\n",
       "      <th>Bing_LatLng</th>\n",
       "      <th>Bing_Address</th>\n",
       "      <th>Zip_of_LatLng</th>\n",
       "      <th>Zip_of_Address</th>\n",
       "      <th>store_zip</th>\n",
       "      <th>revised_store_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [storenumber, Address, city, state, zip, StoreOpenDate, Latitude, Longitude, Ownership, Franchisee_Name, IPAddress, DriveThru, status, StoreCloseDate, Bing_LatLng, Bing_Address, Zip_of_LatLng, Zip_of_Address, store_zip, revised_store_zip]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list[store_list['revised_store_zip']==\"00nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overwrite_zip_stores=store_list[store_list['revised_store_zip']!=store_list['store_zip']]\n",
    "overwrite_zip_stores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get 3 miles zips based on lat lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "store_list['zips_3_miles']=np.nan\n",
    "for i in range(len(store_list)):\n",
    "    store_center=[float(store_list['Latitude'][i]),float(store_list['Longitude'][i])]\n",
    "    list_zip_3_miles=[store_list['revised_store_zip'][i]]\n",
    "    for zip_cd in zip_centers.keys():\n",
    "        dist=haversine(store_center,zip_centers[zip_cd],miles=True)\n",
    "        if dist<=3:\n",
    "            list_zip_3_miles=list_zip_3_miles+[zip_cd]\n",
    "    store_list['zips_3_miles'][i]=list(set(list_zip_3_miles))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=store_list.copy()\n",
    "store_list_df=store_list.copy()\n",
    "data.columns.tolist()\n",
    "del data['Bing_LatLng']\n",
    "del data['Bing_Address']\n",
    "del data['Zip_of_LatLng']\n",
    "del data['Zip_of_Address']\n",
    "del data['store_zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(store_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['TA']=np.nan\n",
    "data=data.reset_index()\n",
    "del data['index']\n",
    "df_TA_zips=pd.DataFrame({\"store\":[data['storenumber'][0]]*len(data['zips_3_miles'][0]),\"zip\":data['zips_3_miles'][0],\"TA\":[1]*len(data['zips_3_miles'][0])},index=[1]*len(data['zips_3_miles'][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "TA_counter=1\n",
    "\n",
    "for i in range(1,len(data)):\n",
    "    intersection_zip=list(set(data['zips_3_miles'][i]).intersection(set(df_TA_zips['zip'].unique().tolist())))\n",
    "    if len(intersection_zip)==0:\n",
    "        TA_counter+=1\n",
    "        df_TA_zips=df_TA_zips.append(pd.DataFrame({\"store\":[data['storenumber'][i]]*len(data['zips_3_miles'][i]),\"zip\":data['zips_3_miles'][i],\"TA\":[TA_counter]*len(data['zips_3_miles'][i])},index=[i]*len(data['zips_3_miles'][i]))).drop_duplicates()\n",
    "        \n",
    "    else:\n",
    "        df_intersection=df_TA_zips[df_TA_zips['zip'].isin(intersection_zip)]\n",
    "        group_df_intersection=df_intersection.groupby(['TA'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False)\n",
    "        selected_TA=group_df_intersection['TA'][0] \n",
    "        \n",
    "        df_TA_zips_0=df_TA_zips[~df_TA_zips['TA'].isin(set(group_df_intersection['TA']))]\n",
    "        df_TA_zips_1=df_TA_zips[df_TA_zips['TA'].isin(group_df_intersection['TA'].tolist())]\n",
    "        df_TA_zips_1['TA']=selected_TA\n",
    "        df_TA_zips=df_TA_zips_0.append(df_TA_zips_1).append(pd.DataFrame({\"store\":[data['storenumber'][i]]*len(data['zips_3_miles'][i]),\"zip\":data['zips_3_miles'][i],\"TA\":[selected_TA]*len(data['zips_3_miles'][i])},index=[i]*len(data['zips_3_miles'][i]))).drop_duplicates()\n",
    "        \n",
    "dict_TA_zips=df_TA_zips.set_index('zip').to_dict()['TA']\n",
    "dict_TA_store=df_TA_zips.set_index('store').to_dict()['TA']\n",
    "data['TA']=data['storenumber'].apply(lambda x: dict_TA_store[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(886, 17)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TA'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ta_num_unique=data[['TA']].drop_duplicates().reset_index()\n",
    "del df_ta_num_unique['index']\n",
    "df_ta_num_unique['new_TA']=[x+1 for x in range(len(df_ta_num_unique))]\n",
    "\n",
    "dict_ta_num_unique=df_ta_num_unique.set_index(['TA']).to_dict()['new_TA']\n",
    "data['TA']=data['TA'].apply(lambda x: dict_ta_num_unique[x])\n",
    "df_TA_zips['TA']=df_TA_zips['TA'].apply(lambda x: dict_ta_num_unique[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "summary_store=data.groupby(\"TA\")['storenumber'].count().to_frame().reset_index().rename(columns={\"storenumber\":\"store_count\"})\n",
    "summary_zip=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].count().to_frame().reset_index().rename(columns={\"zip\":\"zip_count\"})\n",
    "# summary_store_2=df_TA_zips[['TA','store']].drop_duplicates().groupby(\"TA\")['store'].count().to_frame().reset_index().rename(columns={\"store\":\"store_count_2\"})\n",
    "summary_store_list=data.groupby(\"TA\")['storenumber'].apply(list).to_frame().reset_index().rename(columns={\"storenumber\":\"store_list\"})\n",
    "summary_zip_list=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].apply(list).to_frame().reset_index().rename(columns={\"zip\":\"zip_list\"})\n",
    "\n",
    "\n",
    "\n",
    "summary_by_TA=pd.merge(summary_store,summary_zip,on=\"TA\",how=\"outer\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,summary_store_list,on=\"TA\",how=\"outer\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,summary_zip_list,on=\"TA\",how=\"outer\")\n",
    "\n",
    "# summary=pd.merge(summary,summary_store_2,on=\"TA\",how=\"outer\")\n",
    "TA_Store_zip_list=data.groupby(['TA'])['revised_store_zip'].apply(set).to_frame().reset_index().rename(columns={\"revised_store_zip\":\"store_zip_list\"})\n",
    "summary_by_TA=pd.merge(summary_by_TA,TA_Store_zip_list,on=\"TA\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_by_TA.hea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_by_store_count=summary_by_TA.groupby(['store_count'])['TA'].count().to_frame().reset_index().rename(columns={\"TA\":\"TA_count\"})\n",
    "summary_by_store_list=summary_by_TA.groupby(['store_count'])['TA'].apply(list).to_frame().reset_index().rename(columns={\"TA\":\"TA_list\"})\n",
    "summary_by_store_count=pd.merge(summary_by_store_count,summary_by_store_list,on=\"store_count\",how=\"outer\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_zip_dist_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_zip_dist_in_TA['index']\n",
    "\n",
    "output_distance_zip_in_TA=pd.DataFrame()\n",
    "counter_k=0\n",
    "for ta,group in df_zip_dist_in_TA.groupby(['TA']):\n",
    "    group=group.reset_index()\n",
    "    del group['index']\n",
    "    \n",
    "    if len(group)>1:\n",
    "    \n",
    "        dist_list=[]\n",
    "\n",
    "        for i in range(len(group)):\n",
    "            zip_hold=group['zip'][i]\n",
    "\n",
    "            if zip_hold not in zip_centers.keys():\n",
    "                try:\n",
    "                    zip_hold_center=(zipcodes.matching(zip_hold)[0]['lat'],zipcodes.matching(zip_hold)[0]['long'])\n",
    "                except:\n",
    "                    print(\"zip not found, \",zip_hold)\n",
    "\n",
    "            else:\n",
    "                zip_hold_center=zip_centers[zip_hold]\n",
    "\n",
    "            for j in range(i+1,len(group)):\n",
    "                zip_var=group['zip'][j]\n",
    "                if zip_var not in zip_centers.keys():\n",
    "                    try:\n",
    "                        zip_var_center=(zipcodes.matching(zip_var)[0]['lat'],zipcodes.matching(zip_var)[0]['long'])\n",
    "                    except:\n",
    "                        print(\"zip not found, \",zip_hold)\n",
    "\n",
    "                else:\n",
    "                    zip_var_center=zip_centers[zip_var]\n",
    "\n",
    "                try:\n",
    "                    dist=haversine(zip_hold_center,zip_var_center,miles=True)\n",
    "                except:\n",
    "                    dist=np.nan\n",
    "\n",
    "                dist_list=dist_list+[dist]\n",
    "        df=pd.DataFrame({\"TA\":ta,\"dist_min\":min(dist_list),\"dist_max\":max(dist_list),\"dist_median\":np.median(dist_list),\"All_dist\":[dist_list]},index=[counter_k])\n",
    "        counter_k+=1\n",
    "        output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "    else:\n",
    "        df=pd.DataFrame({\"TA\":ta,\"dist_min\":0,\"dist_max\":0,\"dist_median\":0,\"All_dist\":\"single_zip\"},index=[counter_k])\n",
    "        output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_DMA=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",dtype=str,skiprows=1)\n",
    "zip_DMA=zip_DMA.iloc[:,[0,2]]\n",
    "zip_DMA.columns=['zip','DMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_city_state_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_city_state_in_TA['index']\n",
    "\n",
    "def city_of_zip(x):\n",
    "    try:\n",
    "        city=zipcodes.matching(x)[0]['city']\n",
    "    except:\n",
    "        city=np.nan\n",
    "    return city\n",
    "\n",
    "def state_of_zip(x):\n",
    "    try:\n",
    "        state=zipcodes.matching(x)[0]['state']\n",
    "    except:\n",
    "        state=np.nan\n",
    "    return state\n",
    "    \n",
    "df_city_state_in_TA['city']=df_city_state_in_TA['zip'].apply(lambda x: city_of_zip(x))\n",
    "df_city_state_in_TA['state']=df_city_state_in_TA['zip'].apply(lambda x: state_of_zip(x))\n",
    "df_city_state_in_TA['city']=df_city_state_in_TA['city']+\" (\"+df_city_state_in_TA['state']+\")\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>zip</th>\n",
       "      <th>DMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>70047</td>\n",
       "      <td>NEW ORLEANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>70031</td>\n",
       "      <td>NEW ORLEANS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA    zip          DMA\n",
       "0   3  70047  NEW ORLEANS\n",
       "1   3  70031  NEW ORLEANS"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_DMA_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_DMA_in_TA['index']\n",
    "df_DMA_in_TA=pd.merge(df_DMA_in_TA,zip_DMA,on=\"zip\",how=\"left\")\n",
    "df_DMA_in_TA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_city_TA_list=df_city_state_in_TA.groupby(['TA'])['city'].apply(set).to_frame().reset_index()\n",
    "df_city_TA_list=df_city_TA_list.rename(columns={\"city\":\"city_list\"})\n",
    "df_state_TA_list=df_city_state_in_TA.groupby(['TA'])['state'].apply(set).to_frame().reset_index()\n",
    "df_state_TA_list=df_state_TA_list.rename(columns={\"state\":\"state_list\"})\n",
    "df_DMA_TA_list=df_DMA_in_TA.groupby(['TA'])['DMA'].apply(set).to_frame().reset_index()\n",
    "df_DMA_TA_list=df_DMA_TA_list.rename(columns={\"DMA\":\"DMA_list\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "manually_city_dict_of_zip={\"29486\":\"Summerville\"}\n",
    "manually_state_dict_of_zip={\"29486\":\"SC\"}\n",
    "df_city_state_in_TA['city'][df_city_state_in_TA['zip']=='29486']=manually_city_dict_of_zip['29486']\n",
    "df_city_state_in_TA['state'][df_city_state_in_TA['zip']=='29486']=manually_state_dict_of_zip['29486']\n",
    "\n",
    "removed_2_zips_df=df_city_state_in_TA[pd.isnull(df_city_state_in_TA['city'])]\n",
    "df_city_state_in_TA=df_city_state_in_TA[~pd.isnull(df_city_state_in_TA['city'])]\n",
    "# zip \"08644\",\"76190\" removed to determine cities/states because of not existing as in https://www.unitedstateszipcodes.org/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter_k=1\n",
    "df_primary_city_state=pd.DataFrame()\n",
    "df_primary_DMA=pd.DataFrame()\n",
    "for ta,group in df_city_state_in_TA.groupby(['TA']):\n",
    "    df_city=group.groupby(['city'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_city['index']\n",
    "    primary_city=df_city['city'][0]\n",
    "    \n",
    "    df_state=group.groupby(['state'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_state['index']\n",
    "    primary_state=df_state['state'][0]\n",
    "    \n",
    "    df=pd.DataFrame({\"TA\":ta,\"Primary_City\":primary_city,\"Primary_State\":primary_state},index=[counter_k])\n",
    "    counter_k+=1\n",
    "    df_primary_city_state=df_primary_city_state.append(df)\n",
    "\n",
    "    \n",
    "for ta,group in df_DMA_in_TA.groupby(['TA']):\n",
    "    df_DMA=group.groupby(['DMA'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_DMA['index']\n",
    "    primary_DMA=df_DMA['DMA'][0]\n",
    "    \n",
    "    df=pd.DataFrame({\"TA\":ta,\"Primary_DMA\":primary_DMA},index=[counter_k])\n",
    "    counter_k+=1\n",
    "    df_primary_DMA=df_primary_DMA.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_by_TA=pd.merge(summary_by_TA,df_city_TA_list,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_state_TA_list,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_DMA_TA_list,on=\"TA\",how=\"left\")\n",
    "\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_primary_city_state,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_primary_DMA,on=\"TA\",how=\"left\")\n",
    "\n",
    "summary_by_TA=pd.merge(summary_by_TA,output_distance_zip_in_TA,on=\"TA\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Latitude']=data['Latitude'].astype(float)\n",
    "data['Longitude']=data['Longitude'].astype(float)\n",
    "data['TA']=data['TA'].astype(str)\n",
    "summary_by_TA['TA']=summary_by_TA['TA'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_by_TA['ratio_max_media']=summary_by_TA['dist_max']/summary_by_TA['dist_median']\n",
    "\n",
    "summary_by_TA_to_revise=summary_by_TA[(summary_by_TA['ratio_max_media']>2) &\\\n",
    "                                      (summary_by_TA['store_count']>=2) &\\\n",
    "                                     (summary_by_TA['dist_max']>12)]\n",
    "summary_by_TA_to_keep=summary_by_TA[(summary_by_TA['ratio_max_media']<=2) |\\\n",
    "                                      (summary_by_TA['store_count']<2) |\\\n",
    "                                     (summary_by_TA['dist_max']<=12)]\n",
    "summary_by_TA_to_revise=summary_by_TA_to_revise.reset_index()\n",
    "del summary_by_TA_to_revise['index']\n",
    "\n",
    "summary_by_TA_to_keep=summary_by_TA_to_keep.reset_index()\n",
    "del summary_by_TA_to_keep['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary_by_TA['TA'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'str'>], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_by_TA['TA'].apply(lambda x: type(x)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_by_TA['TA'].astype(int).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loop_counter=0\n",
    "while len(summary_by_TA_to_revise)>0:\n",
    "    loop_counter+=1\n",
    "    if loop_counter>30:\n",
    "        break\n",
    "    \n",
    "    summary_by_TA_to_revise=summary_by_TA_to_revise.reset_index()\n",
    "    del summary_by_TA_to_revise['index']\n",
    "\n",
    "    summary_by_TA_to_keep=summary_by_TA_to_keep.reset_index()\n",
    "    del summary_by_TA_to_keep['index']\n",
    "\n",
    "    data_keep=data[data['TA'].isin(summary_by_TA_to_keep['TA'])]\n",
    "    data_revise=data[~data['TA'].isin(summary_by_TA_to_keep['TA'])]\n",
    "    data_revise=data_revise.reset_index()\n",
    "    del data_revise['index']\n",
    "\n",
    "\n",
    "    store_lat_dict=data_revise.set_index(['storenumber']).to_dict()['Latitude']\n",
    "    store_lng_dict=data_revise.set_index(['storenumber']).to_dict()['Longitude']\n",
    "\n",
    "\n",
    "    store_sub_df=pd.DataFrame()\n",
    "    for i in range(len(summary_by_TA_to_revise)):\n",
    "        TA=summary_by_TA_to_revise['TA'][i]\n",
    "        store_list=summary_by_TA_to_revise['store_list'][i].copy()\n",
    "        initial_dist=0\n",
    "        store_pair=[np.nan,np.nan]\n",
    "        while len(store_list)>=2:\n",
    "            store_hold=store_list[0]\n",
    "            store_list.remove(store_hold)\n",
    "            store_hold_center=[store_lat_dict[store_hold],store_lng_dict[store_hold]]\n",
    "            for store_var in store_list:\n",
    "                store_var_center=[store_lat_dict[store_var],store_lng_dict[store_var]]\n",
    "                dist=haversine(store_hold_center,store_var_center,miles=True)\n",
    "                if dist>initial_dist:\n",
    "                    initial_dist=dist\n",
    "                    store_pair=[store_hold,store_var]\n",
    "        store_a=store_pair[0]\n",
    "        store_b=store_pair[1]\n",
    "\n",
    "        store_a_center=[store_lat_dict[store_a],store_lng_dict[store_a]]\n",
    "        store_b_center=[store_lat_dict[store_b],store_lng_dict[store_b]]\n",
    "        store_list=summary_by_TA_to_revise['store_list'][i].copy()\n",
    "        for store in store_list:\n",
    "            store_center=[store_lat_dict[store],store_lng_dict[store]]\n",
    "            dist_a=haversine(store_a_center,store_center,miles=True)\n",
    "            dist_b=haversine(store_b_center,store_center,miles=True)\n",
    "            if dist_a<dist_b:\n",
    "                sub_group=\"a\"\n",
    "            else:\n",
    "                sub_group=\"b\"\n",
    "            df=pd.DataFrame({\"storenumber\":store,\"TA\":TA,\"sub_group\":sub_group},index=[store])\n",
    "            store_sub_df=store_sub_df.append(df)\n",
    "    \n",
    "    store_sub_df['TA']=store_sub_df['TA'].astype(str)\n",
    "    store_sub_df['TA']=store_sub_df['TA']+\"_\"+store_sub_df['sub_group']\n",
    "    store_sub_df=store_sub_df[['storenumber','TA']]\n",
    "    store_sub_df_dic=store_sub_df.set_index(['storenumber']).to_dict()['TA']\n",
    "                    \n",
    "    data_revise['TA']=data_revise['storenumber'].apply(lambda x: store_sub_df_dic[x])\n",
    "    data=data_keep.append(data_revise)\n",
    "    data=data.sort_values(['storenumber'])\n",
    "    data=data.reset_index()\n",
    "    del data['index']\n",
    "    data['TA']=data['TA'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "    df_TA_zips=pd.DataFrame()\n",
    "    for i in range(len(data)):\n",
    "        df=pd.DataFrame({\"store\":[data['storenumber'][i]]*len(data['zips_3_miles'][i]),\n",
    "                         \"TA\":[data['TA'][i]]*len(data['zips_3_miles'][i]),\n",
    "                         \"zip\":data['zips_3_miles'][i]},index=data['zips_3_miles'][i])\n",
    "        df_TA_zips=df_TA_zips.append(df)\n",
    "\n",
    "\n",
    "    summary_store=data.groupby(\"TA\")['storenumber'].count().to_frame().reset_index().rename(columns={\"storenumber\":\"store_count\"})\n",
    "    summary_zip=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].count().to_frame().reset_index().rename(columns={\"zip\":\"zip_count\"})\n",
    "    summary_store_list=data.groupby(\"TA\")['storenumber'].apply(list).to_frame().reset_index().rename(columns={\"storenumber\":\"store_list\"})\n",
    "    summary_zip_list=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].apply(list).to_frame().reset_index().rename(columns={\"zip\":\"zip_list\"})\n",
    "\n",
    "    summary_by_TA=pd.merge(summary_store,summary_zip,on=\"TA\",how=\"outer\")\n",
    "    summary_by_TA=pd.merge(summary_by_TA,summary_store_list,on=\"TA\",how=\"outer\")\n",
    "    summary_by_TA=pd.merge(summary_by_TA,summary_zip_list,on=\"TA\",how=\"outer\")\n",
    "\n",
    "    # summary=pd.merge(summary,summary_store_2,on=\"TA\",how=\"outer\")\n",
    "    TA_Store_zip_list=data.groupby(['TA'])['revised_store_zip'].apply(set).to_frame().reset_index().rename(columns={\"zip_code\":\"store_zip_list\"})\n",
    "    summary_by_TA=pd.merge(summary_by_TA,TA_Store_zip_list,on=\"TA\",how=\"left\")\n",
    "\n",
    "\n",
    "    summary_by_store_count=summary_by_TA.groupby(['store_count'])['TA'].count().to_frame().reset_index().rename(columns={\"TA\":\"TA_count\"})\n",
    "    summary_by_store_list=summary_by_TA.groupby(['store_count'])['TA'].apply(list).to_frame().reset_index().rename(columns={\"TA\":\"TA_list\"})\n",
    "    summary_by_store_count=pd.merge(summary_by_store_count,summary_by_store_list,on=\"store_count\",how=\"outer\")\n",
    "\n",
    "    df_zip_dist_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "    del df_zip_dist_in_TA['index']\n",
    "\n",
    "    output_distance_zip_in_TA=pd.DataFrame()\n",
    "    counter_k=0\n",
    "    for ta,group in df_zip_dist_in_TA.groupby(['TA']):\n",
    "        group=group.reset_index()\n",
    "        del group['index']\n",
    "\n",
    "        if len(group)>1:\n",
    "\n",
    "            dist_list=[]\n",
    "\n",
    "            for i in range(len(group)):\n",
    "                zip_hold=group['zip'][i]\n",
    "\n",
    "                if zip_hold not in zip_centers.keys():\n",
    "                    try:\n",
    "                        zip_hold_center=(zipcodes.matching(zip_hold)[0]['lat'],zipcodes.matching(zip_hold)[0]['long'])\n",
    "                    except:\n",
    "                        print(\"zip not found, \",zip_hold)\n",
    "\n",
    "                else:\n",
    "                    zip_hold_center=zip_centers[zip_hold]\n",
    "\n",
    "                for j in range(i+1,len(group)):\n",
    "                    zip_var=group['zip'][j]\n",
    "                    if zip_var not in zip_centers.keys():\n",
    "                        try:\n",
    "                            zip_var_center=(zipcodes.matching(zip_var)[0]['lat'],zipcodes.matching(zip_var)[0]['long'])\n",
    "                        except:\n",
    "                            print(\"zip not found, \",zip_hold)\n",
    "\n",
    "                    else:\n",
    "                        zip_var_center=zip_centers[zip_var]\n",
    "\n",
    "                    try:\n",
    "                        dist=haversine(zip_hold_center,zip_var_center,miles=True)\n",
    "                    except:\n",
    "                        dist=np.nan\n",
    "\n",
    "                    dist_list=dist_list+[dist]\n",
    "            df=pd.DataFrame({\"TA\":ta,\"dist_min\":min(dist_list),\"dist_max\":max(dist_list),\"dist_median\":np.median(dist_list),\"All_dist\":[dist_list]},index=[counter_k])\n",
    "            counter_k+=1\n",
    "            output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "        else:\n",
    "            df=pd.DataFrame({\"TA\":ta,\"dist_min\":0,\"dist_max\":0,\"dist_median\":0,\"All_dist\":\"single_zip\"},index=[counter_k])\n",
    "            output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "\n",
    "    zip_DMA=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",dtype=str,skiprows=1)\n",
    "    zip_DMA=zip_DMA.iloc[:,[0,2]]\n",
    "    zip_DMA.columns=['zip','DMA']\n",
    "\n",
    "    df_city_state_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "    del df_city_state_in_TA['index']\n",
    "\n",
    "    def city_of_zip(x):\n",
    "        try:\n",
    "            city=zipcodes.matching(x)[0]['city']\n",
    "        except:\n",
    "            city=np.nan\n",
    "        return city\n",
    "\n",
    "    def state_of_zip(x):\n",
    "        try:\n",
    "            state=zipcodes.matching(x)[0]['state']\n",
    "        except:\n",
    "            state=np.nan\n",
    "        return state\n",
    "\n",
    "    df_city_state_in_TA['city']=df_city_state_in_TA['zip'].apply(lambda x: city_of_zip(x))\n",
    "    df_city_state_in_TA['state']=df_city_state_in_TA['zip'].apply(lambda x: state_of_zip(x))\n",
    "    \n",
    "    manually_city_dict_of_zip={\"29486\":\"Summerville\"}\n",
    "    manually_state_dict_of_zip={\"29486\":\"SC\"}\n",
    "    df_city_state_in_TA['city'][df_city_state_in_TA['zip']=='29486']=manually_city_dict_of_zip['29486']\n",
    "    df_city_state_in_TA['state'][df_city_state_in_TA['zip']=='29486']=manually_state_dict_of_zip['29486']\n",
    "\n",
    "    removed_2_zips_df=df_city_state_in_TA[pd.isnull(df_city_state_in_TA['city'])]\n",
    "    df_city_state_in_TA=df_city_state_in_TA[~pd.isnull(df_city_state_in_TA['city'])]\n",
    "    \n",
    "    df_city_state_in_TA['city']=df_city_state_in_TA['city']+\" (\"+df_city_state_in_TA['state']+\")\"\n",
    "\n",
    "    df_DMA_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "    del df_DMA_in_TA['index']\n",
    "    df_DMA_in_TA=pd.merge(df_DMA_in_TA,zip_DMA,on=\"zip\",how=\"left\")\n",
    "\n",
    "    df_city_TA_list=df_city_state_in_TA.groupby(['TA'])['city'].apply(set).to_frame().reset_index()\n",
    "    df_city_TA_list=df_city_TA_list.rename(columns={\"city\":\"city_list\"})\n",
    "    df_state_TA_list=df_city_state_in_TA.groupby(['TA'])['state'].apply(set).to_frame().reset_index()\n",
    "    df_state_TA_list=df_state_TA_list.rename(columns={\"state\":\"state_list\"})\n",
    "    df_DMA_TA_list=df_DMA_in_TA.groupby(['TA'])['DMA'].apply(set).to_frame().reset_index()\n",
    "    df_DMA_TA_list=df_DMA_TA_list.rename(columns={\"DMA\":\"DMA_list\"})\n",
    "\n",
    "    counter_k\n",
    "    df_primary_city_state=pd.DataFrame()\n",
    "    df_primary_DMA=pd.DataFrame()\n",
    "    \n",
    "    df_city_state_in_TA\n",
    "    for ta,group in df_city_state_in_TA.groupby(['TA']):\n",
    "        df_city=group.groupby(['city'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "        del df_city['index']\n",
    "        primary_city=df_city['city'][0]\n",
    "\n",
    "        df_state=group.groupby(['state'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "        del df_state['index']\n",
    "        primary_state=df_state['state'][0]\n",
    "\n",
    "        df=pd.DataFrame({\"TA\":ta,\"Primary_City\":primary_city,\"Primary_State\":primary_state},index=[counter_k])\n",
    "        counter_k+=1\n",
    "        df_primary_city_state=df_primary_city_state.append(df)\n",
    "\n",
    "\n",
    "    for ta,group in df_DMA_in_TA.groupby(['TA']):\n",
    "        df_DMA=group.groupby(['DMA'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "        del df_DMA['index']\n",
    "        primary_DMA=df_DMA['DMA'][0]\n",
    "\n",
    "        df=pd.DataFrame({\"TA\":ta,\"Primary_DMA\":primary_DMA},index=[counter_k])\n",
    "        counter_k+=1\n",
    "        df_primary_DMA=df_primary_DMA.append(df)\n",
    "\n",
    "    summary_by_TA=pd.merge(summary_by_TA,df_city_TA_list,on=\"TA\",how=\"left\")\n",
    "    summary_by_TA=pd.merge(summary_by_TA,df_state_TA_list,on=\"TA\",how=\"left\")\n",
    "    summary_by_TA=pd.merge(summary_by_TA,df_DMA_TA_list,on=\"TA\",how=\"left\")\n",
    "\n",
    "    summary_by_TA=pd.merge(summary_by_TA,df_primary_city_state,on=\"TA\",how=\"left\")\n",
    "    summary_by_TA=pd.merge(summary_by_TA,df_primary_DMA,on=\"TA\",how=\"left\")\n",
    "\n",
    "    summary_by_TA=pd.merge(summary_by_TA,output_distance_zip_in_TA,on=\"TA\",how=\"left\")\n",
    "    summary_by_TA['Old_TA']=summary_by_TA['TA'].apply(lambda x: int(x.split(\"_\")[0]))\n",
    "    summary_by_TA=summary_by_TA.sort_values(['Old_TA','TA'])\n",
    "\n",
    "    summary_by_TA['ratio_max_media']=summary_by_TA['dist_max']/summary_by_TA['dist_median']\n",
    "\n",
    "    summary_by_TA_to_revise=summary_by_TA[(summary_by_TA['ratio_max_media']>2) &\\\n",
    "                                          (summary_by_TA['store_count']>=2) &\\\n",
    "                                         (summary_by_TA['dist_max']>12)]\n",
    "    summary_by_TA_to_keep=summary_by_TA[(summary_by_TA['ratio_max_media']<=2) |\\\n",
    "                                          (summary_by_TA['store_count']<2) |\\\n",
    "                                         (summary_by_TA['dist_max']<=12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "summary_by_TA_output=pd.DataFrame()\n",
    "summary_by_TA=summary_by_TA.sort_values(['Old_TA'])\n",
    "for old_ta,group in summary_by_TA.groupby(['Old_TA']):\n",
    "    if len(group)>1:\n",
    "        group['TA']=[str(old_ta).zfill(3)+\"_\"+str(x+1) for x in range(len(group))]\n",
    "    else:\n",
    "        group['TA']=str(old_ta).zfill(3)\n",
    "    summary_by_TA_output=summary_by_TA_output.append(group)\n",
    "ta_store_list_dic=summary_by_TA_output.set_index(['TA']).to_dict()['store_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_to_new_ta_dict={}\n",
    "for new_ta in ta_store_list_dic.keys():\n",
    "    length=len(ta_store_list_dic[new_ta])\n",
    "    df=pd.DataFrame({\"store\":ta_store_list_dic[new_ta],\"new_ta\":[new_ta]*length},index=[x for x in range(length)])\n",
    "    df_dict=df.set_index(['store']).to_dict()['new_ta']\n",
    "    store_to_new_ta_dict.update(df_dict)\n",
    "len(store_to_new_ta_dict)    \n",
    "data['TA']=data['storenumber'].apply(lambda x: store_to_new_ta_dict[x])\n",
    "df_TA_zips['TA']=df_TA_zips['store'].apply(lambda x: store_to_new_ta_dict[x])\n",
    "\n",
    "summary_by_store_count=summary_by_TA_output.groupby(['store_count'])['TA'].count().to_frame().reset_index().rename(columns={\"TA\":\"TA_count\"})\n",
    "summary_by_store_list=summary_by_TA_output.groupby(['store_count'])['TA'].apply(list).to_frame().reset_index().rename(columns={\"TA\":\"TA_list\"})\n",
    "summary_by_store_count=pd.merge(summary_by_store_count,summary_by_store_list,on=\"store_count\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_for_tableau=data[['storenumber','revised_store_zip','city','state','Latitude','Longitude','TA']]\n",
    "for col in data_for_tableau.columns.tolist()[1:6]:\n",
    "    data_for_tableau=data_for_tableau.rename(columns={col:\"store_\"+col})\n",
    "data_for_tableau=data_for_tableau.append(df_TA_zips[['TA','zip']])\n",
    "data_for_tableau['store_Latitude']=data_for_tableau['store_Latitude'].fillna(0)\n",
    "data_for_tableau['store_Longitude']=data_for_tableau['store_Longitude'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"/home/jian/Projects/Smoothie_King/TA/SmoothieKing_TA_revised_3_miles_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "summary_by_TA_output.to_excel(writer,\"summary_by_TA\",index=False)\n",
    "data['storenumber']=data['storenumber'].astype(int)\n",
    "data=data.sort_values(['storenumber'])\n",
    "data.to_excel(writer,\"output_TA_by_store\",index=False)\n",
    "df_TA_zips.to_excel(writer,\"zip_TA\",index=False)\n",
    "data_for_tableau.to_excel(writer,\"data_for_tableau\",index=False)\n",
    "summary_by_store_count.to_excel(writer,\"summary_by_store_count\",index=False)\n",
    "closed_stores.to_excel(writer,\"closed_stores\",index=False)\n",
    "del overwrite_zip_stores['Bing_LatLng']\n",
    "del overwrite_zip_stores['Bing_Address']\n",
    "overwrite_zip_stores.to_excel(writer,\"stores_zips_overwritten\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
