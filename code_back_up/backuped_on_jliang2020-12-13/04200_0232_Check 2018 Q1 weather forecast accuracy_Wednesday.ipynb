{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "today_str=str(datetime.datetime.now().date())\n",
    "\n",
    "writer_floder=\"/home/jian/Projects/Big_Lots/Weather/Forecast_Validation/\"+today_str+\"/\"\n",
    "try:\n",
    "    os.stat(writer_floder)\n",
    "except:\n",
    "    os.mkdir(writer_floder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forecast_file_list=glob.glob(\"/home/jian/Projects/Big_Lots/Weather/Json_data/forecast/\"+\"*.json\")\n",
    "\n",
    "actual_file_list=glob.glob(\"/home/jian/Projects/Big_Lots/Weather/Json_data/daily/\"+\"*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forecast_file_Q1_df=pd.DataFrame()\n",
    "actual_file_Q1_df=pd.DataFrame()\n",
    "i=1\n",
    "for file in forecast_file_list:\n",
    "    location=file\n",
    "    date=datetime.datetime.strptime(file.split(\"/\")[len(file.split(\"/\"))-1][0:10],\"%Y-%m-%d\").date()\n",
    "    \n",
    "    if (date>=datetime.date(2018,2,4)) & (date<=datetime.date(2018,5,5)) & (date.weekday()==2): #Wednesday only\n",
    "        forecast_file_Q1_df=forecast_file_Q1_df.append(pd.DataFrame({\"Date_Monday\":date,'Date_Saturday':date+datetime.timedelta(days=3),\"forecast_file\":location},index=[i]))\n",
    "        i=i+1\n",
    "i=1\n",
    "for file in actual_file_list:\n",
    "    location=file\n",
    "    date=datetime.datetime.strptime(file.split(\"/\")[len(file.split(\"/\"))-1][0:10],\"%Y-%m-%d\").date()\n",
    "    \n",
    "    if (date>=datetime.date(2018,2,4)) & (date<=datetime.date(2018,5,5)) & (date.weekday()==5): #Saturday only\n",
    "        actual_file_Q1_df=actual_file_Q1_df.append(pd.DataFrame({\"Date_Saturday\":date,\"actual_file\":location},index=[i]))\n",
    "        i=i+1\n",
    "both_file_Q1=pd.merge(actual_file_Q1_df,forecast_file_Q1_df,on=\"Date_Saturday\",how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inclusion_stores=pd.read_excel(\"/home/jian/Projects/Big_Lots/Q1_Post/BL_Sales YoY_JL_20180618.xlsx\",sheetname=\"Inclusion Stores\",skiprows=1,dtype=str)\n",
    "store_zips=pd.read_excel(\"/home/jian/Projects/Big_Lots/Other_Input/all_store_DMA.xlsx\",dtype=str)[['location_id','zip']]\n",
    "store_zips['zip']=store_zips['zip'].apply(lambda x: x.zfill(5))\n",
    "inclusion_stores=pd.merge(inclusion_stores,store_zips,on=\"location_id\",how=\"left\")\n",
    "inclusion_stores=inclusion_stores[['location_id','zip']].rename(columns={\"zip\":\"zip_cd\"})\n",
    "inclusion_stores=inclusion_stores[inclusion_stores['location_id']!='1769']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80110 2018-04-21\n",
      "35806 2018-04-28\n"
     ]
    }
   ],
   "source": [
    "all_forecast_group_value=[]\n",
    "all_forecast_desc_value=[]\n",
    "\n",
    "all_actual_group_value=[]\n",
    "all_actual_desc_value=[]\n",
    "\n",
    "for i in range(len(both_file_Q1)):\n",
    "    json_actual=json.load(open(both_file_Q1['actual_file'][i],\"r\"))\n",
    "    json_forecast=json.load(open(both_file_Q1['forecast_file'][i],\"r\"))\n",
    "    for zip_cd in inclusion_stores['zip_cd'].unique().tolist():\n",
    "        if (zip_cd in list(json_forecast.keys())) & (zip_cd in list(json_actual.keys())):\n",
    "            weather_forecast_list=json_forecast[zip_cd]['list'][23]['weather']\n",
    "            weather_actual_list=json_actual[zip_cd]['weather']\n",
    "\n",
    "            for j in range(len(weather_forecast_list)):\n",
    "                weather_forecast_group=weather_forecast_list[j]['main']\n",
    "                weather_forecast_desc=weather_forecast_list[j]['description']\n",
    "                all_forecast_group_value=list(set(all_forecast_group_value+[weather_forecast_group]))\n",
    "                all_forecast_desc_value=list(set(all_forecast_desc_value+[weather_forecast_desc]))\n",
    "            \n",
    "            for j in range(len(weather_actual_list)):    \n",
    "                weather_actual_group=weather_actual_list[j]['main']\n",
    "                weather_actual_desc=weather_actual_list[j]['description']\n",
    "                all_actual_group_value=list(set(all_actual_group_value+[weather_actual_group]))\n",
    "                all_actual_desc_value=list(set(all_actual_desc_value+[weather_actual_desc]))\n",
    "        else:\n",
    "            print(zip_cd,both_file_Q1['Date_Saturday'][i])\n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Snow', 'Clear', 'Clouds', 'Rain']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_forecast_group_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_weight_rank=pd.read_excel(\"/home/jian/Projects/Big_Lots/Weather/Q1_Weather_Counts/Q1_inclusion_store_all_weather_type_ranked.xlsx\",sheetname=\"all_weather_group_list\")\n",
    "\n",
    "group_weight_rank['Severity']=group_weight_rank['Severity'].astype(int)\n",
    "group_weight_rank['Rank']=group_weight_rank['Rank'].astype(int)\n",
    "group_weight=group_weight_rank[['all_type_group','Severity']]\n",
    "group_weight_dict=group_weight[['all_type_group', 'Severity']].set_index('all_type_group').T.to_dict()\n",
    "\n",
    "group_rank=group_weight_rank[['all_type_group','Rank']]\n",
    "group_rank_dict=group_rank[['all_type_group', 'Rank']].set_index('all_type_group').T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80110 2018-04-21\n",
      "35806 2018-04-28\n"
     ]
    }
   ],
   "source": [
    "output_validation=pd.DataFrame()\n",
    "\n",
    "index_num=1\n",
    "for i in range(len(both_file_Q1)):\n",
    "    json_actual=json.load(open(both_file_Q1['actual_file'][i],\"r\"))\n",
    "    json_forecast=json.load(open(both_file_Q1['forecast_file'][i],\"r\"))\n",
    "    date=both_file_Q1['Date_Saturday'][i]\n",
    "    for zip_cd in inclusion_stores['zip_cd'].unique().tolist():\n",
    "\n",
    "        if (zip_cd in list(json_forecast.keys())) & (zip_cd in list(json_actual.keys())):\n",
    "            forecast_time=datetime.datetime.fromtimestamp(json_forecast[zip_cd]['list'][23]['dt']) \n",
    "            actual_time=datetime.datetime.fromtimestamp(json_actual[zip_cd]['dt']) \n",
    "            \n",
    "            weather_forecast_list=json_forecast[zip_cd]['list'][23]['weather']\n",
    "            weather_actual_list=json_actual[zip_cd]['weather']\n",
    "            all_forecast_group_value_zip=[]\n",
    "            #all_forecast_desc_value_zip=[]\n",
    "            all_actual_group_value_zip=[]\n",
    "            #all_actual_desc_value_zip=[]\n",
    "            \n",
    "            for j in range(len(weather_forecast_list)):\n",
    "                weather_forecast_group=weather_forecast_list[j]['main']\n",
    "                weather_forecast_desc=weather_forecast_list[j]['description']\n",
    "                all_forecast_group_value_zip=list(set(all_forecast_group_value_zip+[weather_forecast_group]))\n",
    "                #all_forecast_desc_value_zip=list(set(all_forecast_desc_value_zip+[weather_forecast_desc]))\n",
    "            \n",
    "            for j in range(len(weather_actual_list)):    \n",
    "                weather_actual_group=weather_actual_list[j]['main']\n",
    "                weather_actual_desc=weather_actual_list[j]['description']\n",
    "                all_actual_group_value_zip=list(set(all_actual_group_value_zip+[weather_actual_group]))\n",
    "                #all_actual_desc_value_zip=list(set(all_actual_desc_value_zip+[weather_actual_desc]))\n",
    "            \n",
    "            all_forecast_group_severity_zip=[]\n",
    "            all_actual_group_severity_zip=[]\n",
    "            \n",
    "            all_forecast_group_rank_zip=[]\n",
    "            all_actual_group_rank_zip=[]\n",
    "            \n",
    "            selected_havest_forecast_group_value_zip=np.nan\n",
    "            selected_havest_actual_group_value_zip=np.nan\n",
    "            \n",
    "            selected_havest_forecast_rank_value_zip=np.nan\n",
    "            selected_havest_actual_rank_value_zip=np.nan\n",
    "            \n",
    "            \n",
    "            for k in range(len(all_forecast_group_value_zip)):\n",
    "                \n",
    "                forecast_severity_zip=group_weight_dict[all_forecast_group_value_zip[k]]['Severity']\n",
    "                all_forecast_group_severity_zip=list(set(all_forecast_group_severity_zip+[forecast_severity_zip]))\n",
    "                \n",
    "                forecast_rank_zip=group_rank_dict[all_forecast_group_value_zip[k]]['Rank']\n",
    "                all_forecast_group_rank_zip=list(set(all_forecast_group_rank_zip+[forecast_rank_zip]))\n",
    "                \n",
    "                if k==0:\n",
    "                    selected_havest_forecast_group_value_zip=all_forecast_group_value_zip[0]\n",
    "                    \n",
    "                else:\n",
    "                    if group_rank_dict[all_forecast_group_value_zip[k]]['Rank']>group_rank_dict[selected_havest_forecast_group_value_zip]['Rank']:\n",
    "                        selected_havest_forecast_group_value_zip=all_forecast_group_value_zip[k]\n",
    "                    \n",
    "                \n",
    "                \n",
    "            for k in range(len(all_actual_group_value_zip)):\n",
    "                \n",
    "                actual_severity_zip=group_weight_dict[all_actual_group_value_zip[k]]['Severity']\n",
    "                all_actual_group_severity_zip=list(set(all_actual_group_severity_zip+[actual_severity_zip]))\n",
    "                \n",
    "                actual_rank_zip=group_rank_dict[all_actual_group_value_zip[k]]['Rank']\n",
    "                all_actual_group_rank_zip=list(set(all_actual_group_rank_zip+[actual_rank_zip]))\n",
    "                if k==0:\n",
    "                    selected_havest_actual_group_value_zip=all_actual_group_value_zip[0]\n",
    "                else:\n",
    "                    if group_rank_dict[all_actual_group_value_zip[k]]['Rank']>group_rank_dict[selected_havest_actual_group_value_zip]['Rank']:\n",
    "                        selected_havest_actual_group_value_zip=all_actual_group_value_zip[k]\n",
    "                        \n",
    "            \n",
    "            forecast_max_severity_zip=max(all_forecast_group_severity_zip)\n",
    "            actual_max_severity_zip=max(all_actual_group_severity_zip)\n",
    "            \n",
    "            forecast_max_rank_zip=max(all_forecast_group_rank_zip)\n",
    "            actual_max_rank_zip=max(all_actual_group_rank_zip)\n",
    "            \n",
    "            \n",
    "            df_app=pd.DataFrame({\"zip_cd\":zip_cd,\"Saturday\":date,\"Forecast_Time\":forecast_time,\"Actual_Time\":actual_time,\n",
    "                                 \"Forecast_Severity\":forecast_max_severity_zip,\"Actual_Severity\":actual_max_severity_zip,\n",
    "                                \"Forecast_Weather_Type\":selected_havest_forecast_group_value_zip,\"Actual_Weather_Type\":selected_havest_actual_group_value_zip,\n",
    "                                \"Forecast_Rank\":forecast_max_rank_zip,\"Actual_Rank\":actual_max_rank_zip},index=[index_num])\n",
    "            index_num=index_num+1\n",
    "            output_validation=output_validation.append(df_app)\n",
    "        else:\n",
    "            print(zip_cd,both_file_Q1['Date_Saturday'][i])\n",
    "            \n",
    "output_validation=output_validation[['zip_cd','Saturday','Forecast_Time','Actual_Time','Forecast_Weather_Type','Actual_Weather_Type',\n",
    "                                     'Forecast_Severity','Actual_Severity','Forecast_Rank','Actual_Rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_validation['Diff_Severity']=output_validation['Actual_Severity']-output_validation['Forecast_Severity']\n",
    "output_validation=pd.merge(output_validation,inclusion_stores,on=\"zip_cd\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales=pd.read_csv(\"/home/jian/BiglotsCode/outputs/combined_sales_long_2018-07-07.csv\",dtype=str)\n",
    "sales['week_end_date']=sales['week_end_date'].apply(lambda x:datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "sales['sales']=sales['sales'].astype(float)\n",
    "sales_2018=sales[(sales['week_end_date']>=datetime.date(2018,1,1)) & (sales['week_end_date']<=datetime.date(2018,5,31))]\n",
    "sales_2018=sales_2018[['location_id','week_end_date','sales']]\n",
    "sales_2018=sales_2018.rename(columns={\"week_end_date\":\"Saturday\",\"sales\":\"Sales_2018\"})\n",
    "sales_2017=sales[(sales['week_end_date']>=datetime.date(2017,1,1)) & (sales['week_end_date']<=datetime.date(2017,5,31))]\n",
    "sales_2017=sales_2017[['location_id','week_end_date','sales']]\n",
    "sales_2017=sales_2017.rename(columns={\"sales\":\"Sales_2017\"})\n",
    "sales_2017['Saturday']=sales_2017['week_end_date'].apply(lambda x: x+datetime.timedelta(days=52*7))\n",
    "sales_2017=sales_2017[['location_id','Saturday','Sales_2017']]\n",
    "\n",
    "sales_YoY=pd.merge(sales_2018,sales_2017,on=['location_id','Saturday'],how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_validation=pd.merge(output_validation,sales_YoY,on=['location_id','Saturday'],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(writer_floder+\"BL_2018 Q1 Forecast 3 days validation Wed Sat_JL_\"+today_str+\".xlsx\",engine=\"xlsxwriter\")\n",
    "output_validation.to_excel(writer,\"all_10_weeks\",index=False)\n",
    "for Saturday,group in output_validation.groupby(['Saturday']):\n",
    "    group.to_excel(writer,str(Saturday),index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
