{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import datetime\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "today_str=str(datetime.datetime.now().date())\n",
    "writer_folder=\"/home/jian/Projects/Big_Lots/Newspaper/output_\"+today_str+\"/\"\n",
    "try:\n",
    "    os.stat(writer_folder)\n",
    "except:\n",
    "    os.mkdir(writer_folder)\n",
    "    \n",
    "\n",
    "logging.basicConfig(filename='read_all_newspaper_'+today_str+'_files.log', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "sales_data=pd.read_excel(\"/home/jian/BiglotsCode/outputs/Output_2018-05-05/wide_sales_date2018-05-05.xlsx\")\n",
    "# Any one week sales >0 in the most recent month, it indicated an \"Open\" status up to 2018-05-05\n",
    "recent_month=sales_data.columns.tolist()[len(sales_data.columns.tolist())-4:len(sales_data.columns.tolist())]\n",
    "most_recent_open_stores=sales_data[['location_id']+recent_month]\n",
    "most_recent_open_stores['4_week_total_sales']=most_recent_open_stores[most_recent_open_stores.columns[1]]+most_recent_open_stores[most_recent_open_stores.columns[2]]+\\\n",
    "                                                                  most_recent_open_stores[most_recent_open_stores.columns[3]]+most_recent_open_stores[most_recent_open_stores.columns[4]]\n",
    "                                                 \n",
    "most_recent_open_stores=most_recent_open_stores[most_recent_open_stores['4_week_total_sales']>0]\n",
    "recent_open_stores=most_recent_open_stores['location_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_latest_non_zero_week=pd.read_csv(\"/home/jian/BiglotsCode/outputs/combined_sales_long_2018-05-12.csv\")\n",
    "store_latest_non_zero_week=store_latest_non_zero_week[['location_id','week_end_date','sales']]\n",
    "store_latest_non_zero_week['week_end_date']=store_latest_non_zero_week['week_end_date'].apply(lambda x:datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "store_latest_non_zero_week=store_latest_non_zero_week[store_latest_non_zero_week['sales']!=0]\n",
    "store_latest_non_zero_week=store_latest_non_zero_week.sort_values([\"location_id\",'week_end_date'],ascending=[True,False]).drop_duplicates(['location_id'])\n",
    "del store_latest_non_zero_week['sales']\n",
    "store_latest_non_zero_week.columns=['storeid','latest_date']\n",
    "store_latest_non_zero_week['storeid']=store_latest_non_zero_week['storeid'].astype(str)\n",
    "store_latest_non_zero_week.reset_index(inplace=True)\n",
    "store_latest_non_zero_week['storeid']=store_latest_non_zero_week['storeid'].astype(int)\n",
    "store_latest_non_zero_week=store_latest_non_zero_week.rename(columns={'storeid':'location_id'})\n",
    "del store_latest_non_zero_week['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_week_list=[datetime.datetime.strptime(x,\"%Y-%m-%d\").date() for x in sales_data.columns.tolist()[1:]]\n",
    "year_2017_weeks=[str(x) for x in all_week_list if (x>=datetime.datetime(2016,5,8).date()) & (x<datetime.datetime(2017,5,8).date())]\n",
    "year_2018_weeks=[str(x) for x in all_week_list if (x>=datetime.datetime(2017,5,8).date()) & (x<datetime.datetime(2018,5,8).date())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_data_2017=sales_data[['location_id']+year_2017_weeks]\n",
    "sales_data_2018=sales_data[['location_id']+year_2018_weeks]\n",
    "sales_data_2017_existing=sales_data_2017[sales_data_2017['location_id'].isin(recent_open_stores)].sort_values('location_id')\n",
    "sales_data_2018_existing=sales_data_2018[sales_data_2018['location_id'].isin(recent_open_stores)].sort_values('location_id')\n",
    "sales_data_2017_existing.reset_index(inplace=True)\n",
    "sales_data_2018_existing.reset_index(inplace=True)\n",
    "del sales_data_2017_existing['index']\n",
    "del sales_data_2018_existing['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(sales_data_2018_existing)):\n",
    "    for j in range(1,53):\n",
    "            if sales_data_2018_existing.iloc[i,j]==0:\n",
    "                sales_data_2017_existing.iloc[i,j]=0\n",
    "            if sales_data_2017_existing.iloc[i,j]==0:\n",
    "                sales_data_2018_existing.iloc[i,j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_wide_2_years=pd.merge(sales_data_2017_existing,sales_data_2018_existing,on='location_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_data_2017_existing['sales_2017']=sales_data_2017_existing[year_2017_weeks].sum(axis=1)\n",
    "sales_data_2018_existing['sales_2018']=sales_data_2018_existing[year_2018_weeks].sum(axis=1)\n",
    "df_2017_sales=sales_data_2017_existing[['location_id','sales_2017']]\n",
    "df_2018_sales=sales_data_2018_existing[['location_id','sales_2018']]\n",
    "df_2_year_sales=pd.merge(df_2017_sales,df_2018_sales,on='location_id',how='left')\n",
    "df_2_year_sales=df_2_year_sales[df_2_year_sales['sales_2017']!=0]\n",
    "df_2_year_sales=df_2_year_sales[df_2_year_sales['sales_2018']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(writer_folder+\"sales_data_2_year_compariable.xlsx\",engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2_year_sales.to_excel(writer,\"rencet_open_stores_compariable\",index=False)\n",
    "sales_wide_2_years.to_excel(writer,\"yearly_sales\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recent_open_stores=[str(x) for x in recent_open_stores]\n",
    "store_latest_non_zero_week['location_id']=store_latest_non_zero_week['location_id'].astype(str)\n",
    "store_latest_non_zero_week=store_latest_non_zero_week.rename(columns={\"location_id\":\"storeid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newspaper Week Availablility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_running=str(datetime.datetime.now())\n",
    "logging.info(\"Newspaper level - Start to run: \"+ start_running)\n",
    "\n",
    "folder=\"/home/jian/Projects/Big_Lots/Newspaper/All newspaper files for reading JL/\"\n",
    "\n",
    "file_list=glob.glob(folder+\"*\")\n",
    "logging.info(\"Newspaper level - Total files: \"+str(len(file_list)))\n",
    "\n",
    "Selected_Col=['projectname','storeid','productname','productid','zoneid','dayname','zips','totalcirc']\n",
    "output_combined_all_date=pd.DataFrame()\n",
    "check_df=pd.DataFrame()\n",
    "finished=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "wide_newspaper_week=pd.DataFrame({\"productid\":[\"-1\"],\"to_be_deleted\":[-1]},index=[0])\n",
    "i=0\n",
    "all_date_list=[]\n",
    "newspapaer_name=pd.read_excel('/home/jian/Projects/Big_Lots/Newspaper/All newspaper files for reading JL/August 28 2016 4 STD.xlsx',sheetname=\"to_read\",dtype=str,na_values=['NULL','null','Null',\"\",\" \"])[[\"productid\",\"productname\"]].drop_duplicates()\n",
    "for file in file_list:\n",
    "    date=file.split(\"/\")[len(file.split(\"/\"))-1].split(\" \")[0]+\" \"+file.split(\"/\")[len(file.split(\"/\"))-1].split(\" \")[1]+\" \"+\\\n",
    "    file.split(\"/\")[len(file.split(\"/\"))-1].split(\" \")[2]\n",
    "    date=date.replace(\"Sept\",\"Sep\")\n",
    "\n",
    "    if len(date.split(\" \")[0])==3:\n",
    "        date=datetime.datetime.strptime(date,\"%b %d %Y\").date()\n",
    "    else:\n",
    "        date=datetime.datetime.strptime(date,\"%B %d %Y\").date()\n",
    "        \n",
    "    # if date>=datetime.datetime(2017,4,1).date(): #Most recent 12 months to reduce stores without information\n",
    "\n",
    "    df=pd.read_excel(file,sheetname=\"to_read\",dtype=str,na_values=['NULL','null','Null',\"\",\" \"])\n",
    "    df=df[['storeid','productid','totalcirc']]\n",
    "\n",
    "    df['totalcirc']=df['totalcirc'].astype(float)\n",
    "    #df['keys']=df['productid'] \n",
    "    #Use only product id to adjust null\n",
    "\n",
    "    df=df[df['storeid'].isin(recent_open_stores)]\n",
    "    df=pd.merge(df,store_latest_non_zero_week,on=\"storeid\",how=\"left\")\n",
    "    df=df[df['latest_date']>=date]\n",
    "    del df['latest_date']\n",
    "    df_agg_newspaper=df.groupby(['productid'])['totalcirc'].sum().to_frame().reset_index()\n",
    "    df_agg_newspaper=df_agg_newspaper.rename(columns={\"totalcirc\":str(date)})\n",
    "    wide_newspaper_week=pd.merge(wide_newspaper_week,df_agg_newspaper,on='productid',how='outer')\n",
    "            \n",
    "    i=i+1\n",
    "    if i %10 ==0:\n",
    "        print(i)\n",
    "        \n",
    "    all_date_list=all_date_list+[date]\n",
    "    \n",
    "    newspapaer_name_newfile=df=pd.read_excel(file,sheetname=\"to_read\",dtype=str,na_values=['NULL','null','Null',\"\",\" \"])[[\"productid\",\"productname\"]].drop_duplicates()\n",
    "    newspapaer_name_newfile.columns=[\"productid\",\"product_new_name\"]\n",
    "    newspapaer_name=pd.merge(newspapaer_name,newspapaer_name_newfile,on=\"productid\",how=\"outer\")\n",
    "    newspapaer_name=newspapaer_name.fillna(\"NA_NAME\")\n",
    "    newspapaer_name.reset_index(inplace=True)\n",
    "    del newspapaer_name['index']\n",
    "    for j in range(len(newspapaer_name)):\n",
    "        if newspapaer_name['product_new_name'][j]!=\"NA_NAME\":\n",
    "            newspapaer_name['productname'][j]=newspapaer_name['product_new_name'][j]\n",
    "    newspapaer_name=newspapaer_name[['productid','productname']]\n",
    "        \n",
    "\n",
    "    \n",
    "all_date_list=[str(x) for x in sorted(all_date_list)]\n",
    "del wide_newspaper_week['to_be_deleted']\n",
    "wide_newspaper_week=wide_newspaper_week[wide_newspaper_week['productid']!=\"-1\"]\n",
    "wide_newspaper_week['productid']=wide_newspaper_week['productid'].astype(int)\n",
    "wide_newspaper_week=wide_newspaper_week.sort_values('productid')\n",
    "wide_newspaper_week.reset_index(inplace=True)\n",
    "del wide_newspaper_week['index']\n",
    "wide_newspaper_week=wide_newspaper_week.fillna(0)\n",
    "wide_newspaper_week['mean']=wide_newspaper_week.iloc[:,1:].mean(axis=1)\n",
    "newspapaer_name['productid']=newspapaer_name['productid'].astype(int)\n",
    "wide_newspaper_week=pd.merge(wide_newspaper_week,newspapaer_name,on='productid',how=\"left\")\n",
    "wide_newspaper_week=wide_newspaper_week[['productid','productname']+all_date_list+['mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(writer_folder+\"wide_news_with_week.xlsx\",engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_newspaper_week.to_excel(writer,\"newspaper_type_by_week\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workbook  = writer.book\n",
    "worksheet = writer.sheets['newspaper_type_by_week']\n",
    "\n",
    "format_high_color=workbook.add_format({'bg_color': '3AFA8B'})\n",
    "format_low_color=workbook.add_format({'bg_color': 'FC9B53'})\n",
    "\n",
    "for i in range(len(wide_newspaper_week)):\n",
    "    range_str=\"C\"+str(i+2)+\":BH\"+str(i+2)\n",
    "    worksheet.conditional_format(range_str, {'type':  'cell',\n",
    "                                            'criteria': '>',\n",
    "                                            'value':    wide_newspaper_week['mean'][i]*1.2, #+20%\n",
    "                                            'format':   format_high_color})\n",
    "    worksheet.conditional_format(range_str, {'type':  'cell',\n",
    "                                            'criteria': '<',\n",
    "                                            'value':    wide_newspaper_week['mean'][i]*0.8, #-20%\n",
    "                                            'format':   format_low_color})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newspaper Circ by Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    date=file.split(\"/\")[len(file.split(\"/\"))-1].split(\" \")[0]+\" \"+file.split(\"/\")[len(file.split(\"/\"))-1].split(\" \")[1]+\" \"+\\\n",
    "    file.split(\"/\")[len(file.split(\"/\"))-1].split(\" \")[2]\n",
    "    date=date.replace(\"Sept\",\"Sep\")\n",
    "\n",
    "    if len(date.split(\" \")[0])==3:\n",
    "        date=datetime.datetime.strptime(date,\"%b %d %Y\").date()\n",
    "    else:\n",
    "        date=datetime.datetime.strptime(date,\"%B %d %Y\").date()\n",
    "        \n",
    "    # if date>=datetime.datetime(2017,4,1).date(): #Most recent 12 months to reduce stores without information\n",
    "\n",
    "    df=pd.read_excel(file,sheetname=\"to_read\",dtype=str,na_values=['NULL','null','Null',\"\",\" \"])\n",
    "    df=df[Selected_Col]\n",
    "    df['zips']=df['zips'].fillna('null')\n",
    "    df['zips']=df['zips'].replace('nan','null')\n",
    "    df['totalcirc']=df['totalcirc'].astype(float)\n",
    "\n",
    "    df['Date']=date\n",
    "    df=df[df['storeid'].isin(recent_open_stores)]\n",
    "    df=pd.merge(df,store_latest_non_zero_week,on=\"storeid\",how=\"left\")\n",
    "    df=df[df['latest_date']>=date]\n",
    "    del df['latest_date']\n",
    "    # check_df=check_df.append(df)\n",
    "\n",
    "\n",
    "\n",
    "    df_combine_date=pd.DataFrame()\n",
    "    #Use only product id to adjust null\n",
    "    for productid in df['productid'].unique():\n",
    "        df_product_store=df[df['productid']==productid]\n",
    "        df_product_store_NA=df_product_store[df_product_store['zips']=='null']\n",
    "        df_product_store_NA.reset_index(inplace=True)\n",
    "        del df_product_store_NA['index']\n",
    "        df_product_store_zip=df_product_store[df_product_store['zips']!='null']\n",
    "        df_product_store_zip.reset_index(inplace=True)\n",
    "        del df_product_store_zip['index']        \n",
    "\n",
    "        if len(df_product_store_NA)==0:\n",
    "            df_product_store_zip=df_product_store.groupby(['storeid','productname','productid','dayname','zips'])['totalcirc'].sum().to_frame()\n",
    "            df_product_store_zip['circ_proportion_of_Null']=0\n",
    "            df_product_store_zip['adjusted_circ_about_Null']=df_product_store_zip['totalcirc']\n",
    "            df_product_store_zip.reset_index(inplace=True)\n",
    "\n",
    "        elif len(df_product_store_zip)==0:              \n",
    "            df_product_store_NA['extract_from_zone 5 digit']=df_product_store_NA['zoneid'].apply(lambda x: re.findall(r\"\\b\\d{5}\\b\", x))\n",
    "            unique_len_from_zone=len(df_product_store_NA['extract_from_zone 5 digit'].apply(lambda x :len(x)).unique())\n",
    "            if unique_len_from_zone==0:\n",
    "                df_product_store_zip=df_product_store.groupby(['storeid','productname','productid','dayname','zips'])['totalcirc'].sum().to_frame()\n",
    "                df_product_store_zip['circ_proportion_of_Null']=1\n",
    "                df_product_store_zip['adjusted_circ_about_Null']=df_product_store_zip['totalcirc']\n",
    "                df_product_store_zip.reset_index(inplace=True)\n",
    "            else:                                                                                                    \n",
    "                df_product_store['extract_from_zone 5 digit']=df_product_store['zoneid'].apply(lambda x: re.findall(r\"\\b\\d{5}\\b\", x))                                                                        \n",
    "                df_product_store['zips']=df_product_store['extract_from_zone 5 digit'].apply(lambda x: str(x)[1:(len(str(x))-1)].replace(\"'\",\"\"))\n",
    "                df_product_store_zip=df_product_store.groupby(['storeid','productname','productid','dayname','zips'])['totalcirc'].sum().to_frame()\n",
    "                df_product_store_zip['circ_proportion_of_Null']=1\n",
    "                df_product_store_zip['adjusted_circ_about_Null']=df_product_store_zip['totalcirc']\n",
    "                df_product_store_zip.reset_index(inplace=True)\n",
    "\n",
    "        elif len(df_product_store_NA)>=1:\n",
    "            na_zip_circ=df_product_store_NA['totalcirc'].sum()\n",
    "            df_product_store_zip=df_product_store_zip.groupby(['storeid','productname','productid','dayname','zips'])['totalcirc'].sum().to_frame()\n",
    "            df_product_store_zip.reset_index(inplace=True)\n",
    "            df_product_store_zip['circ_proportion_of_Null']=df_product_store_zip['totalcirc'].apply(lambda x:x/sum(df_product_store_zip['totalcirc']))\n",
    "            df_product_store_zip['adjusted_circ_about_Null']=df_product_store_zip['totalcirc']+df_product_store_zip['circ_proportion_of_Null']*na_zip_circ\n",
    "        df_combine_date=df_combine_date.append(df_product_store_zip)\n",
    "\n",
    "    df_combine_date['Date']=date\n",
    "    finished=finished+[str(date)]\n",
    "    logging.info(str(date)+ \" : Done of \"+str(len(finished)))\n",
    "\n",
    "    output_combined_all_date=output_combined_all_date.append(df_combine_date) \n",
    "output_combined_all_date.reset_index(inplace=True)\n",
    "del output_combined_all_date['index']\n",
    "output_combined_all_date.to_excel(writer_folder+\"BL_combined newspaper data_JL_\"+today_str+\".xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-452f51adc4c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdf_1_zip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdf_1_zip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'zip_cd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdf_to_app\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_to_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_1_zip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mdf_to_app\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_to_app\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhousehold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zip_cd\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdf_to_app\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Households'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_to_app\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Households'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity)\u001b[0m\n\u001b[1;32m   4545\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4546\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[0;32m-> 4547\u001b[0;31m                       verify_integrity=verify_integrity)\n\u001b[0m\u001b[1;32m   4548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4549\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    204\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(self, inplace)\u001b[0m\n\u001b[1;32m   3154\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inplace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3156\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   3125\u001b[0m         \"\"\"\n\u001b[1;32m   3126\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3127\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3135\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3571\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3572\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3573\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3574\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3578\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3579\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3580\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   4523\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4524\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 4525\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   4526\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   4543\u001b[0m         \u001b[0;31m# combination of those slices is a slice, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4544\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4545\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4547\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4543\u001b[0m         \u001b[0;31m# combination of those slices is a slice, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4544\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4545\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4547\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "household=pd.read_csv(\"/home/jian/Docs/Household and Population/2016/ZipcodePopulation_FromSP.csv\",dtype=str)\n",
    "household=household[['ZIP_CODE',\"HH15\"]]\n",
    "household.columns=['zip_cd','Households']\n",
    "household['Households']=household['Households'].fillna(0)\n",
    "household['Households']=household['Households'].astype(float)\n",
    "\n",
    "output_combined_all_date['zip_list']=output_combined_all_date['zips'].apply(lambda x: [ zip.strip().zfill(5) for zip in x.split(\",\")])\n",
    "output_combined_all_date['zip_count']=output_combined_all_date['zip_list'].apply(lambda x: len(x))\n",
    "\n",
    "output_combined_all_date_1=output_combined_all_date[output_combined_all_date['zip_count']==1]\n",
    "output_combined_all_date_M=output_combined_all_date[output_combined_all_date['zip_count']!=1]\n",
    "output_combined_all_date_1['zip_cd']=output_combined_all_date_1['zips'].str.zfill(5)\n",
    "output_combined_all_date_1['zip_list_proportion']=1\n",
    "output_combined_all_date_1['adjusted_circ_with_list']=output_combined_all_date_1['adjusted_circ_about_Null']\n",
    "output_combined_all_date_M.reset_index(inplace= True)\n",
    "del output_combined_all_date_M['index']\n",
    "output_combined_all_date_M_agg=pd.DataFrame()\n",
    "\n",
    "for i in range(len(output_combined_all_date_M)):\n",
    "    df=output_combined_all_date_M.iloc[i:(i+1),:]\n",
    "    df.reset_index(inplace=True)\n",
    "    del df['index']\n",
    "    df_to_app=pd.DataFrame()\n",
    "    for zip_i in list(set(df['zip_list'][0])):\n",
    "        df_1_zip=df.copy()\n",
    "        df_1_zip['zip_cd']=zip_i\n",
    "        df_to_app=df_to_app.append(df_1_zip)\n",
    "    df_to_app=pd.merge(df_to_app,household,on=\"zip_cd\",how=\"left\")\n",
    "    df_to_app['Households']=df_to_app['Households'].fillna(0)\n",
    "    if df_to_app['Households'].sum()!=0:\n",
    "        df_to_app['zip_list_proportion']=df_to_app['Households']/df_to_app['Households'].sum()\n",
    "        df_to_app['adjusted_circ_with_list']=df_to_app['adjusted_circ_about_Null']*df_to_app['zip_list_proportion']\n",
    "    else:\n",
    "        logging.info(\"All 0 population: \"+str(df_to_app['Date'].unique()[0])+\" \"+str(df_to_app['storeid'].unique()[0])+\" \"+str(df_to_app['productid'].unique()[0]))\n",
    "        logging.info(df_to_app['zip_cd'])\n",
    "        df_to_app['zip_list_proportion']=1/len(df_to_app)\n",
    "        df_to_app['adjusted_circ_with_list']=df_to_app['adjusted_circ_about_Null']*df_to_app['zip_list_proportion']\n",
    "        \n",
    "    output_combined_all_date_M_agg=output_combined_all_date_M_agg.append(df_to_app)\n",
    "    if i % 1000 == 1:\n",
    "        logging.info(str(datetime.datetime.now())+\" :\")\n",
    "        logging.info(\"output_combined_all_date_M_agg done of the row: \"+str(i))\n",
    "        \n",
    "        # print(\"output_combined_all_date_M_agg done of the row: \"+str(i))\n",
    "output_adjusted_final=output_combined_all_date_M_agg.append(output_combined_all_date_1)\n",
    "output_adjusted_final.to_csv(writer_folder+\"BL_combined newspaper final detailed_JL_\"+today_str+\".csv\",index=False)\n",
    "\n",
    "all_store_in_newspaper=output_adjusted_final['storeid'].unique().tolist()                                                                                                    \n",
    "                                                                                                     \n",
    "output_no_detail=output_adjusted_final.groupby(['zip_cd','Date'])['adjusted_circ_with_list'].sum().to_frame()\n",
    "output_no_detail.reset_index(inplace=True)\n",
    "output_no_detail=output_no_detail.sort_values(['Date','zip_cd'])\n",
    "output_no_detail.to_csv(writer_folder+\"BL_newspaper count by zip by date_JL_\"+today_str+\".csv\",index=False)\n",
    "\n",
    "output_no_detail=pd.read_csv(writer_folder+\"BL_newspaper count by zip by date_JL_\"+today_str+\".csv\")\n",
    "test_agg_wide=output_no_detail.pivot(index=\"zip_cd\",columns='Date',values='adjusted_circ_with_list')\n",
    "test_agg_wide.reset_index(inplace=True)\n",
    "test_agg_wide_columns=test_agg_wide.columns.tolist()[1:]\n",
    "test_agg_wide_columns=[\"newspaper_\"+x for x in test_agg_wide_columns]\n",
    "test_agg_wide.columns=[['zip_cd']+test_agg_wide_columns]\n",
    "test_agg_wide=test_agg_wide.fillna(0)\n",
    "test_agg_wide.to_csv(writer_folder+\"BL_newspaper wide of date by zip_JL_\"+today_str+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
