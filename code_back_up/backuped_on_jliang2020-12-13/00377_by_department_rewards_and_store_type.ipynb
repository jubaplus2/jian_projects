{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "logging.basicConfig(filename=\"./sales_table_log.log\", level=logging.INFO)\n",
    "\n",
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "            \n",
    "last_sturday_ty = (datetime.datetime.now()-datetime.timedelta(days=(datetime.datetime.now().weekday()+2))).date()\n",
    "first_week_ty=datetime.date(2020,3,1)\n",
    "\n",
    "last_sturday_ly = last_sturday_ty-datetime.timedelta(days=52*7)\n",
    "first_week_ly=first_week_ty-datetime.timedelta(days=52*7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2020, 4, 25),\n",
       " datetime.date(2020, 3, 1),\n",
       " datetime.date(2019, 4, 27),\n",
       " datetime.date(2019, 3, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_sturday_ty,first_week_ty,last_sturday_ly,first_week_ly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_POS_this_year=list(recursive_file_gen(\"/home/jian/BigLots/2020_by_weeks/\"))\n",
    "list_POS_this_year=[x for x in list_POS_this_year if \"daily\" in x.lower()]\n",
    "\n",
    "list_POS_this_year=[x for x in list_POS_this_year if x.split(\"/MediaStorm_\")[1][:10]>=str(first_week_ty)]\n",
    "list_POS_this_year=[x for x in list_POS_this_year if x.split(\"/MediaStorm_\")[1][:10]<=str(last_sturday_ty)]\n",
    "\n",
    "# \n",
    "list_POS_last_year=list(recursive_file_gen(\"/home/jian/BigLots/2019_by_weeks/\"))\n",
    "list_POS_last_year=[x for x in list_POS_last_year if \"daily\" in x.lower()]\n",
    "\n",
    "list_POS_last_year=[x for x in list_POS_last_year if x.split(\"/MediaStorm_\")[1][:10]>=str(first_week_ly)]\n",
    "list_POS_last_year=[x for x in list_POS_last_year if x.split(\"/MediaStorm_\")[1][:10]<=str(last_sturday_ly)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-07 2020-04-27 12:22:53.410848\n",
      "2020-03-28 2020-04-27 12:23:50.485966\n",
      "2020-03-14 2020-04-27 12:25:43.471407\n",
      "2020-03-21 2020-04-27 12:27:36.511691\n",
      "2020-04-04 2020-04-27 12:28:52.141509\n",
      "2020-04-11 2020-04-27 12:30:18.657948\n",
      "2020-04-18 2020-04-27 12:31:30.108791\n"
     ]
    }
   ],
   "source": [
    "df_2020=pd.DataFrame()\n",
    "df_prod_mapping=pd.read_csv(\"/home/jian/BigLots/static_files/ProductTaxonomy/MediaStormProductTaxonomy20200401-135137-346.txt\",\n",
    "                            sep=\"|\",dtype=str,usecols=['division_id','department_id','class_code_id','subclass_id'])\n",
    "for file in list_POS_this_year:\n",
    "    df=pd.read_csv(file,dtype=str,sep=\"|\")\n",
    "    df=pd.merge(df,df_prod_mapping,on=['class_code_id','subclass_id'],how=\"left\")\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    df['division_id']=df['division_id'].fillna(\"-1\")\n",
    "    df['department_id']=df['department_id'].fillna(\"-1\")\n",
    "    df['rewards_label']=np.where(pd.isnull(df['customer_id_hashed']),\"non_rewards\",\"rewards\")\n",
    "    df['store_label']=np.where(df['location_id']==\"6990\",\"online\",\"instore\")\n",
    "    week_end_dt=df['transaction_dt'].max()\n",
    "    \n",
    "    df_sales=df.groupby(['division_id','department_id','rewards_label','store_label'])['item_transaction_amt'].sum().to_frame().reset_index()\n",
    "    \n",
    "    df_trans=df[['location_id','transaction_dt','transaction_id','rewards_label','division_id','department_id','store_label']].drop_duplicates()\n",
    "    df_trans=df_trans.groupby(['division_id','department_id','rewards_label','store_label'])['transaction_id'].count().to_frame().reset_index()\n",
    "    df=pd.merge(df_sales,df_trans,on=['division_id','department_id','rewards_label','store_label'],how=\"outer\")\n",
    "    \n",
    "    df['week_end_dt']=week_end_dt\n",
    "    df=df.rename(columns={\"item_transaction_amt\":\"sales\",\"transaction_id\":\"trans\"})\n",
    "    df_2020=df_2020.append(df)\n",
    "    print(week_end_dt,datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-09 2020-04-27 12:32:37.880470\n",
      "2019-03-16 2020-04-27 12:33:43.744556\n",
      "2019-03-23 2020-04-27 12:34:48.273265\n",
      "2019-03-30 2020-04-27 12:35:51.650136\n",
      "2019-04-06 2020-04-27 12:37:13.175329\n",
      "2019-04-13 2020-04-27 12:38:36.593070\n",
      "2019-04-20 2020-04-27 12:39:49.663506\n",
      "2019-04-27 2020-04-27 12:40:47.395367\n"
     ]
    }
   ],
   "source": [
    "df_2019=pd.DataFrame()\n",
    "df_prod_mapping=pd.read_csv(\"/home/jian/BigLots/static_files/ProductTaxonomy/MediaStormProductTaxonomy20190401-134939-109.txt\",\n",
    "                            sep=\"|\",dtype=str,usecols=['division_id','department_id','class_code_id','subclass_id'])\n",
    "for file in list_POS_last_year:\n",
    "    df=pd.read_csv(file,dtype=str,sep=\"|\")\n",
    "    df=pd.merge(df,df_prod_mapping,on=['class_code_id','subclass_id'],how=\"left\")\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    df['division_id']=df['division_id'].fillna(\"-1\")\n",
    "    df['department_id']=df['department_id'].fillna(\"-1\")\n",
    "    df['rewards_label']=np.where(pd.isnull(df['customer_id_hashed']),\"non_rewards\",\"rewards\")\n",
    "    df['store_label']=np.where(df['location_id']==\"6990\",\"online\",\"instore\")\n",
    "    week_end_dt=df['transaction_dt'].max()\n",
    "    \n",
    "    df_sales=df.groupby(['division_id','department_id','rewards_label','store_label'])['item_transaction_amt'].sum().to_frame().reset_index()\n",
    "    \n",
    "    df_trans=df[['location_id','transaction_dt','transaction_id','rewards_label','division_id','department_id','store_label']].drop_duplicates()\n",
    "    df_trans=df_trans.groupby(['division_id','department_id','rewards_label','store_label'])['transaction_id'].count().to_frame().reset_index()\n",
    "    df=pd.merge(df_sales,df_trans,on=['division_id','department_id','rewards_label','store_label'],how=\"outer\")\n",
    "    \n",
    "    df['week_end_dt']=week_end_dt\n",
    "    df=df.rename(columns={\"item_transaction_amt\":\"sales\",\"transaction_id\":\"trans\"})\n",
    "    df_2019=df_2019.append(df)\n",
    "    print(week_end_dt,datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_2019.shape (1240, 7)\n",
      "df_2020.shape (1135, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"df_2019.shape\",df_2019.shape)\n",
    "print(\"df_2020.shape\",df_2020.shape)\n",
    "\n",
    "df_2019['division_id']=df_2019['division_id'].astype(int)\n",
    "df_2020['division_id']=df_2020['division_id'].astype(int)\n",
    "df_2019['department_id']=df_2019['department_id'].astype(int)\n",
    "df_2020['department_id']=df_2020['department_id'].astype(int)\n",
    "\n",
    "df_2019=df_2019.sort_values(['division_id','department_id','rewards_label','store_label'])\n",
    "df_2020=df_2020.sort_values(['division_id','department_id','rewards_label','store_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_wide=df_2019.pivot_table(index=['division_id','department_id','rewards_label','store_label'],columns=\"week_end_dt\",values=\"sales\").reset_index()\n",
    "df_2020_wide=df_2020.pivot_table(index=['division_id','department_id','rewards_label','store_label'],columns=\"week_end_dt\",values=\"sales\").reset_index()\n",
    "df_2019_wide.insert(0,'year',\"2019\")\n",
    "df_2020_wide.insert(0,'year',\"2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_2019_wide.columns.tolist():\n",
    "    if \"-\" in col:\n",
    "        df_2019_wide[col]=df_2019_wide[col].fillna(0)\n",
    "        \n",
    "for col in df_2020_wide.columns.tolist():\n",
    "    if \"-\" in col:\n",
    "        df_2020_wide[col]=df_2020_wide[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_name=pd.read_table(\"/home/jian/BigLots/static_files/MediaStorm Data Extract - Division Names.txt\",sep=\"|\")\n",
    "department_name=pd.read_table(\"/home/jian/BigLots/static_files/MediaStorm Data Extract - Department Names.txt\",sep=\"|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"./BL_sales_by_department_week_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_2019_wide.to_excel(writer,\"2019_wide_all\",index=False)\n",
    "df_2020_wide.to_excel(writer,\"2020_wide_all\",index=False)\n",
    "division_name.to_excel(writer,\"division_name\",index=False)\n",
    "department_name.to_excel(writer,\"department_name\",index=False)\n",
    "df_2019.to_excel(writer,\"2019_long_all\",index=False)\n",
    "df_2020.to_excel(writer,\"2020_long_all\",index=False)\n",
    "for comb,group in df_2019_wide.groupby(['rewards_label','store_label']):\n",
    "    year=group['year'].unique().tolist()[0]\n",
    "    tab_name=\"_\".join(comb)+\"_\"+year\n",
    "    group.to_excel(writer,tab_name,index=False)\n",
    "    \n",
    "for comb,group in df_2020_wide.groupby(['rewards_label','store_label']):\n",
    "    year=group['year'].unique().tolist()[0]\n",
    "    tab_name=\"_\".join(comb)+\"_\"+year\n",
    "    group.to_excel(writer,tab_name,index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
