{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import logging\n",
    "import gc\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "price_threshold=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last_saturday=datetime.datetime.now().date()-datetime.timedelta(days=(datetime.datetime.now().date().weekday()+2))\n",
    "# print(last_saturday)\n",
    "last_saturday=datetime.date(2019,2,2) # To be changed to the running Tuesday\n",
    "logging.basicConfig(filename='V2_Multiprocessing_'+str(last_saturday)+'.log', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_folder=\"/home/jian/celery/DBasket/output/\"\n",
    "\n",
    "output_folder=output_folder+str(last_saturday)+\"/\"\n",
    "\n",
    "try:\n",
    "    os.stat(output_folder)\n",
    "except:\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "            \n",
    "most_recent_daily_data=list(recursive_file_gen(\"/home/jian/BigLots/\"))\n",
    "most_recent_daily_data=[x for x in most_recent_daily_data if (\"MediaStormDailySales\" in x) and (str(last_saturday) in x)]\n",
    "\n",
    "if len(most_recent_daily_data)==1:\n",
    "    most_recent_daily_data=most_recent_daily_data[0]\n",
    "else:\n",
    "    most_recent_daily_data=np.nan\n",
    "    logging.info(\"Last Weekly Daily Data Error\", str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/BigLots/2019_by_weeks/MediaStorm_2019-02-09/MediaStormDailySales20190212-122138-494.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_recent_daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_sub_class_id: [1 2 3]\n",
      "len_class_code_id: [5]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_table(most_recent_daily_data,dtype=str,sep=\"|\")\n",
    "print(\"len_sub_class_id:\",data['subclass_id'].apply(lambda x: len(x)).unique())\n",
    "print(\"len_class_code_id:\",data['class_code_id'].apply(lambda x: len(x)).unique())\n",
    "data['subclass_id']=data['subclass_id'].apply(lambda x: x.zfill(3))\n",
    "data['product_comb']=data['class_code_id']+\"-\"+data['subclass_id']\n",
    "\n",
    "data['subclass_transaction_amt']=data['subclass_transaction_amt'].astype(float)\n",
    "data['subclass_transaction_units']=data['subclass_transaction_units'].astype(int)\n",
    "data=data[(data['subclass_transaction_amt']>0) & (data['subclass_transaction_units']>0)]\n",
    "\n",
    "data['price']=data['subclass_transaction_amt']/data['subclass_transaction_units']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxonomy=pd.read_csv(\"/home/jian/BigLots/static_files/ProductTaxonomy/MediaStormProductTaxonomy20190201-133832-059.txt\",dtype=str,sep=\"|\")\n",
    "taxonomy['subclass_id']=taxonomy['subclass_id'].apply(lambda x: x.zfill(3))\n",
    "division_id_id_name=pd.read_table(\"/home/jian/BigLots/static_files/MediaStorm Data Extract - Division Names.txt\",dtype=str,sep=\"|\")\n",
    "department_id_name=pd.read_table(\"/home/jian/BigLots/static_files/MediaStorm Data Extract - Department Names.txt\",dtype=str,sep=\"|\")\n",
    "class_id_name=pd.read_table(\"/home/jian/BigLots/static_files/MediaStorm Data Extract - Class Names.txt\",dtype=str,sep=\"|\",encoding ='ISO-8859-1')\n",
    "# \n",
    "\n",
    "data_item_avg_price=data[['product_comb','price']].groupby(['product_comb'])['price'].mean().to_frame().reset_index()\n",
    "data_item_avg_price=data_item_avg_price.rename(columns={\"price\":\"avg_price\"})\n",
    "\n",
    "data_item_avg_price['class_code_id']=data_item_avg_price['product_comb'].apply(lambda x: x.split(\"-\")[0])\n",
    "data_item_avg_price['subclass_id']=data_item_avg_price['product_comb'].apply(lambda x: x.split(\"-\")[1])\n",
    "\n",
    "data_item_avg_price=pd.merge(data_item_avg_price,taxonomy,on=['class_code_id','subclass_id'],how=\"left\")\n",
    "\n",
    "\n",
    "data_item_avg_price=pd.merge(data_item_avg_price,division_id_id_name,on=\"division_id\",how=\"left\")\n",
    "data_item_avg_price=pd.merge(data_item_avg_price,department_id_name,on=\"department_id\",how=\"left\")\n",
    "data_item_avg_price=pd.merge(data_item_avg_price,class_id_name,on=\"class_code_id\",how=\"left\")\n",
    "data_item_avg_price=data_item_avg_price[['product_comb','avg_price','division_id','division_desc','department_id','department_desc',\n",
    "                                         'class_code_id','class_code_desc','subclass_id','subclass_desc']]\n",
    "\n",
    "data_item_avg_price.to_csv(output_folder+\"/Price_\"+str(last_saturday)+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9620254, 10)\n",
      "(868863, 10)\n"
     ]
    }
   ],
   "source": [
    "# $10 of all items as in the email on 2019-01-14\n",
    "\n",
    "product_comb_under_10_set=set(data_item_avg_price[data_item_avg_price['avg_price']<price_threshold]['product_comb'].unique().tolist())\n",
    "product_comb_10_and_above_list=data_item_avg_price[data_item_avg_price['avg_price']>=10]['product_comb'].unique().tolist()\n",
    "product_comb_10_and_above_df=data_item_avg_price.sort_values('avg_price',ascending=False)\n",
    "product_comb_10_and_above_df=product_comb_10_and_above_df[product_comb_10_and_above_df['avg_price']>=10].reset_index()\n",
    "del product_comb_10_and_above_df['index']\n",
    "\n",
    "print(data.shape)\n",
    "data=data[~data['product_comb'].isin(product_comb_under_10_set)]\n",
    "data_under_10=data[data['product_comb'].isin(product_comb_under_10_set)]\n",
    "data=data.reset_index()\n",
    "del data['index']\n",
    "print(data.shape)\n",
    "dict_item_avg_price=data_item_avg_price.set_index(['product_comb'])['avg_price'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards - Row_RawData: (527727, 8)\n",
      "Rewards - Unique_id: 339783\n",
      "Non_Rewards - Row_RawData: (341136, 8)\n",
      "Non_Rewards - Unique_id: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data['class_code_id']\n",
    "del data['subclass_id']\n",
    "data_NonRewards=data[pd.isnull(data['customer_id_hashed'])]\n",
    "data_Rewards=data[~pd.isnull(data['customer_id_hashed'])]\n",
    "\n",
    "print(\"Rewards - Row_RawData:\",data_Rewards.shape)\n",
    "print(\"Rewards - Unique_id:\", len(data_Rewards['customer_id_hashed'].unique()))\n",
    "\n",
    "print(\"Non_Rewards - Row_RawData:\",data_NonRewards.shape)\n",
    "print(\"Non_Rewards - Unique_id:\", len(data_NonRewards['customer_id_hashed'].unique()))\n",
    "# data=data[(data['subclass_transaction_amt']>0) & (data['subclass_transaction_units']>0)] #Already filtered at the beginning\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_unique(x):\n",
    "    return len(set(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the count of actual transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rewards_transactions_list=data_Rewards.groupby(['location_id','transaction_dt','transaction_id','customer_id_hashed'])['product_comb'].apply(list).to_frame().reset_index().rename(columns={\"product_comb\":\"basket_list\"})\n",
    "Rewards_transactions_units_sales=data_Rewards.groupby(['location_id','transaction_dt','transaction_id','customer_id_hashed'])['subclass_transaction_units','subclass_transaction_amt'].sum().reset_index().rename(columns={\"subclass_transaction_units\":\"total_item_units\",\"subclass_transaction_amt\":\"total_item_revenue\"})\n",
    "Rewards_transactions=pd.merge(Rewards_transactions_list,Rewards_transactions_units_sales,on=['location_id','transaction_dt','transaction_id','customer_id_hashed'],how=\"left\")\n",
    "Rewards_transactions['basket_str']=Rewards_transactions['basket_list'].apply(lambda x: sorted(x)).astype(str)\n",
    "Rewards_transactions['transactin_id_given']=[x for x in range(1,len(Rewards_transactions)+1)]\n",
    "Rewards_transactions['types']=Rewards_transactions['basket_list'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rewards_Trans_by_ID=Rewards_transactions.groupby(['customer_id_hashed'])['transactin_id_given'].count().to_frame().reset_index().rename(columns={\"transactin_id_given\":\"trans_count\"})\n",
    "\n",
    "Rewards_IDCounts_by_Trans=Rewards_Trans_by_ID.groupby(['trans_count'])['customer_id_hashed'].count().to_frame().reset_index()\n",
    "df_Rewards_IDCounts_by_Trans=Rewards_IDCounts_by_Trans.copy()\n",
    "df_Rewards_IDCounts_by_Trans['trans_count']=np.where(df_Rewards_IDCounts_by_Trans['trans_count']>=3,\"3+\",df_Rewards_IDCounts_by_Trans['trans_count'])\n",
    "df_Rewards_IDCounts_by_Trans['trans_count']=df_Rewards_IDCounts_by_Trans['trans_count'].replace(1,\"1\").replace(2,\"2\")\n",
    "df_Rewards_IDCounts_by_Trans=df_Rewards_IDCounts_by_Trans.groupby(['trans_count'])['customer_id_hashed'].sum().to_frame().reset_index().rename(columns={\"customer_id_hashed\":\"ID_Counts\"})\n",
    "df_Rewards_IDCounts_by_Trans['Label']=\"Rewards_ID\"\n",
    "df_Rewards_IDCounts_by_Trans=df_Rewards_IDCounts_by_Trans[['Label','trans_count','ID_Counts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>trans_count</th>\n",
       "      <th>ID_Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rewards_ID</td>\n",
       "      <td>1</td>\n",
       "      <td>314020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rewards_ID</td>\n",
       "      <td>2</td>\n",
       "      <td>22597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rewards_ID</td>\n",
       "      <td>3+</td>\n",
       "      <td>3166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non_Rewards_Trans</td>\n",
       "      <td>1+</td>\n",
       "      <td>253998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Label trans_count  ID_Counts\n",
       "0         Rewards_ID           1     314020\n",
       "1         Rewards_ID           2      22597\n",
       "2         Rewards_ID          3+       3166\n",
       "3  Non_Rewards_Trans          1+     253998"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Non_Rewards_Trans_Count=data_NonRewards[['location_id','transaction_dt','transaction_id']].drop_duplicates()\n",
    "\n",
    "df_output_1_count_by_trans_of_ids_price_10Plus=df_Rewards_IDCounts_by_Trans.append(pd.DataFrame({'Label':\"Non_Rewards_Trans\",'trans_count':\"1+\",'ID_Counts':len(df_Non_Rewards_Trans_Count)},index=[3]))\n",
    "df_output_1_count_by_trans_of_ids_price_10Plus=df_output_1_count_by_trans_of_ids_price_10Plus[['Label','trans_count','ID_Counts']]\n",
    "df_output_1_count_by_trans_of_ids_price_10Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rewards_data_transactions_list=data_Rewards.groupby(['location_id','transaction_dt','transaction_id','customer_id_hashed'])['product_comb'].apply(list).to_frame().reset_index().rename(columns={\"product_comb\":\"basket_list\"})\n",
    "Rewards_data_transactions_units_sales=data_Rewards.groupby(['location_id','transaction_dt','transaction_id','customer_id_hashed'])['subclass_transaction_units','subclass_transaction_amt'].sum().reset_index().rename(columns={\"subclass_transaction_units\":\"total_item_units\",\"subclass_transaction_amt\":\"total_item_revenue\"})\n",
    "\n",
    "Rewards_data_transactions=pd.merge(Rewards_data_transactions_list,Rewards_data_transactions_units_sales,on=['location_id','transaction_dt','transaction_id','customer_id_hashed'],how=\"left\")\n",
    "Rewards_data_transactions['basket_str']=Rewards_data_transactions['basket_list'].apply(lambda x: sorted(x)).astype(str)\n",
    "Rewards_data_transactions['transactin_id_given']=[x for x in range(1,len(Rewards_data_transactions)+1)]\n",
    "Rewards_data_transactions['types']=Rewards_data_transactions['basket_list'].apply(lambda x: len(x))\n",
    "\n",
    "# To save\n",
    "\n",
    "\n",
    "Rewards_data_transactions=pd.merge(data_Rewards,Rewards_data_transactions,on=[\"location_id\",\"transaction_dt\",\"transaction_id\",\"customer_id_hashed\"],how=\"left\")\n",
    "apply_func={\"subclass_transaction_units\":\"sum\",\"transactin_id_given\":\"count\",\"subclass_transaction_amt\":\"sum\"}\n",
    "\n",
    "single_prod_df=Rewards_data_transactions.groupby(['product_comb'])['subclass_transaction_units','transactin_id_given','subclass_transaction_amt'].agg(apply_func).reset_index().rename(columns={\"subclass_transaction_units\":\"Total_Units\",\"transactin_id_given\":\"Total_Trans\",\"subclass_transaction_amt\":\"revenue\"})\n",
    "total_unit=single_prod_df['Total_Units'].sum()\n",
    "total_trans=len(Rewards_data_transactions)\n",
    "\n",
    "single_prod_df['prob_unit']=single_prod_df['Total_Units']/total_unit\n",
    "single_prod_df['prob_tran']=single_prod_df['Total_Trans']/total_trans\n",
    "\n",
    "dict_single_prod_unit=single_prod_df.set_index(['product_comb'])['prob_unit'].to_dict()\n",
    "dict_single_prod_tran=single_prod_df.set_index(['product_comb'])['prob_tran'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rewards_Trans_by_ID=Rewards_Trans_by_ID.rename(columns={\"trans_count\":\"trans_count_by_id\"})\n",
    "Rewards_data_transactions=pd.merge(Rewards_data_transactions,Rewards_Trans_by_ID,on=\"customer_id_hashed\",how=\"left\")\n",
    "Rewards_data_transactions['trans_count_by_id']=np.where(Rewards_data_transactions['trans_count_by_id']>=3,\"3+\",Rewards_data_transactions['trans_count_by_id'])\n",
    "Rewards_data_transactions['trans_count_by_id']=Rewards_data_transactions['trans_count_by_id'].replace(1,\"1\").replace(2,\"2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>trans_count_by_id</th>\n",
       "      <th>item_types</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3+</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>234138</td>\n",
       "      <td>30747</td>\n",
       "      <td>7617</td>\n",
       "      <td>Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>54027</td>\n",
       "      <td>9011</td>\n",
       "      <td>2217</td>\n",
       "      <td>Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16008</td>\n",
       "      <td>3113</td>\n",
       "      <td>778</td>\n",
       "      <td>Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5454</td>\n",
       "      <td>1222</td>\n",
       "      <td>338</td>\n",
       "      <td>Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2127</td>\n",
       "      <td>528</td>\n",
       "      <td>157</td>\n",
       "      <td>Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6+</td>\n",
       "      <td>2266</td>\n",
       "      <td>573</td>\n",
       "      <td>172</td>\n",
       "      <td>Rewards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "trans_count_by_id item_types       1      2    3+    Label\n",
       "0                          1  234138  30747  7617  Rewards\n",
       "1                          2   54027   9011  2217  Rewards\n",
       "2                          3   16008   3113   778  Rewards\n",
       "3                          4    5454   1222   338  Rewards\n",
       "4                          5    2127    528   157  Rewards\n",
       "5                         6+    2266    573   172  Rewards"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_2_1_count_by_trans_of_ids_price_10Plus=Rewards_data_transactions.groupby(['trans_count_by_id','types'])['transactin_id_given'].apply(count_unique).reset_index().rename(columns={\"transactin_id_given\":\"Transaction_Count\"})\n",
    "df_output_2_1_count_by_trans_of_ids_price_10Plus_actual=df_output_2_1_count_by_trans_of_ids_price_10Plus.copy()\n",
    "df_output_2_1_count_by_trans_of_ids_price_10Plus['types']=np.where(df_output_2_1_count_by_trans_of_ids_price_10Plus['types']>=6,\"6+\",df_output_2_1_count_by_trans_of_ids_price_10Plus['types'])\n",
    "\n",
    "df_output_2_1_count_by_trans_of_ids_price_10Plus=df_output_2_1_count_by_trans_of_ids_price_10Plus.groupby(['trans_count_by_id','types'])['Transaction_Count'].sum().reset_index()\n",
    "df_output_2_1_count_by_trans_of_ids_price_10Plus=df_output_2_1_count_by_trans_of_ids_price_10Plus.pivot_table(index=\"types\",columns=\"trans_count_by_id\",values=\"Transaction_Count\").reset_index().rename(columns={\"types\":\"item_types\"})\n",
    "\n",
    "df_output_2_1_count_by_trans_of_ids_price_10Plus=df_output_2_1_count_by_trans_of_ids_price_10Plus.sort_values(\"item_types\")\n",
    "df_output_2_1_count_by_trans_of_ids_price_10Plus['Label']=\"Rewards\"\n",
    "df_output_2_1_count_by_trans_of_ids_price_10Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_types</th>\n",
       "      <th>Transaction_Count</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>199899</td>\n",
       "      <td>Non_Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37036</td>\n",
       "      <td>Non_Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10144</td>\n",
       "      <td>Non_Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3538</td>\n",
       "      <td>Non_Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1483</td>\n",
       "      <td>Non_Rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6+</td>\n",
       "      <td>1898</td>\n",
       "      <td>Non_Rewards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_types  Transaction_Count        Label\n",
       "0          1             199899  Non_Rewards\n",
       "1          2              37036  Non_Rewards\n",
       "2          3              10144  Non_Rewards\n",
       "3          4               3538  Non_Rewards\n",
       "4          5               1483  Non_Rewards\n",
       "5         6+               1898  Non_Rewards"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_2_2_count_by_trans_of_ids_price_10Plus=data_NonRewards.groupby(['location_id','transaction_dt','transaction_id'])['product_comb'].apply(list).reset_index()\n",
    "df_output_2_2_count_by_trans_of_ids_price_10Plus['item_types']=df_output_2_2_count_by_trans_of_ids_price_10Plus['product_comb'].apply(len)\n",
    "df_output_2_2_count_by_trans_of_ids_price_10Plus_actual=df_output_2_2_count_by_trans_of_ids_price_10Plus.groupby(['item_types'])['transaction_id'].count().to_frame().reset_index()\n",
    "df_output_2_2_count_by_trans_of_ids_price_10Plus=df_output_2_2_count_by_trans_of_ids_price_10Plus_actual.copy()\n",
    "df_output_2_2_count_by_trans_of_ids_price_10Plus['item_types']=np.where(df_output_2_2_count_by_trans_of_ids_price_10Plus['item_types']>=6,\"6+\",df_output_2_2_count_by_trans_of_ids_price_10Plus['item_types'])\n",
    "df_output_2_2_count_by_trans_of_ids_price_10Plus=df_output_2_2_count_by_trans_of_ids_price_10Plus.groupby(['item_types'])['transaction_id'].sum().to_frame().reset_index().rename(columns={\"transaction_id\":\"Transaction_Count\"})\n",
    "df_output_2_2_count_by_trans_of_ids_price_10Plus['Label']=\"Non_Rewards\"\n",
    "df_output_2_2_count_by_trans_of_ids_price_10Plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_types</th>\n",
       "      <th>Transaction_Count</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>472401</td>\n",
       "      <td>Rewards_and_NonRewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>102291</td>\n",
       "      <td>Rewards_and_NonRewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30043</td>\n",
       "      <td>Rewards_and_NonRewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10552</td>\n",
       "      <td>Rewards_and_NonRewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4295</td>\n",
       "      <td>Rewards_and_NonRewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6+</td>\n",
       "      <td>4909</td>\n",
       "      <td>Rewards_and_NonRewards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_types  Transaction_Count                   Label\n",
       "0          1             472401  Rewards_and_NonRewards\n",
       "1          2             102291  Rewards_and_NonRewards\n",
       "2          3              30043  Rewards_and_NonRewards\n",
       "3          4              10552  Rewards_and_NonRewards\n",
       "4          5               4295  Rewards_and_NonRewards\n",
       "5         6+               4909  Rewards_and_NonRewards"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['customer_id_hashed']=data['customer_id_hashed'].fillna(\"nan\")\n",
    "df_output_3_count_by_trans_of_ids_price_10Plus=data.groupby(['location_id','transaction_dt','transaction_id','customer_id_hashed'])['product_comb'].apply(list).reset_index()\n",
    "df_output_3_count_by_trans_of_ids_price_10Plus['item_types']=df_output_3_count_by_trans_of_ids_price_10Plus['product_comb'].apply(len)\n",
    "df_output_3_count_by_trans_of_ids_price_10Plus_actual=df_output_3_count_by_trans_of_ids_price_10Plus.groupby(['item_types'])['transaction_id'].count().to_frame().reset_index()\n",
    "df_output_3_count_by_trans_of_ids_price_10Plus=df_output_3_count_by_trans_of_ids_price_10Plus_actual.copy()\n",
    "df_output_3_count_by_trans_of_ids_price_10Plus['item_types']=np.where(df_output_3_count_by_trans_of_ids_price_10Plus['item_types']>=6,\"6+\",df_output_3_count_by_trans_of_ids_price_10Plus['item_types'])\n",
    "df_output_3_count_by_trans_of_ids_price_10Plus=df_output_3_count_by_trans_of_ids_price_10Plus.groupby(['item_types'])['transaction_id'].sum().to_frame().reset_index().rename(columns={\"transaction_id\":\"Transaction_Count\"})\n",
    "df_output_3_count_by_trans_of_ids_price_10Plus['Label']=\"Rewards_and_NonRewards\"\n",
    "df_output_3_count_by_trans_of_ids_price_10Plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"BL_Transaction_Summary_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_output_1_count_by_trans_of_ids_price_10Plus.to_excel(writer,\"summary_1_transactions_ids\")\n",
    "df_output_2_1_count_by_trans_of_ids_price_10Plus.to_excel(writer,\"summary_2_1_Rewards_trans_items\")\n",
    "df_output_2_2_count_by_trans_of_ids_price_10Plus.to_excel(writer,\"summary_2_2_NonRew_trans_items\")\n",
    "df_output_3_count_by_trans_of_ids_price_10Plus.to_excel(writer,\"summary_3_all_transactions\")\n",
    "writer.save()\n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Calcuating BAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_id_df=Rewards_data_transactions.groupby(['product_comb'])['customer_id_hashed'].apply(count_unique).to_frame().reset_index().rename(columns={\"customer_id_hashed\":\"unique_ids\"})\n",
    "single_prod_df=pd.merge(single_prod_df,unique_id_df,on=\"product_comb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_basket=Rewards_data_transactions.groupby(['basket_str'])['total_item_units','total_item_revenue','transactin_id_given'].agg(\n",
    "            {\"total_item_units\":\"sum\",\"total_item_revenue\":\"sum\",\"transactin_id_given\":\"count\"}).reset_index().rename(columns={\"transactin_id_given\":\"trans_count\"})\n",
    "data_basket['basket_list']=data_basket['basket_str'].apply(eval)\n",
    "data_basket['item_types']=data_basket['basket_list'].apply(len)\n",
    "data_basket=data_basket.sort_values(['item_types','basket_str'])\n",
    "\n",
    "data_basket=data_basket.reset_index()\n",
    "del data_basket['index']\n",
    "\n",
    "unique_id_by_basket=Rewards_data_transactions.groupby(['basket_str'])['customer_id_hashed'].apply(lambda x: len(set(x))).to_frame().reset_index().rename(columns={'customer_id_hashed':\"unique_ids\"})\n",
    "data_basket=pd.merge(data_basket,unique_id_by_basket,on=\"basket_str\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_basket.to_csv(\"/home/jian/Projects/Big_Lots/Analysis/2018_Q4/Product_Basket/data_for_freq_dist_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2019-02-20 09:08:40.630433\n",
      "29994\n",
      "3 2019-02-20 09:09:49.480919\n",
      "189122\n",
      "4 2019-02-20 09:10:35.687463\n",
      "543227\n",
      "5 2019-02-20 09:11:29.346777\n",
      "1463605\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "def findsubsets(total_set,item_counts):\n",
    "    return list(set(combinations(total_set, item_counts)))\n",
    "\n",
    "for i in range(2,6):\n",
    "    locals()['set_'+str(i)+\"_comb\"]=[]\n",
    "    output_1_basket_str_list_i=sorted(data_basket[data_basket['item_types']==i]['basket_str'].unique().tolist())\n",
    "    output_2_basket_str_list_i_plus=[]\n",
    "    basket_str_list_i_plus=data_basket[data_basket['item_types']>i]['basket_str'].unique().tolist()\n",
    "    \n",
    "    \n",
    "    for set_str in basket_str_list_i_plus:\n",
    "        set_list=eval(set_str)\n",
    "        output_2_basket_str_list_i_plus=list(set(output_2_basket_str_list_i_plus+[str(list(x)) for x in findsubsets(set_list,i)]))\n",
    "        \n",
    "    locals()['set_'+str(i)+\"_comb\"]=sorted(list(set(output_1_basket_str_list_i+output_2_basket_str_list_i_plus)))\n",
    "    print(i, datetime.datetime.now())\n",
    "    print(len(locals()['set_'+str(i)+\"_comb\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbasket_transaction_2_plus=data_basket[data_basket['item_types']>=2][['basket_str','trans_count']]\\nbasket_transaction_3_plus=data_basket[data_basket['item_types']>=3][['basket_str','trans_count']]\\nbasket_transaction_4_plus=data_basket[data_basket['item_types']>=4][['basket_str','trans_count']]\\nbasket_transaction_5_plus=data_basket[data_basket['item_types']>=5][['basket_str','trans_count']]\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "basket_transaction_2_plus=data_basket[data_basket['item_types']>=2][['basket_str','trans_count']]\n",
    "basket_transaction_3_plus=data_basket[data_basket['item_types']>=3][['basket_str','trans_count']]\n",
    "basket_transaction_4_plus=data_basket[data_basket['item_types']>=4][['basket_str','trans_count']]\n",
    "basket_transaction_5_plus=data_basket[data_basket['item_types']>=5][['basket_str','trans_count']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225948"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_set_all=set_2_comb+set_3_comb+set_4_comb+set_5_comb\n",
    "total_len=len(list_set_all)\n",
    "total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processors=25\n",
    "\n",
    "interval=int(np.floor(total_len/processors))\n",
    "# list_set_all_subset_0=list_set_all_subset_[:interval]\n",
    "# 0 to 9, 10 in total\n",
    "all_list_of_input=[]\n",
    "for i in range(processors-1): \n",
    "    #1 to 9\n",
    "    locals()['list_set_all_subset_'+str(i)]=list_set_all[interval*i:interval*(i+1)]\n",
    "    all_list_of_input=all_list_of_input+[locals()['list_set_all_subset_'+str(i)]]\n",
    "locals()['list_set_all_subset_'+str(processors-1)]=list_set_all[interval*(processors-1):]\n",
    "all_list_of_input=all_list_of_input+[locals()['list_set_all_subset_'+str(processors-1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getting_BAI_items(list_set_subset_i):\n",
    "    i_counter=0\n",
    "    dict_basket_support_trans={}\n",
    "    dict_basket_support_items={}\n",
    "    dict_basket_BAI_trans={}\n",
    "    dict_basket_BAI_items={}\n",
    "    dict_basket_unique_ids={}\n",
    "    dict_basket_revenue={} #revenue only for the selected subset of items\n",
    "    for basket_n in list_set_subset_i:\n",
    "        basket_n_list=eval(basket_n)\n",
    "        len_items=len(basket_n_list)\n",
    "        \n",
    "        df=Rewards_data_transactions[Rewards_data_transactions['product_comb'].isin(basket_n_list)][['basket_str','transactin_id_given','subclass_transaction_units','customer_id_hashed','subclass_transaction_amt']]\n",
    "        \n",
    "        trans_denominator=1\n",
    "        items_denominator=1\n",
    "        \n",
    "        for k in range(len_items):\n",
    "            globals()['basket_item_'+str(k)]=basket_n_list[k]\n",
    "            df=df[df['basket_str'].apply(lambda x: globals()['basket_item_'+str(k)] in x)]\n",
    "            trans_denominator=trans_denominator*dict_single_prod_tran[globals()['basket_item_'+str(k)]]\n",
    "            items_denominator=items_denominator*dict_single_prod_unit[globals()['basket_item_'+str(k)]]\n",
    "\n",
    "        trans_basket=len(df['transactin_id_given'].unique())\n",
    "        items_basket=df['subclass_transaction_units'].sum()\n",
    "        unique_ids_basket=len(df['customer_id_hashed'].unique())\n",
    "        revenue_bakset=df['subclass_transaction_amt'].sum()\n",
    "        \n",
    "        dict_basket_support_trans.update({basket_n:trans_basket})\n",
    "        dict_basket_support_items.update({basket_n:items_basket})\n",
    "        dict_basket_unique_ids.update({basket_n:unique_ids_basket})\n",
    "        dict_basket_revenue.update({basket_n:revenue_bakset})\n",
    "\n",
    "        BAI_basket_trans=(trans_basket/total_trans)/trans_denominator*100\n",
    "        BAI_basket_items=(items_basket/total_unit)/items_denominator*100\n",
    "        \n",
    "        dict_basket_BAI_trans.update({basket_n:BAI_basket_trans})\n",
    "        dict_basket_BAI_items.update({basket_n:BAI_basket_items})\n",
    "        \n",
    "        i_counter+=1\n",
    "        if i_counter%1000==10:\n",
    "            logging.info(str(datetime.datetime.now())+\"|\"+str(i_counter))\n",
    "    results_json={}\n",
    "    results_json.update({\"dict_basket_support_trans\":dict_basket_support_trans})\n",
    "    results_json.update({\"dict_basket_support_items\":dict_basket_support_items})\n",
    "    results_json.update({\"dict_basket_BAI_trans\":dict_basket_BAI_trans})\n",
    "    results_json.update({\"dict_basket_BAI_items\":dict_basket_BAI_items})\n",
    "    results_json.update({\"dict_basket_unique_ids\":dict_basket_unique_ids})\n",
    "    results_json.update({\"dict_basket_revenue\":dict_basket_revenue})\n",
    "    \n",
    "    return results_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "result_dict_basket_support_trans={}\n",
    "result_dict_basket_support_items={}\n",
    "result_dict_basket_BAI_trans={}\n",
    "result_dict_basket_BAI_items={}\n",
    "result_dict_basket_unique_ids={}\n",
    "result_dict_basket_revenue={}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(processors)\n",
    "    result=p.map(getting_BAI_items, all_list_of_input)\n",
    "    for res in result:\n",
    "        if res is not None:\n",
    "            result_dict_basket_support_trans.update(res[\"dict_basket_support_trans\"])\n",
    "            result_dict_basket_support_items.update(res[\"dict_basket_support_items\"])\n",
    "            result_dict_basket_BAI_trans.update(res[\"dict_basket_BAI_trans\"])\n",
    "            result_dict_basket_BAI_items.update(res[\"dict_basket_BAI_items\"])\n",
    "            result_dict_basket_unique_ids.update(res['dict_basket_unique_ids'])\n",
    "            result_dict_basket_revenue.update(res['dict_basket_revenue'])\n",
    "    p.close()\n",
    "    p.join()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "output_1=data_basket[data_basket['item_types']==1]\n",
    "output_2=data_basket[data_basket['item_types'].isin([2,3,4,5])]\n",
    "output_3=data_basket[data_basket['item_types']>5]\n",
    "\n",
    "output_1['BAI_trans']=100\n",
    "output_1['BAI_items']=100\n",
    "\n",
    "output_2['BAI_trans']=output_2['basket_str'].apply(lambda x: result_dict_basket_BAI_trans[x])\n",
    "output_2['BAI_items']=output_2['basket_str'].apply(lambda x: result_dict_basket_BAI_items[x])\n",
    "\n",
    "output_basket=output_1.append(output_2).append(output_3) # To add those only in multiple item trans\n",
    "#E.g. [a,b,c,d] [a,c] doesn't exsit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_prod_df['BAI_Trans']=100\n",
    "single_prod_df['BAI_Items']=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(result_dict_basket_support_trans,index=['Total_Trans']).T.reset_index().rename(columns={\"index\":\"basket_str\"})\n",
    "df2=pd.DataFrame(result_dict_basket_support_items,index=['Total_Units']).T.reset_index().rename(columns={\"index\":\"basket_str\"})\n",
    "df3=pd.DataFrame(result_dict_basket_BAI_trans,index=['BAI_Trans']).T.reset_index().rename(columns={\"index\":\"basket_str\"})\n",
    "df4=pd.DataFrame(result_dict_basket_BAI_items,index=['BAI_Items']).T.reset_index().rename(columns={\"index\":\"basket_str\"})\n",
    "df5=pd.DataFrame(result_dict_basket_unique_ids,index=['unique_ids']).T.reset_index().rename(columns={\"index\":\"basket_str\"})\n",
    "df6=pd.DataFrame(result_dict_basket_revenue,index=['revenue']).T.reset_index().rename(columns={\"index\":\"basket_str\"})\n",
    "\n",
    "output_all_2345_available=pd.merge(df1,df2,on='basket_str')\n",
    "output_all_2345_available=pd.merge(df3,output_all_2345_available,on='basket_str')\n",
    "output_all_2345_available=pd.merge(df4,output_all_2345_available,on='basket_str')\n",
    "output_all_2345_available=pd.merge(df5,output_all_2345_available,on='basket_str')\n",
    "output_all_2345_available=pd.merge(df6,output_all_2345_available,on='basket_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_prod_df['basket_str']=\"['\"+single_prod_df['product_comb']+\"']\"\n",
    "del single_prod_df['product_comb']\n",
    "\n",
    "output_all_12345_available=single_prod_df.append(output_all_2345_available)\n",
    "output_all_12345_available['basket_list']=output_all_12345_available['basket_str'].apply(eval)\n",
    "output_all_12345_available['item_types']=output_all_12345_available['basket_list'].apply(len)\n",
    "output_all_12345_available=output_all_12345_available.sort_values('item_types',ascending=True)\n",
    "\n",
    "# All posibble from the shopped large basket 1-5\n",
    "output_3=data_basket[data_basket['item_types']>5]\n",
    "output_3=output_3.rename(columns={\"trans_count\":\"Total_Trans\",\"total_item_units\":\"Total_Units\",\"total_item_revenue\":\"revenue\"})\n",
    "\n",
    "output_all_12345_available=output_all_12345_available.append(output_3) #Appended >5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1546"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the BAI of items to the baskets\n",
    "\n",
    "len(result_dict_basket_BAI_items)\n",
    "data_item_avg_price_dict=data_item_avg_price.set_index([\"product_comb\"]).to_dict()['avg_price']\n",
    "len(data_item_avg_price_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def brewak_basket_to_top_5(input_x):\n",
    "    input_x=eval(input_x)\n",
    "    len_input_x=len(input_x)\n",
    "    df=pd.DataFrame({\"subcalss_item\":input_x},index=range(len(len_input_x)))\n",
    "    df['price']=df['subcalss_item'].apply(lambda x: data_item_avg_price_dict[x])\n",
    "    df=df.sort_values(\"price\",ascending=False).head(5)\n",
    "    \n",
    "    chapion_subclass=df['subcalss_item'].tolist()[0]\n",
    "    df['class_code_id']=df['subcalss_item'].apply(lambda x: x.split({\"-\"}[0]))\n",
    "    chapion_subclass_id=df['class_code_id'].tolist(0)\n",
    "    \n",
    "    complementary_subclass_df=df[df['class_code_id']==chapion_class_id]\n",
    "    \n",
    "    if len(complementary_subclass_df)>0:\n",
    "        complementary_subclass_df_1=complementary_subclass_df.head(3)\n",
    "        complementary_subclass_df_2=\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "writer=pd.ExcelWriter(output_folder+\"/BL_DBasket_Version2_JL_'+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "# output=output[['basket_str','basket_list','BAI_trans','BAI_units','item_types','total_item_revenue','total_item_units','trans_count','unique_ids','price_list']]\n",
    "output_all_12345_available=output_all_12345_available[['basket_list','BAI_Trans','BAI_Items','item_types','revenue','Total_Units','Total_Trans','unique_ids']]\n",
    "output_all_12345_available=output_all_12345_available.sort_values(['item_types','BAI_Trans'],ascending=[True,False])\n",
    "output_all_12345_available.to_excel(writer,\"BAI_including_subsets\",index=False)\n",
    "data_basket.to_excel(writer,\"basket_shopped_together\",index=False)\n",
    "writer.save()\n",
    "'''\n",
    "logging.info(\"Done: \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_all_12345_available.to_csv(output_folder+\"/BL_DBasket_Version2_BAI_output_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "data_basket.to_csv(output_folder+\"/BL_DBasket_Version2_actual_whole_baskets_output_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_all_12345_available[output_all_12345_available['item_types']==1].to_csv(output_folder+\"/BL_DBasket_Version2_BAI_output_Item_1_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "output_all_12345_available[output_all_12345_available['item_types']==2].to_csv(output_folder+\"/BL_DBasket_Version2_BAI_output_Item_2_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "output_all_12345_available[output_all_12345_available['item_types']==3].to_csv(output_folder+\"/BL_DBasket_Version2_BAI_output_Item_3_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "output_all_12345_available[output_all_12345_available['item_types']==4].to_csv(output_folder+\"/BL_DBasket_Version2_BAI_output_Item_4_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "output_all_12345_available[output_all_12345_available['item_types']==5].to_csv(output_folder+\"/BL_DBasket_Version2_BAI_output_Item_5_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "output_all_12345_available[output_all_12345_available['item_types']>5].to_csv(output_folder+\"/BL_DBasket_Version2_BAI_output_Item_6Plus_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
