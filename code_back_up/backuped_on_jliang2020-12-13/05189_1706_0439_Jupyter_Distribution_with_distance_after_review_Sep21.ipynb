{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2018, 9, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import hashlib\n",
    "import gc\n",
    "from haversine import haversine\n",
    "\n",
    "logging.basicConfig(filename='rewards_py_20180924.log', level=logging.INFO)\n",
    "datetime.datetime.now().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_list_cols=['location_id','address_line_1','address_line_2','city_nm','state_nm','zip_cd']\n",
    "store_list=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStores20180801-133641-576.txt\",dtype=str,sep=\"|\")\n",
    "store_list=store_list[store_list_cols]\n",
    "\n",
    "store_list_2=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStores_20180703.txt\",dtype=str,sep=\"|\")\n",
    "store_list_2=store_list_2[~store_list_2['location_id'].isin(store_list['location_id'].unique().tolist())]\n",
    "store_list_2=store_list_2[store_list_cols]\n",
    "store_list=store_list.append(store_list_2)\n",
    "\n",
    "store_list_2=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStoreList_Nov15.txt\",dtype=str,sep=\"|\")\n",
    "store_list_2=store_list_2[~store_list_2['location_id'].isin(store_list['location_id'].unique().tolist())]\n",
    "store_list_2=store_list_2[store_list_cols]\n",
    "store_list=store_list.append(store_list_2)\n",
    "\n",
    "store_list_2=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStoresList_0913.txt\",dtype=str,sep=\"|\")\n",
    "store_list_2=store_list_2[~store_list_2['location_id'].isin(store_list['location_id'].unique().tolist())]\n",
    "store_list_2=store_list_2[store_list_cols]\n",
    "store_list=store_list.append(store_list_2)\n",
    "\n",
    "store_list['zip_cd']=store_list['zip_cd'].apply(lambda x: x.split(\"-\")[0].zfill(5))\n",
    "store_list=store_list.rename(columns={\"location_id\":\"store\"})\n",
    "store_list['store']=store_list['store'].astype(str)\n",
    "store_list=store_list[~store_list['store'].isin(['145','6990'])]\n",
    "inclusion_store_list_set=set(store_list['store'].unique().tolist())\n",
    "del store_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samplerows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folderpath = '/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/' # usecols=[0,1,5],\n",
    "selected_columns = ['customer_id_hashed', 'email_address_hash','sign_up_location','customer_zip_code']\n",
    "dfiddetail = pd.read_table(folderpath+\"/MediaStormCustTot-hashed-email.txt\",\n",
    "                       header=None,nrows = samplerows,sep = ',',dtype = 'str',usecols=[0,1,4,5])\n",
    "dfiddetail.columns=['customer_id', 'email_address_hash','sign_up_location','customer_zip_code']\n",
    "dfiddetail['customer_id_hashed'] = dfiddetail['customer_id'].apply(lambda x: hashlib.sha256(x.encode('utf-8')).hexdigest())\n",
    "dfiddetail=dfiddetail[selected_columns]\n",
    "dfiddetail=dfiddetail[dfiddetail['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormCustomerTransactionTotals_2018-01-09_2018-03-31.txt',\n",
    "                          nrows = samplerows,sep = ',',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'Existing Reward Member Master as of 2018-06-05.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'New Reward Member Master as of 2018-06-05.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'New Reward Member Master as of 2018-07-03.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180717-132337-377.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180731-130714-098.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180814-130703-491.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail=dfiddetail[['customer_id_hashed','sign_up_location','customer_zip_code']].drop_duplicates()\n",
    "logging.info(\"Finished read of singing up data, with rows of \"+str(dfiddetail.shape[0]))\n",
    "del dfiddetail2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_list_len(x):\n",
    "    y=len(set(x))\n",
    "    return y\n",
    "output_master=dfiddetail.groupby(['sign_up_location'])['customer_id_hashed'].agg(unique_list_len).to_frame().reset_index()\n",
    "# output_master.to_csv(folderpath+\"output/unique_id_signed_up_per_store_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "output_master=output_master.sort_values(['sign_up_location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_id_master_list_set=set(dfiddetail['customer_id_hashed'].unique().tolist())\n",
    "\n",
    "\n",
    "# # Sales unique id visits\n",
    "\n",
    "sales_from_SP=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_sales_data/From_Sp/combinedtransactions_0811.csv\",dtype=str,nrows=samplerows,usecols=['customer_id_hashed','transaction_date','transaction_id','location_id','total_transaction_amt'])\n",
    "sales_from_SP=sales_from_SP.drop_duplicates()\n",
    "\n",
    "sales_from_SP=sales_from_SP[['customer_id_hashed','transaction_date','location_id','total_transaction_amt']]\n",
    "\n",
    "sales_from_SP['total_transaction_amt']=sales_from_SP['total_transaction_amt'].astype(float)\n",
    "\n",
    "sales_from_SP=sales_from_SP[sales_from_SP['total_transaction_amt']>0]\n",
    "\n",
    "sales_from_SP=sales_from_SP[sales_from_SP['location_id'].isin(inclusion_store_list_set)]\n",
    "\n",
    "\n",
    "logging.info(\"Finished read of transaction data from spencer, with rows of \"+str(sales_from_SP.shape[0]))\n",
    "\n",
    "transaction_date=sorted(sales_from_SP['transaction_date'].unique().tolist())\n",
    "purchase_dates_df=pd.DataFrame({\"Date\":transaction_date},index=range(len(transaction_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del sales_from_SP['transaction_date']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Start of 1st task\"+str(datetime.datetime.now()))\n",
    "no_signingup_df=sales_from_SP[~sales_from_SP['customer_id_hashed'].isin(unique_id_master_list_set)]\n",
    "\n",
    "output1_trans_group=sales_from_SP.groupby(['customer_id_hashed'])['location_id'].count().to_frame().reset_index()\n",
    "\n",
    "id_transa_group=output1_trans_group.copy()\n",
    "id_transa_group=id_transa_group.rename(columns={\"location_id\":\"transaction_group\"})\n",
    "\n",
    "id_list_sales_set=set(sales_from_SP['customer_id_hashed'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "removed_2_percentile=id_transa_group[id_transa_group['transaction_group']>=np.percentile(id_transa_group['transaction_group'],98)]\n",
    "# 33 times as the 98 percentile, and == 33 is out\n",
    "removed_2_percentile_id_list=removed_2_percentile['customer_id_hashed'].tolist()\n",
    "sales_from_SP=sales_from_SP[~sales_from_SP['customer_id_hashed'].isin(removed_2_percentile_id_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_transa_group=id_transa_group[~id_transa_group['customer_id_hashed'].isin(removed_2_percentile_id_list)]\n",
    "output1_trans_group=output1_trans_group[~output1_trans_group['customer_id_hashed'].isin(removed_2_percentile_id_list)]\n",
    "\n",
    "id_transa_group['transaction_group']=np.where(id_transa_group['transaction_group']>10,\"10+\",id_transa_group['transaction_group'])\n",
    "id_transa_group['transaction_group']=id_transa_group['transaction_group'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Done of groupby sales_from_SP \"+str(datetime.datetime.now()))\n",
    "rewards_set_1=set(output1_trans_group[output1_trans_group['location_id']==1]['customer_id_hashed'].tolist())\n",
    "rewards_set_2=set(output1_trans_group[output1_trans_group['location_id']==2]['customer_id_hashed'].tolist())\n",
    "rewards_set_3=set(output1_trans_group[output1_trans_group['location_id']==3]['customer_id_hashed'].tolist())\n",
    "rewards_set_4=set(output1_trans_group[output1_trans_group['location_id']==4]['customer_id_hashed'].tolist())\n",
    "rewards_set_5=set(output1_trans_group[output1_trans_group['location_id']==5]['customer_id_hashed'].tolist())\n",
    "rewards_set_6=set(output1_trans_group[output1_trans_group['location_id']==6]['customer_id_hashed'].tolist())\n",
    "rewards_set_7=set(output1_trans_group[output1_trans_group['location_id']==7]['customer_id_hashed'].tolist())\n",
    "rewards_set_8=set(output1_trans_group[output1_trans_group['location_id']==8]['customer_id_hashed'].tolist())\n",
    "rewards_set_9=set(output1_trans_group[output1_trans_group['location_id']==9]['customer_id_hashed'].tolist())\n",
    "rewards_set_10=set(output1_trans_group[output1_trans_group['location_id']==10]['customer_id_hashed'].tolist())\n",
    "rewards_set_10_Plus=set(output1_trans_group[output1_trans_group['location_id']>10]['customer_id_hashed'].tolist())\n",
    "rewards_set_0=set([x for x in unique_id_master_list_set if x not in id_list_sales_set])\n",
    "logging.info(\"Done of set all \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "output1_trans_group=output1_trans_group.rename(columns={\"location_id\":\"transaction_count\"})\n",
    "output1_trans_group['transaction_count']=np.where(output1_trans_group['transaction_count']>10,\"10+\",output1_trans_group['transaction_count'])\n",
    "output1_trans_group=output1_trans_group.groupby(['transaction_count'])['customer_id_hashed'].agg(unique_list_len).to_frame().reset_index()\n",
    "logging.info(\"Done of groupby unique id\")\n",
    "\n",
    "output1_trans_group=output1_trans_group.rename(columns={\"transaction_count\":\"transaction_group\",\"customer_id_hashed\":\"count_unique_ids\"})\n",
    "output1_trans_group['transaction_group']=output1_trans_group['transaction_group'].astype(str)\n",
    "output1_trans_group=pd.DataFrame({\"transaction_group\":\"0\",\"count_unique_ids\":len(rewards_set_0)},index=[0]).append(output1_trans_group)\n",
    "\n",
    "logging.info(\"Done of 1st task\"+str(datetime.datetime.now()))\n",
    "output1_trans_group=output1_trans_group[['transaction_group','count_unique_ids']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output1_trans_group_new_trans=pd.merge(sales_from_SP,id_transa_group,on=\"customer_id_hashed\",how=\"outer\")\n",
    "output1_trans_group_new_trans=output1_trans_group_new_trans.groupby(['transaction_group'])['customer_id_hashed'].count().to_frame().reset_index()\n",
    "output1_trans_group_new_trans=output1_trans_group_new_trans.rename(columns={\"customer_id_hashed\":\"total_transactions\"})\n",
    "\n",
    "output1_trans_group=pd.merge(output1_trans_group,output1_trans_group_new_trans,on=\"transaction_group\",how=\"outer\")\n",
    "output1_trans_group=output1_trans_group.fillna(0)\n",
    "#\n",
    "\n",
    "output1_trans_group.to_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/Rewards_Members_Distritbution_Analysis/output1_Sep21.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "output2_unique_id_by_store=pd.DataFrame({\"store\":list(inclusion_store_list_set)},index=list(inclusion_store_list_set))\n",
    "for i in range(10):\n",
    "    k=i+1\n",
    "    df=sales_from_SP[sales_from_SP['customer_id_hashed'].isin(locals()['rewards_set_'+str(k)])]\n",
    "    df=df.groupby(['location_id'])['customer_id_hashed'].agg(unique_list_len).to_frame().reset_index()\n",
    "    df=df.rename(columns={\"location_id\":\"store\",\"customer_id_hashed\":\"id_counts_transacted_\"+str(k)})\n",
    "    output2_unique_id_by_store=pd.merge(output2_unique_id_by_store,df,on=\"store\",how=\"left\")\n",
    "    logging.info(\"Done of 2nd task, transaction freq \"+str(k)+\" \"+str(datetime.datetime.now()))\n",
    "    del locals()['rewards_set_'+str(k)]\n",
    "    \n",
    "#10+\n",
    "df=sales_from_SP[sales_from_SP['customer_id_hashed'].isin(rewards_set_10_Plus)]\n",
    "df=df.groupby(['location_id'])['customer_id_hashed'].agg(unique_list_len).to_frame().reset_index()\n",
    "df=df.rename(columns={\"location_id\":\"store\",\"customer_id_hashed\":\"id_counts_transacted_10+\"})\n",
    "output2_unique_id_by_store=pd.merge(output2_unique_id_by_store,df,on=\"store\",how=\"left\")\n",
    "\n",
    "logging.info(\"Done of 2nd task \"+str(datetime.datetime.now()))\n",
    "output2_unique_id_by_store['store']=output2_unique_id_by_store['store'].astype(int)\n",
    "output2_unique_id_by_store=output2_unique_id_by_store.sort_values(\"store\",ascending=True)\n",
    "output2_unique_id_by_store=output2_unique_id_by_store.fillna(0)\n",
    "output2_unique_id_by_store.to_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/Rewards_Members_Distritbution_Analysis/output2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1446, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2_unique_id_by_store.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2018-09-23 20:33:51.498259\n",
      "1 2018-09-23 20:46:26.777559\n",
      "2 2018-09-23 20:58:59.713059\n",
      "3 2018-09-23 21:12:05.981277\n",
      "4 2018-09-23 21:24:47.484399\n",
      "5 2018-09-23 21:37:21.946706\n",
      "6 2018-09-23 21:49:51.846214\n",
      "7 2018-09-23 22:02:25.110124\n",
      "8 2018-09-23 22:14:56.216434\n",
      "9 2018-09-23 22:27:28.015769\n",
      "10 2018-09-23 22:39:47.365439\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Start of taks3 \"+str(datetime.datetime.now()))\n",
    "def id_set(x):\n",
    "    y=set(x)\n",
    "    return y\n",
    "output3_unique_id_by_store=sales_from_SP.groupby(['customer_id_hashed'])['location_id'].agg(unique_list_len).to_frame().reset_index()\n",
    "output3_unique_id_by_store['location_id']=np.where(output3_unique_id_by_store['location_id']>10,\"10+\",output3_unique_id_by_store['location_id'])\n",
    "output3_unique_id_by_store['location_id']=output3_unique_id_by_store['location_id'].astype(str)\n",
    "\n",
    "output3_unique_id_by_store=output3_unique_id_by_store.groupby(['location_id'])['customer_id_hashed'].agg(id_set).to_frame().reset_index()\n",
    "output3_unique_id_by_store=output3_unique_id_by_store.rename(columns={\"location_id\":\"went_uniq_store_group\",\"customer_id_hashed\":\"id_list\"})\n",
    "output3_unique_id_by_store['ID_counts']=output3_unique_id_by_store['id_list'].apply(lambda x: len(x))\n",
    "\n",
    "transaction_id=pd.DataFrame()\n",
    "for i in range(len(output3_unique_id_by_store)):\n",
    "    store_group=output3_unique_id_by_store['went_uniq_store_group'][i]\n",
    "    id_set=output3_unique_id_by_store['id_list'][i]\n",
    "    len_trans=len(sales_from_SP[sales_from_SP['customer_id_hashed'].isin(id_set)])\n",
    "    df=pd.DataFrame({\"went_uniq_store_group\":store_group,\"trnasactions_count\":len_trans},index=[0])\n",
    "    transaction_id=transaction_id.append(df)\n",
    "    print(i,datetime.datetime.now())\n",
    "    \n",
    "del output3_unique_id_by_store['id_list']\n",
    "\n",
    "output3_unique_id_by_store=pd.merge(output3_unique_id_by_store,transaction_id,on=\"went_uniq_store_group\",how=\"left\")\n",
    "logging.info(\"Done of taks3 \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Check point 1 \"+str(datetime.datetime.now()))\n",
    "new_2_stores=sales_from_SP.groupby(['customer_id_hashed'])['location_id'].agg(unique_list_len).to_frame().reset_index()\n",
    "new_2_stores=new_2_stores[new_2_stores['location_id']==2]\n",
    "id_list_2_stores=set(new_2_stores['customer_id_hashed'].tolist())\n",
    "df_2_stores_sales=sales_from_SP[sales_from_SP['customer_id_hashed'].isin(id_list_2_stores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Check point 2 \"+str(datetime.datetime.now()))\n",
    "\n",
    "sales_2_stores_trans=df_2_stores_sales.groupby(['customer_id_hashed','location_id'])['total_transaction_amt'].count().to_frame().reset_index()\n",
    "sales_2_stores_trans=sales_2_stores_trans.rename(columns={\"total_transaction_amt\":\"transaction\"})\n",
    "sales_2_stores_sales=df_2_stores_sales.groupby(['customer_id_hashed','location_id'])['total_transaction_amt'].sum().to_frame().reset_index()\n",
    "sales_2_stores_trans=sales_2_stores_trans.rename(columns={\"total_transaction_amt\":\"sales\"})\n",
    "\n",
    "sales_2_stores=pd.merge(sales_2_stores_sales,sales_2_stores_trans,on=['customer_id_hashed','location_id'],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Check point 3 \"+str(datetime.datetime.now()))\n",
    "\n",
    "df_2_stores_sales['location_id']=df_2_stores_sales['location_id'].astype(int)\n",
    "id_count_2_stores=df_2_stores_sales.groupby(['customer_id_hashed'])['location_id'].apply(set).to_frame().reset_index()\n",
    "id_count_2_stores['store_list']=id_count_2_stores['location_id'].apply(lambda x: str(sorted(list(x))))\n",
    "\n",
    "id_count_2_stores=id_count_2_stores.rename(columns={\"location_id\":\"location_set\"})\n",
    "id_count_2_stores['store_1']=id_count_2_stores['location_set'].apply(lambda x: str(sorted(list(x))[0]))\n",
    "id_count_2_stores['store_2']=id_count_2_stores['location_set'].apply(lambda x: str(sorted(list(x))[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Check point 4 \"+str(datetime.datetime.now()))\n",
    "\n",
    "sales_2_stores=sales_2_stores.rename(columns={\"location_id\":\"store_1\",'total_transaction_amt':'sales_store_1','transaction':'trans_store_1'})\n",
    "output_2_stores=pd.merge(id_count_2_stores,sales_2_stores,on=['customer_id_hashed','store_1'],how=\"left\")\n",
    "sales_2_stores=sales_2_stores.rename(columns={\"store_1\":\"store_2\",'sales_store_1':'sales_store_2','trans_store_1':'trans_store_2'})\n",
    "output_2_stores=pd.merge(output_2_stores,sales_2_stores,on=['customer_id_hashed','store_2'],how=\"left\")\n",
    "sales_2_stores=sales_2_stores.rename(columns={\"store_2\":\"location_id\",'sales_store_2':'total_transaction_amt','trans_store_2':'transaction'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Check point 5 \"+str(datetime.datetime.now()))\n",
    "\n",
    "func_2_stores={'customer_id_hashed': unique_list_len, 'sales_store_1':['sum'], 'sales_store_2':['sum'],\n",
    "              'trans_store_1':['sum'], 'trans_store_2':['sum']}\n",
    "output_2_stores=output_2_stores.groupby(['store_list','store_1','store_2'])['customer_id_hashed','sales_store_1','sales_store_2','trans_store_1','trans_store_2'].agg(func_2_stores).reset_index()\n",
    "output_2_stores.columns=output_2_stores.columns.get_level_values(0)\n",
    "output_2_stores=output_2_stores.rename(columns={\"customer_id_hashed\":\"unique_id_count\"})\n",
    "\n",
    "output_2_stores['total_sales']=output_2_stores['sales_store_1']+output_2_stores['sales_store_2']\n",
    "output_2_stores['total_trans']=output_2_stores['trans_store_1']+output_2_stores['trans_store_2']\n",
    "\n",
    "output_2_stores['sales_ratio_store_1']=output_2_stores['sales_store_1']/output_2_stores['total_sales']\n",
    "output_2_stores['trans_ratio_store_1']=output_2_stores['trans_store_1']/output_2_stores['total_trans']\n",
    "\n",
    "output_2_stores['higher_ratio_store_sales']=np.where(output_2_stores['sales_ratio_store_1']>=0.5,output_2_stores['sales_ratio_store_1'],(1-output_2_stores['sales_ratio_store_1']))\n",
    "output_2_stores['higher_ratio_store_trans']=np.where(output_2_stores['sales_ratio_store_1']>=0.5,output_2_stores['trans_ratio_store_1'],(1-output_2_stores['trans_ratio_store_1']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_lat_lng=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStores20180901-133640-935.txt\",dtype=str,sep=\"|\")\n",
    "store_lat_lng=store_lat_lng[['location_id','latitude_meas','longitude_meas']]\n",
    "\n",
    "store_lat_lng_2=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStores20180801-133641-576.txt\",dtype=str,sep=\"|\")\n",
    "store_lat_lng_2=store_lat_lng_2[['location_id','latitude_meas','longitude_meas']]\n",
    "store_lat_lng_2=store_lat_lng_2[~store_lat_lng_2['location_id'].isin(store_lat_lng['location_id'].tolist())]\n",
    "store_lat_lng=store_lat_lng.append(store_lat_lng_2)\n",
    "\n",
    "store_lat_lng_2=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStores_20180703.txt\",dtype=str,sep=\"|\")\n",
    "store_lat_lng_2=store_lat_lng_2[['location_id','latitude_meas','longitude_meas']]\n",
    "store_lat_lng_2=store_lat_lng_2[~store_lat_lng_2['location_id'].isin(store_lat_lng['location_id'].tolist())]\n",
    "store_lat_lng=store_lat_lng.append(store_lat_lng_2)\n",
    "\n",
    "store_lat_lng_2=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStoreList_Nov15.txt\",dtype=str,sep=\"|\")\n",
    "store_lat_lng_2=store_lat_lng_2[['location_id','latitude_meas','longitude_meas']]\n",
    "store_lat_lng_2=store_lat_lng_2[~store_lat_lng_2['location_id'].isin(store_lat_lng['location_id'].tolist())]\n",
    "store_lat_lng=store_lat_lng.append(store_lat_lng_2)\n",
    "\n",
    "store_lat_lng_2=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStoresList_0913.txt\",dtype=str,sep=\"|\")\n",
    "store_lat_lng_2=store_lat_lng_2[['location_id','latitude_meas','longitude_meas']]\n",
    "store_lat_lng_2=store_lat_lng_2[~store_lat_lng_2['location_id'].isin(store_lat_lng['location_id'].tolist())]\n",
    "store_lat_lng=store_lat_lng.append(store_lat_lng_2)\n",
    "\n",
    "store_lat_lng['latitude_meas']=store_lat_lng['latitude_meas'].astype(float)\n",
    "store_lat_lng['longitude_meas']=store_lat_lng['longitude_meas'].astype(float)\n",
    "store_with_lat_long=store_lat_lng['location_id'].unique().tolist()\n",
    "\n",
    "store_lat_dict=store_lat_lng.set_index(\"location_id\").to_dict()['latitude_meas']\n",
    "store_lng_dict=store_lat_lng.set_index(\"location_id\").to_dict()['longitude_meas']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Check point distance \"+str(datetime.datetime.now()))\n",
    "output_2_stores=output_2_stores.reset_index()\n",
    "del output_2_stores['index']\n",
    "output_2_stores['distance']=np.nan\n",
    "output_2_stores['store_list_dist']=output_2_stores['store_1'].apply(lambda x: [x])+output_2_stores['store_2'].apply(lambda x: [x])\n",
    "\n",
    "'''\n",
    "# Too slow\n",
    "for i in range(len(output_2_stores)):\n",
    "    store_1=str(output_2_stores['store_1'][i])\n",
    "    store_2=str(output_2_stores['store_2'][i])\n",
    "    if ((store_1 not in store_with_lat_long) | (store_2 not in store_with_lat_long)):\n",
    "        dist=np.nan\n",
    "    else:\n",
    "        store_1_center=(store_lat_dict[store_1],store_lng_dict[store_1])\n",
    "        store_2_center=(store_lat_dict[store_2],store_lng_dict[store_2])\n",
    "        dist=haversine(store_1_center,store_2_center,miles=True)\n",
    "    output_2_stores['distance'][i]=dist\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_dist_from_store_list(x):\n",
    "    store_1=x[0]\n",
    "    store_2=x[1]\n",
    "    if ((store_1 not in store_with_lat_long) | (store_2 not in store_with_lat_long)):\n",
    "        dist=np.nan\n",
    "    else:\n",
    "        store_1_center=(store_lat_dict[store_1],store_lng_dict[store_1])\n",
    "        store_2_center=(store_lat_dict[store_2],store_lng_dict[store_2])\n",
    "        dist=haversine(store_1_center,store_2_center,miles=True)\n",
    "    return dist\n",
    "        \n",
    "output_2_stores['distance']=output_2_stores['store_list_dist'].apply(lambda x: calculate_dist_from_store_list(x))\n",
    "del output_2_stores['store_list_dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Check point 6 \"+str(datetime.datetime.now()))\n",
    "\n",
    "consumption_output=sales_from_SP.groupby(['location_id'])['customer_id_hashed'].agg(unique_list_len).to_frame().reset_index()\n",
    "consumption_output=consumption_output.sort_values(['location_id'])\n",
    "\n",
    "output_master=output_master.rename(columns={\"sign_up_location\":\"store\",\"customer_id_hashed\":\"signup_id count\"})\n",
    "consumption_output=consumption_output.rename(columns={\"location_id\":\"store\",\"customer_id_hashed\":\"consumption_id count\"})\n",
    "Merge_by_store=pd.merge(output_master,consumption_output,on=\"store\",how=\"left\")\n",
    "Merge_by_store['store']=Merge_by_store['store'].astype(int)\n",
    "Merge_by_store=Merge_by_store.sort_values('store')\n",
    "\n",
    "DMA=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",dtype=str,skiprows=1,usecols=[0,2])\n",
    "DMA.columns=['zip_cd','DMA']\n",
    "DMA=DMA.drop_duplicates(\"zip_cd\")\n",
    "store_list['store']=store_list['store'].astype(int)\n",
    "Merge_by_store=pd.merge(Merge_by_store,store_list,on=\"store\",how=\"outer\")\n",
    "Merge_by_store=pd.merge(Merge_by_store,DMA,on=\"zip_cd\",how=\"left\")\n",
    "Merge_by_store=Merge_by_store[['store','address_line_1','address_line_2','city_nm','state_nm','zip_cd','DMA','signup_id count','consumption_id count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputfolder=\"/home/jian/Projects/Big_Lots/Loyal_members/Rewards_Members_Distritbution_Analysis/output/\"\n",
    "writer=pd.ExcelWriter(outputfolder+\"BL_unique_id_by_store_\"+str(datetime.datetime.now().date())+\".xlsx\",engine='xlsxwriter')\n",
    "output1_trans_group.to_excel(writer,\"output1_trans_group\",index=False)\n",
    "output2_unique_id_by_store.to_excel(writer,\"output2_unique_id_by_store\",index=False)\n",
    "output3_unique_id_by_store.to_excel(writer,\"output3_id_transactions\",index=False)\n",
    "output_2_stores.to_excel(writer,\"ids_went_2_stores\",index=False)\n",
    "\n",
    "Merge_by_store.to_excel(writer,\"distribution_table\",index=False)\n",
    "output_master.to_excel(writer,\"register_id_by_location\",index=False)\n",
    "consumption_output.to_excel(writer,\"purchase_id_by_location\",index=False)\n",
    "purchase_dates_df.to_excel(writer,\"purchase_date_range\",index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
