{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "today_str=str(datetime.datetime.now().date())\n",
    "\n",
    "writer_floder=\"/home/jian/Projects/Big_Lots/Weather/Forecast_Validation/\"+today_str+\"/\"\n",
    "try:\n",
    "    os.stat(writer_floder)\n",
    "except:\n",
    "    os.mkdir(writer_floder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forecast_file_list=glob.glob(\"/home/jian/Projects/Big_Lots/Weather/Json_data/forecast/\"+\"*.json\")\n",
    "\n",
    "actual_file_list=glob.glob(\"/home/jian/Projects/Big_Lots/Weather/Json_data/daily/\"+\"*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forecast_file_Q1_df=pd.DataFrame()\n",
    "Saturday_actual_file_Q1_df=pd.DataFrame()\n",
    "Sunday_actual_file_Q1_df=pd.DataFrame()\n",
    "i=1\n",
    "for file in forecast_file_list:\n",
    "    location=file\n",
    "    date=datetime.datetime.strptime(file.split(\"/\")[len(file.split(\"/\"))-1][0:10],\"%Y-%m-%d\").date()\n",
    "    \n",
    "    if (date>=datetime.date(2018,2,4)) & (date<=datetime.date(2018,5,5)) & (date.weekday()==2): #Wednesday only\n",
    "        forecast_file_Q1_df=forecast_file_Q1_df.append(pd.DataFrame({\"Date_Monday\":date,'Date_Saturday':date+datetime.timedelta(days=3),\"forecast_file\":location},index=[i]))\n",
    "        i=i+1\n",
    "i=1\n",
    "for file in actual_file_list:\n",
    "    location=file\n",
    "    date=datetime.datetime.strptime(file.split(\"/\")[len(file.split(\"/\"))-1][0:10],\"%Y-%m-%d\").date()\n",
    "    saturday_date=date+datetime.timedelta(days=-1)\n",
    "    if (date>=datetime.date(2018,2,4)) & (date<=datetime.date(2018,5,5)) & (date.weekday()==5): #Saturday only\n",
    "        Saturday_actual_file_Q1_df=Saturday_actual_file_Q1_df.append(pd.DataFrame({\"Date_Saturday\":date,\"actual_file_Saturday\":location},index=[i]))\n",
    "        i=i+1\n",
    "        \n",
    "    if (date>=datetime.date(2018,2,4)) & (date<=datetime.date(2018,5,6)) & (date.weekday()==6): #Sunday only\n",
    "        Sunday_actual_file_Q1_df=Sunday_actual_file_Q1_df.append(pd.DataFrame({\"Date_Saturday\":saturday_date,\"actual_file_Sunday\":location},index=[i]))\n",
    "        i=i+1\n",
    "all_3_files_Q1=pd.merge(forecast_file_Q1_df,Saturday_actual_file_Q1_df,on=\"Date_Saturday\",how=\"inner\")\n",
    "all_3_files_Q1=pd.merge(all_3_files_Q1,Sunday_actual_file_Q1_df,on=\"Date_Saturday\",how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inclusion_stores=pd.read_excel(\"/home/jian/Projects/Big_Lots/Q1_Post/BL_Sales YoY_JL_20180618.xlsx\",sheetname=\"Inclusion Stores\",skiprows=1,dtype=str)\n",
    "store_zips=pd.read_excel(\"/home/jian/Projects/Big_Lots/Other_Input/all_store_DMA.xlsx\",dtype=str)[['location_id','zip']]\n",
    "store_zips['zip']=store_zips['zip'].apply(lambda x: x.zfill(5))\n",
    "inclusion_stores=pd.merge(inclusion_stores,store_zips,on=\"location_id\",how=\"left\")\n",
    "inclusion_stores=inclusion_stores[['location_id','zip']].rename(columns={\"zip\":\"zip_cd\"})\n",
    "inclusion_stores=inclusion_stores[inclusion_stores['location_id']!='1769']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80110 2018-04-21\n",
      "35806 2018-04-28\n"
     ]
    }
   ],
   "source": [
    "all_forecast_group_value=[]\n",
    "all_forecast_desc_value=[]\n",
    "\n",
    "all_actual_group_value=[]\n",
    "all_actual_desc_value=[]\n",
    "\n",
    "for i in range(len(all_3_files_Q1)):\n",
    "    json_actual_Saturday=json.load(open(all_3_files_Q1['actual_file_Saturday'][i],\"r\"))\n",
    "    json_actual_Sunday=json.load(open(all_3_files_Q1['actual_file_Sunday'][i],\"r\"))\n",
    "    json_forecast=json.load(open(all_3_files_Q1['forecast_file'][i],\"r\"))\n",
    "    \n",
    "    for zip_cd in inclusion_stores['zip_cd'].unique().tolist():\n",
    "        if (zip_cd in list(json_forecast.keys())) & (zip_cd in list(json_actual_Saturday.keys())) & (zip_cd in list(json_actual_Sunday.keys())):\n",
    "            weather_forecast_list=json_forecast[zip_cd]['list'][23]['weather']\n",
    "            weather_actual_list_Saturday=json_actual_Saturday[zip_cd]['weather']\n",
    "            weather_actual_list_Sunday=json_actual_Sunday[zip_cd]['weather']\n",
    "\n",
    "            for j in range(len(weather_forecast_list)):\n",
    "                weather_forecast_group=weather_forecast_list[j]['main']\n",
    "                # weather_forecast_desc=weather_forecast_list[j]['description']\n",
    "                all_forecast_group_value=list(set(all_forecast_group_value+[weather_forecast_group]))\n",
    "                # all_forecast_desc_value=list(set(all_forecast_desc_value+[weather_forecast_desc]))\n",
    "            \n",
    "            for j in range(len(weather_actual_list_Saturday)):    \n",
    "                weather_actual_group_Saturday=weather_actual_list_Saturday[j]['main']\n",
    "                # weather_actual_desc=weather_actual_list[j]['description']\n",
    "                all_actual_group_value=list(set(all_actual_group_value+[weather_actual_group_Saturday]))\n",
    "                # all_actual_desc_value=list(set(all_actual_desc_value+[weather_actual_desc]))\n",
    "                \n",
    "            for j in range(len(weather_actual_list_Sunday)):    \n",
    "                weather_actual_group_Sunday=weather_actual_list_Sunday[j]['main']\n",
    "                # weather_actual_desc=weather_actual_list[j]['description']\n",
    "                all_actual_group_value=list(set(all_actual_group_value+[weather_actual_group_Sunday]))\n",
    "                # all_actual_desc_value=list(set(all_actual_desc_value+[weather_actual_desc]))\n",
    "        else:\n",
    "            print(zip_cd,all_3_files_Q1['Date_Saturday'][i])\n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rain', 'Snow', 'Clouds', 'Clear']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_forecast_group_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_weight_rank=pd.read_excel(\"/home/jian/Projects/Big_Lots/Weather/Q1_Weather_Counts/Q1_inclusion_store_all_weather_type_ranked.xlsx\",sheetname=\"all_weather_group_list\")\n",
    "\n",
    "group_weight_rank['Severity']=group_weight_rank['Severity'].astype(int)\n",
    "group_weight_rank['Rank']=group_weight_rank['Rank'].astype(int)\n",
    "group_weight=group_weight_rank[['all_type_group','Severity']]\n",
    "group_weight_dict=group_weight[['all_type_group', 'Severity']].set_index('all_type_group').T.to_dict()\n",
    "\n",
    "group_rank=group_weight_rank[['all_type_group','Rank']]\n",
    "group_rank_dict=group_rank[['all_type_group', 'Rank']].set_index('all_type_group').T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80110 2018-04-21\n",
      "35806 2018-04-28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\noutput_validation['Selected_Weekend_Weather']=np.where() #To be added on Monday\\noutput_validation['Selected_Weekend_Rank']=np.where()\\noutput_validation['Selected_Weekend_Severity']=np.where()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_validation=pd.DataFrame()\n",
    "\n",
    "index_num=1\n",
    "for i in range(len(all_3_files_Q1)):\n",
    "    json_actual_Saturday=json.load(open(all_3_files_Q1['actual_file_Saturday'][i],\"r\"))\n",
    "    json_actual_Sunday=json.load(open(all_3_files_Q1['actual_file_Sunday'][i],\"r\"))\n",
    "    json_forecast=json.load(open(all_3_files_Q1['forecast_file'][i],\"r\"))\n",
    "    \n",
    "    date=all_3_files_Q1['Date_Saturday'][i]\n",
    "    for zip_cd in inclusion_stores['zip_cd'].unique().tolist():\n",
    "\n",
    "        if (zip_cd in list(json_forecast.keys())) & (zip_cd in list(json_actual_Saturday.keys()))& (zip_cd in list(json_actual_Sunday.keys())):\n",
    "            forecast_time=datetime.datetime.fromtimestamp(json_forecast[zip_cd]['list'][23]['dt']) \n",
    "            actual_time_Saturday=datetime.datetime.fromtimestamp(json_actual_Saturday[zip_cd]['dt']) \n",
    "            actual_time_Sunday=datetime.datetime.fromtimestamp(json_actual_Sunday[zip_cd]['dt']) \n",
    "            weather_forecast_list=json_forecast[zip_cd]['list'][23]['weather']\n",
    "            weather_actual_list_Saturday=json_actual_Saturday[zip_cd]['weather']\n",
    "            weather_actual_list_Sunday=json_actual_Sunday[zip_cd]['weather']\n",
    "            \n",
    "            all_forecast_group_value_zip=[]\n",
    "            #all_forecast_desc_value_zip=[]\n",
    "            all_actual_group_value_zip_Saturday=[]\n",
    "            all_actual_group_value_zip_Sunday=[]\n",
    "            #all_actual_desc_value_zip_Sautrday=[]\n",
    "            #all_actual_desc_value_zip_Sunday=[]\n",
    "            \n",
    "            for j in range(len(weather_forecast_list)):\n",
    "                weather_forecast_group=weather_forecast_list[j]['main']\n",
    "                #weather_forecast_desc=weather_forecast_list[j]['description']\n",
    "                all_forecast_group_value_zip=list(set(all_forecast_group_value_zip+[weather_forecast_group]))\n",
    "                #all_forecast_desc_value_zip=list(set(all_forecast_desc_value_zip+[weather_forecast_desc]))\n",
    "            \n",
    "            for j in range(len(weather_actual_list_Saturday)):    \n",
    "                weather_actual_group=weather_actual_list_Saturday[j]['main']\n",
    "                #weather_actual_desc=weather_actual_list[j]['description']\n",
    "                all_actual_group_value_zip_Saturday=list(set(all_actual_group_value_zip_Saturday+[weather_actual_group]))\n",
    "                #all_actual_desc_value_zip=list(set(all_actual_desc_value_zip+[weather_actual_desc]))\n",
    "            for j in range(len(weather_actual_list_Sunday)):    \n",
    "                weather_actual_group=weather_actual_list_Sunday[j]['main']\n",
    "                #weather_actual_desc=weather_actual_list[j]['description']\n",
    "                all_actual_group_value_zip_Sunday=list(set(all_actual_group_value_zip_Sunday+[weather_actual_group]))\n",
    "                #all_actual_desc_value_zip=list(set(all_actual_desc_value_zip+[weather_actual_desc]))\n",
    "            \n",
    "            all_forecast_group_severity_zip=[]\n",
    "            all_actual_group_severity_zip_Saturday=[]\n",
    "            all_actual_group_severity_zip_Sunday=[]\n",
    "            \n",
    "            all_forecast_group_rank_zip=[]\n",
    "            all_actual_group_rank_zip_Saturday=[]\n",
    "            all_actual_group_rank_zip_Sunday=[]\n",
    "            \n",
    "            selected_havest_forecast_group_value_zip=np.nan\n",
    "            selected_havest_actual_group_value_zip_Saturday=np.nan\n",
    "            selected_havest_actual_group_value_zip_Sunday=np.nan\n",
    "            \n",
    "            \n",
    "            selected_havest_forecast_rank_value_zip=np.nan\n",
    "            selected_havest_actual_rank_value_zip_Saturday=np.nan\n",
    "            selected_havest_actual_rank_value_zip_Sunday=np.nan\n",
    "            \n",
    "            \n",
    "            for k in range(len(all_forecast_group_value_zip)):\n",
    "                forecast_severity_zip=group_weight_dict[all_forecast_group_value_zip[k]]['Severity']\n",
    "                all_forecast_group_severity_zip=list(set(all_forecast_group_severity_zip+[forecast_severity_zip]))\n",
    "                \n",
    "                forecast_rank_zip=group_rank_dict[all_forecast_group_value_zip[k]]['Rank']\n",
    "                all_forecast_group_rank_zip=list(set(all_forecast_group_rank_zip+[forecast_rank_zip]))\n",
    "                \n",
    "                if k==0:\n",
    "                    selected_havest_forecast_group_value_zip=all_forecast_group_value_zip[0]\n",
    "                    \n",
    "                else:\n",
    "                    if group_rank_dict[all_forecast_group_value_zip[k]]['Rank']>group_rank_dict[selected_havest_forecast_group_value_zip]['Rank']:\n",
    "                        selected_havest_forecast_group_value_zip=all_forecast_group_value_zip[k]\n",
    "                    \n",
    "                \n",
    "                \n",
    "            for k in range(len(all_actual_group_value_zip_Saturday)):\n",
    "                actual_severity_zip=group_weight_dict[all_actual_group_value_zip_Saturday[k]]['Severity']\n",
    "                all_actual_group_severity_zip_Saturday=list(set(all_actual_group_severity_zip_Saturday+[actual_severity_zip]))\n",
    "                \n",
    "                actual_rank_zip=group_rank_dict[all_actual_group_value_zip_Saturday[k]]['Rank']\n",
    "                all_actual_group_rank_zip_Saturday=list(set(all_actual_group_rank_zip_Saturday+[actual_rank_zip]))\n",
    "                if k==0:\n",
    "                    selected_havest_actual_group_value_zip_Saturday=all_actual_group_value_zip_Saturday[0]\n",
    "                else:\n",
    "                    if group_rank_dict[all_actual_group_value_zip_Saturday[k]]['Rank']>group_rank_dict[selected_havest_actual_group_value_zip_Saturday]['Rank']:\n",
    "                        selected_havest_actual_group_value_zip_Saturday=all_actual_group_value_zip_Saturday[k]\n",
    "                        \n",
    "                        \n",
    "            for k in range(len(all_actual_group_value_zip_Sunday)):\n",
    "                actual_severity_zip=group_weight_dict[all_actual_group_value_zip_Sunday[k]]['Severity']\n",
    "                all_actual_group_severity_zip_Sunday=list(set(all_actual_group_severity_zip_Sunday+[actual_severity_zip]))\n",
    "                \n",
    "                actual_rank_zip=group_rank_dict[all_actual_group_value_zip_Sunday[k]]['Rank']\n",
    "                all_actual_group_rank_zip_Sunday=list(set(all_actual_group_rank_zip_Sunday+[actual_rank_zip]))\n",
    "                if k==0:\n",
    "                    selected_havest_actual_group_value_zip_Sunday=all_actual_group_value_zip_Sunday[0]\n",
    "                else:\n",
    "                    if group_rank_dict[all_actual_group_value_zip_Sunday[k]]['Rank']>group_rank_dict[selected_havest_actual_group_value_zip_Sunday]['Rank']:\n",
    "                        selected_havest_actual_group_value_zip_Sunday=all_actual_group_value_zip_Sunday[k]\n",
    "                        \n",
    "            \n",
    "            forecast_max_severity_zip=max(all_forecast_group_severity_zip)\n",
    "            actual_max_severity_zip_Saturday=max(all_actual_group_severity_zip_Saturday)\n",
    "            actual_max_severity_zip_Sunday=max(all_actual_group_severity_zip_Sunday)\n",
    "            \n",
    "            forecast_max_rank_zip=max(all_forecast_group_rank_zip)\n",
    "            actual_max_rank_zip_Saturday=max(all_actual_group_rank_zip_Saturday)\n",
    "            actual_max_rank_zip_Sunday=max(all_actual_group_rank_zip_Sunday)\n",
    "            \n",
    "            df_app=pd.DataFrame({\"zip_cd\":zip_cd,\"Saturday\":date,\"Forecast_Time\":forecast_time,\"Actual_Time_Saturday\":actual_time_Saturday,\"Actual_Time_Sunday\":actual_time_Sunday,\n",
    "                                 \"Forecast_Severity\":forecast_max_severity_zip,\"Actual_Severity_Saturday\":actual_max_severity_zip_Saturday,\"Actual_Severity_Sunday\":actual_max_severity_zip_Sunday,\n",
    "                                \"Forecast_Weather_Type\":selected_havest_forecast_group_value_zip,\"Actual_Weather_Type_Saturday\":selected_havest_actual_group_value_zip_Saturday,\"Actual_Weather_Type_Sunday\":selected_havest_actual_group_value_zip_Sunday,\n",
    "                                \"Forecast_Rank\":forecast_max_rank_zip,\"Actual_Rank_Saturday\":actual_max_rank_zip_Saturday,\"Actual_Rank_Sunday\":actual_max_rank_zip_Sunday},index=[index_num])\n",
    "            index_num=index_num+1\n",
    "            output_validation=output_validation.append(df_app)\n",
    "        else:\n",
    "            print(zip_cd,all_3_files_Q1['Date_Saturday'][i])\n",
    "            \n",
    "output_validation=output_validation[['zip_cd','Saturday','Forecast_Time','Actual_Time_Saturday','Actual_Time_Sunday','Forecast_Weather_Type','Actual_Weather_Type_Saturday','Actual_Weather_Type_Sunday',\n",
    "                                     'Forecast_Severity','Actual_Severity_Saturday','Actual_Severity_Sunday','Forecast_Rank','Actual_Rank_Saturday','Actual_Rank_Sunday']]\n",
    "'''\n",
    "output_validation['Selected_Weekend_Weather']=np.where() #To be added on Monday\n",
    "output_validation['Selected_Weekend_Rank']=np.where()\n",
    "output_validation['Selected_Weekend_Severity']=np.where()\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "temp_Weekend_type=output_validation[['zip_cd','Saturday','Actual_Weather_Type_Saturday','Actual_Weather_Type_Sunday']]\n",
    "temp_Weekend_type=temp_Weekend_type.drop_duplicates(['zip_cd','Saturday'])\n",
    "temp_Weekend_type=temp_Weekend_type.reset_index()\n",
    "del temp_Weekend_type['index']\n",
    "temp_Weekend_type['Selected_Weekend_Weather']=np.nan\n",
    "for i in range(len(temp_Weekend_type)):\n",
    "    if group_rank_dict[temp_Weekend_type['Actual_Weather_Type_Sunday'][i]]['Rank'] > group_rank_dict[temp_Weekend_type['Actual_Weather_Type_Saturday'][i]]['Rank']:\n",
    "        temp_Weekend_type['Selected_Weekend_Weather'][i]=temp_Weekend_type['Actual_Weather_Type_Sunday'][i]\n",
    "    else:\n",
    "        temp_Weekend_type['Selected_Weekend_Weather'][i]=temp_Weekend_type['Actual_Weather_Type_Saturday'][i]\n",
    "del temp_Weekend_type['Actual_Weather_Type_Saturday']\n",
    "del temp_Weekend_type['Actual_Weather_Type_Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_validation=pd.merge(output_validation,temp_Weekend_type,on=['zip_cd','Saturday'],how=\"left\")\n",
    "output_validation['Selected_Weekend_Rank']=output_validation[['Actual_Rank_Saturday','Actual_Rank_Sunday']].max(axis=1)\n",
    "output_validation['Selected_Weekend_Severity']=output_validation[['Actual_Severity_Saturday','Actual_Severity_Sunday']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_validation['Diff_Severity']=output_validation['Selected_Weekend_Severity']-output_validation['Forecast_Severity']\n",
    "output_validation=pd.merge(output_validation,inclusion_stores,on=\"zip_cd\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales=pd.read_csv(\"/home/jian/BiglotsCode/outputs/combined_sales_long_2018-07-07.csv\",dtype=str)\n",
    "sales['week_end_date']=sales['week_end_date'].apply(lambda x:datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "sales['sales']=sales['sales'].astype(float)\n",
    "sales_2018=sales[(sales['week_end_date']>=datetime.date(2018,1,1)) & (sales['week_end_date']<=datetime.date(2018,5,31))]\n",
    "sales_2018=sales_2018[['location_id','week_end_date','sales']]\n",
    "sales_2018=sales_2018.rename(columns={\"week_end_date\":\"Saturday\",\"sales\":\"Sales_2018\"})\n",
    "sales_2017=sales[(sales['week_end_date']>=datetime.date(2017,1,1)) & (sales['week_end_date']<=datetime.date(2017,5,31))]\n",
    "sales_2017=sales_2017[['location_id','week_end_date','sales']]\n",
    "sales_2017=sales_2017.rename(columns={\"sales\":\"Sales_2017\"})\n",
    "sales_2017['Saturday']=sales_2017['week_end_date'].apply(lambda x: x+datetime.timedelta(days=52*7))\n",
    "sales_2017=sales_2017[['location_id','Saturday','Sales_2017']]\n",
    "\n",
    "sales_YoY=pd.merge(sales_2018,sales_2017,on=['location_id','Saturday'],how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_validation=pd.merge(output_validation,sales_YoY,on=['location_id','Saturday'],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_weeks=str(len(output_validation['Saturday'].unique()))\n",
    "\n",
    "writer=pd.ExcelWriter(writer_floder+\"BL_2018 Q1 Forecast 3 days validation Wed Sat_Sun_JL_\"+today_str+\".xlsx\",engine=\"xlsxwriter\")\n",
    "output_validation.to_excel(writer,\"all_\"+unique_weeks+\"_weeks\",index=False)\n",
    "for Saturday,group in output_validation.groupby(['Saturday']):\n",
    "    group.to_excel(writer,str(Saturday),index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
