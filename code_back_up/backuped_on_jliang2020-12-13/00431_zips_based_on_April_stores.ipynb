{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from haversine import haversine\n",
    "\n",
    "zip_centers=json.load(open(\"/home/jian/Docs/Geo_mapping/updated_zip_centers_JL_2019-05-23.json\",\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_list_Apr_2020=pd.read_csv(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20200401-135137-445.txt\",\n",
    "                               dtype=str,sep=\"|\")\n",
    "store_list_Apr_2020['latitude_meas']=store_list_Apr_2020['latitude_meas'].astype(float)\n",
    "store_list_Apr_2020['longitude_meas']=store_list_Apr_2020['longitude_meas'].astype(float)\n",
    "\n",
    "store_list_Apr_2020=store_list_Apr_2020[['location_id','open_dt','latitude_meas','longitude_meas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list_YG=pd.read_excel(\"./OnboardingKit BL 0427.xlsx\",dtype=str,sheet_name=\"List of stores\")\n",
    "store_list_YG=store_list_YG['Store'].tolist()\n",
    "\n",
    "list_missing_location_stores=[x for x in store_list_YG if x not in store_list_Apr_2020['location_id'].tolist()]\n",
    "len(list_missing_location_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5422', '5423', '5424'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x for x in list_missing_location_stores if list_missing_location_stores.count(x)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_num</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>location_id</th>\n",
       "      <th>address_line_1</th>\n",
       "      <th>address_line_2</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>city_nm</th>\n",
       "      <th>state_nm</th>\n",
       "      <th>latitude_meas</th>\n",
       "      <th>longitude_meas</th>\n",
       "      <th>DMA</th>\n",
       "      <th>CTY</th>\n",
       "      <th>all_trans_P_zips</th>\n",
       "      <th>all_trans_S_zips</th>\n",
       "      <th>zips_in_10</th>\n",
       "      <th>trans_P_zips_70_within_TA</th>\n",
       "      <th>trans_S_zips_70_within_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>multiple_1</td>\n",
       "      <td>1949</td>\n",
       "      <td>3178 LAVON DR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75040</td>\n",
       "      <td>GARLAND</td>\n",
       "      <td>TX</td>\n",
       "      <td>32.945015</td>\n",
       "      <td>-96.619194</td>\n",
       "      <td>{'DALLAS-FT. WORTH'}</td>\n",
       "      <td>{'DALLAS'}</td>\n",
       "      <td>['75040', '75044', '75048', '75098']</td>\n",
       "      <td>['75089', '75042', '75043', '75041', '75088', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['75040', '75098', '75044', '75048']</td>\n",
       "      <td>['75088', '75042', '75082', '75043', '75089', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>multiple_1</td>\n",
       "      <td>1255</td>\n",
       "      <td>1418 W MOORE AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75160</td>\n",
       "      <td>TERRELL</td>\n",
       "      <td>TX</td>\n",
       "      <td>32.738772</td>\n",
       "      <td>-96.299877</td>\n",
       "      <td>{'DALLAS-FT. WORTH'}</td>\n",
       "      <td>{'HUNT', 'KAUFMAN', 'ROCKWALL'}</td>\n",
       "      <td>['75160', '75126', '75161']</td>\n",
       "      <td>['75142', '75169', '75474', '75143', '75114', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['75126', '75161', '75160']</td>\n",
       "      <td>['75142', '75169', '75150', '75117', '75143', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TA_num     ta_name location_id    address_line_1 address_line_2 zip_cd  \\\n",
       "0      1  multiple_1        1949     3178 LAVON DR            NaN  75040   \n",
       "1      1  multiple_1        1255  1418 W MOORE AVE            NaN  75160   \n",
       "\n",
       "   city_nm state_nm latitude_meas longitude_meas                   DMA  \\\n",
       "0  GARLAND       TX     32.945015     -96.619194  {'DALLAS-FT. WORTH'}   \n",
       "1  TERRELL       TX     32.738772     -96.299877  {'DALLAS-FT. WORTH'}   \n",
       "\n",
       "                               CTY                      all_trans_P_zips  \\\n",
       "0                       {'DALLAS'}  ['75040', '75044', '75048', '75098']   \n",
       "1  {'HUNT', 'KAUFMAN', 'ROCKWALL'}           ['75160', '75126', '75161']   \n",
       "\n",
       "                                    all_trans_S_zips zips_in_10  \\\n",
       "0  ['75089', '75042', '75043', '75041', '75088', ...         []   \n",
       "1  ['75142', '75169', '75474', '75143', '75114', ...         []   \n",
       "\n",
       "              trans_P_zips_70_within_TA  \\\n",
       "0  ['75040', '75098', '75044', '75048']   \n",
       "1           ['75126', '75161', '75160']   \n",
       "\n",
       "                           trans_S_zips_70_within_TA  \n",
       "0  ['75088', '75042', '75082', '75043', '75089', ...  \n",
       "1  ['75142', '75169', '75150', '75117', '75143', ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TA_zips=pd.ExcelFile(\"/home/jian/Projects/Big_Lots/New_TA/TA_created_in_201906/final_output_20190718/BL_final_TA_updated_JL_2019-07-18.xlsx\")\n",
    "TA_zips=TA_zips.parse(\"view_by_store\",dtype=str)\n",
    "TA_zips.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporary=TA_zips[['location_id','trans_P_zips_70_within_TA','trans_S_zips_70_within_TA','zips_in_10']]\n",
    "df_zip_by_store=pd.DataFrame()\n",
    "\n",
    "for ind,row in df_temporary.iterrows():\n",
    "    location_id=row['location_id']\n",
    "    P_zips=eval(row['trans_P_zips_70_within_TA'])\n",
    "    S_zips=eval(row['trans_S_zips_70_within_TA'])\n",
    "    zip_10=eval(row['zips_in_10'])\n",
    "    \n",
    "\n",
    "    df_P=pd.DataFrame(zip([location_id]*len(P_zips),P_zips))\n",
    "    if len(df_P)>0:\n",
    "        df_P.columns=['location_id','zip_cd']\n",
    "        df_P['zip_type']=\"P\"\n",
    "        \n",
    "    df_S=pd.DataFrame(zip([location_id]*len(S_zips),S_zips))\n",
    "    if len(df_S)>0:\n",
    "        df_S.columns=['location_id','zip_cd']\n",
    "        df_S['zip_type']=\"S\"\n",
    "    \n",
    "    df_10=pd.DataFrame(zip([location_id]*len(zip_10),zip_10))\n",
    "    if len(df_10)>0:\n",
    "        df_10.columns=['location_id','zip_cd']\n",
    "        df_10['zip_type']=\"zip_10\"\n",
    "    \n",
    "    df_zip_by_store=df_zip_by_store.append(df_P).append(df_S).append(df_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_list_YG=pd.DataFrame({\"location_id\":store_list_YG},index=[0]*len(store_list_YG))\n",
    "df_store_list_YG=df_store_list_YG.drop_duplicates()\n",
    "df_store_list_YG['location_id']=df_store_list_YG['location_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'str'>], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_list_YG['location_id'].apply(type).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_list_YG_zips=pd.merge(df_store_list_YG,df_zip_by_store,on=\"location_id\",how=\"left\")\n",
    "df_store_list_YG_zips_existing=df_store_list_YG_zips[pd.notnull(df_store_list_YG_zips['zip_type'])]\n",
    "df_store_list_YG_zips_new=df_store_list_YG_zips[pd.isnull(df_store_list_YG_zips['zip_type'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>open_date</th>\n",
       "      <th>Google Coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4710</td>\n",
       "      <td>2020-04-02 00:00:00</td>\n",
       "      <td>37.5258742,-82.5685063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4712</td>\n",
       "      <td>2020-09-03 00:00:00</td>\n",
       "      <td>40.5684072,-122.3573712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id            open_date       Google Coordinates\n",
       "0        4710  2020-04-02 00:00:00   37.5258742,-82.5685063\n",
       "1        4712  2020-09-03 00:00:00  40.5684072,-122.3573712"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stores_not_open_yet=pd.read_excel(\"./missing_lat_lng_stores_Store List Report 04.23.20.xlsx\",\n",
    "                                     sheet_name=\"missing_stores\",dtype=str,skiprows=1)\n",
    "df_stores_not_open_yet=df_stores_not_open_yet[['location_id','open_date','Google Coordinates']]\n",
    "df_stores_not_open_yet.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_locations_1=store_list_Apr_2020[['location_id','open_dt','latitude_meas','longitude_meas']]\n",
    "df_store_locations_1['store_coor']=df_store_locations_1[['latitude_meas','longitude_meas']].values.tolist()\n",
    "df_store_locations_1=df_store_locations_1[['location_id','open_dt','store_coor']]\n",
    "\n",
    "df_store_locations_2=df_stores_not_open_yet.rename(columns={\"open_date\":\"open_dt\",\"Google Coordinates\":\"store_coor\"})\n",
    "df_store_locations_2['open_dt']=df_store_locations_2['open_dt'].apply(lambda x: str(x)[:10])\n",
    "df_store_locations_2['store_coor']=df_store_locations_2['store_coor'].apply(lambda x: eval(\"[\"+x+\"]\"))\n",
    "\n",
    "\n",
    "df_store_locations_new=df_store_locations_1.append(df_store_locations_2)\n",
    "df_store_locations_new['location_id']=df_store_locations_new['location_id'].apply(lambda x: str(int(x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_store_list_YG_zips_new['zip_cd']\n",
    "del df_store_list_YG_zips_new['zip_type']\n",
    "df_store_list_YG_zips_new=pd.merge(df_store_list_YG_zips_new,df_store_locations_new,on=\"location_id\",how=\"left\")\n",
    "\n",
    "dict_locations_new=df_store_list_YG_zips_new.set_index(\"location_id\").to_dict()['store_coor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_list_YG_zips_new=df_store_list_YG_zips_new.reset_index()\n",
    "del df_store_list_YG_zips_new['index']\n",
    "\n",
    "\n",
    "df_new_store_zips=pd.DataFrame()\n",
    "for i, row in df_store_list_YG_zips_new.iterrows():\n",
    "    store_num=row['location_id']\n",
    "    store_coor=row['store_coor']\n",
    "    list_store_zips=[]\n",
    "    for zip_cd, v in zip_centers.items():\n",
    "        dist=haversine(store_coor,v,unit=\"mi\")\n",
    "        if dist<=10:\n",
    "            list_store_zips.append(zip_cd)\n",
    "    df=pd.DataFrame({\"zip_cd\":list_store_zips},index=['zip_10']*len(list_store_zips))\n",
    "    df=df.reset_index().rename(columns={\"index\":\"zip_type\"})\n",
    "    df.insert(0,\"location_id\",[store_num]*len(list_store_zips))\n",
    "    df_new_store_zips=df_new_store_zips.append(df)\n",
    "    \n",
    "df_store_list_YG_zips_new=pd.merge(df_store_list_YG_zips_new,df_new_store_zips,on=\"location_id\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1348, 5), 1226, 56)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_list_YG_zips_new.shape,df_store_list_YG_zips_new['zip_cd'].nunique(),df_store_list_YG_zips_new['location_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_list_Apr_2020_copy=store_list_Apr_2020.copy()\n",
    "store_list_Apr_2020_copy['store_coor']=store_list_Apr_2020_copy[['latitude_meas','longitude_meas']].values.tolist()\n",
    "store_list_Apr_2020_copy=store_list_Apr_2020_copy[['location_id','open_dt','store_coor']]\n",
    "\n",
    "df_store_list_YG_zips_existing=pd.merge(df_store_list_YG_zips_existing,store_list_Apr_2020_copy,on=\"location_id\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "df_all_zips_for_YG_stores=df_store_list_YG_zips_existing.append(df_store_list_YG_zips_new)\n",
    "df_all_zips_for_YG_stores=df_all_zips_for_YG_stores[df_store_list_YG_zips_existing.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_zip=df_all_zips_for_YG_stores[['zip_cd','zip_type']].drop_duplicates()\n",
    "df_unique_zip=df_unique_zip.sort_values(['zip_cd','zip_type'],ascending=[True,True])\n",
    "df_unique_zip=df_unique_zip.drop_duplicates(\"zip_cd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_type</th>\n",
       "      <th>zip_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>4686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>7724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zip_10</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_type  zip_cd\n",
       "0        P    4686\n",
       "1        S    7724\n",
       "2   zip_10    1067"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_zip.groupby(\"zip_type\")['zip_cd'].count().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipcodes\n",
    "df_unique_zip=df_unique_zip.reset_index()\n",
    "del df_unique_zip['index']\n",
    "df_unique_zip.insert(1,\"city\",np.nan)\n",
    "df_unique_zip.insert(2,\"state\",np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_missing_zip=[]\n",
    "\n",
    "for i, row in df_unique_zip.iterrows():\n",
    "    zip_cd=row['zip_cd']\n",
    "    res=zipcodes.matching(zip_cd)\n",
    "    \n",
    "    if len(res)>=1:\n",
    "    \n",
    "        city=res[0]['city']\n",
    "        state=res[0]['state']\n",
    "\n",
    "\n",
    "        df_unique_zip.loc[i,\"city\"]=city\n",
    "        df_unique_zip.loc[i,\"state\"]=state\n",
    "    else:\n",
    "        list_missing_zip.append(zip_cd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29486', '84009', '86005', '97003', '97703']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_missing_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_missing_zip_city={\n",
    "    \"29486\":\"Summerville\",\n",
    "    \"84009\":\"South Jordan\",\n",
    "    \"86005\":\"Flagstaff\",\n",
    "    \"97003\":\"Beaverton\",\n",
    "    \"97703\":\"Bend\"\n",
    "}\n",
    "\n",
    "\n",
    "dict_missing_zip_state={\n",
    "    \"29486\":\"SC\",\n",
    "    \"84009\":\"UT\",\n",
    "    \"86005\":\"AZ\",\n",
    "    \"97003\":\"OR\",\n",
    "    \"97703\":\"OR\"    \n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df_unique_zip_0=df_unique_zip[pd.notnull(df_unique_zip['city'])]\n",
    "df_unique_zip_1=df_unique_zip[pd.isnull(df_unique_zip['city'])]\n",
    "df_unique_zip_1['city']=df_unique_zip_1['zip_cd'].apply(lambda x: dict_missing_zip_city[x])\n",
    "df_unique_zip_1['state']=df_unique_zip_1['zip_cd'].apply(lambda x: dict_missing_zip_state[x])\n",
    "df_unique_zip=df_unique_zip_0.append(df_unique_zip_1).sort_values(\"zip_cd\")\n",
    "df_unique_zip=df_unique_zip[df_unique_zip_0.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13477, 4), 13477)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_zip.shape,df_unique_zip['zip_cd'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "writer=pd.ExcelWriter(\"./BL_TA_zips_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_unique_zip.to_excel(writer,\"unique_zip_cd\",index=False)\n",
    "df_all_zips_for_YG_stores.to_excel(writer,\"store_with_zips\",index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
