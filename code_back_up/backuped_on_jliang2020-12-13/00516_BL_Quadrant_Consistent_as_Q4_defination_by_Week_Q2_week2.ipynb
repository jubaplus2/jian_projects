{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can be autimated across quarter if needed\n",
    "# To be noted that rolled up to store levels first, and then sum up which results in inflation \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix fisrt week\n",
    "last_saturday=datetime.datetime.now().date()-datetime.timedelta(days=datetime.datetime.now().date().weekday()+2)\n",
    "\n",
    "\n",
    "First_week_ending_Q2_2019=datetime.date(2019,5,11)\n",
    "\n",
    "last_year_week=last_saturday-datetime.timedelta(days=52*7)\n",
    "\n",
    "Nth_week=int((last_saturday-First_week_ending_Q2_2019).days/7)+1\n",
    "\n",
    "write_folder=\"/home/jian/Projects/Big_Lots/Analysis/2019_Q2/BL_Excutive_Dashboard/output/output_\"+str(last_saturday)+\"/\"\n",
    "try:\n",
    "    os.stat(write_folder)\n",
    "except:\n",
    "    os.mkdir(write_folder)\n",
    "str(last_saturday)\n",
    "Nth_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking for the recent weeks that haven't moved to the folder\n",
    "possible_recent_folders=\"/home/jian/BigLots/MediaStorm_\"+str(last_saturday)+\"/\"\n",
    "daily_data_recent=[x for x in list(recursive_file_gen(possible_recent_folders)) if (\"aily\" in x) & (\".txt\" in x)]\n",
    "\n",
    "archived_folders_2018=\"/home/jian/BigLots/2018_by_weeks/MediaStorm_\"+str(last_saturday)+\"/\"\n",
    "daily_data_2018_achived=[x for x in list(recursive_file_gen(archived_folders_2018)) if (\"aily\" in x) & (\".txt\" in x)]\n",
    "\n",
    "archived_folders_2019=\"/home/jian/BigLots/2019_by_weeks/MediaStorm_\"+str(last_saturday)+\"/\"\n",
    "daily_data_2019_achived=[x for x in list(recursive_file_gen(archived_folders_2019)) if (\"aily\" in x) & (\".txt\" in x)]\n",
    "\n",
    "daily_data_list=daily_data_recent+daily_data_2018_achived+daily_data_2019_achived\n",
    "if len(daily_data_list)!=1:\n",
    "    print(\"Error of Daily Sales Data Path\")\n",
    "else:\n",
    "    daily_data_path_this_year=daily_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_data_list_hist=glob.glob(\"/home/jian/BigLots/hist_daily_data_subclasslevel/*.txt\")\n",
    "daily_data_list_hist=[x for x in daily_data_list_hist if (str(last_year_week) in x)&(\"DailySales\" in x)]\n",
    "if len(daily_data_list_hist)!=1:\n",
    "    print(\"Error of Daily Sales Data Path\")\n",
    "else:\n",
    "    daily_data_path_last_year=daily_data_list_hist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1361, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df_2018Q4_Quadrant=pd.read_excel(\"/home/jian/Projects/Big_Lots/Analysis/2019_Q2/BL_Excutive_Dashboard/Excel_BL_2019_Q1_post_quadrants_JL_2019-05-15.xlsx\",\n",
    "                                 dype=str,sheetname=\"2018_Q4_Store_Quad_Defination\",usecols=['location_id','Quadrant'])\n",
    "Df_2018Q4_Quadrant['location_id']=Df_2018Q4_Quadrant['location_id'].astype(str)\n",
    "Df_2018Q4_Quadrant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_unique_id(x):\n",
    "    return len(set(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/BigLots/hist_daily_data_subclasslevel/MediaStormDailySales_week_ending_2018-05-19.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data_path_last_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agg_daily_data_by_store_subclass_level(file_path_daily):\n",
    "    df=pd.read_table(file_path_daily,dtype=str,sep=\"|\",usecols=['location_id','transaction_dt','transaction_id','customer_id_hashed','subclass_transaction_amt'])\n",
    "    df=df[df['location_id']!=\"6990\"] # 6990 removed\n",
    "    df['subclass_transaction_amt']=df['subclass_transaction_amt'].astype(float)\n",
    "    df['Reward_Level']=np.where(pd.isnull(df['customer_id_hashed']),\"Non_Rewards\",\"Rewards\")\n",
    "    \n",
    "    print(\"Total_Sales:\",df['subclass_transaction_amt'].sum())\n",
    "    df_sales=df.groupby(['location_id','Reward_Level'])['subclass_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"subclass_transaction_amt\":\"Sales\"})\n",
    "    df_trans=df[['location_id','transaction_dt','transaction_id','customer_id_hashed','Reward_Level']].drop_duplicates().groupby(['location_id','Reward_Level'])['transaction_id'].count().to_frame().reset_index().rename(columns={\"transaction_id\":\"Transactions\"})\n",
    "    \n",
    "    df=df[df['Reward_Level']==\"Rewards\"]\n",
    "    df_ids=df.groupby(['location_id','Reward_Level'])['customer_id_hashed'].agg(count_unique_id).to_frame().reset_index().rename(columns={\"customer_id_hashed\":\"shopped_unique_ids_in_the_week\"})\n",
    "    \n",
    "    df=pd.merge(df_sales,df_trans,on=[\"location_id\",'Reward_Level'],how=\"outer\")\n",
    "    df=pd.merge(df,df_ids,on=[\"location_id\",'Reward_Level'],how=\"outer\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agg_daily_data_by_store_item_level(file_path_daily):\n",
    "    df=pd.read_table(file_path_daily,dtype=str,sep=\"|\",usecols=['location_id','transaction_dt','transaction_id','customer_id_hashed','item_transaction_amt'])\n",
    "    df=df[df['location_id']!=\"6990\"] # 6990 removed\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    df['Reward_Level']=np.where(pd.isnull(df['customer_id_hashed']),\"Non_Rewards\",\"Rewards\")\n",
    "    \n",
    "    print(\"Total_Sales:\",df['item_transaction_amt'].sum())\n",
    "    df_sales=df.groupby(['location_id','Reward_Level'])['item_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"item_transaction_amt\":\"Sales\"})\n",
    "    df_trans=df[['location_id','transaction_dt','transaction_id','customer_id_hashed','Reward_Level']].drop_duplicates().groupby(['location_id','Reward_Level'])['transaction_id'].count().to_frame().reset_index().rename(columns={\"transaction_id\":\"Transactions\"})\n",
    "    \n",
    "    df=df[df['Reward_Level']==\"Rewards\"]\n",
    "    df_ids=df.groupby(['location_id','Reward_Level'])['customer_id_hashed'].agg(count_unique_id).to_frame().reset_index().rename(columns={\"customer_id_hashed\":\"shopped_unique_ids_in_the_week\"})\n",
    "    \n",
    "    df=pd.merge(df_sales,df_trans,on=[\"location_id\",'Reward_Level'],how=\"outer\")\n",
    "    df=pd.merge(df,df_ids,on=[\"location_id\",'Reward_Level'],how=\"outer\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_Sales: 85723652.55\n",
      "Total_Sales: 84970886.57\n"
     ]
    }
   ],
   "source": [
    "df_daily_this_year_by_store=agg_daily_data_by_store_item_level(daily_data_path_this_year)\n",
    "df_daily_last_year_by_store=agg_daily_data_by_store_subclass_level(daily_data_path_last_year)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_daily_this_year_by_store.columns=df_daily_this_year_by_store.columns.tolist()[:2]+[\"This_Year_\"+x for x in df_daily_this_year_by_store.columns.tolist()[2:]]\n",
    "df_daily_last_year_by_store.columns=df_daily_last_year_by_store.columns.tolist()[:2]+[\"Last_Year_\"+x for x in df_daily_last_year_by_store.columns.tolist()[2:]]\n",
    "both_year=pd.merge(df_daily_this_year_by_store,df_daily_last_year_by_store,on=['location_id','Reward_Level'],how=\"outer\")\n",
    "both_year=pd.merge(both_year,Df_2018Q4_Quadrant,on=\"location_id\",how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "both_year_exlusion_last_year=both_year[(pd.isnull(both_year['Last_Year_Sales'])) | (pd.isnull(both_year['Last_Year_Transactions']))]\n",
    "both_year_exlusion_this_year=both_year[(pd.isnull(both_year['This_Year_Sales'])) | (pd.isnull(both_year['This_Year_Transactions']))]\n",
    "exlusion_no_quad=both_year[pd.isnull(both_year['Quadrant'])]\n",
    "\n",
    "all_exclusion_stores=set(both_year_exlusion_last_year['location_id'].tolist()+both_year_exlusion_this_year['location_id'].tolist()+exlusion_no_quad['location_id'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "both_year_inclusions=both_year[~both_year['location_id'].isin(all_exclusion_stores)]\n",
    "\n",
    "both_year_inclusions_Total=both_year_inclusions.groupby(['Reward_Level'])['This_Year_Sales','This_Year_Transactions','This_Year_shopped_unique_ids_in_the_week','Last_Year_Sales','Last_Year_Transactions','Last_Year_shopped_unique_ids_in_the_week'].sum().reset_index()\n",
    "both_year_inclusions_Total[\"Summary_Level\"]=\"Total\"\n",
    "both_year_inclusions_Total_store_counts=both_year_inclusions.groupby(['Reward_Level'])['location_id'].apply(count_unique_id).reset_index().rename(columns={\"location_id\":\"store_counts\"})\n",
    "both_year_inclusions_Total=pd.merge(both_year_inclusions_Total,both_year_inclusions_Total_store_counts,on=\"Reward_Level\")\n",
    "\n",
    "both_year_inclusions_Quad=both_year_inclusions.groupby(['Reward_Level','Quadrant'])['This_Year_Sales','This_Year_Transactions','This_Year_shopped_unique_ids_in_the_week','Last_Year_Sales','Last_Year_Transactions','Last_Year_shopped_unique_ids_in_the_week'].sum().reset_index()\n",
    "both_year_inclusions_Quad_store_counts=both_year_inclusions.groupby(['Reward_Level','Quadrant'])['location_id'].apply(count_unique_id).reset_index().rename(columns={\"location_id\":\"store_counts\"})\n",
    "both_year_inclusions_Quad=pd.merge(both_year_inclusions_Quad,both_year_inclusions_Quad_store_counts,on=[\"Reward_Level\",\"Quadrant\"])\n",
    "both_year_inclusions_Quad=both_year_inclusions_Quad.rename(columns={\"Quadrant\":\"Summary_Level\"})\n",
    "\n",
    "output=both_year_inclusions_Total.append(both_year_inclusions_Quad)\n",
    "output=output.sort_values(['Summary_Level','Reward_Level'],ascending=[True,False])\n",
    "\n",
    "output=output[output['Summary_Level']==\"Total\"].append(output[output['Summary_Level']!=\"Total\"])\n",
    "\n",
    "output_sales_both_R_N=output.groupby(['Summary_Level'])['This_Year_Sales'].sum().to_frame().reset_index().rename(columns={\"This_Year_Sales\":\"This_week_Total_R_and_N\"})\n",
    "output=pd.merge(output,output_sales_both_R_N,on=\"Summary_Level\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output['YoY_Incr_Sales']=np.round((output['This_Year_Sales']-output['Last_Year_Sales'])/output['Last_Year_Sales'],4)\n",
    "output['YoY_Incr_Rew_Shoppers']=np.round((output['This_Year_shopped_unique_ids_in_the_week']-output['Last_Year_shopped_unique_ids_in_the_week'])/output['Last_Year_shopped_unique_ids_in_the_week'],4)\n",
    "output['YoY_Incr_Transactions']=np.round((output['This_Year_Transactions']-output['Last_Year_Transactions'])/output['Last_Year_Transactions'],4)\n",
    "output['Avg_Order_Value']=np.round(output['This_Year_Sales']/output['This_Year_Transactions'],4)\n",
    "\n",
    "output['Rew/Non-Rew_Share_of_Sales']=np.round(output['This_Year_Sales']/output['This_week_Total_R_and_N'],4)\n",
    "output['Week_Ending_Date']=str(last_saturday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_final=output[['Week_Ending_Date','Summary_Level','Reward_Level','store_counts','YoY_Incr_Sales','YoY_Incr_Rew_Shoppers','YoY_Incr_Transactions','Avg_Order_Value',\n",
    "                     'Rew/Non-Rew_Share_of_Sales','This_Year_Transactions','This_Year_Sales','This_Year_shopped_unique_ids_in_the_week']].rename(columns={\"This_Year_Transactions\":\"Transactions_last_7_days\",\n",
    "                     \"This_Year_Sales\":\"Sales_last_7_days\",\"This_Year_shopped_unique_ids_in_the_week\":\"Shopped_Rew_Unique_IDs_last_7_days\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "exclusion_1=exlusion_no_quad[['location_id']]\n",
    "exclusion_1['exclusion']=\"Not_Defined_Quadrant\"\n",
    "\n",
    "exclusion_2=both_year_exlusion_last_year[['location_id']]\n",
    "exclusion_2['exclusion']=\"Lack_of_week_last_year\"\n",
    "\n",
    "exclusion_3=both_year_exlusion_this_year[['location_id']]\n",
    "exclusion_3['exclusion']=\"Lack_of_week_this_year\"\n",
    "\n",
    "exclusion_df=exclusion_3.append(exclusion_2).append(exclusion_1).drop_duplicates('location_id')\n",
    "exclusion_df['Week_Ending_Date']=str(last_saturday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def int_ceil_not_NA(x):\n",
    "    if ~np.isnan(x):\n",
    "        y=int(np.ceil(x))\n",
    "    else:\n",
    "        y=x\n",
    "    return y\n",
    "\n",
    "\n",
    "output_final=output_final.rename(columns={\"Week_Ending_Date\":\"Week Ending Date\",\"Summary_Level\":\"Summary Level\",\"Reward_Level\":\"Reward Level\",\n",
    "                         \"store_counts\":\"# Stores\",\"YoY_Incr_Sales\":\"YOY incr Sales/Store\",\"YoY_Incr_Rew_Shoppers\":\"YOY incr Rew Shoppers/Store\",\n",
    "                         \"YoY_Incr_Transactions\":\"YOY incr Transactions/Store\",\"Avg_Order_Value\":\"Avg Order Value\",\n",
    "                         \"Rew/Non-Rew_Share_of_Sales\":\"Rew share of Sales\",\"Transactions_last_7_days\":\"Transactions last 7 days\",\n",
    "                         \"Sales_last_7_days\":\"Total Sales Last 7 Days\",\"Shopped_Rew_Unique_IDs_last_7_days\":\"Shopped Rew IDs Last 7 days\"})\n",
    "output_final['Reward Level']=output_final['Reward Level'].replace(\"Non_Rewards\",\"Non-Rewards\")\n",
    "output_final['Avg # of Reward IDs shopped per store']=output_final['Shopped Rew IDs Last 7 days']/output_final['# Stores']\n",
    "\n",
    "\n",
    "output_final['Avg # of Reward IDs shopped per store']=output_final['Avg # of Reward IDs shopped per store'].apply(lambda x: int_ceil_not_NA(x))\n",
    "output_final['Weekly Cost']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_final.to_csv(write_folder+\"output_\"+str(last_saturday)+\".csv\",index=False)\n",
    "exclusion_df.to_csv(write_folder+\"exclusion_stores_\"+str(last_saturday)+\".csv\",index=False)\n",
    "both_year_inclusions.to_csv(write_folder+\"inclusion_by_store_\"+str(last_saturday)+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Simeng_recent_weekly_data_folder=\"/home/simeng/outputs_\"+str(last_saturday)+\"/\"\n",
    "\n",
    "output_final.to_csv(Simeng_recent_weekly_data_folder + 'output_quadrant.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
