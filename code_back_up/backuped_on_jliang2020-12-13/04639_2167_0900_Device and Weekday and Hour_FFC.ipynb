{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end_date = \"2017-09-24\"\n",
    "start_date = \"2017-08-01\"\n",
    "xls_path='/Users/JayLiang/Desktop/Media Storm/PEI/CallAway/Auto Run _ Device and Weekday/Device_Weekday_Hour_From_'+str(start_date)+'_To_'+str(end_date)+'.xlsx'\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 6\n",
    "import os\n",
    "import argparse\n",
    "import httplib2\n",
    "import pprint\n",
    "import time\n",
    "import datetime\n",
    "from io import StringIO\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from oauth2client import GOOGLE_TOKEN_URI\n",
    "from oauth2client.client import OAuth2Credentials\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "\n",
    "def create_credentials():\n",
    "    \"\"\"Create Google OAuth2 credentials.\n",
    "\n",
    "    Args:\n",
    "        client_id: Client id of a Google Cloud console project.\n",
    "        client_secret: Client secret of a Google Cloud console project.\n",
    "        refresh_token: A refresh token authorizing the Google Cloud console project\n",
    "          to access the DS data of some Google user.\n",
    "    Returns:\n",
    "        OAuth2Credentials\n",
    "    \"\"\"\n",
    "    return OAuth2Credentials(access_token=None,\n",
    "                           client_id='549790627766-qnth4m8qvuimg87pnsp4b82lhte7dk5a.apps.googleusercontent.com',\n",
    "                           client_secret='Vta4lQLOL49vVYvktkcPGRNb',\n",
    "                           refresh_token='1/ab7pCGMu3K5AveG0UOUpQ0J08vCp6uM357O8qmoPDMs',\n",
    "                           token_expiry=None,\n",
    "                           token_uri=\"https://accounts.google.com/o/oauth2/token\",\n",
    "                           user_agent=None)\n",
    "\n",
    "def get_service(credentials):\n",
    "    \"\"\"Set up a new DoubleClick Search service.\n",
    "\n",
    "    Args:\n",
    "        credentials: An OAuth2Credentials generated with create_credentials, or\n",
    "        flows in the oatuh2client.client package.\n",
    "    Returns:\n",
    "        An authorized Doubleclicksearch serivce.\n",
    "    \"\"\"\n",
    "    # Use the authorize() function of OAuth2Credentials to apply necessary credential\n",
    "    # headers to all requests.\n",
    "    http = credentials.authorize(http = httplib2.Http())\n",
    "\n",
    "    # Construct the service object for the interacting with the DoubleClick Search API.\n",
    "    service = build('doubleclicksearch', 'v2', http=http)\n",
    "    return service\n",
    "\n",
    "def poll_report(service, report_id):\n",
    "    \"\"\"Poll the API with the reportId until the report is ready, up to ten times.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        report_id: The ID DS has assigned to a report.\n",
    "    Returns:\n",
    "        pd.DataFrame, report file\n",
    "    \"\"\"\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            request = service.reports().get(reportId=report_id)\n",
    "            json_data = request.execute()\n",
    "            if json_data['isReportReady']:\n",
    "                pprint.pprint('The report is ready.')\n",
    "\n",
    "                # For large reports, DS automatically fragments the report into multiple\n",
    "                # files. The 'files' property in the JSON object that DS returns contains\n",
    "                # the list of URLs for file fragment. To download a report, DS needs to\n",
    "                # know the report ID and the index of a file fragment.\n",
    "                report = pd.DataFrame()\n",
    "                for i in range(len(json_data['files'])):\n",
    "                    pprint.pprint('Downloading fragment ' + str(i) + ' for report ' + report_id)\n",
    "                    report = report.append(download_files(service, report_id, str(i)), ignore_index = True) # See Download the report.\n",
    "                return report\n",
    "\n",
    "            else:\n",
    "                pprint.pprint('Report is not ready. I will try again.')\n",
    "                time.sleep(10)\n",
    "        except HttpError as e:\n",
    "            error = simplejson.loads(e.content)['error']['errors'][0]\n",
    "\n",
    "            # See Response Codes\n",
    "            pprint.pprint('HTTP code %d, reason %s' % (e.resp.status, error['reason']))\n",
    "            break\n",
    "        \n",
    "def download_files(service, report_id, report_fragment):\n",
    "    \"\"\"Generate and print sample report.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        report_id: The ID DS has assigned to a report.\n",
    "        report_fragment: The 0-based index of the file fragment from the files array.\n",
    "    Returns:\n",
    "        pd.DataFrame report file\n",
    "    \"\"\"\n",
    "    request = service.reports().getFile(reportId=report_id, reportFragment=report_fragment)\n",
    "    return pd.read_csv(StringIO(request.execute().decode('utf-8')))\n",
    "\n",
    "def request_report(service, start_date, end_date, columns):\n",
    "    \"\"\"Request sample report and print the report ID that DS returns. See Set Up Your Application.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        columns: list of columns will be in the report\n",
    "    Returns:\n",
    "        The report id.\n",
    "    \"\"\"\n",
    "    request = service.reports().request(\n",
    "        body={\n",
    "                \"reportScope\": {\n",
    "                    \"agencyId\": \"20100000000000932\",\n",
    "                    \"advertiserId\": \"21700000001365301\", # Callaway Apparel - Perry Ellis International\n",
    "                    #\"engineAccountId\": \"700000001564770\" # Google - Callaway Apparel\n",
    "                    #\"advertiserId\": \"21700000001131725\", # Celebrity Cruise\n",
    "                    #\"engineAccountId\": \"700000001217833\" # Celebrity Cruise\n",
    "                    #\"engineAccountId\": \"700000001561242\" # Celebrity Cruise - Juba Plus\n",
    "                },\n",
    "                \"reportType\": \"account\",\n",
    "                \"columns\": [{'columnName': column} for column in columns],   \n",
    "                \"timeRange\" : {\n",
    "                    \"startDate\" : start_date,\n",
    "                    \"endDate\" : end_date\n",
    "                    },\n",
    "                \n",
    "                #\"filters\": [\n",
    "                #    {\n",
    "                #        \"column\" : { \"columnName\": \"keywordLabels\" },\n",
    "                #        \"operator\" : \"containsElement\",\n",
    "                #        \"values\" : [\"JubaNovTest\",]\n",
    "                #    }\n",
    "                #],\n",
    "                \n",
    "                \"downloadFormat\": \"csv\",\n",
    "                \"maxRowsPerFile\": 100000000,\n",
    "                \"statisticsCurrency\": \"agency\",\n",
    "                \"verifySingleTimeZone\": \"false\",\n",
    "                \"includeRemovedEntities\": \"false\"\n",
    "            }\n",
    "    )\n",
    "    json_data = request.execute()\n",
    "    return json_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-01\n",
      "2017-09-24\n",
      "'Report is not ready. I will try again.'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAnkf3ZXYra-rKx'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAnirUg35m2jn8G'\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "creds = create_credentials()\n",
    "\n",
    "service = get_service(creds)\n",
    "\n",
    "\n",
    "print(start_date), print(end_date)\n",
    "REPORTID_nonHVA = request_report(service, start_date, end_date, \n",
    "                                 ['accountType', 'deviceSegment', 'clicks', 'cost', 'impr','dfaRevenue', 'dfaTransactions'])\n",
    "REPORTID_HVA = request_report(service, start_date, end_date, \n",
    "                              ['accountType', 'deviceSegment',\n",
    "                               'floodlightActivity', 'dfaActions'])\n",
    "non_hva_device= poll_report(service, REPORTID_nonHVA)\n",
    "hva_device = poll_report(service, REPORTID_HVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Device_1=non_hva_device\n",
    "Device_2=hva_device\n",
    "\n",
    "Device_2=Device_2.pivot_table(index=['deviceSegment','accountType'],columns=['floodlightActivity'],values=['dfaActions'])\n",
    "Device_2.columns =Device_2.columns.get_level_values(1)\n",
    "Device_2.reset_index(inplace=True)\n",
    "\n",
    "Merge_2_Device=pd.merge(Device_1,Device_2,on=[\"deviceSegment\",\"accountType\"])\n",
    "HVA_List=list(hva_device['floodlightActivity'].unique())\n",
    "Merge_2_Device['HVA']=np.sum(Merge_2_Device.loc[:,HVA_List],axis=1)\n",
    "Merge_2_Device['ROI']=Merge_2_Device['dfaRevenue']/Merge_2_Device['cost']\n",
    "Merge_2_Device['Click Through Rate']=Merge_2_Device['clicks']/Merge_2_Device['impr']\n",
    "Merge_2_Device['Cost per Transaction']=Merge_2_Device['cost']/Merge_2_Device['dfaTransactions']  \n",
    "Merge_2_Device['Cost per Click']=Merge_2_Device['cost']/Merge_2_Device['clicks']\n",
    "Merge_2_Device['Cost per HVA (total)']=Merge_2_Device['cost']/Merge_2_Device['HVA']\n",
    "\n",
    "cols = Merge_2_Device.columns.tolist()\n",
    "cols_new=cols[:2]+['ROI']+cols[2:7]+['HVA']+cols[-4:]+cols[7:-6]\n",
    "Merge_2_Device_Final=Merge_2_Device[cols_new]\n",
    "Merge_2_Device_Final=Merge_2_Device_Final.sort_values(by=['accountType','ROI'],ascending=[True,False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-01\n",
      "2017-09-24\n",
      "'Report is not ready. I will try again.'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAn2WJdLKvr9dK2'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAnQ_SkzEhZRf9S'\n"
     ]
    }
   ],
   "source": [
    "# Weekday\n",
    "creds = create_credentials()\n",
    "\n",
    "service = get_service(creds)\n",
    "\n",
    "\n",
    "print(start_date), print(end_date)\n",
    "REPORTID_nonHVA = request_report(service, start_date, end_date, \n",
    "                                 ['accountType', 'date', 'clicks', 'cost', 'impr','dfaRevenue', 'dfaTransactions'])\n",
    "REPORTID_HVA = request_report(service, start_date, end_date, \n",
    "                              ['accountType', 'date',\n",
    "                               'floodlightActivity', 'dfaActions'])\n",
    "non_hva_date= poll_report(service, REPORTID_nonHVA)\n",
    "hva_date= poll_report(service, REPORTID_HVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWeekday_2_Group_3HVA=Weekday_2_Group_New.groupby([\\'accountType\\',\\'weekday\\',\\'Group Name\\'])[[\\'dfaActions\\']].sum() \\nWeekday_2_Group_3HVA.reset_index(inplace = True)\\nWeekday_2_Group_3HVA_Wide=Weekday_2_Group_3HVA.pivot_table(index=[\\'weekday\\',\\'accountType\\'],columns=[\\'Group Name\\'],values=[\\'dfaActions\\'])\\n\\nWeekday_2_Group_floodlightActivity=Weekday_2_Group_New\\ndel Weekday_2_Group_floodlightActivity[\\'Group Name\\']\\nWeekday_2_Group_53Activities=Weekday_2_Group_floodlightActivity.pivot_table(index=[\\'weekday\\',\\'accountType\\'],columns=[\\'floodlightActivity\\'],values=[\\'dfaActions\\'])\\nWeekday_2_Group_3HVA_Wide.columns =Weekday_2_Group_3HVA_Wide.columns.get_level_values(1)\\nWeekday_2_Group_3HVA_Wide.reset_index(inplace=True)\\nWeekday_2_Group_53Activities.columns =Weekday_2_Group_53Activities.columns.get_level_values(1)\\nWeekday_2_Group_53Activities.reset_index(inplace=True)\\n\\nMerge_1_Weekday=pd.merge(Weekday_1_Agg,Weekday_2_Group_3HVA_Wide,on=[\"weekday\",\"accountType\"])\\nMerge_2_Weekday=pd.merge(Merge_1_Weekday,Weekday_2_Group_53Activities,on=[\"weekday\",\"accountType\"])\\nMerge_2_Weekday[\\'Conversions\\']=np.sum(Merge_2_Weekday.loc[:,[\\'Callaway - HVA 1\\',\\'Callaway - HVA 2\\',\\'Callaway - HVA 3\\']],axis=1)\\nMerge_2_Weekday[\\'ROI\\']=Merge_2_Weekday[\\'dfaRevenue\\']/Merge_2_Weekday[\\'cost\\']\\nMerge_2_Weekday[\\'Click Through Rate\\']=Merge_2_Weekday[\\'clicks\\']/Merge_2_Weekday[\\'impr\\']\\nMerge_2_Weekday[\\'Cost per Transaction\\']=Merge_2_Weekday[\\'cost\\']/Merge_2_Weekday[\\'dfaTransactions\\']  \\nMerge_2_Weekday[\\'Cost per Click\\']=Merge_2_Weekday[\\'cost\\']/Merge_2_Weekday[\\'clicks\\']\\nMerge_2_Weekday[\\'Cost per HVA (total)\\']=Merge_2_Weekday[\\'cost\\']/Merge_2_Weekday[\\'Conversions\\']\\nMerge_2_Weekday[\\'Cost per HVA 1\\']=Merge_2_Weekday[\\'cost\\']/Merge_2_Weekday[\\'Callaway - HVA 1\\']\\nMerge_2_Weekday[\\'Cost per HVA 2\\']=Merge_2_Weekday[\\'cost\\']/Merge_2_Weekday[\\'Callaway - HVA 2\\']\\nMerge_2_Weekday[\\'Cost per HVA 3\\']=Merge_2_Weekday[\\'cost\\']/Merge_2_Weekday[\\'Callaway - HVA 3\\']\\n\\ncols = Merge_2_Weekday.columns.tolist()\\ncols_new=cols[:2]+[\\'ROI\\']+cols[2:7]+[\\'Conversions\\']+cols[-7:]+cols[7:-9]\\nMerge_2_Weekday_Final=Merge_2_Weekday[cols_new]\\n\\nMerge_2_Weekday_Final=Merge_2_Weekday_Final.sort_values(by=[\\'accountType\\',\\'ROI\\'],ascending=[True,False])\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weekday_1=non_hva_date\n",
    "Weekday_2=hva_date\n",
    "import calendar\n",
    "Weekday_1['weekday']=Weekday_1['date'].apply(lambda x: calendar.day_name[pd.to_datetime(x).weekday()])\n",
    "Weekday_2['weekday']=Weekday_2['date'].apply(lambda x: calendar.day_name[pd.to_datetime(x).weekday()])\n",
    "\n",
    "Weekday_1_Agg=Weekday_1.groupby(['accountType','weekday'])[['clicks','cost','impr','dfaRevenue','dfaTransactions']].sum()\n",
    "Weekday_1_Agg.reset_index(inplace=True)\n",
    "\n",
    "Weekday_2_Agg=Weekday_2.groupby(['accountType','weekday','floodlightActivity'])[['dfaActions']].sum()\n",
    "Weekday_2_Agg.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "Weekday_2_Agg=Weekday_2_Agg.pivot_table(index=['weekday','accountType'],columns=['floodlightActivity'],values=['dfaActions'])\n",
    "Weekday_2_Agg.columns =Weekday_2_Agg.columns.get_level_values(1)\n",
    "Weekday_2_Agg.reset_index(inplace=True)\n",
    "\n",
    "Merge_2_Weekday=pd.merge(Weekday_1_Agg,Weekday_2_Agg,on=[\"weekday\",\"accountType\"])\n",
    "HVA_List=list(Weekday_2['floodlightActivity'].unique())\n",
    "\n",
    "Merge_2_Weekday['HVA']=np.sum(Merge_2_Weekday.loc[:,HVA_List],axis=1)\n",
    "Merge_2_Weekday['ROI']=Merge_2_Weekday['dfaRevenue']/Merge_2_Weekday['cost']\n",
    "Merge_2_Weekday['Click Through Rate']=Merge_2_Weekday['clicks']/Merge_2_Weekday['impr']\n",
    "Merge_2_Weekday['Cost per Transaction']=Merge_2_Weekday['cost']/Merge_2_Weekday['dfaTransactions']  \n",
    "Merge_2_Weekday['Cost per Click']=Merge_2_Weekday['cost']/Merge_2_Weekday['clicks']\n",
    "Merge_2_Weekday['Cost per HVA (total)']=Merge_2_Weekday['cost']/Merge_2_Weekday['HVA']\n",
    "\n",
    "cols = Merge_2_Weekday.columns.tolist()\n",
    "cols_new=cols[:2]+['ROI']+cols[2:7]+['HVA']+cols[-4:]+cols[7:-6]\n",
    "Merge_2_Weekday_Final=Merge_2_Weekday[cols_new]\n",
    "Merge_2_Weekday_Final=Merge_2_Weekday_Final.sort_values(by=['accountType','ROI'],ascending=[True,False])\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Weekday_2_Group_3HVA=Weekday_2_Group_New.groupby(['accountType','weekday','Group Name'])[['dfaActions']].sum() \n",
    "Weekday_2_Group_3HVA.reset_index(inplace = True)\n",
    "Weekday_2_Group_3HVA_Wide=Weekday_2_Group_3HVA.pivot_table(index=['weekday','accountType'],columns=['Group Name'],values=['dfaActions'])\n",
    "\n",
    "Weekday_2_Group_floodlightActivity=Weekday_2_Group_New\n",
    "del Weekday_2_Group_floodlightActivity['Group Name']\n",
    "Weekday_2_Group_53Activities=Weekday_2_Group_floodlightActivity.pivot_table(index=['weekday','accountType'],columns=['floodlightActivity'],values=['dfaActions'])\n",
    "Weekday_2_Group_3HVA_Wide.columns =Weekday_2_Group_3HVA_Wide.columns.get_level_values(1)\n",
    "Weekday_2_Group_3HVA_Wide.reset_index(inplace=True)\n",
    "Weekday_2_Group_53Activities.columns =Weekday_2_Group_53Activities.columns.get_level_values(1)\n",
    "Weekday_2_Group_53Activities.reset_index(inplace=True)\n",
    "\n",
    "Merge_1_Weekday=pd.merge(Weekday_1_Agg,Weekday_2_Group_3HVA_Wide,on=[\"weekday\",\"accountType\"])\n",
    "Merge_2_Weekday=pd.merge(Merge_1_Weekday,Weekday_2_Group_53Activities,on=[\"weekday\",\"accountType\"])\n",
    "Merge_2_Weekday['Conversions']=np.sum(Merge_2_Weekday.loc[:,['Callaway - HVA 1','Callaway - HVA 2','Callaway - HVA 3']],axis=1)\n",
    "Merge_2_Weekday['ROI']=Merge_2_Weekday['dfaRevenue']/Merge_2_Weekday['cost']\n",
    "Merge_2_Weekday['Click Through Rate']=Merge_2_Weekday['clicks']/Merge_2_Weekday['impr']\n",
    "Merge_2_Weekday['Cost per Transaction']=Merge_2_Weekday['cost']/Merge_2_Weekday['dfaTransactions']  \n",
    "Merge_2_Weekday['Cost per Click']=Merge_2_Weekday['cost']/Merge_2_Weekday['clicks']\n",
    "Merge_2_Weekday['Cost per HVA (total)']=Merge_2_Weekday['cost']/Merge_2_Weekday['Conversions']\n",
    "Merge_2_Weekday['Cost per HVA 1']=Merge_2_Weekday['cost']/Merge_2_Weekday['Callaway - HVA 1']\n",
    "Merge_2_Weekday['Cost per HVA 2']=Merge_2_Weekday['cost']/Merge_2_Weekday['Callaway - HVA 2']\n",
    "Merge_2_Weekday['Cost per HVA 3']=Merge_2_Weekday['cost']/Merge_2_Weekday['Callaway - HVA 3']\n",
    "\n",
    "cols = Merge_2_Weekday.columns.tolist()\n",
    "cols_new=cols[:2]+['ROI']+cols[2:7]+['Conversions']+cols[-7:]+cols[7:-9]\n",
    "Merge_2_Weekday_Final=Merge_2_Weekday[cols_new]\n",
    "\n",
    "Merge_2_Weekday_Final=Merge_2_Weekday_Final.sort_values(by=['accountType','ROI'],ascending=[True,False])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountType</th>\n",
       "      <th>weekday</th>\n",
       "      <th>ROI</th>\n",
       "      <th>clicks</th>\n",
       "      <th>cost</th>\n",
       "      <th>impr</th>\n",
       "      <th>dfaRevenue</th>\n",
       "      <th>dfaTransactions</th>\n",
       "      <th>Conversions</th>\n",
       "      <th>Click Through Rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Membership</th>\n",
       "      <th>Membership-Join now</th>\n",
       "      <th>Our Wines Diamond Collection</th>\n",
       "      <th>Shop - Diamond Collection Wines</th>\n",
       "      <th>Shop Now</th>\n",
       "      <th>Shop online - Wine</th>\n",
       "      <th>Shopping Cart</th>\n",
       "      <th>Store Locator</th>\n",
       "      <th>Thank You Page</th>\n",
       "      <th>Visit Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Google AdWords</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>3150</td>\n",
       "      <td>4911.72</td>\n",
       "      <td>117296</td>\n",
       "      <td>3773.980000</td>\n",
       "      <td>26</td>\n",
       "      <td>6661</td>\n",
       "      <td>0.026855</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>128</td>\n",
       "      <td>3168</td>\n",
       "      <td>20</td>\n",
       "      <td>300</td>\n",
       "      <td>554</td>\n",
       "      <td>105</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google AdWords</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.664804</td>\n",
       "      <td>3286</td>\n",
       "      <td>5149.50</td>\n",
       "      <td>120462</td>\n",
       "      <td>3423.409998</td>\n",
       "      <td>22</td>\n",
       "      <td>6723</td>\n",
       "      <td>0.027278</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>115</td>\n",
       "      <td>3236</td>\n",
       "      <td>10</td>\n",
       "      <td>376</td>\n",
       "      <td>575</td>\n",
       "      <td>157</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google AdWords</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0.587133</td>\n",
       "      <td>3274</td>\n",
       "      <td>5606.38</td>\n",
       "      <td>118943</td>\n",
       "      <td>3291.690000</td>\n",
       "      <td>20</td>\n",
       "      <td>6578</td>\n",
       "      <td>0.027526</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>110</td>\n",
       "      <td>3173</td>\n",
       "      <td>14</td>\n",
       "      <td>299</td>\n",
       "      <td>578</td>\n",
       "      <td>110</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Google AdWords</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.372862</td>\n",
       "      <td>3141</td>\n",
       "      <td>4939.55</td>\n",
       "      <td>116172</td>\n",
       "      <td>1841.770000</td>\n",
       "      <td>19</td>\n",
       "      <td>6410</td>\n",
       "      <td>0.027037</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>145</td>\n",
       "      <td>3106</td>\n",
       "      <td>14</td>\n",
       "      <td>264</td>\n",
       "      <td>506</td>\n",
       "      <td>97</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google AdWords</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0.351191</td>\n",
       "      <td>3068</td>\n",
       "      <td>5751.72</td>\n",
       "      <td>126594</td>\n",
       "      <td>2019.949999</td>\n",
       "      <td>11</td>\n",
       "      <td>5689</td>\n",
       "      <td>0.024235</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>130</td>\n",
       "      <td>2862</td>\n",
       "      <td>13</td>\n",
       "      <td>236</td>\n",
       "      <td>552</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google AdWords</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.343266</td>\n",
       "      <td>3506</td>\n",
       "      <td>5989.37</td>\n",
       "      <td>122459</td>\n",
       "      <td>2055.950000</td>\n",
       "      <td>15</td>\n",
       "      <td>6332</td>\n",
       "      <td>0.028630</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>115</td>\n",
       "      <td>3288</td>\n",
       "      <td>28</td>\n",
       "      <td>270</td>\n",
       "      <td>503</td>\n",
       "      <td>108</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accountType    weekday       ROI  clicks     cost    impr   dfaRevenue  \\\n",
       "6   Google AdWords  Wednesday  0.768362    3150  4911.72  117296  3773.980000   \n",
       "4   Google AdWords   Thursday  0.664804    3286  5149.50  120462  3423.409998   \n",
       "0   Google AdWords     Friday  0.587133    3274  5606.38  118943  3291.690000   \n",
       "..             ...        ...       ...     ...      ...     ...          ...   \n",
       "5   Google AdWords    Tuesday  0.372862    3141  4939.55  116172  1841.770000   \n",
       "3   Google AdWords     Sunday  0.351191    3068  5751.72  126594  2019.949999   \n",
       "2   Google AdWords   Saturday  0.343266    3506  5989.37  122459  2055.950000   \n",
       "\n",
       "    dfaTransactions  Conversions  Click Through Rate       ...        \\\n",
       "6                26         6661            0.026855       ...         \n",
       "4                22         6723            0.027278       ...         \n",
       "0                20         6578            0.027526       ...         \n",
       "..              ...          ...                 ...       ...         \n",
       "5                19         6410            0.027037       ...         \n",
       "3                11         5689            0.024235       ...         \n",
       "2                15         6332            0.028630       ...         \n",
       "\n",
       "    Membership  Membership-Join now  Our Wines Diamond Collection  \\\n",
       "6           82                  128                          3168   \n",
       "4           48                  115                          3236   \n",
       "0           54                  110                          3173   \n",
       "..         ...                  ...                           ...   \n",
       "5           67                  145                          3106   \n",
       "3           67                  130                          2862   \n",
       "2           50                  115                          3288   \n",
       "\n",
       "    Shop - Diamond Collection Wines  Shop Now  Shop online - Wine  \\\n",
       "6                                20       300                 554   \n",
       "4                                10       376                 575   \n",
       "0                                14       299                 578   \n",
       "..                              ...       ...                 ...   \n",
       "5                                14       264                 506   \n",
       "3                                13       236                 552   \n",
       "2                                28       270                 503   \n",
       "\n",
       "    Shopping Cart  Store Locator  Thank You Page  Visit Location  \n",
       "6             105             76               0             700  \n",
       "4             157             75               0             660  \n",
       "0             110             86               0             621  \n",
       "..            ...            ...             ...             ...  \n",
       "5              97             46               0             695  \n",
       "3             100             82               0             510  \n",
       "2             108            101               0             588  \n",
       "\n",
       "[7 rows x 39 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Merge_2_Weekday_Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JayLiang/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "hour1=pd.read_excel(\"/Users/JayLiang/Desktop/Media Storm/PEI/CallAway/Device_Day_Hour/Sep 5/Download/Hour 1.xlsx\")\n",
    "hour2=pd.read_excel(\"/Users/JayLiang/Desktop/Media Storm/PEI/CallAway/Device_Day_Hour/Sep 5/Download/Hour 2.xlsx\")\n",
    "Hour_of_day_1=hour1[[\"Engine\",\"Hour of day\",\"Clicks\",\"Cost\",\"Impr\",\"Revenue\",\"Trans\"]]\n",
    "Hour_of_day_2=hour2[[\"Engine\",\"Hour of day\",\"Floodlight activity\",\"Actions\"]]\n",
    "\n",
    "Hour_of_day_2.loc[Hour_of_day_2['Floodlight activity']=='Callaway - Billing_Payment - All','Floodlight activity']='Callaway - Billing_Payment'\n",
    "Hour_of_day_2.loc[Hour_of_day_2['Floodlight activity']=='Callaway - Order Review - All','Floodlight activity']='Callaway - Order Review'\n",
    "Hour_of_day_2.loc[Hour_of_day_2['Floodlight activity']=='Callaway - Shipping - All','Floodlight activity']='Callaway - Shipping'\n",
    "Group.rename(columns={'floodlightActivity':'Floodlight activity'}, inplace=True)\n",
    "\n",
    "Hour_of_day_2_Group_New=pd.merge(Hour_of_day_2,Group,  on=\"Floodlight activity\")\n",
    "Hour_of_day_2_Group_New.drop(['DCM activity mapping','Activity Name'], axis=1, inplace=True)\n",
    "\n",
    "Hour_of_day_2_Group_3HVA=Hour_of_day_2_Group_New.groupby(['Engine','Hour of day','Group Name'],as_index=False)['Actions'].sum()\n",
    "Hour_of_day_2_Group_3HVA_Wide=Hour_of_day_2_Group_3HVA.pivot_table(index=['Hour of day','Engine'],columns=['Group Name'],values=['Actions'])\n",
    "Hour_of_day_2_Group_3HVA_Wide.columns =Hour_of_day_2_Group_3HVA_Wide.columns.get_level_values(1)\n",
    "Hour_of_day_2_Group_3HVA_Wide.reset_index(inplace=True)\n",
    "\n",
    "Hour_of_day_2_Group_floodlightActivity=Hour_of_day_2_Group_New\n",
    "\n",
    "Hour_of_day_2_Group_53Activities_Wide=Hour_of_day_2_Group_floodlightActivity.pivot_table(index=['Hour of day','Engine'],columns=['Floodlight activity'],values=['Actions'])\n",
    "Hour_of_day_2_Group_53Activities_Wide.columns =Hour_of_day_2_Group_53Activities_Wide.columns.get_level_values(1)\n",
    "Hour_of_day_2_Group_53Activities_Wide.reset_index(inplace=True)\n",
    "##\n",
    "Merge_1_Hour=pd.merge(Hour_of_day_1,Hour_of_day_2_Group_3HVA_Wide,on=[\"Hour of day\",\"Engine\"])\n",
    "Merge_2_Hour_of_day=pd.merge(Merge_1_Hour,Hour_of_day_2_Group_53Activities_Wide,on=[\"Hour of day\",\"Engine\"])\n",
    "\n",
    "Merge_2_Hour_of_day['Conversions']=np.sum(Merge_2_Hour_of_day.loc[:,['Callaway - HVA 1','Callaway - HVA 2','Callaway - HVA 3']],axis=1)\n",
    "Merge_2_Hour_of_day['ROI']=Merge_2_Hour_of_day['Revenue']/Merge_2_Hour_of_day['Cost']\n",
    "Merge_2_Hour_of_day['Click Through Rate']=Merge_2_Hour_of_day['Clicks']/Merge_2_Hour_of_day['Impr']\n",
    "Merge_2_Hour_of_day['Cost per Transaction']=Merge_2_Hour_of_day['Cost']/Merge_2_Hour_of_day['Trans']  \n",
    "Merge_2_Hour_of_day['Cost per Click']=Merge_2_Hour_of_day['Cost']/Merge_2_Hour_of_day['Clicks']\n",
    "Merge_2_Hour_of_day['Cost per HVA (total)']=Merge_2_Hour_of_day['Cost']/Merge_2_Hour_of_day['Conversions']\n",
    "Merge_2_Hour_of_day['Cost per HVA 1']=Merge_2_Hour_of_day['Cost']/Merge_2_Hour_of_day['Callaway - HVA 1']\n",
    "Merge_2_Hour_of_day['Cost per HVA 2']=Merge_2_Hour_of_day['Cost']/Merge_2_Hour_of_day['Callaway - HVA 2']\n",
    "Merge_2_Hour_of_day['Cost per HVA 3']=Merge_2_Hour_of_day['Cost']/Merge_2_Hour_of_day['Callaway - HVA 3']\n",
    "\n",
    "cols = Merge_2_Hour_of_day.columns.tolist()\n",
    "cols_new=cols[:2]+['ROI']+cols[2:7]+['Conversions']+cols[-7:]+cols[7:-9]\n",
    "Hour_of_day_Final=Merge_2_Hour_of_day[cols_new]\n",
    "\n",
    "Hour_of_day_Final=Hour_of_day_Final.sort_values(by=['Engine','ROI'],ascending=[True,False])\n",
    "# To change later #### Hour_of_day_Final.to_excel('Aug. 21/Weekday.xlsx', sheet_name='Hour_of_day_Final', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 72)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hour_of_day_Final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_dfs=[Merge_2_Device_Final,Merge_2_Weekday_Final,Hour_of_day_Final]\n",
    "def save_xls(list_dfs, xls_path):\n",
    "    writer = ExcelWriter(xls_path)\n",
    "    for n, df in enumerate(list_dfs):\n",
    "        df.to_excel(writer,'sheet%s' % n,index=False)\n",
    "    writer.save()\n",
    "save_xls(list_dfs,xls_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
