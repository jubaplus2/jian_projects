{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/Projects/Smoothie_King/Analysis/TA_test_20190315'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summary_by_TA', 'output_TA_by_store', 'zip_TA', 'summary_by_store_count']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_ta=pd.ExcelFile(\"/home/jian/Projects/Smoothie_King/weekly_TA_updates/output_20190311/SmoothieKing_TA_of_3_miles_zips_JL_2019-03-11.xlsx\")\n",
    "latest_ta.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ta_by_store=latest_ta.parse(\"output_TA_by_store\",dtype=str)\n",
    "df_ta_by_store=df_ta_by_store[df_ta_by_store['status']==\"Same\"]\n",
    "df_ta_by_store.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jian/Projects/Smoothie_King/Weekly_Sales/WeeklySalesSummaryData_20190128.xlsx',\n",
       " '/home/jian/Projects/Smoothie_King/Weekly_Sales/WeeklySalesSummaryData_20190204.xlsx',\n",
       " '/home/jian/Projects/Smoothie_King/Weekly_Sales/WeeklySalesSummaryData_20190211.xlsx',\n",
       " '/home/jian/Projects/Smoothie_King/Weekly_Sales/WeeklySalesSummaryData_20190218.xlsx',\n",
       " '/home/jian/Projects/Smoothie_King/Weekly_Sales/WeeklySalesSummaryData_20190225.xlsx',\n",
       " '/home/jian/Projects/Smoothie_King/Weekly_Sales/WeeklySalesSummaryData_20190304.xlsx',\n",
       " '/home/jian/Projects/Smoothie_King/Weekly_Sales/WeeklySalesSummaryData_20190311.xlsx',\n",
       " '/home/jian/Projects/Smoothie_King/Weekly_Sales/WeeklySalesSummaryData_20190121.xlsx',\n",
       " '/home/jian/Projects/Smoothie_King/Weekly_Sales/WeeklySalesSummaryData_20190114.xlsx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_sales_folder=glob.glob(\"/home/jian/Projects/Smoothie_King/Weekly_Sales/*.xlsx\")\n",
    "weekly_sales_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all_weekly_sales_2019=pd.DataFrame()\n",
    "\n",
    "test=pd.read_excel(\"/home/jian/Projects/Smoothie_King/Weekly_Sales/WeeklySalesSummaryData_20190114.xlsx\")\n",
    "cols=test.columns.tolist()\n",
    "\n",
    "\n",
    "for file in weekly_sales_folder:\n",
    "    df=pd.read_excel(file,dtype=str,usecols=cols)\n",
    "    df['WeekEndDate']=df['WeekEndDate'].apply(lambda x:x[:10])\n",
    "    df['NetSalesSmoothie']=df['NetSalesSmoothie'].astype(float)\n",
    "    df['NetSalesRetail']=df['NetSalesRetail'].astype(float)\n",
    "    df['WeekEndDate']=df['WeekEndDate'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "    df_all_weekly_sales_2019=df_all_weekly_sales_2019.append(df)\n",
    "    \n",
    "df_all_weekly_sales_2019=df_all_weekly_sales_2019[(df_all_weekly_sales_2019['WeekEndDate']>=datetime.date(2019,1,6)) & (df_all_weekly_sales_2019['WeekEndDate']<=datetime.date(2019,3,9))]\n",
    "week_end_dates_2019=sorted(df_all_weekly_sales_2019['WeekEndDate'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all_weekly_sales_2018=pd.read_excel(\"/home/jian/Projects/Smoothie_King/data/WeeklySalesSummaryData_111218.xlsx\",dtype=str)\n",
    "df_all_weekly_sales_2018['NetSalesSmoothie']=df_all_weekly_sales_2018['NetSalesSmoothie'].astype(float)\n",
    "df_all_weekly_sales_2018['NetSalesRetail']=df_all_weekly_sales_2018['NetSalesRetail'].astype(float)\n",
    "\n",
    "df_all_weekly_sales_2018['WeekEndDate']=df_all_weekly_sales_2018['WeekEndDate'].apply(lambda x: datetime.datetime.strptime(x[:10],\"%Y-%m-%d\").date())\n",
    "week_end_dates_2018=[x - datetime.timedelta(days=52*7) for x in week_end_dates_2019]\n",
    "df_all_weekly_sales_2018=df_all_weekly_sales_2018[df_all_weekly_sales_2018['WeekEndDate'].isin(week_end_dates_2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "sales_available_count_df=df_all_weekly_sales_2018.append(df_all_weekly_sales_2019)\n",
    "sales_available_count_df=sales_available_count_df.groupby(['StoreNumber'])['WeekEndDate'].count().to_frame().reset_index()\n",
    "print(sales_available_count_df['WeekEndDate'].max())\n",
    "\n",
    "Weeks_Available_full=sales_available_count_df[sales_available_count_df['WeekEndDate']==18]\n",
    "all_weeks_available_stores=Weeks_Available_full['StoreNumber'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    }
   ],
   "source": [
    "all_sales_both_year=df_all_weekly_sales_2018.append(df_all_weekly_sales_2019)\n",
    "all_sales_both_year=all_sales_both_year[all_sales_both_year['StoreNumber'].isin(all_weeks_available_stores)]\n",
    "\n",
    "print(len(all_sales_both_year['StoreNumber'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765\n"
     ]
    }
   ],
   "source": [
    "all_SameStore_sales_both_year=all_sales_both_year[all_sales_both_year['StoreNumber'].isin(df_ta_by_store['storenumber'])]\n",
    "print(len(all_SameStore_sales_both_year['StoreNumber'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QC\n",
    "aaa=all_sales_both_year[~all_sales_both_year['StoreNumber'].isin(df_ta_by_store['storenumber'])]\n",
    "missed_stores=aaa['StoreNumber'].unique().tolist()\n",
    "len(missed_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 14)\n",
      "['NonComp']\n"
     ]
    }
   ],
   "source": [
    "store_list_latest=pd.read_excel(\"/home/jian/Projects/Smoothie_King/store_list_weekly/StoreList_20190311.xlsx\",dtype=str)\n",
    "store_list_latest[store_list_latest['storenumber'].isin(missed_stores)]\n",
    "print(store_list_latest[store_list_latest['storenumber'].isin(missed_stores)].shape)\n",
    "print(store_list_latest[store_list_latest['storenumber'].isin(missed_stores)]['status'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "all_SameStore_sales_both_year['Total_Net_Sales']=all_SameStore_sales_both_year['NetSalesSmoothie']+all_SameStore_sales_both_year['NetSalesRetail']\n",
    "\n",
    "all_SameStore_sales_both_year['Year']=all_SameStore_sales_both_year['WeekEndDate'].apply(lambda x: x.year)\n",
    "\n",
    "sales_by_store_by_year=all_SameStore_sales_both_year.groupby(['StoreNumber','Year'])['Total_Net_Sales'].sum().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoreNumber</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total_Net_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000</td>\n",
       "      <td>2018</td>\n",
       "      <td>159149.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000</td>\n",
       "      <td>2019</td>\n",
       "      <td>97871.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002</td>\n",
       "      <td>2018</td>\n",
       "      <td>118417.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002</td>\n",
       "      <td>2019</td>\n",
       "      <td>122197.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003</td>\n",
       "      <td>2018</td>\n",
       "      <td>128778.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StoreNumber  Year  Total_Net_Sales\n",
       "0        0000  2018        159149.68\n",
       "1        0000  2019         97871.02\n",
       "2        0002  2018        118417.05\n",
       "3        0002  2019        122197.07\n",
       "4        0003  2018        128778.99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_by_store_by_year.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_by_store_by_year_pivot=sales_by_store_by_year.pivot_table(index=\"StoreNumber\",columns=\"Year\").reset_index()\n",
    "col_level_1_list=sales_by_store_by_year_pivot.columns.get_level_values(0).tolist()\n",
    "col_level_2_list=sales_by_store_by_year_pivot.columns.get_level_values(1).tolist()\n",
    "new_cols=[]\n",
    "for i in range(len(col_level_1_list)):\n",
    "    new_cols=new_cols+[str(col_level_1_list[i])+\"_\"+str(col_level_2_list[i])]\n",
    "sales_by_store_by_year_pivot.columns=new_cols\n",
    "sales_by_store_by_year_pivot=sales_by_store_by_year_pivot.rename(columns={\"StoreNumber_\":\"storenumber\"})\n",
    "# sales_by_store_by_year_pivot.columns=sales_by_store_by_year_pivot.columns.get_level_values([0,1])\n",
    "# sales_by_store_by_year_pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ta_by_store=df_ta_by_store[['storenumber','TA']].drop_duplicates()\n",
    "\n",
    "sales_by_store_by_year_pivot=pd.merge(sales_by_store_by_year_pivot,df_ta_by_store,on=\"storenumber\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storenumber</th>\n",
       "      <th>Total_Net_Sales_2018</th>\n",
       "      <th>Total_Net_Sales_2019</th>\n",
       "      <th>TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000</td>\n",
       "      <td>159149.68</td>\n",
       "      <td>97871.02</td>\n",
       "      <td>17_['0000', '0002', '0003', '0006', '0010', '0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002</td>\n",
       "      <td>118417.05</td>\n",
       "      <td>122197.07</td>\n",
       "      <td>17_['0000', '0002', '0003', '0006', '0010', '0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  storenumber  Total_Net_Sales_2018  Total_Net_Sales_2019  \\\n",
       "0        0000             159149.68              97871.02   \n",
       "1        0002             118417.05             122197.07   \n",
       "\n",
       "                                                  TA  \n",
       "0  17_['0000', '0002', '0003', '0006', '0010', '0...  \n",
       "1  17_['0000', '0002', '0003', '0006', '0010', '0...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_by_store_by_year_pivot.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df_store_count=sales_by_store_by_year_pivot.groupby('TA')['storenumber'].count().to_frame().reset_index().rename(columns={\"storenumber\":\"same_store_count\"})\n",
    "output_df_store_list=sales_by_store_by_year_pivot.groupby('TA')['storenumber'].apply(list).to_frame().reset_index().rename(columns={\"storenumber\":\"same_store_list\"})\n",
    "output_df_store_sales=sales_by_store_by_year_pivot.groupby('TA')['Total_Net_Sales_2018','Total_Net_Sales_2019'].sum().reset_index()\n",
    "\n",
    "\n",
    "output_df=pd.merge(output_df_store_count,output_df_store_list,on=\"TA\",how=\"outer\")\n",
    "output_df=pd.merge(output_df,output_df_store_sales,on=\"TA\",how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_TA_info=latest_ta.parse(\"summary_by_TA\",dtype=str)\n",
    "df_TA_info=df_TA_info[['TA','Primary_DMA','DMA_list']]\n",
    "df_TA_info['DMA_list']=df_TA_info['DMA_list'].apply(lambda x: eval(x.replace(\"nan, \",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df=pd.merge(output_df,df_TA_info,on=\"TA\",how=\"left\")\n",
    "output_df=output_df[['TA','Primary_DMA','same_store_count','Total_Net_Sales_2019','Total_Net_Sales_2018','DMA_list']]\n",
    "\n",
    "output_df['DMA_count']=output_df['DMA_list'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"/home/jian/Projects/Smoothie_King/Analysis/TA_test_20190315/SK_Same_store_sales_comp_by_TA_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "output_df.to_excel(writer,\"output\",index=False)\n",
    "sales_by_store_by_year_pivot.to_excel(writer,\"Same_store_inclusion\",index=False)\n",
    "all_SameStore_sales_both_year.to_excel(writer,\"Same_store_by_week\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018_Min:  2018-01-13\n",
      "2018_Max:  2018-03-10\n",
      "2019_Min:  2019-01-12\n",
      "2019_Max:  2019-03-09\n"
     ]
    }
   ],
   "source": [
    "print(\"2018_Min: \",all_SameStore_sales_both_year[all_SameStore_sales_both_year['Year']==2018]['WeekEndDate'].min())\n",
    "print(\"2018_Max: \",all_SameStore_sales_both_year[all_SameStore_sales_both_year['Year']==2018]['WeekEndDate'].max())\n",
    "\n",
    "print(\"2019_Min: \",all_SameStore_sales_both_year[all_SameStore_sales_both_year['Year']==2019]['WeekEndDate'].min())\n",
    "print(\"2019_Max: \",all_SameStore_sales_both_year[all_SameStore_sales_both_year['Year']==2019]['WeekEndDate'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
