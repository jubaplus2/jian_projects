{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/Projects/Big_Lots/Analysis/2018_Q4/Planner_Request/Exclude_ids_purchased_mattress_Danielle_20181228'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "            \n",
    "last_saturday=datetime.datetime.now().date()-datetime.timedelta(days=datetime.datetime.now().date().weekday()+2)\n",
    "\n",
    "recent_52_weeks=[last_saturday-datetime.timedelta(days=7*x) for x in range(52)]\n",
    "recent_26_weeks=[last_saturday-datetime.timedelta(days=7*x) for x in range(26)]\n",
    "earlier_26_weeks=[last_saturday-datetime.timedelta(days=7*x) for x in range(26,52)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking for the recent weeks that haven't moved to the folder\n",
    "possible_recent_folders=[\"/home/jian/BigLots/MediaStorm_\"+str(x)+\"/\" for x in recent_52_weeks]\n",
    "recent_daily_list=[]\n",
    "for dirc in possible_recent_folders:\n",
    "    list_recent=[x for x in list(recursive_file_gen(dirc)) if (\"aily\" in x) & (\".txt\" in x) ]\n",
    "    recent_daily_list=recent_daily_list+list_recent\n",
    "recent_daily_df=pd.DataFrame({\"path\":recent_daily_list,\"date\":[datetime.datetime.strptime(x.split(\"MediaStormDailySales\")[1][:8],\"%Y%m%d\").date()-datetime.timedelta(days=3) for x in recent_daily_list]},index=[x for x in range(len(recent_daily_list))])\n",
    "\n",
    "\n",
    "list_1_after_201806=[x for x in list(recursive_file_gen(\"/home/jian/BigLots/2018_by_weeks/\")) if (\"aily\" in x) & (\".txt\" in x) ]\n",
    "folder_date=[datetime.datetime.strptime(x.split(\"/\")[len(x.split(\"/\"))-2].split(\"_\")[1],\"%Y-%m-%d\").date() for x in list_1_after_201806]\n",
    "df_1_after_201806=pd.DataFrame({\"date\":folder_date,\"path\":list_1_after_201806},index=[x for x in range(len(list_1_after_201806))])\n",
    "df_1_after_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "df_1_after_201806=df_1_after_201806.sort_values(\"date\").reset_index()\n",
    "del df_1_after_201806['index']\n",
    "\n",
    "list_2_before_201806=list(recursive_file_gen(\"/home/jian/BigLots/hist_daily_data/\"))\n",
    "folder_date=[datetime.datetime.strptime(x.split(\"/\")[len(x.split(\"/\"))-1].split(\"_\")[3].split(\".\")[0],\"%Y-%m-%d\").date() for x in list_2_before_201806]\n",
    "df_2_before_201806=pd.DataFrame({\"date\":folder_date,\"path\":list_2_before_201806},index=[x for x in range(len(list_2_before_201806))])\n",
    "df_2_before_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "df_2_before_201806=df_2_before_201806.sort_values('date').reset_index()\n",
    "del df_2_before_201806['index']\n",
    "df_2_before_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "\n",
    "all_daily_path_df=df_2_before_201806.append(df_1_after_201806).append(recent_daily_df)\n",
    "daily_recent_26weeks_list=all_daily_path_df[all_daily_path_df['date'].isin(recent_26_weeks)]['path'].tolist()\n",
    "daily_earlier_26weeks_list=all_daily_path_df[all_daily_path_df['date'].isin(earlier_26_weeks)]['path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 2018-12-28 13:29:51.465121\n",
      "1 2018-12-28 13:31:01.645426\n",
      "2 2018-12-28 13:31:56.039532\n",
      "3 2018-12-28 13:32:40.152656\n",
      "4 2018-12-28 13:33:10.093660\n",
      "5 2018-12-28 13:33:47.529031\n",
      "6 2018-12-28 13:34:28.045650\n",
      "7 2018-12-28 13:35:03.302113\n",
      "8 2018-12-28 13:35:38.610269\n",
      "9 2018-12-28 13:36:16.382552\n",
      "10 2018-12-28 13:36:59.713593\n",
      "11 2018-12-28 13:37:35.086022\n",
      "12 2018-12-28 13:38:19.963318\n",
      "13 2018-12-28 13:38:57.047471\n",
      "14 2018-12-28 13:39:55.003758\n",
      "15 2018-12-28 13:40:57.395066\n",
      "16 2018-12-28 13:41:31.704362\n",
      "17 2018-12-28 13:42:27.404257\n",
      "18 2018-12-28 13:43:15.125433\n",
      "19 2018-12-28 13:43:45.599599\n",
      "20 2018-12-28 13:44:20.163336\n",
      "21 2018-12-28 13:44:58.500237\n",
      "22 2018-12-28 13:45:52.278529\n",
      "23 2018-12-28 13:46:26.557588\n",
      "24 2018-12-28 13:48:58.956469\n",
      "25 2018-12-28 13:50:03.597477\n",
      "26 2018-12-28 13:50:48.711905\n"
     ]
    }
   ],
   "source": [
    "print(\"Start \"+str(datetime.datetime.now()))\n",
    "all_daily_df_mattress_recent_26_weeks=pd.DataFrame()\n",
    "i_count=0\n",
    "for file_path in daily_recent_26weeks_list:\n",
    "    df=pd.read_table(file_path,dtype=str,sep=\"|\",usecols=['customer_id_hashed','transaction_dt','class_code_id'])\n",
    "    df=df[df['class_code_id'].isin(['61501','61502','61503','61504','61505'])]\n",
    "    all_daily_df_mattress_recent_26_weeks=all_daily_df_mattress_recent_26_weeks.append(df)\n",
    "    i_count+=1\n",
    "    print(i_count,datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 2018-12-28 13:50:48.730174\n",
      "1 2018-12-28 13:51:11.517177\n",
      "2 2018-12-28 13:51:29.442446\n",
      "3 2018-12-28 13:51:48.561184\n",
      "4 2018-12-28 13:52:18.084296\n",
      "5 2018-12-28 13:52:45.960724\n",
      "6 2018-12-28 13:53:08.222884\n",
      "7 2018-12-28 13:53:32.011646\n",
      "8 2018-12-28 13:53:53.125433\n",
      "9 2018-12-28 13:54:08.840777\n",
      "10 2018-12-28 13:54:25.726966\n",
      "11 2018-12-28 13:54:42.396402\n",
      "12 2018-12-28 13:54:58.851618\n",
      "13 2018-12-28 13:55:15.064859\n",
      "14 2018-12-28 13:55:32.907314\n",
      "15 2018-12-28 13:55:52.307233\n",
      "16 2018-12-28 13:56:11.970281\n",
      "17 2018-12-28 13:56:26.561433\n",
      "18 2018-12-28 13:56:41.586924\n",
      "19 2018-12-28 13:56:57.739956\n",
      "20 2018-12-28 13:57:11.942579\n",
      "21 2018-12-28 13:57:25.541398\n",
      "22 2018-12-28 13:57:40.248674\n",
      "23 2018-12-28 13:57:55.464159\n",
      "24 2018-12-28 13:58:10.160436\n",
      "25 2018-12-28 13:58:28.482810\n",
      "26 2018-12-28 13:58:43.597957\n"
     ]
    }
   ],
   "source": [
    "print(\"Start \"+str(datetime.datetime.now()))\n",
    "all_daily_df_mattress_earlier_26_weeks=pd.DataFrame()\n",
    "i_count=0\n",
    "for file_path in daily_earlier_26weeks_list:\n",
    "    df=pd.read_table(file_path,dtype=str,sep=\"|\",usecols=['customer_id_hashed','transaction_dt','class_code_id'])\n",
    "    df=df[df['class_code_id'].isin(['61501','61502','61503','61504','61505'])]\n",
    "    all_daily_df_mattress_earlier_26_weeks=all_daily_df_mattress_earlier_26_weeks.append(df)\n",
    "    i_count+=1\n",
    "    print(i_count,datetime.datetime.now())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_recent_26_weeks=all_daily_df_mattress_recent_26_weeks['customer_id_hashed'].unique().tolist()\n",
    "list_recent_26_weeks.remove(np.nan)\n",
    "\n",
    "list_earilier_26_weeks=all_daily_df_mattress_earlier_26_weeks['customer_id_hashed'].unique().tolist()\n",
    "list_earilier_26_weeks.remove(np.nan)\n",
    "\n",
    "list_recent_52_weeks=list(set(list_recent_26_weeks+list_earilier_26_weeks))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping with Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_to_20180922=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/masterids_0922_From_Sp.csv\",usecols=['customer_id_hashed','email_address_hash','customer_zip_code'])\n",
    "master_to_20180922=master_to_20180922.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_recent_folders=[\"/home/jian/BigLots/MediaStorm_\"+str(x)+\"/\" for x in recent_52_weeks]\n",
    "recent_master_list=[]\n",
    "for dirc in possible_recent_folders:\n",
    "    list_recent=[x for x in list(recursive_file_gen(dirc)) if (\"aster\" in x) & (\".txt\" in x) ]\n",
    "    recent_master_list=recent_master_list+list_recent\n",
    "recent_master_df=pd.DataFrame({\"path\":recent_master_list,\"date\":[datetime.datetime.strptime(x.split(\"MediaStormMasterBiWeekly\")[1][:8],\"%Y%m%d\").date()-datetime.timedelta(days=3) for x in recent_master_list]},index=[x for x in range(len(recent_master_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_master_after_201806=[x for x in list(recursive_file_gen(\"/home/jian/BigLots/2018_by_weeks/\")) if (\"aster\" in x) & (\".txt\" in x) ]\n",
    "folder_date=[datetime.datetime.strptime(x.split(\"/\")[len(x.split(\"/\"))-2].split(\"_\")[1],\"%Y-%m-%d\").date() for x in list_master_after_201806]\n",
    "df_master_after_201806=pd.DataFrame({\"date\":folder_date,\"path\":list_master_after_201806},index=[x for x in range(len(list_master_after_201806))])\n",
    "df_master_after_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "df_master_after_201806=df_master_after_201806.sort_values(\"date\").reset_index()\n",
    "del df_master_after_201806['index']\n",
    "df_master_after_201806=df_master_after_201806[df_master_after_201806['date']>datetime.date(2018,9,22)]\n",
    "\n",
    "master_path=recent_master_df.append(df_master_after_201806)['path'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df=pd.DataFrame()\n",
    "\n",
    "for file_path in master_path:\n",
    "    df=pd.read_table(file_path,dtype=str,sep=\"|\",usecols=['customer_id_hashed','email_address_hash','customer_zip_code']).drop_duplicates()\n",
    "    combined_df=combined_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4820"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df=master_to_20180922.append(combined_df).drop_duplicates()\n",
    "del master_to_20180922\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/combined_masterids_up_to_20181215_JL.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "del combined_df['customer_zip_code']\n",
    "combined_df=combined_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchased_recent_52_weeks=pd.DataFrame({\"customer_id_hashed\":list_recent_52_weeks},index=[x for x in range(len(list_recent_52_weeks))])\n",
    "df_purchased_recent_26_weeks=pd.DataFrame({\"customer_id_hashed\":list_recent_26_weeks},index=[x for x in range(len(list_recent_26_weeks))])\n",
    "\n",
    "df_purchased_recent_52_weeks=pd.merge(df_purchased_recent_52_weeks,combined_df,on=\"customer_id_hashed\",how=\"left\")\n",
    "df_purchased_recent_26_weeks=pd.merge(df_purchased_recent_26_weeks,combined_df,on=\"customer_id_hashed\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchased_recent_52_weeks.to_csv('/home/jian/Projects/Big_Lots/Analysis/2018_Q4/Planner_Request/Exclude_ids_purchased_mattress_Danielle_20181228/BL_V1_members_purchased_mattress_in_past_52_weeks_JL_'+str(datetime.datetime.now().date())+'.csv',index=False)\n",
    "df_purchased_recent_26_weeks.to_csv('/home/jian/Projects/Big_Lots/Analysis/2018_Q4/Planner_Request/Exclude_ids_purchased_mattress_Danielle_20181228/BL_V2_members_purchased_mattress_in_past_26_weeks_JL_'+str(datetime.datetime.now().date())+'.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
