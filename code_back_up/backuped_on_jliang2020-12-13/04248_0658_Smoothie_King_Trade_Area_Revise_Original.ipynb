{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine_zips_with_any_intersection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from haversine import haversine\n",
    "import zipcodes\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_centers=json.load(open(\"/home/jian/Docs/Geo_mapping/center_of_rentrak_zip.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/home/jian/Projects/Smoothie_King/TA/data_from_Jay/zip_within_3_mile.csv\",dtype=str)\n",
    "data['zip_code']=data['zip_code'].apply(lambda x: x.zfill(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolate close stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_store_status=pd.read_excel(\"/home/jian/Projects/Smoothie_King/TA/5.StoreList.xlsx\",dtype=str)\n",
    "all_store_status['check_address']=all_store_status['Address']+\", \"+all_store_status['city']+\", \"+all_store_status['state']+all_store_status['zip']\n",
    "store_status_no_closed=all_store_status[all_store_status['status']!=\"Closed\"]\n",
    "store_status=all_store_status[all_store_status['status']==\"Closed\"]\n",
    "store_status=store_status[['storenumber','check_address','status']].rename(columns={\"storenumber\":\"store_number\"})\n",
    "store_status_no_closed=store_status_no_closed[['storenumber','check_address','status']].rename(columns={\"storenumber\":\"store_number\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.merge(data,store_status,on=\"store_number\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude_df=data[~pd.isnull(data['status'])]\n",
    "data=data[pd.isnull(data['status'])]\n",
    "data=data.reset_index()\n",
    "del data['index']\n",
    "del data['status']\n",
    "del data['check_address']\n",
    "exclude_df.to_csv(\"/home/jian/Projects/Smoothie_King/TA/excluded_stores_from_Jay_as_closed_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "\n",
    "data['zip_list']=data['zip_within_3_mile'].apply(lambda x: list(set([str(y).zfill(5) for y in eval(x)])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_check=pd.merge(data,store_status_no_closed,on=\"store_number\",how=\"left\")\n",
    "# looks all right, though with 5 nan rows\n",
    "del data_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check store zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the address to fetch the lat/long, then compare with the lat/long\n",
    "# If not correct, overwrite the store zip in both the zip column and zip list column\n",
    "\n",
    "key='AIzaSyDxp8O8JKOvbuB6F5DfqyyJMYPPKwIXLdY'\n",
    "gmaps = googlemaps.Client(key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 2018-10-25 14:13:18.822531\n",
      "220 2018-10-25 14:16:23.346732\n",
      "420 2018-10-25 14:19:25.034650\n",
      "620 2018-10-25 14:22:27.503678\n",
      "820 2018-10-25 14:25:33.434338\n"
     ]
    }
   ],
   "source": [
    "data['search_address_key']=\"Smoothie King\"+\", \"+data['address']+\", \"+data['city']+\", \"+data['state']+\", \"+data['zip_code']\n",
    "data['search_lat_long_key']=data['latitude']+\", \"+data['longitude']\n",
    "\n",
    "data['google_AddressKey_lat']=np.nan\n",
    "data['google_AddressKey_lng']=np.nan\n",
    "data['google_AddressKey_address']=np.nan\n",
    "data['google_AddressKey_zip']=np.nan\n",
    "\n",
    "data['google_LLKey_lat']=np.nan\n",
    "data['google_LLKey_lng']=np.nan\n",
    "data['google_LLKey_address']=np.nan\n",
    "data['google_LLKey_zip']=np.nan\n",
    "\n",
    "\n",
    "for i in range(len(data)):\n",
    "    \n",
    "    search_address_key=data['search_address_key'][i]\n",
    "    response=gmaps.geocode(search_address_key)\n",
    "    \n",
    "    data['google_AddressKey_lat'][i]=response[0]['geometry']['location']['lat']\n",
    "    data['google_AddressKey_lng'][i]=response[0]['geometry']['location']['lng']\n",
    "    data['google_AddressKey_address'][i]=response[0]['formatted_address']\n",
    "    zip_code=\"00000\"\n",
    "    for j in range(len(response[0]['address_components'])):\n",
    "        if response[0]['address_components'][j]['types'][0]=='postal_code':\n",
    "            zip_code=response[0]['address_components'][j]['long_name']\n",
    "    data['google_AddressKey_zip'][i]=str(zip_code).split(\".\")[0].zfill(5)\n",
    "    \n",
    "    \n",
    "    search_LL_key=data['search_lat_long_key'][i]\n",
    "    response=gmaps.geocode(search_LL_key)\n",
    "    \n",
    "    data['google_LLKey_lat'][i]=response[0]['geometry']['location']['lat']\n",
    "    data['google_LLKey_lng'][i]=response[0]['geometry']['location']['lng']\n",
    "    data['google_LLKey_address'][i]=response[0]['formatted_address']\n",
    "    zip_code=\"00000\"\n",
    "    for j in range(len(response[0]['address_components'])):\n",
    "        if response[0]['address_components'][j]['types'][0]=='postal_code':\n",
    "            zip_code=response[0]['address_components'][j]['long_name']\n",
    "    data['google_LLKey_zip'][i]=str(zip_code).split(\".\")[0].zfill(5)\n",
    "    if i %200 ==20:\n",
    "        print(i, datetime.datetime.now())\n",
    "    \n",
    "data['google_AddressKey_zip']=data['google_AddressKey_zip'].apply(lambda x: str(int(x)).zfill(5))         \n",
    "data['google_LLKey_zip']=data['google_LLKey_zip'].apply(lambda x: str(int(x)).zfill(5))\n",
    "data=pd.merge(data,store_status_no_closed,on=\"store_number\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['check_original_zip_either']=np.where(data['zip_code']==data['google_AddressKey_zip'],\"Correct\",\n",
    "                                          np.where(data['zip_code']==data['google_LLKey_zip'],\"Correct\",\"NotSure\")\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_correct_zip=data[data['check_original_zip_either']==\"Correct\"]\n",
    "data_revise_zip=data[data['check_original_zip_either']==\"NotSure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_revise_zip.to_csv(\"/home/jian/Projects/Smoothie_King/TA/check_7_stores_to_revise_original_zips_\"+str(datetime.datetime.now().date())+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_zip_dict=data_revise_zip.set_index(['store_number']).to_dict()['google_LLKey_zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'str'>], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['zip_code'].apply(lambda x: type(x)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "data['changed_original_zip']=np.nan\n",
    "for i in range(len(data)):\n",
    "    if data['store_number'][i] in update_zip_dict.keys():\n",
    "        old_store_zip=data['zip_code'][i]\n",
    "        original_zip_list=data['zip_list'][i]\n",
    "        new_store_zip=update_zip_dict[data['store_number'][i]]\n",
    "        data['zip_code'][i]=new_store_zip\n",
    "        data['changed_original_zip'][i]=\"changed\"\n",
    "        original_zip_list.remove(old_store_zip)\n",
    "        data['zip_list'][i]=list(set(original_zip_list+[new_store_zip]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data[['store_number','store_name','address','city','state','zip_code','phone_number','store_hours',\n",
    "           'latitude','longitude','geo_accuracy','country','country_code','county','zip_within_3_mile','zip_list']]\n",
    "\n",
    "data['TA']=np.nan\n",
    "data['TA']=1\n",
    "data=data.reset_index()\n",
    "del data['index']\n",
    "df_TA_zips=pd.DataFrame({\"store\":[data['store_number'][0]]*len(data['zip_list'][0]),\"zip\":data['zip_list'][0],\"TA\":[1]*len(data['zip_list'][0])},index=[1]*len(data['zip_list'][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata[\\'lat_lng_dist\\']=np.nan\\ndata[\\'orignal_lat_lng_zip_dist\\']=np.nan\\nfor i in range(len(data)):\\n    original_center=[float(data[\\'latitude\\'][i]),float(data[\\'longitude\\'][i])]\\n    google_center=[data[\\'google_lat\\'][i],data[\\'google_lng\\'][i]]\\n    original_zip=data[\\'zip_code\\'][i]\\n    data[\\'lat_lng_dist\\'][i]=haversine(original_center,google_center,miles=True)\\n    if original_zip in zip_centers.keys():\\n        data[\\'orignal_lat_lng_zip_dist\\'][i]=haversine(original_center,zip_centers[original_zip],miles=True)\\n\\ndata[\\'Zip_Same\\']=np.where(data[\\'zip_code\\']==data[\\'google_zip\\'],\"Same\",\"Diff\")\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data['lat_lng_dist']=np.nan\n",
    "data['orignal_lat_lng_zip_dist']=np.nan\n",
    "for i in range(len(data)):\n",
    "    original_center=[float(data['latitude'][i]),float(data['longitude'][i])]\n",
    "    google_center=[data['google_lat'][i],data['google_lng'][i]]\n",
    "    original_zip=data['zip_code'][i]\n",
    "    data['lat_lng_dist'][i]=haversine(original_center,google_center,miles=True)\n",
    "    if original_zip in zip_centers.keys():\n",
    "        data['orignal_lat_lng_zip_dist'][i]=haversine(original_center,zip_centers[original_zip],miles=True)\n",
    "\n",
    "data['Zip_Same']=np.where(data['zip_code']==data['google_zip'],\"Same\",\"Diff\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_diff_zip[\\'lat_lng_dist\\']=np.nan\\nfor i in range(len(df_diff_zip)):\\n    original_center=[float(df_diff_zip[\\'latitude\\'][i]),float(df_diff_zip[\\'longitude\\'][i])]\\n    google_center=[df_diff_zip[\\'google_lat\\'][i],df_diff_zip[\\'google_lng\\'][i]]\\n    df_diff_zip[\\'lat_lng_dist\\'][i]=haversine(original_center,google_center,miles=True)\\n\\ndf_to_revise=df_diff_zip[df_diff_zip[\\'lat_lng_dist\\']>0.1]\\ndf_to_revise.to_csv(\"/home/jian/Projects/Smoothie_King/TA/check_to_revise_stores_zips_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_diff_zip['lat_lng_dist']=np.nan\n",
    "for i in range(len(df_diff_zip)):\n",
    "    original_center=[float(df_diff_zip['latitude'][i]),float(df_diff_zip['longitude'][i])]\n",
    "    google_center=[df_diff_zip['google_lat'][i],df_diff_zip['google_lng'][i]]\n",
    "    df_diff_zip['lat_lng_dist'][i]=haversine(original_center,google_center,miles=True)\n",
    "\n",
    "df_to_revise=df_diff_zip[df_diff_zip['lat_lng_dist']>0.1]\n",
    "df_to_revise.to_csv(\"/home/jian/Projects/Smoothie_King/TA/check_to_revise_stores_zips_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "TA_counter=1\n",
    "\n",
    "for i in range(1,len(data)):\n",
    "    intersection_zip=list(set(data['zip_list'][i]).intersection(set(df_TA_zips['zip'].unique().tolist())))\n",
    "    if len(intersection_zip)==0:\n",
    "        TA_counter+=1\n",
    "        df_TA_zips=df_TA_zips.append(pd.DataFrame({\"store\":[data['store_number'][i]]*len(data['zip_list'][i]),\"zip\":data['zip_list'][i],\"TA\":[TA_counter]*len(data['zip_list'][i])},index=[i]*len(data['zip_list'][i]))).drop_duplicates()\n",
    "        \n",
    "    else:\n",
    "        df_intersection=df_TA_zips[df_TA_zips['zip'].isin(intersection_zip)]\n",
    "        group_df_intersection=df_intersection.groupby(['TA'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False)\n",
    "        selected_TA=group_df_intersection['TA'][0] \n",
    "        \n",
    "        df_TA_zips_0=df_TA_zips[~df_TA_zips['TA'].isin(set(group_df_intersection['TA']))]\n",
    "        df_TA_zips_1=df_TA_zips[df_TA_zips['TA'].isin(group_df_intersection['TA'].tolist())]\n",
    "        df_TA_zips_1['TA']=selected_TA\n",
    "        df_TA_zips=df_TA_zips_0.append(df_TA_zips_1).append(pd.DataFrame({\"store\":[data['store_number'][i]]*len(data['zip_list'][i]),\"zip\":data['zip_list'][i],\"TA\":[selected_TA]*len(data['zip_list'][i])},index=[i]*len(data['zip_list'][i]))).drop_duplicates()\n",
    "        \n",
    "dict_TA_zips=df_TA_zips.set_index('zip').to_dict()['TA']\n",
    "dict_TA_store=df_TA_zips.set_index('store').to_dict()['TA']\n",
    "data['TA']=data['store_number'].apply(lambda x: dict_TA_store[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ta_num_unique=data[['TA']].drop_duplicates().reset_index()\n",
    "del df_ta_num_unique['index']\n",
    "df_ta_num_unique['new_TA']=[x+1 for x in range(len(df_ta_num_unique))]\n",
    "\n",
    "dict_ta_num_unique=df_ta_num_unique.set_index(['TA']).to_dict()['new_TA']\n",
    "data['TA']=data['TA'].apply(lambda x: dict_ta_num_unique[x])\n",
    "df_TA_zips['TA']=df_TA_zips['TA'].apply(lambda x: dict_ta_num_unique[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "summary_store=data.groupby(\"TA\")['store_number'].count().to_frame().reset_index().rename(columns={\"store_number\":\"store_count\"})\n",
    "summary_zip=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].count().to_frame().reset_index().rename(columns={\"zip\":\"zip_count\"})\n",
    "# summary_store_2=df_TA_zips[['TA','store']].drop_duplicates().groupby(\"TA\")['store'].count().to_frame().reset_index().rename(columns={\"store\":\"store_count_2\"})\n",
    "summary_store_list=data.groupby(\"TA\")['store_number'].apply(list).to_frame().reset_index().rename(columns={\"store_number\":\"store_list\"})\n",
    "summary_zip_list=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].apply(list).to_frame().reset_index().rename(columns={\"zip\":\"zip_list\"})\n",
    "\n",
    "\n",
    "\n",
    "summary_by_TA=pd.merge(summary_store,summary_zip,on=\"TA\",how=\"outer\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,summary_store_list,on=\"TA\",how=\"outer\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,summary_zip_list,on=\"TA\",how=\"outer\")\n",
    "\n",
    "# summary=pd.merge(summary,summary_store_2,on=\"TA\",how=\"outer\")\n",
    "TA_Store_zip_list=data.groupby(['TA'])['zip_code'].apply(set).to_frame().reset_index().rename(columns={\"zip_code\":\"store_zip_list\"})\n",
    "summary_by_TA=pd.merge(summary_by_TA,TA_Store_zip_list,on=\"TA\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_by_store_count=summary_by_TA.groupby(['store_count'])['TA'].count().to_frame().reset_index().rename(columns={\"TA\":\"TA_count\"})\n",
    "summary_by_store_list=summary_by_TA.groupby(['store_count'])['TA'].apply(list).to_frame().reset_index().rename(columns={\"TA\":\"TA_list\"})\n",
    "summary_by_store_count=pd.merge(summary_by_store_count,summary_by_store_list,on=\"store_count\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_zip_dist_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_zip_dist_in_TA['index']\n",
    "\n",
    "output_distance_zip_in_TA=pd.DataFrame()\n",
    "counter_k=0\n",
    "for ta,group in df_zip_dist_in_TA.groupby(['TA']):\n",
    "    group=group.reset_index()\n",
    "    del group['index']\n",
    "    \n",
    "    if len(group)>1:\n",
    "    \n",
    "        dist_list=[]\n",
    "\n",
    "        for i in range(len(group)):\n",
    "            zip_hold=group['zip'][i]\n",
    "\n",
    "            if zip_hold not in zip_centers.keys():\n",
    "                try:\n",
    "                    zip_hold_center=(zipcodes.matching(zip_hold)[0]['lat'],zipcodes.matching(zip_hold)[0]['long'])\n",
    "                except:\n",
    "                    print(\"zip not found, \",zip_hold)\n",
    "\n",
    "            else:\n",
    "                zip_hold_center=zip_centers[zip_hold]\n",
    "\n",
    "            for j in range(i+1,len(group)):\n",
    "                zip_var=group['zip'][j]\n",
    "                if zip_var not in zip_centers.keys():\n",
    "                    try:\n",
    "                        zip_var_center=(zipcodes.matching(zip_var)[0]['lat'],zipcodes.matching(zip_var)[0]['long'])\n",
    "                    except:\n",
    "                        print(\"zip not found, \",zip_hold)\n",
    "\n",
    "                else:\n",
    "                    zip_var_center=zip_centers[zip_var]\n",
    "\n",
    "                try:\n",
    "                    dist=haversine(zip_hold_center,zip_var_center,miles=True)\n",
    "                except:\n",
    "                    dist=np.nan\n",
    "\n",
    "                dist_list=dist_list+[dist]\n",
    "        df=pd.DataFrame({\"TA\":ta,\"dist_min\":min(dist_list),\"dist_max\":max(dist_list),\"dist_median\":np.median(dist_list),\"All_dist\":[dist_list]},index=[counter_k])\n",
    "        counter_k+=1\n",
    "        output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "    else:\n",
    "        df=pd.DataFrame({\"TA\":ta,\"dist_min\":0,\"dist_max\":0,\"dist_median\":0,\"All_dist\":\"single_zip\"},index=[counter_k])\n",
    "        output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_DMA=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",dtype=str,skiprows=1)\n",
    "zip_DMA=zip_DMA.iloc[:,[0,2]]\n",
    "zip_DMA.columns=['zip','DMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_city_state_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_city_state_in_TA['index']\n",
    "\n",
    "def city_of_zip(x):\n",
    "    try:\n",
    "        city=zipcodes.matching(x)[0]['city']\n",
    "    except:\n",
    "        city=np.nan\n",
    "    return city\n",
    "\n",
    "def state_of_zip(x):\n",
    "    try:\n",
    "        state=zipcodes.matching(x)[0]['state']\n",
    "    except:\n",
    "        state=np.nan\n",
    "    return state\n",
    "    \n",
    "df_city_state_in_TA['city']=df_city_state_in_TA['zip'].apply(lambda x: city_of_zip(x))\n",
    "df_city_state_in_TA['state']=df_city_state_in_TA['zip'].apply(lambda x: state_of_zip(x))\n",
    "df_city_state_in_TA['city']=df_city_state_in_TA['city']+\" (\"+df_city_state_in_TA['state']+\")\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>zip</th>\n",
       "      <th>DMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>70047</td>\n",
       "      <td>NEW ORLEANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>70031</td>\n",
       "      <td>NEW ORLEANS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA    zip          DMA\n",
       "0   3  70047  NEW ORLEANS\n",
       "1   3  70031  NEW ORLEANS"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_DMA_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_DMA_in_TA['index']\n",
    "df_DMA_in_TA=pd.merge(df_DMA_in_TA,zip_DMA,on=\"zip\",how=\"left\")\n",
    "df_DMA_in_TA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_city_TA_list=df_city_state_in_TA.groupby(['TA'])['city'].apply(set).to_frame().reset_index()\n",
    "df_city_TA_list=df_city_TA_list.rename(columns={\"city\":\"city_list\"})\n",
    "df_state_TA_list=df_city_state_in_TA.groupby(['TA'])['state'].apply(set).to_frame().reset_index()\n",
    "df_state_TA_list=df_state_TA_list.rename(columns={\"state\":\"state_list\"})\n",
    "df_DMA_TA_list=df_DMA_in_TA.groupby(['TA'])['DMA'].apply(set).to_frame().reset_index()\n",
    "df_DMA_TA_list=df_DMA_TA_list.rename(columns={\"DMA\":\"DMA_list\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>zip</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>70047</td>\n",
       "      <td>DESTREHAN (LA)</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>70031</td>\n",
       "      <td>AMA (LA)</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA    zip            city state\n",
       "0   3  70047  DESTREHAN (LA)    LA\n",
       "1   3  70031        AMA (LA)    LA"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city_state_in_TA.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter_k\n",
    "df_primary_city_state=pd.DataFrame()\n",
    "df_primary_DMA=pd.DataFrame()\n",
    "for ta,group in df_city_state_in_TA.groupby(['TA']):\n",
    "    df_city=group.groupby(['city'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_city['index']\n",
    "    primary_city=df_city['city'][0]\n",
    "    \n",
    "    df_state=group.groupby(['state'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_state['index']\n",
    "    primary_state=df_state['state'][0]\n",
    "    \n",
    "    df=pd.DataFrame({\"TA\":ta,\"Primary_City\":primary_city,\"Primary_State\":primary_state},index=[counter_k])\n",
    "    counter_k+=1\n",
    "    df_primary_city_state=df_primary_city_state.append(df)\n",
    "\n",
    "    \n",
    "for ta,group in df_DMA_in_TA.groupby(['TA']):\n",
    "    df_DMA=group.groupby(['DMA'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_DMA['index']\n",
    "    primary_DMA=df_DMA['DMA'][0]\n",
    "    \n",
    "    df=pd.DataFrame({\"TA\":ta,\"Primary_DMA\":primary_DMA},index=[counter_k])\n",
    "    counter_k+=1\n",
    "    df_primary_DMA=df_primary_DMA.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_by_TA=pd.merge(summary_by_TA,df_city_TA_list,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_state_TA_list,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_DMA_TA_list,on=\"TA\",how=\"left\")\n",
    "\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_primary_city_state,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_primary_DMA,on=\"TA\",how=\"left\")\n",
    "\n",
    "summary_by_TA=pd.merge(summary_by_TA,output_distance_zip_in_TA,on=\"TA\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['zip_within_3_mile']=data['zip_list'].apply(lambda x: str(x))\n",
    "data['latitude']=data['latitude'].astype(float)\n",
    "data['longitude']=data['longitude'].astype(float)\n",
    "data['TA']=data['TA'].astype(str)\n",
    "summary_by_TA['TA']=summary_by_TA['TA'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_by_TA['ratio_max_media']=summary_by_TA['dist_max']/summary_by_TA['dist_median']\n",
    "\n",
    "summary_by_TA_to_revise=summary_by_TA[(summary_by_TA['ratio_max_media']>2) &\\\n",
    "                                      (summary_by_TA['store_count']>=2) &\\\n",
    "                                     (summary_by_TA['dist_max']>12)]\n",
    "summary_by_TA_to_keep=summary_by_TA[(summary_by_TA['ratio_max_media']<=2) |\\\n",
    "                                      (summary_by_TA['store_count']<2) |\\\n",
    "                                     (summary_by_TA['dist_max']<=12)]\n",
    "summary_by_TA_to_revise=summary_by_TA_to_revise.reset_index()\n",
    "del summary_by_TA_to_revise['index']\n",
    "\n",
    "summary_by_TA_to_keep=summary_by_TA_to_keep.reset_index()\n",
    "del summary_by_TA_to_keep['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_keep=data[data['TA'].isin(summary_by_TA_to_keep['TA'])]\n",
    "data_revise=data[~data['TA'].isin(summary_by_TA_to_keep['TA'])]\n",
    "data_revise=data_revise.reset_index()\n",
    "del data_revise['index']\n",
    "\n",
    "\n",
    "store_lat_dict=data_revise.set_index(['store_number']).to_dict()['latitude']\n",
    "store_lng_dict=data_revise.set_index(['store_number']).to_dict()['longitude']\n",
    "\n",
    "\n",
    "store_sub_df=pd.DataFrame()\n",
    "for i in range(len(summary_by_TA_to_revise)):\n",
    "    TA=summary_by_TA_to_revise['TA'][i]\n",
    "    store_list=summary_by_TA_to_revise['store_list'][i].copy()\n",
    "    initial_dist=0\n",
    "    store_pair=[np.nan,np.nan]\n",
    "    while len(store_list)>=2:\n",
    "        store_hold=store_list[0]\n",
    "        store_list.remove(store_hold)\n",
    "        store_hold_center=[store_lat_dict[store_hold],store_lng_dict[store_hold]]\n",
    "        for store_var in store_list:\n",
    "            store_var_center=[store_lat_dict[store_var],store_lng_dict[store_var]]\n",
    "            dist=haversine(store_hold_center,store_var_center,miles=True)\n",
    "            if dist>initial_dist:\n",
    "                initial_dist=dist\n",
    "                store_pair=[store_hold,store_var]\n",
    "    store_a=store_pair[0]\n",
    "    store_b=store_pair[1]\n",
    "    \n",
    "    store_a_center=[store_lat_dict[store_a],store_lng_dict[store_a]]\n",
    "    store_b_center=[store_lat_dict[store_b],store_lng_dict[store_b]]\n",
    "    store_list=summary_by_TA_to_revise['store_list'][i].copy()\n",
    "    for store in store_list:\n",
    "        store_center=[store_lat_dict[store],store_lng_dict[store]]\n",
    "        dist_a=haversine(store_a_center,store_center,miles=True)\n",
    "        dist_b=haversine(store_b_center,store_center,miles=True)\n",
    "        if dist_a<dist_b:\n",
    "            sub_group=\"a\"\n",
    "        else:\n",
    "            sub_group=\"b\"\n",
    "        df=pd.DataFrame({\"store_number\":store,\"TA\":TA,\"sub_group\":sub_group},index=[store])\n",
    "        store_sub_df=store_sub_df.append(df)\n",
    "    \n",
    "\n",
    "                \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sub_df['TA']=store_sub_df['TA'].astype(str)\n",
    "store_sub_df['TA']=store_sub_df['TA']+\"_\"+store_sub_df['sub_group']\n",
    "store_sub_df=store_sub_df[['store_number','TA']]\n",
    "store_sub_df_dic=store_sub_df.set_index(['store_number']).to_dict()['TA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_revise['TA']=data_revise['store_number'].apply(lambda x: store_sub_df_dic[x])\n",
    "data=data_keep.append(data_revise)\n",
    "data=data.sort_values(['store_number'])\n",
    "data=data.reset_index()\n",
    "del data['index']\n",
    "data['TA']=data['TA'].apply(lambda x: str(x).zfill(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_TA_zips=pd.DataFrame()\n",
    "for i in range(len(data)):\n",
    "    df=pd.DataFrame({\"store\":[data['store_number'][i]]*len(data['zip_list'][i]),\n",
    "                     \"TA\":[data['TA'][i]]*len(data['zip_list'][i]),\n",
    "                     \"zip\":data['zip_list'][i]},index=data['zip_list'][i])\n",
    "    df_TA_zips=df_TA_zips.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_store=data.groupby(\"TA\")['store_number'].count().to_frame().reset_index().rename(columns={\"store_number\":\"store_count\"})\n",
    "summary_zip=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].count().to_frame().reset_index().rename(columns={\"zip\":\"zip_count\"})\n",
    "summary_store_list=data.groupby(\"TA\")['store_number'].apply(list).to_frame().reset_index().rename(columns={\"store_number\":\"store_list\"})\n",
    "summary_zip_list=df_TA_zips[['TA','zip']].drop_duplicates().groupby(\"TA\")['zip'].apply(list).to_frame().reset_index().rename(columns={\"zip\":\"zip_list\"})\n",
    "\n",
    "summary_by_TA=pd.merge(summary_store,summary_zip,on=\"TA\",how=\"outer\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,summary_store_list,on=\"TA\",how=\"outer\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,summary_zip_list,on=\"TA\",how=\"outer\")\n",
    "\n",
    "# summary=pd.merge(summary,summary_store_2,on=\"TA\",how=\"outer\")\n",
    "TA_Store_zip_list=data.groupby(['TA'])['zip_code'].apply(set).to_frame().reset_index().rename(columns={\"zip_code\":\"store_zip_list\"})\n",
    "summary_by_TA=pd.merge(summary_by_TA,TA_Store_zip_list,on=\"TA\",how=\"left\")\n",
    "\n",
    "\n",
    "summary_by_store_count=summary_by_TA.groupby(['store_count'])['TA'].count().to_frame().reset_index().rename(columns={\"TA\":\"TA_count\"})\n",
    "summary_by_store_list=summary_by_TA.groupby(['store_count'])['TA'].apply(list).to_frame().reset_index().rename(columns={\"TA\":\"TA_list\"})\n",
    "summary_by_store_count=pd.merge(summary_by_store_count,summary_by_store_list,on=\"store_count\",how=\"outer\")\n",
    "\n",
    "df_zip_dist_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_zip_dist_in_TA['index']\n",
    "\n",
    "output_distance_zip_in_TA=pd.DataFrame()\n",
    "counter_k=0\n",
    "for ta,group in df_zip_dist_in_TA.groupby(['TA']):\n",
    "    group=group.reset_index()\n",
    "    del group['index']\n",
    "    \n",
    "    if len(group)>1:\n",
    "    \n",
    "        dist_list=[]\n",
    "\n",
    "        for i in range(len(group)):\n",
    "            zip_hold=group['zip'][i]\n",
    "\n",
    "            if zip_hold not in zip_centers.keys():\n",
    "                try:\n",
    "                    zip_hold_center=(zipcodes.matching(zip_hold)[0]['lat'],zipcodes.matching(zip_hold)[0]['long'])\n",
    "                except:\n",
    "                    print(\"zip not found, \",zip_hold)\n",
    "\n",
    "            else:\n",
    "                zip_hold_center=zip_centers[zip_hold]\n",
    "\n",
    "            for j in range(i+1,len(group)):\n",
    "                zip_var=group['zip'][j]\n",
    "                if zip_var not in zip_centers.keys():\n",
    "                    try:\n",
    "                        zip_var_center=(zipcodes.matching(zip_var)[0]['lat'],zipcodes.matching(zip_var)[0]['long'])\n",
    "                    except:\n",
    "                        print(\"zip not found, \",zip_hold)\n",
    "\n",
    "                else:\n",
    "                    zip_var_center=zip_centers[zip_var]\n",
    "\n",
    "                try:\n",
    "                    dist=haversine(zip_hold_center,zip_var_center,miles=True)\n",
    "                except:\n",
    "                    dist=np.nan\n",
    "\n",
    "                dist_list=dist_list+[dist]\n",
    "        df=pd.DataFrame({\"TA\":ta,\"dist_min\":min(dist_list),\"dist_max\":max(dist_list),\"dist_median\":np.median(dist_list),\"All_dist\":[dist_list]},index=[counter_k])\n",
    "        counter_k+=1\n",
    "        output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "    else:\n",
    "        df=pd.DataFrame({\"TA\":ta,\"dist_min\":0,\"dist_max\":0,\"dist_median\":0,\"All_dist\":\"single_zip\"},index=[counter_k])\n",
    "        output_distance_zip_in_TA=output_distance_zip_in_TA.append(df)\n",
    "\n",
    "zip_DMA=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",dtype=str,skiprows=1)\n",
    "zip_DMA=zip_DMA.iloc[:,[0,2]]\n",
    "zip_DMA.columns=['zip','DMA']\n",
    "\n",
    "df_city_state_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_city_state_in_TA['index']\n",
    "\n",
    "def city_of_zip(x):\n",
    "    try:\n",
    "        city=zipcodes.matching(x)[0]['city']\n",
    "    except:\n",
    "        city=np.nan\n",
    "    return city\n",
    "\n",
    "def state_of_zip(x):\n",
    "    try:\n",
    "        state=zipcodes.matching(x)[0]['state']\n",
    "    except:\n",
    "        state=np.nan\n",
    "    return state\n",
    "    \n",
    "df_city_state_in_TA['city']=df_city_state_in_TA['zip'].apply(lambda x: city_of_zip(x))\n",
    "df_city_state_in_TA['state']=df_city_state_in_TA['zip'].apply(lambda x: state_of_zip(x))\n",
    "df_city_state_in_TA['city']=df_city_state_in_TA['city']+\" (\"+df_city_state_in_TA['state']+\")\"\n",
    "\n",
    "df_DMA_in_TA=df_TA_zips[[\"TA\",\"zip\"]].drop_duplicates().reset_index()\n",
    "del df_DMA_in_TA['index']\n",
    "df_DMA_in_TA=pd.merge(df_DMA_in_TA,zip_DMA,on=\"zip\",how=\"left\")\n",
    "\n",
    "df_city_TA_list=df_city_state_in_TA.groupby(['TA'])['city'].apply(set).to_frame().reset_index()\n",
    "df_city_TA_list=df_city_TA_list.rename(columns={\"city\":\"city_list\"})\n",
    "df_state_TA_list=df_city_state_in_TA.groupby(['TA'])['state'].apply(set).to_frame().reset_index()\n",
    "df_state_TA_list=df_state_TA_list.rename(columns={\"state\":\"state_list\"})\n",
    "df_DMA_TA_list=df_DMA_in_TA.groupby(['TA'])['DMA'].apply(set).to_frame().reset_index()\n",
    "df_DMA_TA_list=df_DMA_TA_list.rename(columns={\"DMA\":\"DMA_list\"})\n",
    "\n",
    "counter_k\n",
    "df_primary_city_state=pd.DataFrame()\n",
    "df_primary_DMA=pd.DataFrame()\n",
    "for ta,group in df_city_state_in_TA.groupby(['TA']):\n",
    "    df_city=group.groupby(['city'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_city['index']\n",
    "    primary_city=df_city['city'][0]\n",
    "    \n",
    "    df_state=group.groupby(['state'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_state['index']\n",
    "    primary_state=df_state['state'][0]\n",
    "    \n",
    "    df=pd.DataFrame({\"TA\":ta,\"Primary_City\":primary_city,\"Primary_State\":primary_state},index=[counter_k])\n",
    "    counter_k+=1\n",
    "    df_primary_city_state=df_primary_city_state.append(df)\n",
    "\n",
    "    \n",
    "for ta,group in df_DMA_in_TA.groupby(['TA']):\n",
    "    df_DMA=group.groupby(['DMA'])['zip'].count().to_frame().reset_index().sort_values(['zip'],ascending=False).reset_index()\n",
    "    del df_DMA['index']\n",
    "    primary_DMA=df_DMA['DMA'][0]\n",
    "    \n",
    "    df=pd.DataFrame({\"TA\":ta,\"Primary_DMA\":primary_DMA},index=[counter_k])\n",
    "    counter_k+=1\n",
    "    df_primary_DMA=df_primary_DMA.append(df)\n",
    "    \n",
    "summary_by_TA=pd.merge(summary_by_TA,df_city_TA_list,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_state_TA_list,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_DMA_TA_list,on=\"TA\",how=\"left\")\n",
    "\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_primary_city_state,on=\"TA\",how=\"left\")\n",
    "summary_by_TA=pd.merge(summary_by_TA,df_primary_DMA,on=\"TA\",how=\"left\")\n",
    "\n",
    "summary_by_TA=pd.merge(summary_by_TA,output_distance_zip_in_TA,on=\"TA\",how=\"left\")\n",
    "summary_by_TA['Old_TA']=summary_by_TA['TA'].apply(lambda x: int(x.split(\"_\")[0]))\n",
    "summary_by_TA=summary_by_TA.sort_values(['Old_TA','TA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"/home/jian/Projects/Smoothie_King/TA/SmoothieKing_TA_revised_3_miles_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "summary_by_TA.to_excel(writer,\"summary_by_TA\",index=False)\n",
    "data.to_excel(writer,\"output_TA_by_store\",index=False)\n",
    "df_TA_zips.to_excel(writer,\"zip_TA\",index=False)\n",
    "summary_by_store_count.to_excel(writer,\"summary_by_store_count\",index=False)\n",
    "exclude_df.to_excel(writer,\"closed_stores\",index=False)\n",
    "data_revise_zip.to_excel(writer,\"stores_zips_overwritten\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
