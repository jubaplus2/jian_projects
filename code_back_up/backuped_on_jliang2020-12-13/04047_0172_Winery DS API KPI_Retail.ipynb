{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 6\n",
    "\n",
    "import argparse\n",
    "import httplib2\n",
    "import pprint\n",
    "import time\n",
    "import datetime\n",
    "from io import StringIO\n",
    "\n",
    "from apiclient.discovery import build\n",
    "from oauth2client import GOOGLE_TOKEN_URI\n",
    "from oauth2client.client import OAuth2Credentials\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "\n",
    "def create_credentials():\n",
    "    \"\"\"Create Google OAuth2 credentials.\n",
    "\n",
    "    Args:\n",
    "        client_id: Client id of a Google Cloud console project.\n",
    "        client_secret: Client secret of a Google Cloud console project.\n",
    "        refresh_token: A refresh token authorizing the Google Cloud console project\n",
    "          to access the DS data of some Google user.\n",
    "    Returns:\n",
    "        OAuth2Credentials\n",
    "    \"\"\"\n",
    "    return OAuth2Credentials(access_token=None,\n",
    "                           client_id='549790627766-qnth4m8qvuimg87pnsp4b82lhte7dk5a.apps.googleusercontent.com',\n",
    "                           client_secret='Vta4lQLOL49vVYvktkcPGRNb',\n",
    "                           refresh_token='1/ab7pCGMu3K5AveG0UOUpQ0J08vCp6uM357O8qmoPDMs',\n",
    "                           token_expiry=None,\n",
    "                           token_uri=\"https://accounts.google.com/o/oauth2/token\",\n",
    "                           user_agent=None)\n",
    "\n",
    "def get_service(credentials):\n",
    "    \"\"\"Set up a new DoubleClick Search service.\n",
    "\n",
    "    Args:\n",
    "        credentials: An OAuth2Credentials generated with create_credentials, or\n",
    "        flows in the oatuh2client.client package.\n",
    "    Returns:\n",
    "        An authorized Doubleclicksearch serivce.\n",
    "    \"\"\"\n",
    "    # Use the authorize() function of OAuth2Credentials to apply necessary credential\n",
    "    # headers to all requests.\n",
    "    http = credentials.authorize(http = httplib2.Http())\n",
    "\n",
    "    # Construct the service object for the interacting with the DoubleClick Search API.\n",
    "    service = build('doubleclicksearch', 'v2', http=http)\n",
    "    return service\n",
    "\n",
    "def poll_report(service, report_id):\n",
    "    \"\"\"Poll the API with the reportId until the report is ready, up to ten times.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        report_id: The ID DS has assigned to a report.\n",
    "    Returns:\n",
    "        pd.DataFrame, report file\n",
    "    \"\"\"\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            request = service.reports().get(reportId=report_id)\n",
    "            json_data = request.execute()\n",
    "            if json_data['isReportReady']:\n",
    "                pprint.pprint('The report is ready.')\n",
    "\n",
    "                # For large reports, DS automatically fragments the report into multiple\n",
    "                # files. The 'files' property in the JSON object that DS returns contains\n",
    "                # the list of URLs for file fragment. To download a report, DS needs to\n",
    "                # know the report ID and the index of a file fragment.\n",
    "                report = pd.DataFrame()\n",
    "                for i in range(len(json_data['files'])):\n",
    "                    pprint.pprint('Downloading fragment ' + str(i) + ' for report ' + report_id)\n",
    "                    report = report.append(download_files(service, report_id, str(i)), ignore_index = True) # See Download the report.\n",
    "                return report\n",
    "\n",
    "            else:\n",
    "                pprint.pprint('Report is not ready. I will try again.')\n",
    "                time.sleep(10)\n",
    "        except HttpError as e:\n",
    "            error = simplejson.loads(e.content)['error']['errors'][0]\n",
    "\n",
    "            # See Response Codes\n",
    "            pprint.pprint('HTTP code %d, reason %s' % (e.resp.status, error['reason']))\n",
    "            break\n",
    "        \n",
    "def download_files(service, report_id, report_fragment):\n",
    "    \"\"\"Generate and print sample report.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        report_id: The ID DS has assigned to a report.\n",
    "        report_fragment: The 0-based index of the file fragment from the files array.\n",
    "    Returns:\n",
    "        pd.DataFrame report file\n",
    "    \"\"\"\n",
    "    request = service.reports().getFile(reportId=report_id, reportFragment=report_fragment)\n",
    "    return pd.read_csv(StringIO(request.execute().decode('utf-8')))\n",
    "\n",
    "def request_report(service, start_date, end_date, columns):\n",
    "    \"\"\"Request sample report and print the report ID that DS returns. See Set Up Your Application.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        columns: list of columns will be in the report\n",
    "    Returns:\n",
    "        The report id.\n",
    "    \"\"\"\n",
    "    request = service.reports().request(\n",
    "        body={\n",
    "                \"reportScope\": {\n",
    "                    \"agencyId\": \"20100000000000932\",\n",
    "                    \"advertiserId\": \"21700000001365301\",\n",
    "                    #\"advertiserId\": \"21700000001406447\", # Callaway Apparel - Perry Ellis International\n",
    "                    #\"engineAccountId\": \"700000001564770\" # Google - Callaway Apparel\n",
    "                    #\"advertiserId\": \"21700000001131725\", # Celebrity Cruise\n",
    "                    #\"engineAccountId\": \"700000001217833\" # Celebrity Cruise\n",
    "                    #\"engineAccountId\": \"700000001561242\" # Celebrity Cruise - Juba Plus\n",
    "                },\n",
    "                \"reportType\": \"keyword\",\n",
    "                \"columns\": [{'columnName': column} for column in columns],   \n",
    "                \"timeRange\" : {\n",
    "                    \"startDate\" : start_date,\n",
    "                    \"endDate\" : end_date\n",
    "                    },\n",
    "                \n",
    "                \"filters\": [\n",
    "                    {\n",
    "                        \"column\" : { \"columnName\": \"effectiveLabels\" },\n",
    "                        \"operator\" : \"containsElement\",\n",
    "                        \"values\" : [\"KPI_Retail\",]\n",
    "                    }\n",
    "                ],\n",
    "                \n",
    "                \"downloadFormat\": \"csv\",\n",
    "                \"maxRowsPerFile\": 100000000,\n",
    "                \"statisticsCurrency\": \"agency\",\n",
    "                \"verifySingleTimeZone\": \"false\",\n",
    "                \"includeRemovedEntities\": \"false\"\n",
    "            }\n",
    "    )\n",
    "    json_data = request.execute()\n",
    "    return json_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017-08-01', '2017-12-17']\n",
      "'Report is not ready. I will try again.'\n",
      "'Report is not ready. I will try again.'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAnrvIxEUPKxXjz'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAnZR3QkSF3PLrW'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAn4uNrJ9a5J6Iu'\n"
     ]
    }
   ],
   "source": [
    "# download reports\n",
    "creds = create_credentials()\n",
    "\n",
    "service = get_service(creds)\n",
    "\n",
    "end_date = \"2017-12-17\"\n",
    "start_date = \"2017-08-01\"\n",
    "\n",
    "print ([start_date, end_date])\n",
    "\n",
    "REPORTID_nonHVA = request_report(service, start_date, end_date, \n",
    "                                 ['account','campaign', 'adGroup', 'keywordText', 'date', 'deviceSegment', \n",
    "                                  'status', 'keywordMatchType', 'keywordMaxCpc', \n",
    "                                  'topOfPageBidCurrent', 'topOfPageBidAvg',\n",
    "                                  'effectiveKeywordMaxCpc', 'impr', 'clicks', 'cost', 'effectiveLabels',\n",
    "                                  'avgCpc', 'avgPos', 'dfaRevenue'])\n",
    "REPORTID_HVA = request_report(service, start_date, end_date, \n",
    "                              ['account','campaign', 'adGroup', 'keywordText', 'status','date', 'deviceSegment', 'keywordMatchType',\n",
    "                               'floodlightActivity', 'dfaActions', 'effectiveLabels'])\n",
    "REPORTID_kw_meta = request_report(service, start_date, end_date, \n",
    "                              ['keywordText', 'account','campaign', 'adGroup', 'status', 'keywordMatchType', \n",
    "                                        'keywordMaxCpc', 'topOfPageBidCurrent', 'topOfPageBidAvg',\n",
    "                                        'avgPos'])\n",
    "\n",
    "\n",
    "non_hva = poll_report(service, REPORTID_nonHVA)\n",
    "hva = poll_report(service, REPORTID_HVA)\n",
    "kw_meta=poll_report(service, REPORTID_kw_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merged hva and non_hva\n",
    "def merge_hva_and_non_hva(hva, non_hva):\n",
    "    '''merge two reports downloaded by download_reports().\n",
    "    Args:\n",
    "        hva: pd.DataFrame\n",
    "        non_hva: pd.DataFrame\n",
    "        columns_hva: list of string\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    '''   \n",
    "    columns_hva= [\n",
    "        'All Products',\n",
    "        'Checkout',\n",
    "        'Diamond - Cabernet Sauvignon page',\n",
    "        'Diamond - Chardonnay page',\n",
    "        'Diamond - Claret page',\n",
    "        'Diamond - Diamond Red Blend page',\n",
    "        'Diamond - Malbec page',\n",
    "        'Diamond - Merlot page',\n",
    "        'Diamond - Pavilion page',\n",
    "        'Diamond - Pinot Grigio page',\n",
    "        'Diamond - Pinot Noir page',\n",
    "        'Diamond - Sauvignon Blanc page',\n",
    "        'Diamond - Syrah Shiraz page',\n",
    "        'Diamond - Zinfandel page',\n",
    "        'Diamond Adventure landing page',\n",
    "        'FFC Home Page',\n",
    "        'Membership',\n",
    "        'Membership-Join now',\n",
    "        'Our Wines Diamond Collection',\n",
    "        'Shop - Diamond Collection Wines',\n",
    "        'Shop Now',\n",
    "        'Shop online - Wine',\n",
    "        'Shopping Cart',\n",
    "        'Store Locator',\n",
    "        'Thank You Page',\n",
    "        'Visit Location']\n",
    "    \n",
    "    result = pd.DataFrame(columns=['keywordText', 'date', 'deviceSegment',]+columns_hva)\n",
    "    \n",
    "    for (account,keyword, keywordMatchType, status,adGroup, campaign, date, device), group in hva.groupby(['account','keywordText', 'keywordMatchType', 'status','adGroup', 'campaign', 'date', 'deviceSegment']):\n",
    "        df = pd.DataFrame([{\n",
    "            'account':account,\n",
    "            'keywordMatchType':keywordMatchType,\n",
    "            'campaign': campaign,\n",
    "            'adGroup': adGroup,\n",
    "            'keywordText' : keyword,\n",
    "            'status':status,\n",
    "            'date': date,\n",
    "            'deviceSegment': device\n",
    "        }])\n",
    "\n",
    "        for column in columns_hva:\n",
    "            if column in group['floodlightActivity'].values:\n",
    "                df[column] = group[group['floodlightActivity'] == column]['dfaActions'].values[0]\n",
    "            else:\n",
    "                df[column] = 0\n",
    "                \n",
    "        result = result.append(df, ignore_index = True)\n",
    "\n",
    "    # combine hva and non_hva\n",
    "    merged = non_hva.merge(result, \n",
    "                           on = ['account','campaign','keywordText', 'keywordMatchType', 'adGroup','status','date', 'deviceSegment'], \n",
    "                           how = 'left')\n",
    "\n",
    "    # generate baseline and resid compare\n",
    "    merged = merged.fillna(value = 0)\n",
    "    \n",
    "    # generate new fields\n",
    "    merged['HVA'] = merged[columns_hva].sum(axis=1).apply(int)   \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = merge_hva_and_non_hva(hva, non_hva)\n",
    "\n",
    "weekdays='Monday Tuesday Wednesday Thursday Friday Saturday Sunday'.split()\n",
    "df['weekday'] = df['date'].apply(lambda x:weekdays[datetime.datetime.strptime(x, '%Y-%m-%d').weekday()])\n",
    "\n",
    "\n",
    "columns_cum = ['impr', 'clicks', 'cost', 'dfaRevenue', 'HVA',\n",
    "                'All Products',\n",
    "                'Checkout',\n",
    "                'Diamond - Cabernet Sauvignon page',\n",
    "                'Diamond - Chardonnay page',\n",
    "                'Diamond - Claret page',\n",
    "                'Diamond - Diamond Red Blend page',\n",
    "                'Diamond - Malbec page',\n",
    "                'Diamond - Merlot page',\n",
    "                'Diamond - Pavilion page',\n",
    "                'Diamond - Pinot Grigio page',\n",
    "                'Diamond - Pinot Noir page',\n",
    "                'Diamond - Sauvignon Blanc page',\n",
    "                'Diamond - Syrah Shiraz page',\n",
    "                'Diamond - Zinfandel page',\n",
    "                'Diamond Adventure landing page',\n",
    "                'FFC Home Page',\n",
    "                'Membership',\n",
    "                'Membership-Join now',\n",
    "                'Our Wines Diamond Collection',\n",
    "                'Shop - Diamond Collection Wines',\n",
    "                'Shop Now',\n",
    "                'Shop online - Wine',\n",
    "                'Shopping Cart',\n",
    "                'Store Locator',\n",
    "                'Thank You Page',\n",
    "                'Visit Location']\n",
    "\n",
    "writer = pd.ExcelWriter('/home/jian/Projects/FFC/SEM/Sem_%s_%s.xlsx'%(start_date, end_date))\n",
    "\n",
    "for view in ['keywordText']:\n",
    "    result = df.groupby([view,'account','status','keywordMatchType','campaign','adGroup'])[columns_cum].sum()\n",
    "    result.insert(4, 'CPStoreLocator', result['cost']/(result['Visit Location']+ result['Store Locator']))\n",
    "    result.insert(4, 'cphva', result['cost']/result['HVA'])\n",
    "    result.insert(4, 'cpc', result['cost']/result['clicks'])\n",
    "    result.insert(4, 'cpm', result['cost']/result['impr'])\n",
    "    result.insert(4, 'ctr', result['clicks']/result['impr'])\n",
    "    \n",
    "    if view == 'keywordText':\n",
    "        result.reset_index(inplace=True)\n",
    "        result=pd.merge(kw_meta,result,on=['keywordText','account','status','keywordMatchType','campaign','adGroup'],how=\"right\")\n",
    "        # result = kw_meta.merge(result, left_on=['keywordText','account','status','keywordMatchType','campaign','adGroup'], right_index=True)\n",
    "        result.index = result['keywordText']\n",
    "        del result['keywordText']\n",
    "    result.sort_values(by='CPStoreLocator', inplace=True)\n",
    "    result.to_excel(writer, view)\n",
    "\n",
    "\n",
    "for view in ['date', 'weekday', 'deviceSegment']:\n",
    "    result = df.groupby(view)[columns_cum].sum()\n",
    "    result.insert(4, 'CPStoreLocator', result['cost']/(result['Visit Location']+ result['Store Locator']))\n",
    "    result.insert(4, 'cphva', result['cost']/result['HVA'])\n",
    "    result.insert(4, 'cpc', result['cost']/result['clicks'])\n",
    "    result.insert(4, 'cpm', result['cost']/result['impr'])\n",
    "    result.insert(4, 'ctr', result['clicks']/result['impr'])\n",
    "    \n",
    "\n",
    "    if view !='date':\n",
    "        result.sort_values(by='CPStoreLocator', inplace=True)\n",
    "    result.to_excel(writer, view)\n",
    "#writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually run\n",
    "\n",
    "# Filter the all lables with \"KPI_Retail\" in the DCS UI\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows=6\n",
    "\n",
    "hva_hour = pd.read_excel('/home/jian/Projects/FFC/SEM/Hour Downloads/Aug 1 to Dec 17/FFC Hour of Day Hva.xlsx')\n",
    "non_hva_hour = pd.read_excel('/home/jian/Projects/FFC/SEM/Hour Downloads/Aug 1 to Dec 17/FFC Hour of Day Non Hva.xlsx')\n",
    "\n",
    "# non_hva_hour['Cost'] = non_hva_hour['Cost'].apply(lambda x: float(x.replace(',', '')))\n",
    "\n",
    "result_non_hva = non_hva_hour.groupby('Hour of day')['Impr', 'Clicks', 'Cost','Revenue'].sum()\n",
    "\n",
    "result_non_hva.insert(0, 'hour', result_non_hva.index)\n",
    "\n",
    "columns_hva= [\n",
    "    'All Products',\n",
    "    'Checkout',\n",
    "    'Diamond - Cabernet Sauvignon page',\n",
    "    'Diamond - Chardonnay page',\n",
    "    'Diamond - Claret page',\n",
    "    'Diamond - Diamond Red Blend page',\n",
    "    'Diamond - Malbec page',\n",
    "    'Diamond - Merlot page',\n",
    "    'Diamond - Pavilion page',\n",
    "    'Diamond - Pinot Grigio page',\n",
    "    'Diamond - Pinot Noir page',\n",
    "    'Diamond - Sauvignon Blanc page',\n",
    "    'Diamond - Syrah Shiraz page',\n",
    "    'Diamond - Zinfandel page',\n",
    "    'Diamond Adventure landing page',\n",
    "    'FFC Home Page',\n",
    "    'Membership',\n",
    "    'Membership-Join now',\n",
    "    'Our Wines Diamond Collection',\n",
    "    'Shop - Diamond Collection Wines',\n",
    "    'Shop Now',\n",
    "    'Shop online - Wine',\n",
    "    'Shopping Cart',\n",
    "    'Store Locator',\n",
    "    'Thank You Page',\n",
    "    'Visit Location']\n",
    "\n",
    "result_hva = pd.DataFrame(columns=['Hour of day']+columns_hva)\n",
    "\n",
    "for hour, group in hva_hour.groupby('Hour of day'):\n",
    "    df = pd.DataFrame([{\n",
    "        'hour': hour\n",
    "    }])\n",
    "\n",
    "    for column in columns_hva:\n",
    "        if column in group['Floodlight activity'].values:\n",
    "            df[column] = group[group['Floodlight activity'] == column]['Actions'].sum()\n",
    "        else:\n",
    "            df[column] = 0\n",
    "\n",
    "    result_hva = result_hva.append(df, ignore_index = True)\n",
    "\n",
    "result = result_non_hva.merge(result_hva, on='hour', how='left')\n",
    "result.insert(5, 'HVA', result[columns_hva].sum(axis=1))\n",
    "result.insert(5, 'CPStoreLocator', result['Cost']/(result['Visit Location']+ result['Store Locator']))\n",
    "result.insert(5, 'cphva', result['Cost']/result['HVA'])\n",
    "result.insert(5, 'cpc', result['Cost']/result['Clicks'])\n",
    "result.insert(5, 'cpm', result['Cost']/result['Impr'])\n",
    "result.insert(5, 'ctr', result['Clicks']/result['Impr'])\n",
    "result.set_index('hour', inplace=True)\n",
    "result.sort_values(by='CPStoreLocator', inplace=True)\n",
    "# result.to_csv('/root/jzou/winery/sem/hour_%s_%s.csv'%(start_date, end_date), index=False)\n",
    "result.to_excel(writer, 'hour')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workbook  = writer.book\n",
    "keywordText=writer.sheets['keywordText']\n",
    "date=writer.sheets['date']\n",
    "weekday=writer.sheets['weekday']\n",
    "deviceSegment=writer.sheets['deviceSegment']\n",
    "hour=writer.sheets['hour']\n",
    "\n",
    "format1_Dollar = workbook.add_format({'num_format': '[$$-409]#,##0.00'})\n",
    "format2_Pctg = workbook.add_format({'num_format': '0.00%'})\n",
    "\n",
    "keywordText.set_column('G:I', None, format1_Dollar)\n",
    "keywordText.set_column('M:N', None, format1_Dollar)\n",
    "keywordText.set_column('P:S', None, format1_Dollar)\n",
    "keywordText.set_column('O:O', None, format2_Pctg)\n",
    "\n",
    "date.set_column('D:E', None, format1_Dollar)\n",
    "date.set_column('G:J', None, format1_Dollar)\n",
    "date.set_column('F:F', None, format2_Pctg)\n",
    "\n",
    "weekday.set_column('D:E', None, format1_Dollar)\n",
    "weekday.set_column('G:J', None, format1_Dollar)\n",
    "weekday.set_column('F:F', None, format2_Pctg)\n",
    "\n",
    "deviceSegment.set_column('D:E', None, format1_Dollar)\n",
    "deviceSegment.set_column('G:J', None, format1_Dollar)\n",
    "deviceSegment.set_column('F:F', None, format2_Pctg)\n",
    "\n",
    "hour.set_column('D:E', None, format1_Dollar)\n",
    "hour.set_column('G:J', None, format1_Dollar)\n",
    "hour.set_column('F:F', None, format2_Pctg)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
