{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/JayLiang/Desktop/Media Storm/PEI/Perry Ellis/SEM Optimization/Non_Brand_PE_From_2017-07-18_To_2017-09-20.xlsx\n"
     ]
    }
   ],
   "source": [
    "end_date = \"2017-09-20\"\n",
    "start_date = \"2017-07-18\"\n",
    "\n",
    "Save_Path='/Users/JayLiang/Desktop/Media Storm/PEI/Perry Ellis/SEM Optimization/Non_Brand_PE'+'_From_'+str(start_date)+'_To_'+str(end_date)+'.xlsx'\n",
    "print(Save_Path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 6\n",
    "import os\n",
    "import argparse\n",
    "import httplib2\n",
    "import pprint\n",
    "import time\n",
    "import datetime\n",
    "from io import StringIO\n",
    "\n",
    "from apiclient.discovery import build\n",
    "from oauth2client import GOOGLE_TOKEN_URI\n",
    "from oauth2client.client import OAuth2Credentials\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "\n",
    "def create_credentials():\n",
    "    \"\"\"Create Google OAuth2 credentials.\n",
    "\n",
    "    Args:\n",
    "        client_id: Client id of a Google Cloud console project.\n",
    "        client_secret: Client secret of a Google Cloud console project.\n",
    "        refresh_token: A refresh token authorizing the Google Cloud console project\n",
    "          to access the DS data of some Google user.\n",
    "    Returns:\n",
    "        OAuth2Credentials\n",
    "    \"\"\"\n",
    "    return OAuth2Credentials(access_token=None,\n",
    "                           client_id='549790627766-qnth4m8qvuimg87pnsp4b82lhte7dk5a.apps.googleusercontent.com',\n",
    "                           client_secret='Vta4lQLOL49vVYvktkcPGRNb',\n",
    "                           refresh_token='1/ab7pCGMu3K5AveG0UOUpQ0J08vCp6uM357O8qmoPDMs',\n",
    "                           token_expiry=None,\n",
    "                           token_uri=\"https://accounts.google.com/o/oauth2/token\",\n",
    "                           user_agent=None)\n",
    "\n",
    "def get_service(credentials):\n",
    "    \"\"\"Set up a new DoubleClick Search service.\n",
    "\n",
    "    Args:\n",
    "        credentials: An OAuth2Credentials generated with create_credentials, or\n",
    "        flows in the oatuh2client.client package.\n",
    "    Returns:\n",
    "        An authorized Doubleclicksearch serivce.\n",
    "    \"\"\"\n",
    "    # Use the authorize() function of OAuth2Credentials to apply necessary credential\n",
    "    # headers to all requests.\n",
    "    http = credentials.authorize(http = httplib2.Http())\n",
    "\n",
    "    # Construct the service object for the interacting with the DoubleClick Search API.\n",
    "    service = build('doubleclicksearch', 'v2', http=http)\n",
    "    return service\n",
    "\n",
    "def poll_report(service, report_id):\n",
    "    \"\"\"Poll the API with the reportId until the report is ready, up to ten times.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        report_id: The ID DS has assigned to a report.\n",
    "    Returns:\n",
    "        pd.DataFrame, report file\n",
    "    \"\"\"\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            request = service.reports().get(reportId=report_id)\n",
    "            json_data = request.execute()\n",
    "            if json_data['isReportReady']:\n",
    "                pprint.pprint('The report is ready.')\n",
    "\n",
    "                # For large reports, DS automatically fragments the report into multiple\n",
    "                # files. The 'files' property in the JSON object that DS returns contains\n",
    "                # the list of URLs for file fragment. To download a report, DS needs to\n",
    "                # know the report ID and the index of a file fragment.\n",
    "                report = pd.DataFrame()\n",
    "                for i in range(len(json_data['files'])):\n",
    "                    pprint.pprint('Downloading fragment ' + str(i) + ' for report ' + report_id)\n",
    "                    report = report.append(download_files(service, report_id, str(i)), ignore_index = True) # See Download the report.\n",
    "                return report\n",
    "\n",
    "            else:\n",
    "                pprint.pprint('Report is not ready. I will try again.')\n",
    "                time.sleep(10)\n",
    "        except HttpError as e:\n",
    "            error = simplejson.loads(e.content)['error']['errors'][0]\n",
    "\n",
    "            # See Response Codes\n",
    "            pprint.pprint('HTTP code %d, reason %s' % (e.resp.status, error['reason']))\n",
    "            break\n",
    "        \n",
    "def download_files(service, report_id, report_fragment):\n",
    "    \"\"\"Generate and print sample report.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        report_id: The ID DS has assigned to a report.\n",
    "        report_fragment: The 0-based index of the file fragment from the files array.\n",
    "    Returns:\n",
    "        pd.DataFrame report file\n",
    "    \"\"\"\n",
    "    request = service.reports().getFile(reportId=report_id, reportFragment=report_fragment)\n",
    "    return pd.read_csv(StringIO(request.execute().decode('utf-8')))\n",
    "\n",
    "def request_report(service, start_date, end_date, columns):\n",
    "    \"\"\"Request sample report and print the report ID that DS returns. See Set Up Your Application.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        columns: list of columns will be in the report\n",
    "    Returns:\n",
    "        The report id.\n",
    "    \"\"\"\n",
    "    request = service.reports().request(\n",
    "        body={\n",
    "                \"reportScope\": {\n",
    "                    \"agencyId\": \"20100000000000932\",\n",
    "                    \"advertiserId\": \"21700000001423776\", # Callaway Apparel - Perry Ellis International\n",
    "                    #\"engineAccountId\": \"700000001564770\" # Google - Callaway Apparel\n",
    "                    #\"advertiserId\": \"21700000001131725\", # Celebrity Cruise\n",
    "                    #\"engineAccountId\": \"700000001217833\" # Celebrity Cruise\n",
    "                    #\"engineAccountId\": \"700000001561242\" # Celebrity Cruise - Juba Plus\n",
    "                },\n",
    "                \"reportType\": \"keyword\",\n",
    "                \"columns\": [{'columnName': column} for column in columns],   \n",
    "                \"timeRange\" : {\n",
    "                    \"startDate\" : start_date,\n",
    "                    \"endDate\" : end_date\n",
    "                    },\n",
    "                \n",
    "                #\"filters\": [\n",
    "                #    {\n",
    "                #        \"column\" : { \"columnName\": \"keywordLabels\" },\n",
    "                #        \"operator\" : \"containsElement\",\n",
    "                #        \"values\" : [\"JubaNovTest\",]\n",
    "                #    }\n",
    "                #],\n",
    "                \n",
    "                \"downloadFormat\": \"csv\",\n",
    "                \"maxRowsPerFile\": 100000000,\n",
    "                \"statisticsCurrency\": \"agency\",\n",
    "                \"verifySingleTimeZone\": \"false\",\n",
    "                \"includeRemovedEntities\": \"false\"\n",
    "            }\n",
    "    )\n",
    "    json_data = request.execute()\n",
    "    return json_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-18 2017-09-20\n",
      "'Report is not ready. I will try again.'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAnlwTMxh9biVUx'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAntHWumGePHsVo'\n"
     ]
    }
   ],
   "source": [
    "# download reports\n",
    "creds = create_credentials()\n",
    "\n",
    "service = get_service(creds)\n",
    "\n",
    "\n",
    "print(start_date, end_date)\n",
    "REPORTID_nonHVA = request_report(service, start_date, end_date, \n",
    "                                 ['campaign', 'adGroup', 'keywordText', 'keywordMatchType', 'status', \n",
    "                                  'effectiveKeywordMaxCpc', 'keywordMaxCpc', 'topOfPageBidCurrent',\n",
    "                                  'topOfPageBidAvg', 'impr', 'clicks', 'cost', \n",
    "                                  'avgCpc', 'avgPos', 'dfaRevenue'])\n",
    "REPORTID_HVA = request_report(service, start_date, end_date, \n",
    "                              ['campaign', 'adGroup', 'keywordText', 'keywordMatchType', \n",
    "                               'floodlightActivity', 'dfaActions'])\n",
    "\n",
    "non_hva = poll_report(service, REPORTID_nonHVA)\n",
    "hva = poll_report(service, REPORTID_HVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Copy and include all\n",
    "def merge_hva_and_non_hva(hva, non_hva):\n",
    "    '''merge two reports downloaded by download_reports().\n",
    "    Args:\n",
    "        hva: pd.DataFrame\n",
    "        non_hva: pd.DataFrame\n",
    "        columns_hva: list of string\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    '''   \n",
    "    columns_hva= ['Perry Ellis - Store Locator',\n",
    " 'Perry Ellis - Supreme Perks',\n",
    " 'Perry Ellis - About Us',\n",
    " 'Perry Ellis - Accessories_Accessories',\n",
    " 'Perry Ellis - Accessories_Accessories_Athletic-Socks',\n",
    " 'Perry Ellis - Accessories_Accessories_Bags_Luggage',\n",
    " 'Perry Ellis - Accessories_Accessories_Belts',\n",
    " 'Perry Ellis - Accessories_Accessories_Cufflinks',\n",
    " 'Perry Ellis - Accessories_Accessories_Dress-Socks',\n",
    " 'Perry Ellis - Accessories_Accessories_Grooming-Kits',\n",
    " 'Perry Ellis - Accessories_Accessories_Hats',\n",
    " 'Perry Ellis - Accessories_Accessories_Suiting-Essentials',\n",
    " 'Perry Ellis - Accessories_Accessories_Sunglasses',\n",
    " 'Perry Ellis - Accessories_Accessories_Ties_Pocket-Squares',\n",
    " 'Perry Ellis - Accessories_Accessories_Wallets',\n",
    " 'Perry Ellis - Accessories_Accessories_Watches',\n",
    " 'Perry Ellis - Accessories_Fragrance',\n",
    " 'Perry Ellis - Accessories_Fragrance_Gift-Sets',\n",
    " 'Perry Ellis - Accessories_Fragrance_Mens-Fragrance',\n",
    " 'Perry Ellis - Accessories_Fragrance_Womens-Fragrance',\n",
    " 'Perry Ellis - Accessories_Shoes',\n",
    " 'Perry Ellis - Accessories_Shoes_Casual-Shoes',\n",
    " 'Perry Ellis - Accessories_Shoes_Dress-Shoes',\n",
    " 'Perry Ellis - Big-Tall_Casual-Shirts',\n",
    " 'Perry Ellis - Big-Tall_New-Arrivals',\n",
    " 'Perry Ellis - Big-Tall_Outerwear'#Not Found',\n",
    " 'Perry Ellis - Big-Tall_Pants',\n",
    " 'Perry Ellis - Big-Tall_Polos-Knits',\n",
    " 'Perry Ellis - Big-Tall_Sale'#Not Found',\n",
    " 'Perry Ellis - Big-Tall_Suits',\n",
    " 'Perry Ellis - Clothing_Features_360-Performance-Collection',\n",
    " 'Perry Ellis - Clothing_Features_The-Slim-Shop',\n",
    " 'Perry Ellis - Clothing_Features_The-Travel-Luxe-Collection',\n",
    " 'Perry Ellis - Clothing_Pants',\n",
    " 'Perry Ellis - Clothing_Pants_Casual Pants',\n",
    " 'Perry Ellis - Clothing_Pants_Denim',\n",
    " 'Perry Ellis - Clothing_Pants_Dress-Pants',\n",
    " 'Perry Ellis - Clothing_Pants_Shorts',\n",
    " 'Perry Ellis - Clothing_Suit-Separates_Jackets',\n",
    " 'Perry Ellis - Clothing_Suit-Separates_Pants',\n",
    " 'Perry Ellis - Clothing_Suit-Separates_Suits',\n",
    " 'Perry Ellis - Clothing_Suit-Separates_Vests',\n",
    " 'Perry Ellis - Clothing_Tops',\n",
    " 'Perry Ellis - Clothing_Tops_Casual-Shirts',\n",
    " 'Perry Ellis - Clothing_Tops_Dress-Shirts',\n",
    " 'Perry Ellis - Clothing_Tops_Outerwear',\n",
    " 'Perry Ellis - Clothing_Tops_Polo-Knits',\n",
    " 'Perry Ellis - Clothing_Tops_Sweaters',\n",
    " 'Perry Ellis - Products - Bags',\n",
    " 'Perry Ellis - Products - Belts',\n",
    " 'Perry Ellis - Products - Casual-Pants',\n",
    " 'Perry Ellis - Products - Casual-Shirts',\n",
    " 'Perry Ellis - Products - Cologne',\n",
    " 'Perry Ellis - Products - Cufflinks',\n",
    " 'Perry Ellis - Products - Denim',\n",
    " 'Perry Ellis - Products - Dress-Pants',\n",
    " 'Perry Ellis - Products - Dress-Shirts',\n",
    " 'Perry Ellis - Products - Gifables',\n",
    " 'Perry Ellis - Products - Hats',\n",
    " 'Perry Ellis - Products - Jackets-Outerwear',\n",
    " 'Perry Ellis - Products - Perfume',\n",
    " 'Perry Ellis - Products - Polo-Knits',\n",
    " 'Perry Ellis - Products - Shoes',\n",
    " 'Perry Ellis - Products - Shorts',\n",
    " 'Perry Ellis - Products - Sleepwear',\n",
    " 'Perry Ellis - Products - Socks',\n",
    " 'Perry Ellis - Products - Suit-Jackets',\n",
    " 'Perry Ellis - Products - Suit-Vests',\n",
    " 'Perry Ellis - Products - Sunglasses',\n",
    " 'Perry Ellis - Products - Sweaters',\n",
    " 'Perry Ellis - Products - Ties',\n",
    " 'Perry Ellis - Products - Underwear',\n",
    " 'Perry Ellis - Products - Wallets',\n",
    " 'Perry Ellis - Products - Watches',\n",
    " 'Perry Ellis - Sale_Accessories',\n",
    " 'Perry Ellis - Sale_Big-and-Tall',\n",
    " 'Perry Ellis - Search',\n",
    " 'Perry Ellis - Underwear',\n",
    " 'Perry Ellis - Underwear_Boxer-Briefs',\n",
    " 'Perry Ellis - Underwear_Boxers',\n",
    " 'Perry Ellis - Underwear_Multipacks',\n",
    " 'Perry Ellis - Underwear_Sleepwear',\n",
    " 'Perry Ellis - Email Sign Up Thank You Page',\n",
    " 'Perry Ellis - Order Review - All',\n",
    " 'Perry Ellis - PayPal Checkout',\n",
    " 'Perry Ellis - Secure Checkout'#Not Found',\n",
    " 'Perry Ellis - Shipping - All',\n",
    " 'Perry Ellis - Billing Payment - All',\n",
    " 'Perry Ellis - Thank You Page - Items Sold'#Not Found',\n",
    " 'Perry Ellis - Thank You Page - Transactions'#Not Found (Perry Ellis - Thank You Page - Transactions, for not use)',\n",
    " 'Perry Ellis - Add to Cart']\n",
    "    \n",
    "    result = pd.DataFrame(columns=['campaign', 'adGroup', 'keywordText', 'keywordMatchType']+columns_hva)\n",
    "    \n",
    "    for (campaign, ad_group, keyword, keyword_match_type), group in hva.groupby(['campaign', 'adGroup', \n",
    "                                                                                 'keywordText', 'keywordMatchType']):\n",
    "        df = pd.DataFrame([{\n",
    "            'campaign': campaign,\n",
    "            'adGroup': ad_group,\n",
    "            'keywordText' : keyword,\n",
    "            'keywordMatchType': keyword_match_type\n",
    "        }])\n",
    "\n",
    "        for column in columns_hva:\n",
    "            if column in group['floodlightActivity'].values:\n",
    "                df[column] = group[group['floodlightActivity'] == column]['dfaActions'].values[0]\n",
    "            else:\n",
    "                df[column] = 0\n",
    "                \n",
    "        result = result.append(df, ignore_index = True)\n",
    "\n",
    "    # combine hva and non_hva\n",
    "    merged = non_hva.merge(result, \n",
    "                           on = ['campaign', 'adGroup', 'keywordText', 'keywordMatchType'], \n",
    "                           how = 'left')\n",
    "\n",
    "    # generate baseline and resid compare\n",
    "    merged = merged.fillna(value = 0)\n",
    "    \n",
    "    # generate new fields\n",
    "    merged['HVA'] = merged[columns_hva].sum(axis=1).apply(int)   \n",
    "    merged['ROI'] = merged['dfaRevenue'] / merged['cost']\n",
    "    merged['ROI'] = merged['ROI'].fillna(0)\n",
    "    return merged[['campaign', 'adGroup', 'keywordText', 'keywordMatchType', \n",
    "                   'status', 'keywordMaxCpc', 'effectiveKeywordMaxCpc', \n",
    "                   'topOfPageBidCurrent', 'topOfPageBidAvg', 'impr', 'clicks', \n",
    "                   'HVA', 'avgCpc', 'avgPos', 'cost', 'dfaRevenue', 'ROI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_Non-Brand_Perry Ellis_Big & Tall_EST-2777 2958\n",
      "G_Non-Brand_Perry Ellis_Mens_EST-2777 2674\n",
      "B_Non-Brand_Perry Ellis_Big & Tall_EST-2777 2826\n",
      "B_Non-Brand_Perry Ellis_Mens_EST-2777 2731\n",
      "Y_Non-Brand_Perry Ellis_Big & Tall_EST-2777 2694\n",
      "Y_Non-Brand_Perry Ellis_Mens_EST-2777 2220\n"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter(Save_Path, engine='xlsxwriter')\n",
    "campaigns = {\n",
    "    'G_Non-Brand BigTall': 'G_Non-Brand_Perry Ellis_Big & Tall_EST-2777',\n",
    "    'G_Non-Brand Men': 'G_Non-Brand_Perry Ellis_Mens_EST-2777',\n",
    "    'B_Non-Brand BigTall': 'B_Non-Brand_Perry Ellis_Big & Tall_EST-2777',\n",
    "    'B_Non-Brand Men': 'B_Non-Brand_Perry Ellis_Mens_EST-2777',\n",
    "    'Y_Non-Brand BigTall': 'Y_Non-Brand_Perry Ellis_Big & Tall_EST-2777',\n",
    "    'Y_Non-Brand Men': 'Y_Non-Brand_Perry Ellis_Mens_EST-2777'\n",
    "}\n",
    "\n",
    "List=[]\n",
    "for tab in campaigns:\n",
    "    CAMPAIGN = campaigns[tab]\n",
    "    hva_1 = hva[hva['campaign'] == CAMPAIGN]\n",
    "    non_hva_1 = non_hva[non_hva['campaign'] == CAMPAIGN]\n",
    "    print(CAMPAIGN, len(hva_1))\n",
    "    df = merge_hva_and_non_hva(hva_1, non_hva_1)\n",
    "    df = df[(df['keywordText'] != 'Display Network Stats') & (df['status'] == 'Active')]\n",
    "    if len(df)==0:\n",
    "        df['group'] = None\n",
    "\n",
    "    elif len(df['ROI'].unique())==1 and df['ROI'].unique()[0]==0 and len(df['HVA'].unique())==1 and df['HVA'].unique()[0]==0:\n",
    "        df['group'] = None\n",
    "\n",
    "    else:\n",
    "        # group1\n",
    "        df.loc[(df['ROI'] > 0)&(df['clicks'] < 30), 'group'] = 'group1_lowClick'\n",
    "        df.loc[(df['ROI'] > 0)&(df['clicks'] >= 30), 'group'] = 'group1'\n",
    "\n",
    "        # group2\n",
    "        HVA_mean = df['HVA'].mean()\n",
    "        if HVA_mean < 10:\n",
    "            impr_75 = sorted(list(df['impr']))\n",
    "            HVA_mean = df[df['HVA'] > 0]['HVA'].mean()\n",
    "        impr_75 = sorted(list(df['impr']))[int(np.floor(int(len(df)*3/4)))]\n",
    "\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] >= HVA_mean)&\n",
    "               (df['clicks'] >= 30)&\n",
    "               (df['impr']>=impr_75), 'group'] = 'group2'\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] >= HVA_mean)&\n",
    "               (df['clicks'] >= 30)&\n",
    "               (df['impr']<impr_75), 'group'] = 'group2_highImpr'\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] >= HVA_mean)&\n",
    "               (df['clicks'] < 30), 'group'] = 'group2_lowClick'\n",
    "\n",
    "        impr_mean = df[df['group'].isnull()]['impr'].mean() #Not allocated group 'impr' mean\n",
    "\n",
    "        # group3\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] >= impr_mean)&\n",
    "               (df['cost'] > 0)&\n",
    "               (df['clicks'] >= 30), 'group'] = 'group3'\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] >= impr_mean)&\n",
    "               (df['cost'] > 0)&\n",
    "               (df['clicks'] < 30), 'group'] = 'group3_lowClick'\n",
    "\n",
    "        # group4\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] >= impr_mean)&\n",
    "               (df['avgPos'] <= 2)&\n",
    "               (df['cost'] == 0), 'group'] = 'group4'\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] >= impr_mean)&\n",
    "               (df['avgPos'] > 2)&\n",
    "               (df['cost'] == 0), 'group'] = 'group4_lowPosition'\n",
    "\n",
    "        # group5\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] < impr_mean)&\n",
    "               (df['clicks'] >= 30), 'group'] = 'group5'\n",
    "        df.loc[(df['ROI'] == 0)&\n",
    "               (df['HVA'] < HVA_mean)&\n",
    "               (df['impr'] < impr_mean)&\n",
    "               (df['clicks'] < 30), 'group'] = 'group5_lowClick'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        applications_SEM = {\n",
    "            'group1': 'Maintain',\n",
    "            'group1_lowClick': 'keep_running',\n",
    "            'group2': '75% Desktop, 25% Mobile',\n",
    "            'group2_highImpr': 'Type= Exact, add ngatiove KWs',\n",
    "            'group2_lowClick': 'keep_running',\n",
    "            'group3': 'pause/ Add to sitelinkes in other ad-groups',\n",
    "            'group3_lowClick': 'keep_running',\n",
    "            'group4': 'keep_running',\n",
    "            'group4_lowPosition': 'improve position to 1-2 (increase CPC)',\n",
    "            'group5': 'pause',\n",
    "            'group5_lowClick': 'keep_running'}\n",
    "\n",
    "        applications_FB_Programatic = {\n",
    "            'group1': 'Add Products',\n",
    "            'group1_lowClick': 'keep_running',\n",
    "            'group2': 'Add Products',\n",
    "            'group2_highImpr': 'Add Products',\n",
    "            'group2_lowClick': 'keep_running',\n",
    "            'group3': 'n.a',\n",
    "            'group3_lowClick': 'keep_running',\n",
    "            'group4': 'n.a',\n",
    "            'group4_lowPosition': 'n.a',\n",
    "            'group5': 'n.a',\n",
    "            'group5_lowClick': 'keep_running'}\n",
    "\n",
    "        applications_PLA = {\n",
    "            'group1': 'Maintain/add Products',\n",
    "            'group1_lowClick': 'keep_running',\n",
    "            'group2': 'Filter by Zips',\n",
    "            'group2_highImpr': 'Add Products',\n",
    "            'group2_lowClick': 'keep_running',\n",
    "            'group3': 'pause',\n",
    "            'group3_lowClick': 'keep_running',\n",
    "            'group4': 'keep running',\n",
    "            'group4_lowPosition': 'improve position to 1-2 (increase CPC)',\n",
    "            'group5': 'n.a',\n",
    "            'group5_lowClick': 'keep_running'}\n",
    "        applications_Display = {\n",
    "            'group1': 'Add Products',\n",
    "            'group1_lowClick': 'keep_running',\n",
    "            'group2': 'Filter by Zips/100% Desktop',\n",
    "            'group2_highImpr': 'n.a',\n",
    "            'group2_lowClick': 'keep_running',\n",
    "            'group3': 'n.a.',\n",
    "            'group3_lowClick': 'keep_running',\n",
    "            'group4': 'n.a',\n",
    "            'group4_lowPosition': 'n.a',\n",
    "            'group5': 'n.a',\n",
    "            'group5_lowClick': 'keep_running'}\n",
    "        criterion = {\n",
    "            'group1': 'ROI > 0',\n",
    "            'group1_lowClick': 'clicks are too low to drive conclusion',\n",
    "            'group2': 'ROI = 0, high HVA',\n",
    "            'group2_highImpr': 'ROI = 0, high HVA, high impression',\n",
    "            'group2_lowClick': 'clicks are too low to drive conclusion',\n",
    "            'group3': 'ROI = 0, low HVA, high impression, cost > 0',\n",
    "            'group3_lowClick': 'clicks are too low to drive conclusion',\n",
    "            'group4': 'ROI = 0, low HVA, high impression, cost = 0, position already high',\n",
    "            'group4_lowPosition': 'ROI = 0, low HVA, high impression, cost = 0, low position',\n",
    "            'group5': 'ROI = 0, low HVA, low impression',\n",
    "            'group5_lowClick': 'clicks are too low to drive conclusion'}\n",
    "\n",
    "        df['criterion'] = df['group'].apply(lambda x: criterion[x])\n",
    "        df['applications_FB_Programatic'] = df['group'].apply(lambda x: applications_FB_Programatic[x])\n",
    "        df['applications_SEM'] = df['group'].apply(lambda x: applications_SEM[x])\n",
    "        df['applications_PLA'] = df['group'].apply(lambda x: applications_PLA[x])\n",
    "        df['applications_Display'] = df['group'].apply(lambda x: applications_Display[x])\n",
    "    \n",
    "    df.sort_values('group', inplace=True)\n",
    "    List.append(df)\n",
    "    df.to_excel(writer, sheet_name=tab, index=False)\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "new_df = []\n",
    "for i in range(len(List)):\n",
    "    if i%3 == 0:\n",
    "        newdf = pd.concat([List[i],List[i+1],List[i+2]])\n",
    "        new_df.append(newdf)\n",
    "\n",
    "newnew_df = []        \n",
    "for summ in new_df:\n",
    "    summ['Engine']=summ['campaign'].apply(lambda x: x[0])\n",
    "    summ = pd.pivot_table(summ[['campaign','Engine','group','keywordText']],index = ['campaign','Engine','group'], aggfunc = 'count' )\n",
    "    summ.columns =summ.columns.get_level_values(0)\n",
    "    summ.reset_index(inplace=True)\n",
    "    summ['SEM RECOMMENDATION'] = summ['group'].apply(lambda x : applications_SEM[x])\n",
    "    summ['FB/PROGRAMMATIC'] = summ['group'].apply(lambda x : applications_FB_Programatic[x])\n",
    "    summ['PLA RECOMMENDATION'] = summ['group'].apply(lambda x : applications_PLA[x])\n",
    "    summ['Display RECOMMENDATION'] = summ['group'].apply(lambda x : applications_Display[x])\n",
    "    newnew_df.append(summ)\n",
    "    \n",
    "summary = pd.concat(newnew_df)\n",
    "summary_2=summary.pivot_table(summary[['campaign','Engine','SEM RECOMMENDATION','FB/PROGRAMMATIC','PLA RECOMMENDATION','Display RECOMMENDATION','keywordText']],index = ['campaign','Engine','SEM RECOMMENDATION','FB/PROGRAMMATIC','PLA RECOMMENDATION','Display RECOMMENDATION'], aggfunc = 'sum' )\n",
    "summary_2.columns=summary_2.columns.get_level_values(0)\n",
    "summary_2.reset_index(inplace=True)\n",
    "summary_2['campaign']=summary_2['campaign'].apply(lambda x: x[24:(len(x)-9)])\n",
    "summary_2.sort_values(['campaign','Engine'], inplace=True)\n",
    "summary_2=summary_2[['campaign', 'Engine', 'keywordText', 'SEM RECOMMENDATION', 'FB/PROGRAMMATIC',\n",
    "       'PLA RECOMMENDATION', 'Display RECOMMENDATION']]\n",
    "Engine_Rep_dict={'G':\"Google\",\"B\":\"Bing\",\"Y\":'Yahoo'}\n",
    "summary_2['Engine']=summary_2['Engine'].apply(lambda x:Engine_Rep_dict[x])\n",
    "summary_2.to_excel(writer, sheet_name='summary', index=False)\n",
    "\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
