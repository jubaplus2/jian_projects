{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \\nBL_engine = sqlalchemy.create_engine(\\n        BL_SQL_CONNECTION, \\n        pool_recycle=1800\\n    )\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "from haversine import haversine\n",
    "\n",
    "import gc\n",
    "# import sqlalchemy\n",
    "import json\n",
    "'''\n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_cutoff=7000 \n",
    "\n",
    "folder_store_list=\"/home/jian/BigLots/static_files/Store_list/\"\n",
    "path_nielsen_zip=\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\"\n",
    "path_json_zip_centers=\"/home/jian/Docs/Geo_mapping/updated_zip_centers_JL_2019-05-23.json\"\n",
    "path_weekly_sales_folder=\"/home/jian/BigLots/\"\n",
    "output_folder=\"./output_%s/\"%(datetime.datetime.now().date())\n",
    "dict_update_location_latlng={}\n",
    "\n",
    "\n",
    "try:\n",
    "    os.stat(output_folder)\n",
    "except:\n",
    "    os.mkdir(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_centers=json.load(open(path_json_zip_centers,\"r\"))\n",
    "\n",
    "latest_store_list=glob.glob(folder_store_list+\"*.txt\")\n",
    "latest_store_list=sorted(latest_store_list,key=lambda x: os.stat(x).st_mtime)\n",
    "latest_store_list=latest_store_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type in lat and lng: %d, %d\n",
      "4525 N ORACLE RD, TUCSON, AZ, 85705-1637, US\n",
      "32.2913637,-110.9872086\n",
      "260 REMOUNT RD, FRONT ROYAL, VA, 22630-2145, US\n",
      "1,1\n",
      "dict_update_location_latlng: \n",
      " {'4715': {'lat': 32.2913637, 'lng': -110.9872086}, '5416': {'lat': 1, 'lng': 1}}\n"
     ]
    }
   ],
   "source": [
    "def revise_store_lat_lng(path_store_list_input=latest_store_list):\n",
    "    df=pd.read_csv(path_store_list_input,sep=\"|\",dtype=str)\n",
    "    df['latitude_meas']=df['latitude_meas'].astype(float)\n",
    "    df=df[~df['location_id'].isin(['145','6990'])]\n",
    "    df=df[df['latitude_meas']==0]\n",
    "    print(\"type in lat and lng: %d, %d\")\n",
    "    for i,row in df.iterrows():\n",
    "        store_num=row['location_id']\n",
    "        address=row['address_line_1']+\", \"+row['city_nm']+\", \"+row['state_nm']+\", \"+row['zip_cd']+\", US\"\n",
    "        print(address)\n",
    "        \n",
    "        google_lat_long=str(input())\n",
    "        lat=eval(google_lat_long)[0]\n",
    "        lng=eval(google_lat_long)[1]\n",
    "        dict_update_location_latlng.update({store_num:{\"lat\":lat,\"lng\":lng}})\n",
    "    print(\"dict_update_location_latlng: \\n %s\"%dict_update_location_latlng)\n",
    "        \n",
    "revise_store_lat_lng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>DMA_set</th>\n",
       "      <th>ST_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00501</td>\n",
       "      <td>{'NEW YORK'}</td>\n",
       "      <td>{'NY'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00544</td>\n",
       "      <td>{'NEW YORK'}</td>\n",
       "      <td>{'NY'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001</td>\n",
       "      <td>{'SPRINGFIELD-HOLYOKE'}</td>\n",
       "      <td>{'MA'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_zip_code                  DMA_set  ST_set\n",
       "0             00501             {'NEW YORK'}  {'NY'}\n",
       "1             00544             {'NEW YORK'}  {'NY'}\n",
       "2             01001  {'SPRINGFIELD-HOLYOKE'}  {'MA'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DMA_nielsen=pd.read_excel(path_nielsen_zip,dtype=str,usecols=[0,2,6],skiprows=1)\n",
    "DMA_nielsen.columns=['customer_zip_code','DMA_set','ST_set']\n",
    "DMA_nielsen=DMA_nielsen.drop_duplicates()\n",
    "def func_set_str(x):\n",
    "    return str(set(x))\n",
    "DMA_nielsen=DMA_nielsen.groupby(\"customer_zip_code\")['DMA_set','ST_set'].agg(func_set_str).reset_index()\n",
    "DMA_nielsen.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py:166: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'2019-07-19'\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_sql_start_date=\"'\"+str(pd.read_sql(\"select max(transaction_dt) from Pred_POS_Department;\",con=BL_engine).iloc[0,0]-datetime.timedelta(days=365))+\"'\"\n",
    "str_sql_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select t1.customer_id_hashed, t_crm.customer_zip_code, t1.location_id, total_sales, total_trans from (select customer_id_hashed, location_id, sum(sales) as total_sales, count(distinct trans_order_since_18Q1) as total_trans from Pred_POS_Department where sales>1 and transaction_dt >= '2019-07-19' group by customer_id_hashed, location_id) as t1 left join BL_Rewards_Master as t_crm on t1.customer_id_hashed=t_crm.customer_id_hashed;\n"
     ]
    }
   ],
   "source": [
    "query=\"select t1.customer_id_hashed, t_crm.customer_zip_code, t1.location_id, total_sales, total_trans from \\\n",
    "(select customer_id_hashed, location_id, sum(sales) as total_sales, count(distinct trans_order_since_18Q1) as total_trans \\\n",
    "from Pred_POS_Department \\\n",
    "where sales>1 and transaction_dt >= %s \\\n",
    "group by customer_id_hashed, location_id) as t1 \\\n",
    "left join BL_Rewards_Master as t_crm \\\n",
    "on t1.customer_id_hashed=t_crm.customer_id_hashed;\" %str_sql_start_date\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-22 19:29:54.032732\n",
      "2020-07-22 20:21:52.430399\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "df_sales_by_id=pd.read_sql(query,con=BL_engine)\n",
    "df_sales_by_id['location_id']=df_sales_by_id['location_id'].astype(str)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25778930, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_by_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25775698, 5) 19637850\n",
      "total rewards sales: 3908668650\n",
      "total rewards trans: 84372071\n"
     ]
    }
   ],
   "source": [
    "# filtered out id sales higher than 7000\n",
    "df_sales_by_id=df_sales_by_id[pd.notnull(df_sales_by_id['customer_id_hashed'])]\n",
    "df_sales_by_id=df_sales_by_id[df_sales_by_id['total_sales']<sales_cutoff]\n",
    "print(df_sales_by_id.shape,df_sales_by_id['customer_id_hashed'].nunique())\n",
    "\n",
    "#QC\n",
    "print(\"total rewards sales: %d\"%df_sales_by_id['total_sales'].sum())\n",
    "print(\"total rewards trans: %d\"%df_sales_by_id['total_trans'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_weekly_sales_files 53\n"
     ]
    }
   ],
   "source": [
    "n_open_dates_threshold=60\n",
    "# also recent sales in 1 month\n",
    "# read_from_store_level\n",
    "def recursive_file_gen(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "list_file_store_sales=list(recursive_file_gen(path_weekly_sales_folder))\n",
    "list_file_store_sales=[x for x in list_file_store_sales if \"salesweekly\" in x.lower() and x[-4:]==\".txt\" and \"/MediaStorm_\" in x]\n",
    "list_file_store_sales=[x for x in list_file_store_sales if x.split(\"/MediaStorm_\")[1][:10] >= str_sql_start_date.replace(\"'\",\"\")]\n",
    "print(\"len_weekly_sales_files\",len(list_file_store_sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_open_weeks=pd.DataFrame()\n",
    "\n",
    "for file in list_file_store_sales:\n",
    "    df=pd.read_table(file,sep=\"|\",usecols=[\"location_id\",\"week_end_dt\",\"gross_sales_amt\"]).drop_duplicates()\n",
    "    df=df[df['gross_sales_amt']>0]\n",
    "    df_store_open_weeks=df_store_open_weeks.append(df)\n",
    "\n",
    "df_store_open_weeks=df_store_open_weeks.groupby(\"location_id\")['week_end_dt'].agg(['max','nunique']).reset_index()\n",
    "df_store_open_weeks['location_id']=df_store_open_weeks['location_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1397"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date=df_store_open_weeks['max'].max()\n",
    "date_one_month_ago=datetime.datetime.strptime(max_date,\"%Y-%m-%d\").date()-datetime.timedelta(days=4*7)\n",
    "\n",
    "list_store_inclusions=df_store_open_weeks[df_store_open_weeks['max']>=str(date_one_month_ago)]\n",
    "list_store_inclusions=list_store_inclusions[list_store_inclusions['nunique']>=8]\n",
    "list_store_inclusions=list_store_inclusions['location_id'].tolist()\n",
    "len(list_store_inclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2041538, 5)\n",
      "3388012337.3999968 75928401 22194168\n",
      "[<class 'str'>]\n",
      "[<class 'str'>]\n",
      "[ 5 10  4  9  6  3  1  2  8]\n"
     ]
    }
   ],
   "source": [
    "agg_func={\"total_sales\":\"sum\",\"total_trans\":\"sum\",\"customer_id_hashed\":\"nunique\"}\n",
    "\n",
    "df_sales_by_zip=df_sales_by_id.groupby([\"location_id\",\"customer_zip_code\"])['total_sales','total_trans','customer_id_hashed'].agg(agg_func).reset_index()\n",
    "df_sales_by_zip=df_sales_by_zip.rename(columns={\"total_sales\":\"sales\",\"total_trans\":\"trans\",\"customer_id_hashed\":\"id_count\"})\n",
    "# zip nan removed\n",
    "\n",
    "print(df_sales_by_zip.shape)\n",
    "print(df_sales_by_zip['sales'].sum(),df_sales_by_zip['trans'].sum(),df_sales_by_zip['id_count'].sum())\n",
    "\n",
    "print(df_sales_by_zip['location_id'].apply(type).unique())\n",
    "print(df_sales_by_zip['customer_zip_code'].apply(type).unique())\n",
    "print(df_sales_by_zip['customer_zip_code'].apply(len).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1846612, 5)\n",
      "3321986058.969999 74729729 21653273\n"
     ]
    }
   ],
   "source": [
    "# ecommer removed\n",
    "df_sales_by_zip=df_sales_by_zip[df_sales_by_zip['location_id'].isin(list_store_inclusions)]\n",
    "\n",
    "df_sales_by_zip=df_sales_by_zip[df_sales_by_zip['location_id']!=\"6990\"]\n",
    "df_sales_by_zip['customer_zip_code']=df_sales_by_zip['customer_zip_code'].apply(lambda x: x.split(\"-\")[0].split(\" \")[0].zfill(5)[:5])\n",
    "df_sales_by_zip=df_sales_by_zip.groupby([\"location_id\",\"customer_zip_code\"])['sales','trans','id_count'].sum().reset_index()\n",
    "print(df_sales_by_zip.shape)\n",
    "print(df_sales_by_zip['sales'].sum(),df_sales_by_zip['trans'].sum(),df_sales_by_zip['id_count'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>trans</th>\n",
       "      <th>id_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_validation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unknown_Zip</th>\n",
       "      <td>1.741347e+07</td>\n",
       "      <td>399504</td>\n",
       "      <td>123967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valid_Zip</th>\n",
       "      <td>3.304573e+09</td>\n",
       "      <td>74330225</td>\n",
       "      <td>21529306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sales     trans  id_count\n",
       "zip_validation                                  \n",
       "Unknown_Zip     1.741347e+07    399504    123967\n",
       "Valid_Zip       3.304573e+09  74330225  21529306"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_by_zip['zip_validation']=np.where(df_sales_by_zip['customer_zip_code'].isin(zip_centers.keys()),\"Valid_Zip\",\"Unknown_Zip\")\n",
    "df_sales_by_zip.groupby(\"zip_validation\")['sales','trans','id_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum=df_sales_by_zip.groupby(\"location_id\")['sales','trans'].sum().reset_index().rename(columns={\"sales\":\"sum_sales\",\"trans\":\"sum_trans\"})\n",
    "df_sales_by_zip=pd.merge(df_sales_by_zip,df_sum,on=\"location_id\",how=\"left\")\n",
    "del df_sum\n",
    "\n",
    "\n",
    "# sales label\n",
    "\n",
    "df_sales_by_zip=df_sales_by_zip.sort_values(['location_id','sales'],ascending=[True,False])\n",
    "df_sales_by_zip['cum_sum_sales']=df_sales_by_zip.groupby(['location_id'])['sales'].cumsum()\n",
    "df_sales_max=df_sales_by_zip.drop_duplicates(\"location_id\",keep=\"first\")\n",
    "df_sales_max_index=df_sales_max.index\n",
    "\n",
    "df_sales_by_zip['sales_pctg_cum']=df_sales_by_zip['cum_sum_sales']/df_sales_by_zip['sum_sales']\n",
    "df_sales_by_zip['sales_label']=np.where(df_sales_by_zip.index.isin(df_sales_max_index),\"P\",\n",
    "                                        np.where(df_sales_by_zip['sales_pctg_cum']<=0.6,\"P\",\n",
    "                                                 np.where(df_sales_by_zip['sales_pctg_cum']<=0.8,\"S\",\"T\"\n",
    "                                                         )\n",
    "                                                )\n",
    "                                       )\n",
    "\n",
    "# trans label\n",
    "df_sales_by_zip=df_sales_by_zip.sort_values(['location_id','trans'],ascending=[True,False])\n",
    "df_sales_by_zip['cum_sum_trans']=df_sales_by_zip.groupby(['location_id'])['trans'].cumsum()\n",
    "df_trans_max=df_sales_by_zip.drop_duplicates(\"location_id\",keep=\"first\")\n",
    "df_trans_max_index=df_trans_max.index\n",
    "\n",
    "df_sales_by_zip['trans_pctg_cum']=df_sales_by_zip['cum_sum_trans']/df_sales_by_zip['sum_trans']\n",
    "df_sales_by_zip['trans_label']=np.where(df_sales_by_zip.index.isin(df_trans_max_index),\"P\",\n",
    "                                        np.where(df_sales_by_zip['trans_pctg_cum']<=0.6,\"P\",\n",
    "                                                 np.where(df_sales_by_zip['trans_pctg_cum']<=0.8,\"S\",\"T\"\n",
    "                                                         )\n",
    "                                                )\n",
    "                                       )\n",
    "\n",
    "del df_sales_max\n",
    "del df_sales_max_index\n",
    "\n",
    "del df_trans_max\n",
    "del df_trans_max_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_store_location(df):\n",
    "    for store_num, store_revised_loc in dict_update_location_latlng.items():\n",
    "\n",
    "        df.loc[df['location_id']==store_num,'latitude_meas']=store_revised_loc['lat']\n",
    "        df.loc[df['location_id']==store_num,'longitude_meas']=store_revised_loc['lng']\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1846612, 16)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inner merge with recent store list\n",
    "df_store_location=pd.read_table(latest_store_list,sep=\"|\",usecols=['location_id','latitude_meas','longitude_meas'])\n",
    "df_store_location['location_id']=df_store_location['location_id'].astype(str)\n",
    "df_store_location['latitude_meas']=df_store_location['latitude_meas'].astype(float)\n",
    "df_store_location['longitude_meas']=df_store_location['longitude_meas'].astype(float)\n",
    "df_store_location=update_store_location(df_store_location)\n",
    "\n",
    "df_sales_by_zip=pd.merge(df_sales_by_zip,df_store_location,on=\"location_id\",how=\"inner\")\n",
    "df_sales_by_zip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_address=pd.read_table(latest_store_list,sep=\"|\",dtype=str,\n",
    "                               usecols=['location_id','address_line_1','address_line_2','city_nm','state_nm','zip_cd','latitude_meas','longitude_meas'])\n",
    "df_store_address['latitude_meas']=df_store_address['latitude_meas'].astype(float)\n",
    "df_store_address['longitude_meas']=df_store_address['longitude_meas'].astype(float)\n",
    "df_store_address=update_store_location(df_store_address)\n",
    "\n",
    "df_store_address=df_store_address[~df_store_address['location_id'].isin([\"145\",\"6990\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>sales</th>\n",
       "      <th>trans</th>\n",
       "      <th>id_count</th>\n",
       "      <th>zip_validation</th>\n",
       "      <th>sum_sales</th>\n",
       "      <th>sum_trans</th>\n",
       "      <th>cum_sum_sales</th>\n",
       "      <th>sales_pctg_cum</th>\n",
       "      <th>sales_label</th>\n",
       "      <th>cum_sum_trans</th>\n",
       "      <th>trans_pctg_cum</th>\n",
       "      <th>trans_label</th>\n",
       "      <th>longitude_meas</th>\n",
       "      <th>latitude_meas</th>\n",
       "      <th>dist_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43232</td>\n",
       "      <td>780565.59</td>\n",
       "      <td>18645</td>\n",
       "      <td>3745</td>\n",
       "      <td>Valid_Zip</td>\n",
       "      <td>3137532.28</td>\n",
       "      <td>65332</td>\n",
       "      <td>780565.59</td>\n",
       "      <td>0.248783</td>\n",
       "      <td>P</td>\n",
       "      <td>18645</td>\n",
       "      <td>0.285388</td>\n",
       "      <td>P</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>2.717659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43207</td>\n",
       "      <td>427723.96</td>\n",
       "      <td>7438</td>\n",
       "      <td>1959</td>\n",
       "      <td>Valid_Zip</td>\n",
       "      <td>3137532.28</td>\n",
       "      <td>65332</td>\n",
       "      <td>1208289.55</td>\n",
       "      <td>0.385108</td>\n",
       "      <td>P</td>\n",
       "      <td>26083</td>\n",
       "      <td>0.399238</td>\n",
       "      <td>P</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>2.955574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>43209</td>\n",
       "      <td>290590.66</td>\n",
       "      <td>7335</td>\n",
       "      <td>1395</td>\n",
       "      <td>Valid_Zip</td>\n",
       "      <td>3137532.28</td>\n",
       "      <td>65332</td>\n",
       "      <td>1498880.21</td>\n",
       "      <td>0.477726</td>\n",
       "      <td>P</td>\n",
       "      <td>33418</td>\n",
       "      <td>0.511510</td>\n",
       "      <td>P</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>3.095922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>43227</td>\n",
       "      <td>205925.10</td>\n",
       "      <td>4584</td>\n",
       "      <td>1179</td>\n",
       "      <td>Valid_Zip</td>\n",
       "      <td>3137532.28</td>\n",
       "      <td>65332</td>\n",
       "      <td>1704805.31</td>\n",
       "      <td>0.543359</td>\n",
       "      <td>P</td>\n",
       "      <td>38002</td>\n",
       "      <td>0.581675</td>\n",
       "      <td>P</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>2.482874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43110</td>\n",
       "      <td>164091.28</td>\n",
       "      <td>3349</td>\n",
       "      <td>1036</td>\n",
       "      <td>Valid_Zip</td>\n",
       "      <td>3137532.28</td>\n",
       "      <td>65332</td>\n",
       "      <td>1868896.59</td>\n",
       "      <td>0.595658</td>\n",
       "      <td>P</td>\n",
       "      <td>41351</td>\n",
       "      <td>0.632936</td>\n",
       "      <td>S</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>7.142063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id customer_zip_code      sales  trans  id_count zip_validation  \\\n",
       "0           1             43232  780565.59  18645      3745      Valid_Zip   \n",
       "1           1             43207  427723.96   7438      1959      Valid_Zip   \n",
       "2           1             43209  290590.66   7335      1395      Valid_Zip   \n",
       "3           1             43227  205925.10   4584      1179      Valid_Zip   \n",
       "4           1             43110  164091.28   3349      1036      Valid_Zip   \n",
       "\n",
       "    sum_sales  sum_trans  cum_sum_sales  sales_pctg_cum sales_label  \\\n",
       "0  3137532.28      65332      780565.59        0.248783           P   \n",
       "1  3137532.28      65332     1208289.55        0.385108           P   \n",
       "2  3137532.28      65332     1498880.21        0.477726           P   \n",
       "3  3137532.28      65332     1704805.31        0.543359           P   \n",
       "4  3137532.28      65332     1868896.59        0.595658           P   \n",
       "\n",
       "   cum_sum_trans  trans_pctg_cum trans_label  longitude_meas  latitude_meas  \\\n",
       "0          18645        0.285388           P      -82.914789      39.913636   \n",
       "1          26083        0.399238           P      -82.914789      39.913636   \n",
       "2          33418        0.511510           P      -82.914789      39.913636   \n",
       "3          38002        0.581675           P      -82.914789      39.913636   \n",
       "4          41351        0.632936           S      -82.914789      39.913636   \n",
       "\n",
       "   dist_miles  \n",
       "0    2.717659  \n",
       "1    2.955574  \n",
       "2    3.095922  \n",
       "3    2.482874  \n",
       "4    7.142063  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dist_in_df(zip_cd,store_lat,store_long):\n",
    "    try:\n",
    "        dist=haversine(zip_centers[zip_cd],(store_lat,store_long),unit=\"mi\")\n",
    "    except:\n",
    "        dist=np.nan\n",
    "    return dist\n",
    "\n",
    "df_sales_by_zip['dist_miles']=df_sales_by_zip.apply(lambda x: get_dist_in_df(x['customer_zip_code'],x['latitude_meas'],x['longitude_meas']),axis=1)\n",
    "df_sales_by_zip.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23881, 17)\n"
     ]
    }
   ],
   "source": [
    "df_output_PS_50_miles=df_sales_by_zip[(df_sales_by_zip['trans_label'].isin(['P','S'])) &(df_sales_by_zip['dist_miles']<=50)]\n",
    "print(df_output_PS_50_miles.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1846612, 17)\n"
     ]
    }
   ],
   "source": [
    "print(df_sales_by_zip.shape)\n",
    "df_sales_by_zip.to_csv(\"df_sales_by_zip.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23881, 17)\n"
     ]
    }
   ],
   "source": [
    "df_output_PS_50_miles=df_sales_by_zip[(df_sales_by_zip['trans_label'].isin(['P','S'])) &(df_sales_by_zip['dist_miles']<=50)]\n",
    "print(df_output_PS_50_miles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting overlaps between stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_zip_both=df_output_PS_50_miles[['location_id','trans_label','customer_zip_code','latitude_meas','longitude_meas']].rename(columns={\"customer_zip_code\":\"zip_list_P_and_S\"}).drop_duplicates()\n",
    "df_store_zip_both=df_store_zip_both.groupby([\"location_id\",'latitude_meas','longitude_meas'])['zip_list_P_and_S'].apply(set).to_frame().reset_index()\n",
    "df_store_zip_both['zip_list_P_and_S']=df_store_zip_both['zip_list_P_and_S'].apply(lambda x: list(x))\n",
    "\n",
    "df_store_zip_P=df_output_PS_50_miles[df_output_PS_50_miles['trans_label']==\"P\"]\n",
    "df_store_zip_P=df_store_zip_P[['location_id','trans_label','customer_zip_code','latitude_meas','longitude_meas']].rename(columns={\"customer_zip_code\":\"zip_list_P\"}).drop_duplicates()\n",
    "df_store_zip_P=df_store_zip_P.groupby([\"location_id\",'latitude_meas','longitude_meas'])['zip_list_P'].apply(set).to_frame().reset_index()\n",
    "df_store_zip_P['zip_list_P']=df_store_zip_P['zip_list_P'].apply(lambda x: list(x))\n",
    "\n",
    "df_store_zip_S=df_output_PS_50_miles[df_output_PS_50_miles['trans_label']==\"S\"]\n",
    "df_store_zip_S=df_store_zip_S[['location_id','trans_label','customer_zip_code','latitude_meas','longitude_meas']].rename(columns={\"customer_zip_code\":\"zip_list_S\"}).drop_duplicates()\n",
    "df_store_zip_S=df_store_zip_S.groupby([\"location_id\",'latitude_meas','longitude_meas'])['zip_list_S'].apply(set).to_frame().reset_index()\n",
    "df_store_zip_S['zip_list_S']=df_store_zip_S['zip_list_S'].apply(lambda x: list(x))\n",
    "\n",
    "df_store_zip=pd.merge(df_store_zip_both,df_store_zip_P,on=[\"location_id\",'latitude_meas','longitude_meas'],how=\"outer\")\n",
    "df_store_zip=pd.merge(df_store_zip,df_store_zip_S,on=[\"location_id\",'latitude_meas','longitude_meas'],how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42169"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_zip_0=df_store_zip.copy()\n",
    "\n",
    "df_store_zip.columns=[\"store_A_\"+x for x in df_store_zip.columns.tolist()]\n",
    "df_store_zip_0.columns=[\"store_B_\"+x for x in df_store_zip_0.columns.tolist()]\n",
    "\n",
    "df_store_zip['key']=1\n",
    "df_store_zip_0['key']=1\n",
    "\n",
    "df_store_zip=pd.merge(df_store_zip,df_store_zip_0,on=\"key\",how=\"outer\")\n",
    "del df_store_zip_0\n",
    "\n",
    "\n",
    "df_store_zip=df_store_zip[df_store_zip['store_A_location_id']!=df_store_zip['store_B_location_id']]\n",
    "df_store_zip=df_store_zip.reset_index()\n",
    "del df_store_zip['index']\n",
    "del df_store_zip['key']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersection(list_1,list_2):\n",
    "    return list(set(list_1).intersection(set(list_2)))\n",
    "def dist_miles(lat_1,log_1,lat_2,log_2):\n",
    "    return haversine((lat_1,log_1),(lat_2,log_2),unit=\"mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_zip['intersection_both_P_S']=df_store_zip.apply(lambda x: find_intersection(x['store_A_zip_list_P_and_S'],x['store_B_zip_list_P_and_S']),axis=1)\n",
    "\n",
    "df_store_zip['count_of_overlap_zips']=df_store_zip['intersection_both_P_S'].apply(lambda x: len(x))\n",
    "df_store_zip['count_of_A_zips']=df_store_zip['store_A_zip_list_P_and_S'].apply(lambda x: len(x))\n",
    "df_store_zip['count_of_B_zips']=df_store_zip['store_B_zip_list_P_and_S'].apply(lambda x: len(x))\n",
    "df_store_zip['total_zips']=df_store_zip['count_of_A_zips']+df_store_zip['count_of_B_zips']-df_store_zip['count_of_overlap_zips']\n",
    "\n",
    "df_store_zip['overlap_pctg']=df_store_zip['count_of_overlap_zips']/df_store_zip['total_zips']\n",
    "\n",
    "df_store_zip=df_store_zip[df_store_zip['count_of_overlap_zips']>0]\n",
    "df_store_zip['dist_between_stores']=df_store_zip.apply(lambda x: dist_miles(x['store_A_latitude_meas'],x['store_A_longitude_meas'],x['store_B_latitude_meas'],x['store_B_longitude_meas']),axis=1)\n",
    "df_store_zip=df_store_zip.reset_index()\n",
    "del df_store_zip['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_zip.to_csv(\"BL_zip_overlap_between_stores_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_A_location_id</th>\n",
       "      <th>store_A_latitude_meas</th>\n",
       "      <th>store_A_longitude_meas</th>\n",
       "      <th>store_A_zip_list_P_and_S</th>\n",
       "      <th>store_A_zip_list_P</th>\n",
       "      <th>store_A_zip_list_S</th>\n",
       "      <th>store_B_location_id</th>\n",
       "      <th>store_B_latitude_meas</th>\n",
       "      <th>store_B_longitude_meas</th>\n",
       "      <th>store_B_zip_list_P_and_S</th>\n",
       "      <th>store_B_zip_list_P</th>\n",
       "      <th>store_B_zip_list_S</th>\n",
       "      <th>intersection_both_P_S</th>\n",
       "      <th>count_of_overlap_zips</th>\n",
       "      <th>count_of_A_zips</th>\n",
       "      <th>count_of_B_zips</th>\n",
       "      <th>total_zips</th>\n",
       "      <th>overlap_pctg</th>\n",
       "      <th>dist_between_stores</th>\n",
       "      <th>store_pair</th>\n",
       "      <th>store_pair_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>['43207', '43227', '43232', '43209']</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>1379</td>\n",
       "      <td>40.141346</td>\n",
       "      <td>-82.985584</td>\n",
       "      <td>['43228', '43015', '43110', '43231', '43206', ...</td>\n",
       "      <td>['43015', '43065', '43082', '43230', '43235', ...</td>\n",
       "      <td>['43228', '43110', '43231', '43206', '43207', ...</td>\n",
       "      <td>['43110', '43206', '43213', '43068', '43209', ...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>16.172965</td>\n",
       "      <td>['1', '1379']</td>\n",
       "      <td>['1', '1379']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>['43207', '43227', '43232', '43209']</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>1666</td>\n",
       "      <td>40.100960</td>\n",
       "      <td>-83.091519</td>\n",
       "      <td>['43228', '43015', '43207', '43123', '43119', ...</td>\n",
       "      <td>['43026', '43065', '43015', '43016', '43017', ...</td>\n",
       "      <td>['43228', '43202', '43230', '43040', '43229', ...</td>\n",
       "      <td>['43207', '43068', '43232', '43219']</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>15.968635</td>\n",
       "      <td>['1', '1666']</td>\n",
       "      <td>['1', '1666']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>['43207', '43227', '43232', '43209']</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>1668</td>\n",
       "      <td>40.109719</td>\n",
       "      <td>-82.922925</td>\n",
       "      <td>['43231', '43211', '43219', '43235', '43229', ...</td>\n",
       "      <td>['43229', '43082', '43081', '43231']</td>\n",
       "      <td>['43074', '43230', '43235', '43068', '43213', ...</td>\n",
       "      <td>['43213', '43068', '43209', '43232', '43219']</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>13.554885</td>\n",
       "      <td>['1', '1668']</td>\n",
       "      <td>['1', '1668']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>['43207', '43227', '43232', '43209']</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>410</td>\n",
       "      <td>40.062415</td>\n",
       "      <td>-82.964520</td>\n",
       "      <td>['43228', '43202', '43230', '43231', '43213', ...</td>\n",
       "      <td>['43224', '43229', '43219', '43211']</td>\n",
       "      <td>['43228', '43202', '43230', '43231', '43213', ...</td>\n",
       "      <td>['43213', '43068', '43209', '43207', '43227', ...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>10.611412</td>\n",
       "      <td>['1', '410']</td>\n",
       "      <td>['1', '410']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>['43207', '43227', '43232', '43209']</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>451</td>\n",
       "      <td>39.882313</td>\n",
       "      <td>-83.070668</td>\n",
       "      <td>['43228', '43026', '43103', '43223', '43207', ...</td>\n",
       "      <td>['43123']</td>\n",
       "      <td>['43228', '43026', '43103', '43223', '43207', ...</td>\n",
       "      <td>['43207']</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>8.541503</td>\n",
       "      <td>['1', '451']</td>\n",
       "      <td>['1', '451']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>['43207', '43227', '43232', '43209']</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>5092</td>\n",
       "      <td>40.002365</td>\n",
       "      <td>-83.151785</td>\n",
       "      <td>['43026', '43228', '43206', '43016', '43235', ...</td>\n",
       "      <td>['43026', '43228']</td>\n",
       "      <td>['43206', '43016', '43235', '43229', '43223', ...</td>\n",
       "      <td>['43207', '43206']</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>13.968760</td>\n",
       "      <td>['1', '5092']</td>\n",
       "      <td>['1', '5092']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>['43207', '43227', '43232', '43209']</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>5176</td>\n",
       "      <td>39.911463</td>\n",
       "      <td>-82.780957</td>\n",
       "      <td>['43110', '43130', '43062', '43125', '43213', ...</td>\n",
       "      <td>['43068', '43147']</td>\n",
       "      <td>['43130', '43110', '43062', '43125', '43213', ...</td>\n",
       "      <td>['43110', '43125', '43213', '43068', '43207', ...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>7.094196</td>\n",
       "      <td>['1', '5176']</td>\n",
       "      <td>['1', '5176']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>['43207', '43227', '43232', '43209']</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>5243</td>\n",
       "      <td>39.954666</td>\n",
       "      <td>-83.115771</td>\n",
       "      <td>['43228', '43026', '43206', '43229', '43223', ...</td>\n",
       "      <td>['43228', '43204', '43119']</td>\n",
       "      <td>['43026', '43206', '43229', '43223', '43207', ...</td>\n",
       "      <td>['43207', '43232', '43206']</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>11.018871</td>\n",
       "      <td>['1', '5243']</td>\n",
       "      <td>['1', '5243']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>['43207', '43227', '43232', '43209']</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>5324</td>\n",
       "      <td>39.941864</td>\n",
       "      <td>-82.829898</td>\n",
       "      <td>['43110', '43062', '43004', '43213', '43068', ...</td>\n",
       "      <td>['43068', '43227', '43232']</td>\n",
       "      <td>['43110', '43062', '43004', '43213', '43209', ...</td>\n",
       "      <td>['43110', '43213', '43068', '43209', '43207', ...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>4.902568</td>\n",
       "      <td>['1', '5324']</td>\n",
       "      <td>['1', '5324']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>39.913636</td>\n",
       "      <td>-82.914789</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>['43207', '43227', '43232', '43209']</td>\n",
       "      <td>['43110', '43206', '43125', '43213', '43068', ...</td>\n",
       "      <td>5356</td>\n",
       "      <td>39.988013</td>\n",
       "      <td>-83.045482</td>\n",
       "      <td>['43228', '43206', '43223', '43207', '43123', ...</td>\n",
       "      <td>['43202', '43215', '43201', '43212', '43204', ...</td>\n",
       "      <td>['43228', '43026', '43206', '43235', '43229', ...</td>\n",
       "      <td>['43206', '43213', '43209', '43207', '43232', ...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>8.621383</td>\n",
       "      <td>['1', '5356']</td>\n",
       "      <td>['1', '5356']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_A_location_id  store_A_latitude_meas  store_A_longitude_meas  \\\n",
       "0                    1              39.913636              -82.914789   \n",
       "1                    1              39.913636              -82.914789   \n",
       "2                    1              39.913636              -82.914789   \n",
       "3                    1              39.913636              -82.914789   \n",
       "4                    1              39.913636              -82.914789   \n",
       "5                    1              39.913636              -82.914789   \n",
       "6                    1              39.913636              -82.914789   \n",
       "7                    1              39.913636              -82.914789   \n",
       "8                    1              39.913636              -82.914789   \n",
       "9                    1              39.913636              -82.914789   \n",
       "\n",
       "                            store_A_zip_list_P_and_S  \\\n",
       "0  ['43110', '43206', '43125', '43213', '43068', ...   \n",
       "1  ['43110', '43206', '43125', '43213', '43068', ...   \n",
       "2  ['43110', '43206', '43125', '43213', '43068', ...   \n",
       "3  ['43110', '43206', '43125', '43213', '43068', ...   \n",
       "4  ['43110', '43206', '43125', '43213', '43068', ...   \n",
       "5  ['43110', '43206', '43125', '43213', '43068', ...   \n",
       "6  ['43110', '43206', '43125', '43213', '43068', ...   \n",
       "7  ['43110', '43206', '43125', '43213', '43068', ...   \n",
       "8  ['43110', '43206', '43125', '43213', '43068', ...   \n",
       "9  ['43110', '43206', '43125', '43213', '43068', ...   \n",
       "\n",
       "                     store_A_zip_list_P  \\\n",
       "0  ['43207', '43227', '43232', '43209']   \n",
       "1  ['43207', '43227', '43232', '43209']   \n",
       "2  ['43207', '43227', '43232', '43209']   \n",
       "3  ['43207', '43227', '43232', '43209']   \n",
       "4  ['43207', '43227', '43232', '43209']   \n",
       "5  ['43207', '43227', '43232', '43209']   \n",
       "6  ['43207', '43227', '43232', '43209']   \n",
       "7  ['43207', '43227', '43232', '43209']   \n",
       "8  ['43207', '43227', '43232', '43209']   \n",
       "9  ['43207', '43227', '43232', '43209']   \n",
       "\n",
       "                                  store_A_zip_list_S  store_B_location_id  \\\n",
       "0  ['43110', '43206', '43125', '43213', '43068', ...                 1379   \n",
       "1  ['43110', '43206', '43125', '43213', '43068', ...                 1666   \n",
       "2  ['43110', '43206', '43125', '43213', '43068', ...                 1668   \n",
       "3  ['43110', '43206', '43125', '43213', '43068', ...                  410   \n",
       "4  ['43110', '43206', '43125', '43213', '43068', ...                  451   \n",
       "5  ['43110', '43206', '43125', '43213', '43068', ...                 5092   \n",
       "6  ['43110', '43206', '43125', '43213', '43068', ...                 5176   \n",
       "7  ['43110', '43206', '43125', '43213', '43068', ...                 5243   \n",
       "8  ['43110', '43206', '43125', '43213', '43068', ...                 5324   \n",
       "9  ['43110', '43206', '43125', '43213', '43068', ...                 5356   \n",
       "\n",
       "   store_B_latitude_meas  store_B_longitude_meas  \\\n",
       "0              40.141346              -82.985584   \n",
       "1              40.100960              -83.091519   \n",
       "2              40.109719              -82.922925   \n",
       "3              40.062415              -82.964520   \n",
       "4              39.882313              -83.070668   \n",
       "5              40.002365              -83.151785   \n",
       "6              39.911463              -82.780957   \n",
       "7              39.954666              -83.115771   \n",
       "8              39.941864              -82.829898   \n",
       "9              39.988013              -83.045482   \n",
       "\n",
       "                            store_B_zip_list_P_and_S  \\\n",
       "0  ['43228', '43015', '43110', '43231', '43206', ...   \n",
       "1  ['43228', '43015', '43207', '43123', '43119', ...   \n",
       "2  ['43231', '43211', '43219', '43235', '43229', ...   \n",
       "3  ['43228', '43202', '43230', '43231', '43213', ...   \n",
       "4  ['43228', '43026', '43103', '43223', '43207', ...   \n",
       "5  ['43026', '43228', '43206', '43016', '43235', ...   \n",
       "6  ['43110', '43130', '43062', '43125', '43213', ...   \n",
       "7  ['43228', '43026', '43206', '43229', '43223', ...   \n",
       "8  ['43110', '43062', '43004', '43213', '43068', ...   \n",
       "9  ['43228', '43206', '43223', '43207', '43123', ...   \n",
       "\n",
       "                                  store_B_zip_list_P  \\\n",
       "0  ['43015', '43065', '43082', '43230', '43235', ...   \n",
       "1  ['43026', '43065', '43015', '43016', '43017', ...   \n",
       "2               ['43229', '43082', '43081', '43231']   \n",
       "3               ['43224', '43229', '43219', '43211']   \n",
       "4                                          ['43123']   \n",
       "5                                 ['43026', '43228']   \n",
       "6                                 ['43068', '43147']   \n",
       "7                        ['43228', '43204', '43119']   \n",
       "8                        ['43068', '43227', '43232']   \n",
       "9  ['43202', '43215', '43201', '43212', '43204', ...   \n",
       "\n",
       "                                  store_B_zip_list_S  \\\n",
       "0  ['43228', '43110', '43231', '43206', '43207', ...   \n",
       "1  ['43228', '43202', '43230', '43040', '43229', ...   \n",
       "2  ['43074', '43230', '43235', '43068', '43213', ...   \n",
       "3  ['43228', '43202', '43230', '43231', '43213', ...   \n",
       "4  ['43228', '43026', '43103', '43223', '43207', ...   \n",
       "5  ['43206', '43016', '43235', '43229', '43223', ...   \n",
       "6  ['43130', '43110', '43062', '43125', '43213', ...   \n",
       "7  ['43026', '43206', '43229', '43223', '43207', ...   \n",
       "8  ['43110', '43062', '43004', '43213', '43209', ...   \n",
       "9  ['43228', '43026', '43206', '43235', '43229', ...   \n",
       "\n",
       "                               intersection_both_P_S  count_of_overlap_zips  \\\n",
       "0  ['43110', '43206', '43213', '43068', '43209', ...                      8   \n",
       "1               ['43207', '43068', '43232', '43219']                      4   \n",
       "2      ['43213', '43068', '43209', '43232', '43219']                      5   \n",
       "3  ['43213', '43068', '43209', '43207', '43227', ...                      7   \n",
       "4                                          ['43207']                      1   \n",
       "5                                 ['43207', '43206']                      2   \n",
       "6  ['43110', '43125', '43213', '43068', '43207', ...                      7   \n",
       "7                        ['43207', '43232', '43206']                      3   \n",
       "8  ['43110', '43213', '43068', '43209', '43207', ...                      8   \n",
       "9  ['43206', '43213', '43209', '43207', '43232', ...                      6   \n",
       "\n",
       "   count_of_A_zips  count_of_B_zips  total_zips  overlap_pctg  \\\n",
       "0               11               40          43      0.186047   \n",
       "1               11               29          36      0.111111   \n",
       "2               11               22          28      0.178571   \n",
       "3               11               18          22      0.318182   \n",
       "4               11                9          19      0.052632   \n",
       "5               11               17          26      0.076923   \n",
       "6               11               11          15      0.466667   \n",
       "7               11               13          21      0.142857   \n",
       "8               11               11          14      0.571429   \n",
       "9               11               24          29      0.206897   \n",
       "\n",
       "   dist_between_stores     store_pair store_pair_str  \n",
       "0            16.172965  ['1', '1379']  ['1', '1379']  \n",
       "1            15.968635  ['1', '1666']  ['1', '1666']  \n",
       "2            13.554885  ['1', '1668']  ['1', '1668']  \n",
       "3            10.611412   ['1', '410']   ['1', '410']  \n",
       "4             8.541503   ['1', '451']   ['1', '451']  \n",
       "5            13.968760  ['1', '5092']  ['1', '5092']  \n",
       "6             7.094196  ['1', '5176']  ['1', '5176']  \n",
       "7            11.018871  ['1', '5243']  ['1', '5243']  \n",
       "8             4.902568  ['1', '5324']  ['1', '5324']  \n",
       "9             8.621383  ['1', '5356']  ['1', '5356']  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns=99\n",
    "df_store_zip=pd.read_csv(\"./output_2020-07-22/BL_zip_overlap_between_stores_unique_JL_2020-07-22.csv\",nrows=10)\n",
    "df_store_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BL_zip_overlap_between_stores_unique_JL_2020-07-22.csv',\n",
       " 'BL_new_TA_pair_dist_table_summary_JL_2020-07-22.xlsx',\n",
       " 'BL_TA_combination_JL_2020-07-22.xlsx',\n",
       " 'sorted_600_stores_T1B_T2C_JL_2020-07-22.xlsx',\n",
       " 'initial_TA_output.xlsx',\n",
       " 'BL_remaining_stores_and_defined_TA_JL_2020-07-22.xlsx',\n",
       " 'BL_remaining_stores_and_defined_2_TA_JL_2020-07-22.xlsx',\n",
       " 'BL_final_TA_updated_JL_2020-07-22.xlsx']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.listdir(\"./output_2020-07-22/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_pair_func(store_A,store_B):\n",
    "    return sorted([store_A,store_B])\n",
    "df_store_zip_unique_pairs=df_store_zip.copy()\n",
    "df_store_zip_unique_pairs['store_pair']=df_store_zip_unique_pairs.apply(lambda x: store_pair_func(x['store_A_location_id'],x['store_B_location_id']),axis=1)\n",
    "df_store_zip_unique_pairs['store_pair_str']=df_store_zip_unique_pairs['store_pair'].astype(str)\n",
    "df_store_zip_unique_pairs=df_store_zip_unique_pairs.sort_values(['store_pair_str','store_A_location_id','store_B_location_id'])\n",
    "df_store_zip_unique_pairs=df_store_zip_unique_pairs.drop_duplicates(\"store_pair_str\")\n",
    "df_store_zip_unique_pairs.to_csv(output_folder+\"BL_zip_overlap_between_stores_unique_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_zip_unique_pairs['overlap_group']=np.where(df_store_zip_unique_pairs['overlap_pctg']>0.2,\"20%+\",\n",
    "                                                   np.where(df_store_zip_unique_pairs['overlap_pctg']>0.15,\"15%-20%\",\n",
    "                                                           np.where(df_store_zip_unique_pairs['overlap_pctg']>0.1,\"10%-15%\",\n",
    "                                                                   np.where(df_store_zip_unique_pairs['overlap_pctg']>0.05,'5%-10%',\n",
    "                                                                           np.where(df_store_zip_unique_pairs['overlap_pctg']>0.03,'3%-5%',\"<3%\")\n",
    "                                                                           )\n",
    "                                                                   )\n",
    "                                                           )\n",
    "                                                   )\n",
    "\n",
    "df_store_zip_unique_pairs['dist_group']=np.where(df_store_zip_unique_pairs['dist_between_stores']>28,\"28+ miles\",\n",
    "                                                   np.where(df_store_zip_unique_pairs['dist_between_stores']>20,\"20-28 miles\",\n",
    "                                                           np.where(df_store_zip_unique_pairs['dist_between_stores']>10,\"10-20 miles\",\"0-10 miles\")\n",
    "                                                           )\n",
    "                                                   )\n",
    "df_summary_overlap_dist_group_pair_count=df_store_zip_unique_pairs.groupby(['overlap_group','dist_group'])['store_pair_str'].count().to_frame().reset_index().rename(columns={\"store_pair_str\":\"pairs_count\"})\n",
    "df_summary_overlap_dist_group_unique_stores=df_store_zip_unique_pairs.groupby(['overlap_group','dist_group'])['store_pair'].sum().to_frame().reset_index().rename(columns={\"store_pair\":\"stores_involved\"})\n",
    "\n",
    "df_store_zip_unique_pairs['zips_P_S_50_both_stores']=df_store_zip_unique_pairs['store_B_zip_list_P_and_S']+df_store_zip_unique_pairs['store_A_zip_list_P_and_S']\n",
    "df_store_zip_unique_pairs['zips_P_S_50_both_stores']=df_store_zip_unique_pairs['zips_P_S_50_both_stores'].apply(lambda x: list(set(x)))\n",
    "df_summary_overlap_dist_group_unique_zips=df_store_zip_unique_pairs.groupby(['overlap_group','dist_group'])['zips_P_S_50_both_stores'].sum().to_frame().reset_index().rename(columns={\"zips_P_S_50_both_stores\":\"zips_involved\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_dict={\"<3%\":1,\"3%-5%\":2,\"5%-10%\":3,\"10%-15%\":4,\"15%-20%\":5,\"20%+\":6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_pivot_pair=df_summary_overlap_dist_group_pair_count.pivot_table(index=\"overlap_group\",columns='dist_group',values=\"pairs_count\").reset_index()\n",
    "df_summary_pivot_pair['sort']=df_summary_pivot_pair['overlap_group'].apply(lambda x: sort_dict[x])\n",
    "df_summary_pivot_pair=df_summary_pivot_pair.sort_values(\"sort\").reset_index()\n",
    "del df_summary_pivot_pair['sort']\n",
    "del df_summary_pivot_pair['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_overlap_dist_group_unique_stores['stores_involved']=df_summary_overlap_dist_group_unique_stores['stores_involved'].apply(lambda x: set(x))\n",
    "df_summary_overlap_dist_group_unique_stores['store_count_involved']=df_summary_overlap_dist_group_unique_stores['stores_involved'].apply(lambda x: len(x))\n",
    "\n",
    "df_summary_pivot_store=df_summary_overlap_dist_group_unique_stores.pivot_table(index=\"overlap_group\",columns='dist_group',values=\"store_count_involved\").reset_index()\n",
    "df_summary_pivot_store['sort']=df_summary_pivot_store['overlap_group'].apply(lambda x: sort_dict[x])\n",
    "df_summary_pivot_store=df_summary_pivot_store.sort_values(\"sort\").reset_index()\n",
    "del df_summary_pivot_store['sort']\n",
    "del df_summary_pivot_store['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_overlap_dist_group_unique_zips['zips_involved']=df_summary_overlap_dist_group_unique_zips['zips_involved'].apply(lambda x: set(x))\n",
    "df_summary_overlap_dist_group_unique_zips['zip_count_involved']=df_summary_overlap_dist_group_unique_zips['zips_involved'].apply(lambda x: len(x))\n",
    "\n",
    "df_summary_pivot_zip=df_summary_overlap_dist_group_unique_zips.pivot_table(index=\"overlap_group\",columns='dist_group',values=\"zip_count_involved\").reset_index()\n",
    "df_summary_pivot_zip['sort']=df_summary_pivot_zip['overlap_group'].apply(lambda x: sort_dict[x])\n",
    "df_summary_pivot_zip=df_summary_pivot_zip.sort_values(\"sort\").reset_index()\n",
    "del df_summary_pivot_zip['sort']\n",
    "del df_summary_pivot_zip['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '1379']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_zip_unique_pairs['store_pair'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_group=df_store_zip_unique_pairs.groupby(['dist_group'])['store_pair'].sum().to_frame().reset_index().rename(columns={\"store_pair\":\"unique_store_list\"})\n",
    "dist_group['unique_store_list']=dist_group['unique_store_list'].apply(lambda x: list(set(x)))\n",
    "dist_group['unique_store_count']=dist_group['unique_store_list'].apply(lambda x: len(x))\n",
    "\n",
    "dist_group_pair_count=df_store_zip_unique_pairs.groupby(['dist_group'])['store_pair'].count().to_frame().reset_index().rename(columns={\"store_pair\":\"pair_counts\"})\n",
    "\n",
    "dist_group=pd.merge(dist_group,dist_group_pair_count,on=\"dist_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_lat_dict=df_store_location.set_index(\"location_id\").to_dict()['latitude_meas']\n",
    "store_long_dict=df_store_location.set_index(\"location_id\").to_dict()['longitude_meas']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_P_zips_by_store=df_sales_by_zip[df_sales_by_zip['trans_label']==\"P\"].groupby(['location_id'])['customer_zip_code'].apply(list).to_frame().reset_index().rename(columns={\"customer_zip_code\":\"all_P_zips\"})\n",
    "df_all_S_zips_by_store=df_sales_by_zip[df_sales_by_zip['trans_label']==\"S\"].groupby(['location_id'])['customer_zip_code'].apply(list).to_frame().reset_index().rename(columns={\"customer_zip_code\":\"all_S_zips\"})\n",
    "\n",
    "df_50_miles_P_zips_by_store=df_sales_by_zip[(df_sales_by_zip['trans_label']==\"P\") & (df_sales_by_zip['dist_miles']<=50)].groupby(['location_id'])['customer_zip_code'].apply(list).to_frame().reset_index().rename(columns={\"customer_zip_code\":\"50_miles_P_zips\"})\n",
    "df_50_miles_S_zips_by_store=df_sales_by_zip[(df_sales_by_zip['trans_label']==\"S\") & (df_sales_by_zip['dist_miles']<=50)].groupby(['location_id'])['customer_zip_code'].apply(list).to_frame().reset_index().rename(columns={\"customer_zip_code\":\"50_miles_S_zips\"})\n",
    "\n",
    "df_P_S_zips_by_store=pd.merge(df_all_P_zips_by_store,df_all_S_zips_by_store,on=\"location_id\",how=\"outer\")\n",
    "df_P_S_zips_by_store=pd.merge(df_P_S_zips_by_store,df_50_miles_P_zips_by_store,on=\"location_id\",how=\"outer\")\n",
    "df_P_S_zips_by_store=pd.merge(df_P_S_zips_by_store,df_50_miles_S_zips_by_store,on=\"location_id\",how=\"outer\")\n",
    "df_P_S_zips_by_store=df_P_S_zips_by_store.fillna(\"[]\")\n",
    "df_P_S_zips_by_store['all_P_zips']=df_P_S_zips_by_store['all_P_zips'].astype(str).apply(lambda x: eval(x))\n",
    "df_P_S_zips_by_store['all_S_zips']=df_P_S_zips_by_store['all_S_zips'].astype(str).apply(lambda x: eval(x))\n",
    "df_P_S_zips_by_store['50_miles_P_zips']=df_P_S_zips_by_store['50_miles_P_zips'].astype(str).apply(lambda x: eval(x))\n",
    "df_P_S_zips_by_store['50_miles_S_zips']=df_P_S_zips_by_store['50_miles_S_zips'].astype(str).apply(lambda x: eval(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dist_of_2_str_stores(pair_stores_str):\n",
    "    pair_stores_str=eval(pair_stores_str)\n",
    "    store_a=pair_stores_str[0]\n",
    "    store_b=pair_stores_str[1]\n",
    "    dist=haversine([store_lat_dict[store_a],store_long_dict[store_a]],[store_lat_dict[store_b],store_long_dict[store_b]],unit=\"mi\")\n",
    "    return dist\n",
    "\n",
    "# Only used in below loop\n",
    "def find_nearest_store(store_id):\n",
    "    shortest_dist=99999\n",
    "    nearest_store=np.nan\n",
    "    for i_store in df_store_address['location_id'].tolist():\n",
    "        if i_store!=store_id:\n",
    "            dist=haversine([store_lat_dict[store_id],store_long_dict[store_id]],[store_lat_dict[i_store],store_long_dict[i_store]],unit=\"mi\")\n",
    "            if dist<shortest_dist:\n",
    "                shortest_dist=dist\n",
    "                nearest_store=i_store\n",
    "    return nearest_store, shortest_dist\n",
    "\n",
    "def find_overlaped_stores(store_id):\n",
    "    df=df_store_zip_unique_pairs[df_store_zip_unique_pairs['store_pair'].apply(lambda x: store_id in x)]\n",
    "    df=df.sort_values('overlap_pctg',ascending=True).reset_index()\n",
    "    min_overlap_pctg=df.loc[0,'overlap_pctg']\n",
    "    min_overlap_store_pair_str=df.loc[0,'store_pair_str']\n",
    "    \n",
    "    max_overlap_pctg=df.loc[len(df)-1,'overlap_pctg']\n",
    "    max_overlap_store_pair_str=df.loc[len(df)-1,'store_pair_str']\n",
    "    \n",
    "    return min_overlap_pctg,min_overlap_store_pair_str,max_overlap_pctg,max_overlap_store_pair_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/jian/.local/lib/python3.6/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "nearest_store_dist_criteria_dict={\"0-10 miles\":0,\"10-20 miles\":10,\"20-28 miles\":20,\"28+ miles\":28}\n",
    "\n",
    "writer=pd.ExcelWriter(output_folder+\"BL_new_TA_pair_dist_table_summary_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "dist_group.to_excel(writer,\"pairs_and_stores_by_pair_dist\",index=False)\n",
    "\n",
    "ordered_cols=['dist_group','location_id','address_line_1','address_line_2','city_nm','state_nm','zip_cd','latitude_meas','longitude_meas',\n",
    "              'all_P_zips','all_S_zips','All_P&S_zips','50_miles_P_zips','50_miles_S_zips','All_P&S_zips_50_miles',\n",
    "              'nearest_store','dist_to_nearest_store',\n",
    "              'max_overlap_store','max_overlap_pctg','dist_max_overlap_pairs',\n",
    "              'min_overlap_pctg','min_overlap_store','dist_min_overlap_pairs']\n",
    "\n",
    "all_paired_group_store_df=pd.DataFrame(columns=ordered_cols)\n",
    "all_single_store_df=pd.DataFrame(columns=['nearest_store_dist_criteria']+ordered_cols)\n",
    "all_high_overlap_store_df=pd.DataFrame(columns=ordered_cols)\n",
    "\n",
    "for dist,group in dist_group.groupby(\"dist_group\"):\n",
    "    store_list_in_dist_group=group['unique_store_list'].values[0]\n",
    "    df_store_zip_unique_pairs_removed=df_store_zip_unique_pairs[(~df_store_zip_unique_pairs['store_A_location_id'].isin(store_list_in_dist_group)) &\\\n",
    "                                                                 (~df_store_zip_unique_pairs['store_B_location_id'].isin(store_list_in_dist_group))]\n",
    "\n",
    "    df_removed_pairs_rows=df_store_zip_unique_pairs[df_store_zip_unique_pairs['dist_group']==dist]\n",
    "    df_store_zip_unique_pairs_removed_stores=df_store_zip_unique_pairs[(df_store_zip_unique_pairs['store_A_location_id'].isin(store_list_in_dist_group)) |\\\n",
    "                                                                 (df_store_zip_unique_pairs['store_B_location_id'].isin(store_list_in_dist_group))]\n",
    "    \n",
    "    df_removed_stores_1=pd.DataFrame({\"location_id\":store_list_in_dist_group})\n",
    "    df_removed_stores_1=pd.merge(df_removed_stores_1,df_store_address,on=\"location_id\",how=\"left\")\n",
    "    df_removed_stores_1=pd.merge(df_removed_stores_1,df_P_S_zips_by_store,on=\"location_id\",how=\"left\")\n",
    "    \n",
    "    df_removed_stores_1['nearest_store']=df_removed_stores_1['location_id'].apply(lambda x: find_nearest_store(x)[0])\n",
    "    df_removed_stores_1['dist_to_nearest_store']=df_removed_stores_1['location_id'].apply(lambda x: find_nearest_store(x)[1])\n",
    "\n",
    "    df_removed_stores_1['min_overlap_pctg']=df_removed_stores_1['location_id'].apply(lambda x: find_overlaped_stores(x)[0])\n",
    "    df_removed_stores_1['min_overlap_store']=df_removed_stores_1['location_id'].apply(lambda x: find_overlaped_stores(x)[1])\n",
    "    df_removed_stores_1['max_overlap_pctg']=df_removed_stores_1['location_id'].apply(lambda x: find_overlaped_stores(x)[2])\n",
    "    df_removed_stores_1['max_overlap_store']=df_removed_stores_1['location_id'].apply(lambda x: find_overlaped_stores(x)[3])\n",
    "\n",
    "    df_removed_stores_1['All_P&S_zips']=df_removed_stores_1['all_P_zips']+df_removed_stores_1['all_S_zips']\n",
    "    df_removed_stores_1['All_P&S_zips_50_miles']=df_removed_stores_1['50_miles_P_zips']+df_removed_stores_1['50_miles_S_zips']\n",
    "\n",
    "    df_removed_stores_1['dist_min_overlap_pairs']=df_removed_stores_1['min_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "    df_removed_stores_1['dist_max_overlap_pairs']=df_removed_stores_1['max_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "    df_removed_stores_1['dist_group']=dist\n",
    "        \n",
    "    df_removed_stores_1=df_removed_stores_1[ordered_cols]\n",
    "    df_removed_stores_1=df_removed_stores_1.sort_values(\"dist_to_nearest_store\",ascending=False)\n",
    "    \n",
    "    \n",
    "    nearest_store_dist_criteria=nearest_store_dist_criteria_dict[dist]\n",
    "    single_store_df=df_removed_stores_1[(df_removed_stores_1['dist_to_nearest_store']>nearest_store_dist_criteria) &\\\n",
    "                                        (df_removed_stores_1['max_overlap_pctg']<=0.15)]\n",
    "    single_store_df['nearest_store_dist_criteria']=nearest_store_dist_criteria\n",
    "    \n",
    "    high_overlap_store_df=df_removed_stores_1[(df_removed_stores_1['dist_to_nearest_store']<=10) &\\\n",
    "                                        (df_removed_stores_1['max_overlap_pctg']>=0.5)]\n",
    "       \n",
    "    df_removed_stores_1.to_excel(writer,dist+\"_all_stores\",index=False)\n",
    "    \n",
    "    \n",
    "    all_paired_group_store_df=all_paired_group_store_df.append(df_removed_stores_1)\n",
    "    all_single_store_df=all_single_store_df.append(single_store_df)\n",
    "\n",
    "    all_high_overlap_store_df=all_high_overlap_store_df.append(high_overlap_store_df)\n",
    "    \n",
    "\n",
    "def clean_list_col(df):\n",
    "    for col in df.columns.tolist():\n",
    "        if df[col].apply(lambda x: type(x)).unique()[0]==list:\n",
    "            df[col]=df[col].astype(str)\n",
    "    return df\n",
    "            \n",
    "all_single_store_df=clean_list_col(all_single_store_df)\n",
    "all_paired_group_store_df=clean_list_col(all_paired_group_store_df)\n",
    "all_high_overlap_store_df=clean_list_col(all_high_overlap_store_df)\n",
    "\n",
    "all_single_store_df=all_single_store_df.drop_duplicates()\n",
    "all_paired_group_store_df=all_paired_group_store_df.drop_duplicates()\n",
    "all_high_overlap_store_df=all_high_overlap_store_df.drop_duplicates()\n",
    "\n",
    "all_single_store_df=all_single_store_df[['nearest_store_dist_criteria']+ordered_cols]\n",
    "all_single_store_df.to_excel(writer,\"all_single_store_df\",index=False)\n",
    "all_paired_group_store_df.to_excel(writer,\"all_paired_group_store_df\",index=False)\n",
    "all_high_overlap_store_df.to_excel(writer,\"all_high_overlap_store_df\",index=False)\n",
    "\n",
    "all_unique_high_overlap_stores=all_high_overlap_store_df.copy()\n",
    "del all_high_overlap_store_df['dist_group']\n",
    "all_high_overlap_store_df=all_high_overlap_store_df.drop_duplicates()\n",
    "all_high_overlap_store_df=all_high_overlap_store_df.sort_values([\"state_nm\",'city_nm','dist_to_nearest_store'])\n",
    "all_high_overlap_store_df.to_excel(writer,\"unique_all_high_overlap_store\",index=False)\n",
    "\n",
    "df_summary_high_overlap_store_st=all_high_overlap_store_df.groupby(all_high_overlap_store_df['state_nm'])['location_id'].nunique().to_frame().reset_index()\n",
    "df_summary_high_overlap_store_st.to_excel(writer,\"summary_high_overlap_st_count\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_the_hold_store(pair_list,hold_store):\n",
    "    y=pair_list.copy()\n",
    "    y.remove(hold_store)\n",
    "    return y[0]\n",
    "\n",
    "all_paired_group_store_df['min_overlap_store']=all_paired_group_store_df['min_overlap_store'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['max_overlap_store']=all_paired_group_store_df['max_overlap_store'].apply(lambda x: eval(x))\n",
    "\n",
    "all_paired_group_store_df['all_P_zips']=all_paired_group_store_df['all_P_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['all_S_zips']=all_paired_group_store_df['all_S_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['All_P&S_zips']=all_paired_group_store_df['All_P&S_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['50_miles_P_zips']=all_paired_group_store_df['50_miles_P_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['50_miles_S_zips']=all_paired_group_store_df['50_miles_S_zips'].apply(lambda x: eval(x))\n",
    "all_paired_group_store_df['All_P&S_zips_50_miles']=all_paired_group_store_df['All_P&S_zips_50_miles'].apply(lambda x: eval(x))\n",
    "\n",
    "    \n",
    "all_paired_group_store_df['min_paired_store']=all_paired_group_store_df.apply(lambda x: remove_the_hold_store(x['min_overlap_store'],x['location_id']),axis=1)\n",
    "all_paired_group_store_df['max_paired_store']=all_paired_group_store_df.apply(lambda x: remove_the_hold_store(x['max_overlap_store'],x['location_id']),axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "store_PS_50=df_P_S_zips_by_store[['location_id','50_miles_P_zips','50_miles_S_zips']]\n",
    "store_PS_50['all_PS_50']=store_PS_50['50_miles_P_zips']+store_PS_50['50_miles_S_zips']\n",
    "store_PS_50['all_PS_50']=store_PS_50['all_PS_50'].apply(lambda x: list(set(x)))\n",
    "store_PS_50=store_PS_50[['location_id','all_PS_50']]\n",
    "\n",
    "store_PS_50_min=store_PS_50.rename(columns={\"location_id\":\"min_paired_store\",\"all_PS_50\":\"min_store_all_PS_50\"})\n",
    "store_PS_50_max=store_PS_50.rename(columns={\"location_id\":\"max_paired_store\",\"all_PS_50\":\"max_store_all_PS_50\"})\n",
    "store_PS_50_near=store_PS_50.rename(columns={\"location_id\":\"nearest_store\",\"all_PS_50\":\"near_store_all_PS_50\"})\n",
    "\n",
    "all_paired_group_store_df=pd.merge(all_paired_group_store_df,store_PS_50_min,on=\"min_paired_store\")\n",
    "all_paired_group_store_df=pd.merge(all_paired_group_store_df,store_PS_50_max,on=\"max_paired_store\")\n",
    "all_paired_group_store_df=pd.merge(all_paired_group_store_df,store_PS_50_near,on=\"nearest_store\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_2_list(list_1,list_2):\n",
    "    inter_list=list(set(list_1).intersection(set(list_2)))\n",
    "    inter_pctg_1=len(inter_list)/len(list_1)\n",
    "    inter_pctg_2=len(inter_list)/len(list_2)\n",
    "    return inter_list,inter_pctg_1,inter_pctg_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paired_group_store_df['nearest_intersection_zips']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[0],axis=1)\n",
    "all_paired_group_store_df['nearest_pair_overlap_with_hold']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[1],axis=1)\n",
    "all_paired_group_store_df['nearest_pair_overlap_with_nearest']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[2],axis=1)\n",
    "\n",
    "all_paired_group_store_df['max_intersection_zips']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[0],axis=1)\n",
    "all_paired_group_store_df['max_pair_overlap_with_hold']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[1],axis=1)\n",
    "all_paired_group_store_df['max_pair_overlap_with_max']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[2],axis=1)\n",
    "\n",
    "all_paired_group_store_df['min_intersection_zips']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[0],axis=1)\n",
    "all_paired_group_store_df['min_pair_overlap_with_hold']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[1],axis=1)\n",
    "all_paired_group_store_df['min_pair_overlap_with_min']=all_paired_group_store_df.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2951, 37)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list=['dist_group','location_id','address_line_1','address_line_2','city_nm','state_nm','zip_cd','latitude_meas','longitude_meas',\n",
    "          'all_P_zips','all_S_zips','All_P&S_zips','50_miles_P_zips','50_miles_S_zips','All_P&S_zips_50_miles',\n",
    "          'nearest_store','dist_to_nearest_store','near_store_all_PS_50','nearest_intersection_zips','nearest_pair_overlap_with_hold','nearest_pair_overlap_with_nearest',\n",
    "          'max_overlap_store','max_overlap_pctg','dist_max_overlap_pairs','max_paired_store','max_store_all_PS_50',\n",
    "          'max_intersection_zips','max_pair_overlap_with_hold','max_pair_overlap_with_max',\n",
    "          'min_overlap_store','min_overlap_pctg','dist_min_overlap_pairs','min_paired_store','min_store_all_PS_50',\n",
    "          'min_intersection_zips','min_pair_overlap_with_hold','min_pair_overlap_with_min']\n",
    "all_paired_group_store_df=all_paired_group_store_df[col_list]\n",
    "all_paired_group_store_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_removed_stores_1['All_P&S_zips']=df_removed_stores_1['all_P_zips']+df_removed_stores_1['all_S_zips']\n",
    "df_removed_stores_1['All_P&S_zips_50_miles']=df_removed_stores_1['50_miles_P_zips']+df_removed_stores_1['50_miles_S_zips']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_all_stores_in_single_TA_1 124\n",
      "list_all_stores_in_single_TA_2 62\n",
      "already_defined_stores, 186\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "\n",
    "# list_all_stores_in_single_TA_1 -- no overlap at all\n",
    "list_all_stores_in_single_TA_1=df_P_S_zips_by_store[~df_P_S_zips_by_store['location_id'].isin(all_paired_group_store_df['location_id'].tolist())]\n",
    "list_all_stores_in_single_TA_1=list_all_stores_in_single_TA_1['location_id'].unique().tolist()\n",
    "print(\"list_all_stores_in_single_TA_1\",len(list_all_stores_in_single_TA_1))\n",
    "df_no_overlap_at_all=pd.DataFrame({\"location_id\":list_all_stores_in_single_TA_1})\n",
    "df_no_overlap_at_all=pd.merge(df_no_overlap_at_all,df_store_address,on=\"location_id\",how=\"left\")\n",
    "df_no_overlap_at_all=pd.merge(df_no_overlap_at_all,df_P_S_zips_by_store,on=\"location_id\",how=\"left\")\n",
    "df_no_overlap_at_all['All_P&S_zips']=df_no_overlap_at_all['all_P_zips']+df_no_overlap_at_all['all_S_zips']\n",
    "df_no_overlap_at_all['All_P&S_zips_50_miles']=df_no_overlap_at_all['50_miles_P_zips']+df_no_overlap_at_all['50_miles_S_zips']\n",
    "\n",
    "\n",
    "\n",
    "# list_all_stores_in_single_TA_2 -- low oeverlap\n",
    "list_all_stores_in_single_TA_2=all_paired_group_store_df[(all_paired_group_store_df['nearest_store']==all_paired_group_store_df['max_paired_store']) &\\\n",
    "                                                         (all_paired_group_store_df['nearest_store']==all_paired_group_store_df['min_paired_store']) &\\\n",
    "                                                         (all_paired_group_store_df['max_overlap_pctg']<0.15) &\\\n",
    "                                                         (all_paired_group_store_df['nearest_pair_overlap_with_hold']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['nearest_pair_overlap_with_nearest']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['max_pair_overlap_with_hold']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['max_pair_overlap_with_max']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['min_pair_overlap_with_hold']<0.5) &\\\n",
    "                                                         (all_paired_group_store_df['min_pair_overlap_with_min']<0.5)]['location_id'].unique().tolist()\n",
    "print(\"list_all_stores_in_single_TA_2\",len(list_all_stores_in_single_TA_2))\n",
    "col_single_store_TA=all_paired_group_store_df.columns.tolist()\n",
    "df_all_single_store_TA=all_paired_group_store_df[all_paired_group_store_df['location_id'].isin(list_all_stores_in_single_TA_2)]\n",
    "df_all_single_store_TA=df_all_single_store_TA.append(df_no_overlap_at_all)[col_single_store_TA]\n",
    "\n",
    "already_defined_stores=df_all_single_store_TA['location_id'].unique().tolist()\n",
    "print(\"already_defined_stores,\",len(already_defined_stores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_included_P_S_stores=df_P_S_zips_by_store['location_id'].unique().tolist()\n",
    "\n",
    "new_stores=df_store_address[~df_store_address['location_id'].isin(all_included_P_S_stores)]\n",
    "new_stores=new_stores[new_stores['location_id']!=\"145\"]\n",
    "new_stores=new_stores[new_stores['location_id']!=\"6990\"]\n",
    "\n",
    "new_stores.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_stores_already_asigned(stores_per_row,all_defined_list):\n",
    "    # y_in_defined_list=[x for x in stores_per_row if x in all_defined_list]\n",
    "    y_notin_defined_list=[x for x in stores_per_row if x not in all_defined_list]\n",
    "    \n",
    "    return y_notin_defined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "all_paired_group_store_df['original_combined_stores_4']=\"[\"+\"'\"+all_paired_group_store_df['location_id']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['nearest_store']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['max_paired_store']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['min_paired_store']+\"'\"+\"]\"\n",
    "all_paired_group_store_df['original_combined_stores_4']=all_paired_group_store_df['original_combined_stores_4'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "all_paired_group_store_df['original_combined_stores_3']=\"[\"+\"'\"+all_paired_group_store_df['location_id']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['nearest_store']+\"'\"+\", \"+\"'\"+all_paired_group_store_df['max_paired_store']+\"'\"+\"]\"\n",
    "all_paired_group_store_df['original_combined_stores_3']=all_paired_group_store_df['original_combined_stores_3'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['original_combined_stores_4']\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['original_combined_stores_3']\n",
    "\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1- >=50% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_B_all_merge_4_50_above_involved_stores 25\n",
      "already_defined_stores 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# B - T1 >=50%\n",
    "# merge 1: 4 stores - hold, max&min, nearest 10 miles\n",
    "\n",
    "\n",
    "df_B_all_merge_4_50_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']<=10) &\\\n",
    "                                         (all_paired_group_store_df['max_overlap_pctg']>=0.5) &\\\n",
    "                                         (all_paired_group_store_df['min_overlap_pctg']>=0.5)]\n",
    "df_B_all_merge_4_50_above['result_combined_stores']=df_B_all_merge_4_50_above['cleaned_combined_stores_4']\n",
    "\n",
    "list_df_B_all_merge_4_50_above_involved_stores=list(set(df_B_all_merge_4_50_above['result_combined_stores'].sum()))\n",
    "print('list_df_B_all_merge_4_50_above_involved_stores',len(list_df_B_all_merge_4_50_above_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_B_all_merge_4_50_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_C_all_merge_3_50_above_involved_stores 297\n",
      "already_defined_stores 508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# C - T1 >=50%\n",
    "# merge 2: 3 stores - hold, max|min, nearest 10 miles\n",
    "\n",
    "df_C_all_merge_3_50_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']<=10) &\\\n",
    "                                           ((all_paired_group_store_df['max_overlap_pctg']>=0.5) | (all_paired_group_store_df['min_overlap_pctg']>=0.5))]\n",
    "df_C_all_merge_3_50_above['result_combined_stores']=df_C_all_merge_3_50_above['cleaned_combined_stores_3']\n",
    "\n",
    "list_df_C_all_merge_3_50_above_involved_stores=list(set(df_C_all_merge_3_50_above['result_combined_stores'].sum()))\n",
    "print('list_df_C_all_merge_3_50_above_involved_stores',len(list_df_C_all_merge_3_50_above_involved_stores))\n",
    "\n",
    "####\n",
    "already_defined_stores=list(set(already_defined_stores+list_df_C_all_merge_3_50_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_D_all_merge_4_50_above_involved_stores 2\n",
      "already_defined_stores 510\n"
     ]
    }
   ],
   "source": [
    "# D - T1 >=50%\n",
    "# merge 3: 4 stores - hold, max&min, nearest 10-28 miles\n",
    "\n",
    "\n",
    "df_D_all_merge_4_50_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']>10) &\\\n",
    "                                           (all_paired_group_store_df['dist_to_nearest_store']<=28) &\\\n",
    "                                           (all_paired_group_store_df['max_overlap_pctg']>=0.5) &\\\n",
    "                                           (all_paired_group_store_df['min_overlap_pctg']>=0.5)]\n",
    "df_D_all_merge_4_50_above['result_combined_stores']=df_D_all_merge_4_50_above['cleaned_combined_stores_4']\n",
    "if len(df_D_all_merge_4_50_above)>0:\n",
    "    list_df_D_all_merge_4_50_above_involved_stores=list(set(df_D_all_merge_4_50_above['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_D_all_merge_4_50_above_involved_stores=[]\n",
    "print('list_df_D_all_merge_4_50_above_involved_stores',len(list_df_D_all_merge_4_50_above_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_D_all_merge_4_50_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_E_all_merge_3_50_above_involved_stores 10\n",
      "already_defined_stores 520\n"
     ]
    }
   ],
   "source": [
    "# E - T1 >=50%\n",
    "# merge 4: 3 stores - hold, max|min, nearest 10-28 miles\n",
    "\n",
    "\n",
    "df_E_all_merge_3_50_above=all_paired_group_store_df[(all_paired_group_store_df['dist_to_nearest_store']>10) &\\\n",
    "                                           (all_paired_group_store_df['dist_to_nearest_store']<=28) &\\\n",
    "                                           ((all_paired_group_store_df['max_overlap_pctg']>=0.5)|(all_paired_group_store_df['min_overlap_pctg']>=0.5))]\n",
    "df_E_all_merge_3_50_above['result_combined_stores']=df_E_all_merge_3_50_above['cleaned_combined_stores_3']\n",
    "\n",
    "if len(df_E_all_merge_3_50_above)>0:\n",
    "    list_df_E_all_merge_3_50_above_involved_stores=list(set(df_E_all_merge_3_50_above['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_E_all_merge_3_50_above_involved_stores=[]\n",
    "print('list_df_E_all_merge_3_50_above_involved_stores',len(list_df_E_all_merge_3_50_above_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_E_all_merge_3_50_above_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T2- >=35% & <50% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_B_all_merge_4_35_50_involved_stores 40\n",
      "already_defined_stores 560\n"
     ]
    }
   ],
   "source": [
    "# B - T2 [35%,50%)\n",
    "# merge 1: 4 stores - hold, max&min, nearest without dist criteria\n",
    "\n",
    "# nearest_always kept in the result\n",
    "# whichever satisfied the cretearia, whichever should be included, max or min \n",
    "\n",
    "df_B_all_merge_4_35_50=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.35) & (all_paired_group_store_df['max_overlap_pctg']<0.5)) &\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.35) & (all_paired_group_store_df['min_overlap_pctg']<0.5))]\n",
    "df_B_all_merge_4_35_50['result_combined_stores']=df_B_all_merge_4_35_50['cleaned_combined_stores_4']\n",
    "\n",
    "if len(df_B_all_merge_4_35_50)>0:\n",
    "    list_df_B_all_merge_4_35_50_involved_stores=list(set(df_B_all_merge_4_35_50['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_B_all_merge_4_35_50_involved_stores=[]\n",
    "    \n",
    "print('list_df_B_all_merge_4_35_50_involved_stores',len(list_df_B_all_merge_4_35_50_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_B_all_merge_4_35_50_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_C_all_merge_3_35_50_involved_stores 270\n",
      "already_defined_stores 830\n"
     ]
    }
   ],
   "source": [
    "# C - T2 [35%,50%)\n",
    "# merge 2: 3 stores - hold, max|min, nearest without dist criteria\n",
    "\n",
    "df_C_all_merge_3_35_50=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.35) & (all_paired_group_store_df['max_overlap_pctg']<0.5)) |\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.35) & (all_paired_group_store_df['min_overlap_pctg']<0.5))]\n",
    "\n",
    "df_C_all_merge_3_35_50_1_Max=df_C_all_merge_3_35_50[(df_C_all_merge_3_35_50['max_overlap_pctg']>=0.35) & (df_C_all_merge_3_35_50['max_overlap_pctg']<0.5)]\n",
    "df_C_all_merge_3_35_50_2_Min=df_C_all_merge_3_35_50[(df_C_all_merge_3_35_50['min_overlap_pctg']>=0.35) & (df_C_all_merge_3_35_50['min_overlap_pctg']<0.5)]\n",
    "\n",
    "df_C_all_merge_3_35_50_1_Max['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_35_50_1_Max['location_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_50_1_Max['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_50_1_Max['max_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_35_50_1_Max['result_combined_stores']=df_C_all_merge_3_35_50_1_Max['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_35_50_2_Min['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_35_50_2_Min['location_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_50_2_Min['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_35_50_2_Min['min_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_35_50_2_Min['result_combined_stores']=df_C_all_merge_3_35_50_2_Min['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_35_50=df_C_all_merge_3_35_50_1_Max.append(df_C_all_merge_3_35_50_2_Min)\n",
    "\n",
    "df_C_all_merge_3_35_50['result_combined_stores']=df_C_all_merge_3_35_50['result_combined_stores'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "\n",
    "\n",
    "list_df_C_all_merge_3_35_50_involved_stores=list(set(df_C_all_merge_3_35_50['result_combined_stores'].sum()))\n",
    "print('list_df_C_all_merge_3_35_50_involved_stores',len(list_df_C_all_merge_3_35_50_involved_stores))\n",
    "\n",
    "####\n",
    "already_defined_stores=list(set(already_defined_stores+list_df_C_all_merge_3_35_50_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T3- >=15% & <35% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_B_all_merge_4_15_35_involved_stores 74\n",
      "already_defined_stores 904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# B - T3 [15%,35%)\n",
    "# merge 1: 4 stores - hold, max&min, nearest without dist criteria\n",
    "\n",
    "# nearest_always kept in the result\n",
    "# whichever satisfied the cretearia, whichever should be included, max or min \n",
    "\n",
    "df_B_all_merge_4_15_35=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.15) & (all_paired_group_store_df['max_overlap_pctg']<0.35)) &\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.15) & (all_paired_group_store_df['min_overlap_pctg']<0.35))]\n",
    "df_B_all_merge_4_15_35['result_combined_stores']=df_B_all_merge_4_15_35['cleaned_combined_stores_4']\n",
    "\n",
    "if len(df_B_all_merge_4_15_35)>0:\n",
    "    list_df_B_all_merge_4_15_35_involved_stores=list(set(df_B_all_merge_4_15_35['result_combined_stores'].sum()))\n",
    "else:\n",
    "    list_df_B_all_merge_4_15_35_involved_stores=[]\n",
    "    \n",
    "print('list_df_B_all_merge_4_15_35_involved_stores',len(list_df_B_all_merge_4_15_35_involved_stores))\n",
    "#### \n",
    "already_defined_stores=list(set(already_defined_stores+list_df_B_all_merge_4_15_35_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_df_C_all_merge_3_15_35_involved_stores 312\n",
      "already_defined_stores 1216\n"
     ]
    }
   ],
   "source": [
    "# C - T3 [15%,35%)\n",
    "# merge 2: 3 stores - hold, max|min, nearest without dist criteria\n",
    "\n",
    "df_C_all_merge_3_15_35=all_paired_group_store_df[((all_paired_group_store_df['max_overlap_pctg']>=0.15) & (all_paired_group_store_df['max_overlap_pctg']<0.35)) |\\\n",
    "                                                 ((all_paired_group_store_df['min_overlap_pctg']>=0.15) & (all_paired_group_store_df['min_overlap_pctg']<0.35))]\n",
    "\n",
    "df_C_all_merge_3_15_35_1_Max=df_C_all_merge_3_15_35[(df_C_all_merge_3_15_35['max_overlap_pctg']>=0.15) & (df_C_all_merge_3_15_35['max_overlap_pctg']<0.35)]\n",
    "df_C_all_merge_3_15_35_2_Min=df_C_all_merge_3_15_35[(df_C_all_merge_3_15_35['min_overlap_pctg']>=0.15) & (df_C_all_merge_3_15_35['min_overlap_pctg']<0.35)]\n",
    "\n",
    "df_C_all_merge_3_15_35_1_Max['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_15_35_1_Max['location_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_1_Max['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_1_Max['max_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_15_35_1_Max['result_combined_stores']=df_C_all_merge_3_15_35_1_Max['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_15_35_2_Min['result_combined_stores']=\"[\"+\"'\"+df_C_all_merge_3_15_35_2_Min['location_id']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_2_Min['nearest_store']+\"'\"+\", \"+\"'\"+df_C_all_merge_3_15_35_2_Min['min_paired_store']+\"'\"+\"]\"\n",
    "df_C_all_merge_3_15_35_2_Min['result_combined_stores']=df_C_all_merge_3_15_35_2_Min['result_combined_stores'].apply(lambda x: list(set(eval(x))))\n",
    "\n",
    "df_C_all_merge_3_15_35=df_C_all_merge_3_15_35_1_Max.append(df_C_all_merge_3_15_35_2_Min)\n",
    "\n",
    "df_C_all_merge_3_15_35['result_combined_stores']=df_C_all_merge_3_15_35['result_combined_stores'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "\n",
    "\n",
    "list_df_C_all_merge_3_15_35_involved_stores=list(set(df_C_all_merge_3_15_35['result_combined_stores'].sum()))\n",
    "print('list_df_C_all_merge_3_15_35_involved_stores',len(list_df_C_all_merge_3_15_35_involved_stores))\n",
    "\n",
    "####\n",
    "already_defined_stores=list(set(already_defined_stores+list_df_C_all_merge_3_15_35_involved_stores))\n",
    "print(\"already_defined_stores\",len(already_defined_stores))\n",
    "\n",
    "######\n",
    "# Clean\n",
    "all_paired_group_store_df['cleaned_combined_stores_4']=all_paired_group_store_df['cleaned_combined_stores_4'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n",
    "all_paired_group_store_df['cleaned_combined_stores_3']=all_paired_group_store_df['cleaned_combined_stores_3'].apply(lambda x: identify_stores_already_asigned(x,already_defined_stores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remained_stores=all_paired_group_store_df[~all_paired_group_store_df['location_id'].isin(already_defined_stores)]\n",
    "\n",
    "remained_stores['location_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 9)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store list by group column\n",
    "\n",
    "max_len_store=max(len(df_all_single_store_TA['location_id'].unique().tolist()),\n",
    "                 len(list_df_B_all_merge_4_50_above_involved_stores),\n",
    "                 len(list_df_C_all_merge_3_50_above_involved_stores),\n",
    "                 len(list_df_D_all_merge_4_50_above_involved_stores),\n",
    "                 len(list_df_E_all_merge_3_50_above_involved_stores),\n",
    "                 len(list_df_B_all_merge_4_35_50_involved_stores),\n",
    "                 len(list_df_C_all_merge_3_35_50_involved_stores),\n",
    "                 len(list_df_B_all_merge_4_15_35_involved_stores),\n",
    "                 len(list_df_C_all_merge_3_15_35_involved_stores),\n",
    "                 )\n",
    "\n",
    "df_stores_in_each_group=pd.DataFrame({\"T1_A_single_store_TA\":df_all_single_store_TA['location_id'].unique().tolist()+[np.nan]*(max_len_store-len(df_all_single_store_TA['location_id'].unique().tolist())),\n",
    "                                      \"T1_B_all_merge_4_50_above_involved_stores\":list_df_B_all_merge_4_50_above_involved_stores+[np.nan]*(max_len_store-len(list_df_B_all_merge_4_50_above_involved_stores)),\n",
    "                                      \"T1_C_all_merge_3_50_above_involved_stores\":list_df_C_all_merge_3_50_above_involved_stores+[np.nan]*(max_len_store-len(list_df_C_all_merge_3_50_above_involved_stores)),\n",
    "                                      \"T1_D_all_merge_4_50_above_involved_stores\":list_df_D_all_merge_4_50_above_involved_stores+[np.nan]*(max_len_store-len(list_df_D_all_merge_4_50_above_involved_stores)),\n",
    "                                      \"T1_E_all_merge_3_50_above_involved_stores\":list_df_E_all_merge_3_50_above_involved_stores+[np.nan]*(max_len_store-len(list_df_E_all_merge_3_50_above_involved_stores)),\n",
    "                                      \"T2_B_all_merge_4_35_50_involved_stores\":list_df_B_all_merge_4_35_50_involved_stores+[np.nan]*(max_len_store-len(list_df_B_all_merge_4_35_50_involved_stores)),\n",
    "                                      \"T2_C_all_merge_3_35_50_involved_stores\":list_df_C_all_merge_3_35_50_involved_stores+[np.nan]*(max_len_store-len(list_df_C_all_merge_3_35_50_involved_stores)),\n",
    "                                      \"T3_B_all_merge_4_15_35_involved_stores\":list_df_B_all_merge_4_15_35_involved_stores+[np.nan]*(max_len_store-len(list_df_B_all_merge_4_15_35_involved_stores)),\n",
    "                                      \"T3_C_all_merge_3_15_35_involved_stores\":list_df_C_all_merge_3_15_35_involved_stores+[np.nan]*(max_len_store-len(list_df_C_all_merge_3_15_35_involved_stores)),\n",
    "                                     },index=[x for x in range(max_len_store)])\n",
    "df_stores_in_each_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>store_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_A_single_store_TA</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_B_all_merge_4_50_above_involved_stores</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_C_all_merge_3_50_above_involved_stores</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_D_all_merge_4_50_above_involved_stores</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1_E_all_merge_3_50_above_involved_stores</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2_B_all_merge_4_35_50_involved_stores</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2_C_all_merge_3_35_50_involved_stores</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T3_B_all_merge_4_15_35_involved_stores</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T3_C_all_merge_3_15_35_involved_stores</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       group  store_count\n",
       "0                       T1_A_single_store_TA          186\n",
       "0  T1_B_all_merge_4_50_above_involved_stores           25\n",
       "0  T1_C_all_merge_3_50_above_involved_stores          297\n",
       "0  T1_D_all_merge_4_50_above_involved_stores            2\n",
       "0  T1_E_all_merge_3_50_above_involved_stores           10\n",
       "0     T2_B_all_merge_4_35_50_involved_stores           40\n",
       "0     T2_C_all_merge_3_35_50_involved_stores          270\n",
       "0     T3_B_all_merge_4_15_35_involved_stores           74\n",
       "0     T3_C_all_merge_3_15_35_involved_stores          312"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_count=pd.DataFrame()\n",
    "\n",
    "for col in df_stores_in_each_group.columns.tolist():\n",
    "    list_col=df_stores_in_each_group[col].unique().tolist()\n",
    "    list_col=[x for x in list_col if str(x)!=\"nan\"]\n",
    "    len_col=len(list_col)\n",
    "    df=pd.DataFrame({\"group\":col,\"store_count\":len_col},index=[0])\n",
    "    df_store_count=df_store_count.append(df)\n",
    "df_store_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"BL_TA_combination_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_all_single_store_TA.to_excel(writer,\"T1_df_all_single_store_TA\",index=False)\n",
    "df_B_all_merge_4_50_above.to_excel(writer,\"T1_df_B_all_merge_4\",index=False)\n",
    "df_C_all_merge_3_50_above.to_excel(writer,\"T1_df_C_all_merge_3\",index=False)\n",
    "df_D_all_merge_4_50_above.to_excel(writer,\"T1_df_D_all_merge_4\",index=False)\n",
    "df_E_all_merge_3_50_above.to_excel(writer,\"T1_df_E_all_merge_3\",index=False)\n",
    "\n",
    "df_B_all_merge_4_35_50.to_excel(writer,\"T2_df_B_all_merge_4_15_35\",index=False)\n",
    "df_C_all_merge_3_35_50.to_excel(writer,\"T2_df_C_all_merge_3_15_35\",index=False)\n",
    "\n",
    "df_B_all_merge_4_15_35.to_excel(writer,\"T3_df_B_all_merge_4_15_35\",index=False)\n",
    "df_C_all_merge_3_15_35.to_excel(writer,\"T3_df_C_all_merge_3_15_35\",index=False)\n",
    "\n",
    "df_store_count.to_excel(writer,\"group_store_count\",index=False)\n",
    "\n",
    "df_stores_in_each_group.to_excel(writer,\"defined_stores\",index=False)\n",
    "\n",
    "all_paired_group_store_df.to_excel(writer,\"all_paired_group_store_df\",index=False)\n",
    "remained_stores.to_excel(writer,\"remained_stores\",index=False)\n",
    "new_stores.to_excel(writer,\"new_stores_without_P_S\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected_600_stores_as_initial_aggregated_TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMA_nielsen=pd.read_excel(path_nielsen_zip,\n",
    "                          dtype=str,skiprows=1,usecols=['CODE','NAME','NAME.1'])\n",
    "DMA_nielsen=DMA_nielsen.rename(columns={\"CODE\":\"zip_cd\",\"NAME\":\"DMA\",\"NAME.1\":\"CTY\"})\n",
    "DMA_nielsen=DMA_nielsen.drop_duplicates()\n",
    "zip_DMA=DMA_nielsen.groupby(\"zip_cd\")['DMA'].apply(set).to_frame().reset_index()\n",
    "zip_CTY=DMA_nielsen.groupby(\"zip_cd\")['CTY'].apply(set).to_frame().reset_index()\n",
    "DMA_nielsen=pd.merge(zip_DMA,zip_CTY,on=\"zip_cd\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644, 2)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected T1B - T2C\n",
    "selected_groups=['T1_B_all_merge_4_50_above_involved_stores',\n",
    "                 'T1_C_all_merge_3_50_above_involved_stores',\n",
    "                 'T1_D_all_merge_4_50_above_involved_stores',\n",
    "                 'T1_E_all_merge_3_50_above_involved_stores',\n",
    "                 'T2_B_all_merge_4_35_50_involved_stores',\n",
    "                 'T2_C_all_merge_3_35_50_involved_stores']\n",
    "\n",
    "df_output_600_stores_selected=pd.DataFrame()\n",
    "\n",
    "for group in selected_groups:\n",
    "    store_list=df_stores_in_each_group[group].unique().tolist()\n",
    "    store_list=[x for x in store_list if str(x)!=\"nan\"]\n",
    "    df=pd.DataFrame({\"location_id\":store_list},index=[group]*len(store_list)).reset_index().rename(columns={\"index\":\"group\"})\n",
    "    df_output_600_stores_selected=df_output_600_stores_selected.append(df)\n",
    "df_output_600_stores_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_list=pd.read_table(latest_store_list,sep=\"|\",dtype=str)\n",
    "store_list.columns.tolist()\n",
    "store_list=store_list[['location_id','address_line_1','address_line_2','zip_cd','city_nm','state_nm','latitude_meas','longitude_meas']]\n",
    "store_list['latitude_meas']=store_list['latitude_meas'].astype(float)\n",
    "store_list['longitude_meas']=store_list['longitude_meas'].astype(float)\n",
    "store_list=update_store_location(store_list)\n",
    "\n",
    "\n",
    "store_list['zip_cd']=store_list['zip_cd'].apply(lambda x: x.split(\"-\")[0].zfill(5))\n",
    "\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,store_list,on=\"location_id\",how=\"left\")\n",
    "\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "\n",
    "df_output_600_stores_selected['DMA']=df_output_600_stores_selected['DMA'].astype(str)\n",
    "df_output_600_stores_selected['CTY']=df_output_600_stores_selected['CTY'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P_S_zips_by_store_copy=df_P_S_zips_by_store.copy()\n",
    "df_P_S_zips_by_store_copy['All_P&S_zips']=df_P_S_zips_by_store_copy['all_P_zips']+df_P_S_zips_by_store_copy['all_S_zips']\n",
    "df_P_S_zips_by_store_copy['All_P&S_zips_50_miles']=df_P_S_zips_by_store_copy['50_miles_P_zips']+df_P_S_zips_by_store_copy['50_miles_S_zips']\n",
    "df_P_S_zips_by_store_copy=df_P_S_zips_by_store_copy[['location_id','all_P_zips','all_S_zips','All_P&S_zips','50_miles_P_zips','50_miles_S_zips','All_P&S_zips_50_miles']]\n",
    "\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,df_P_S_zips_by_store_copy,on=\"location_id\",how=\"left\")\n",
    "\n",
    "df_output_600_stores_selected['nearest_store']=df_output_600_stores_selected['location_id'].apply(lambda x: find_nearest_store(x)[0])\n",
    "df_output_600_stores_selected['dist_to_nearest_store']=df_output_600_stores_selected['location_id'].apply(lambda x: find_nearest_store(x)[1])\n",
    "\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,store_PS_50_near,on=\"nearest_store\")\n",
    "df_output_600_stores_selected['nearest_intersection_zips']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[0],axis=1)\n",
    "df_output_600_stores_selected['nearest_pair_overlap_with_hold']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[1],axis=1)\n",
    "df_output_600_stores_selected['nearest_pair_overlap_with_nearest']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[2],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_600_stores_selected['min_overlap_pctg']=df_output_600_stores_selected['location_id'].apply(lambda x: find_overlaped_stores(x)[0])\n",
    "df_output_600_stores_selected['min_overlap_store']=df_output_600_stores_selected['location_id'].apply(lambda x: find_overlaped_stores(x)[1])\n",
    "df_output_600_stores_selected['max_overlap_pctg']=df_output_600_stores_selected['location_id'].apply(lambda x: find_overlaped_stores(x)[2])\n",
    "df_output_600_stores_selected['max_overlap_store']=df_output_600_stores_selected['location_id'].apply(lambda x: find_overlaped_stores(x)[3])\n",
    "\n",
    "\n",
    "df_output_600_stores_selected['min_overlap_store']=df_output_600_stores_selected['min_overlap_store'].apply(lambda x: eval(x))\n",
    "df_output_600_stores_selected['max_overlap_store']=df_output_600_stores_selected['max_overlap_store'].apply(lambda x: eval(x))\n",
    "\n",
    "df_output_600_stores_selected['min_paired_store']=df_output_600_stores_selected.apply(lambda x: remove_the_hold_store(x['min_overlap_store'],x['location_id']),axis=1)\n",
    "df_output_600_stores_selected['max_paired_store']=df_output_600_stores_selected.apply(lambda x: remove_the_hold_store(x['max_overlap_store'],x['location_id']),axis=1)\n",
    "\n",
    "df_output_600_stores_selected['min_overlap_store']=df_output_600_stores_selected['min_overlap_store'].astype(str)\n",
    "df_output_600_stores_selected['max_overlap_store']=df_output_600_stores_selected['max_overlap_store'].astype(str)\n",
    "\n",
    "df_output_600_stores_selected['dist_min_overlap_pairs']=df_output_600_stores_selected['min_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "df_output_600_stores_selected['dist_max_overlap_pairs']=df_output_600_stores_selected['max_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "\n",
    "\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,store_PS_50_min,on=\"min_paired_store\")\n",
    "df_output_600_stores_selected=pd.merge(df_output_600_stores_selected,store_PS_50_max,on=\"max_paired_store\")\n",
    "\n",
    "\n",
    "df_output_600_stores_selected['max_intersection_zips']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[0],axis=1)\n",
    "df_output_600_stores_selected['max_pair_overlap_with_hold']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[1],axis=1)\n",
    "df_output_600_stores_selected['max_pair_overlap_with_max']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[2],axis=1)\n",
    "\n",
    "df_output_600_stores_selected['min_intersection_zips']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[0],axis=1)\n",
    "df_output_600_stores_selected['min_pair_overlap_with_hold']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[1],axis=1)\n",
    "df_output_600_stores_selected['min_pair_overlap_with_min']=df_output_600_stores_selected.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_B_all_merge_4_50_above_involved_stores 25\n",
      "T1_B_all_merge_4_50_above_involved_stores 25\n",
      "T1_C_all_merge_3_50_above_involved_stores 297\n",
      "T1_C_all_merge_3_50_above_involved_stores 297\n",
      "T1_D_all_merge_4_50_above_involved_stores 2\n",
      "T1_D_all_merge_4_50_above_involved_stores 2\n",
      "T1_E_all_merge_3_50_above_involved_stores 10\n",
      "T1_E_all_merge_3_50_above_involved_stores 10\n",
      "T2_B_all_merge_4_35_50_involved_stores 40\n",
      "T2_B_all_merge_4_35_50_involved_stores 40\n",
      "T2_C_all_merge_3_35_50_involved_stores 270\n",
      "T2_C_all_merge_3_35_50_involved_stores 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_output_600_stores_selected_with_result=pd.DataFrame()\n",
    "for group,df_group in df_output_600_stores_selected.groupby(\"group\"):\n",
    "    print(group,df_group.shape[0])\n",
    "\n",
    "    if (group in ['T1_B_all_merge_4_50_above_involved_stores','T2_B_all_merge_4_35_50_involved_stores']):\n",
    "        df_1=df_group[df_group['min_overlap_pctg']>=0.35]\n",
    "        df_2=df_group[df_group['min_overlap_pctg']<0.35]\n",
    "        \n",
    "        df_1['result_combined_store']=df_1[['location_id','nearest_store','max_paired_store','min_paired_store']].values.tolist()\n",
    "        df_2['result_combined_store']=df_2[['location_id','nearest_store','max_paired_store']].values.tolist()\n",
    "        \n",
    "        df_group=df_1.append(df_2)\n",
    "        \n",
    "    elif (group in ['T1_C_all_merge_3_50_above_involved_stores','T1_D_all_merge_4_50_above_involved_stores','T1_E_all_merge_3_50_above_involved_stores']):\n",
    "        df_group['result_combined_store']=df_group[['location_id','nearest_store','max_paired_store']].values.tolist()\n",
    "        \n",
    "    elif group==\"T2_C_all_merge_3_35_50_involved_stores\":\n",
    "        df_group_max=df_group[(df_group['max_overlap_pctg']>=0.35) & (df_group['max_overlap_pctg']<0.5)]\n",
    "        df_group_min=df_group[(df_group['min_overlap_pctg']>=0.35) & (df_group['min_overlap_pctg']<0.5)]\n",
    "        list_max_group=df_group_max['location_id'].unique().tolist()\n",
    "        list_min_group=df_group_min['location_id'].unique().tolist()\n",
    "        list_both_group=list_max_group+list_min_group\n",
    "        \n",
    "        df_group_others=df_group[~df_group['location_id'].isin(list_both_group)]\n",
    "        \n",
    "        \n",
    "        df_group_max['result_combined_store']=df_group_max[['location_id','nearest_store','max_paired_store']].values.tolist()\n",
    "        df_group_min['result_combined_store']=df_group_min[['location_id','nearest_store','min_paired_store']].values.tolist()\n",
    "        \n",
    "        df_group=df_group_max.append(df_group_min).append(df_group_others)\n",
    "        \n",
    "    print(group,len(df_group))\n",
    "    df_output_600_stores_selected_with_result=df_output_600_stores_selected_with_result.append(df_group)\n",
    "df_output_600_stores_selected_with_result['result_combined_store']=df_output_600_stores_selected_with_result['result_combined_store'].fillna(\"[]\")\n",
    "df_output_600_stores_selected_with_result['result_combined_store']=df_output_600_stores_selected_with_result['result_combined_store'].astype(str)\n",
    "df_output_600_stores_selected_with_result['result_combined_store']=df_output_600_stores_selected_with_result['result_combined_store'].apply(lambda x: sorted(list(set(eval(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_2=col_list.copy()\n",
    "col_list_2.remove(\"dist_group\")\n",
    "\n",
    "col_list_2=col_list_2[:6]+['CTY','DMA']+col_list_2[6:]\n",
    "df_output_600_stores_selected_with_result=df_output_600_stores_selected_with_result[[\"group\"]+col_list_2+[\"result_combined_store\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_600_stores_selected_with_result=df_output_600_stores_selected_with_result.sort_values([\"dist_to_nearest_store\",\"state_nm\",\"CTY\",\"city_nm\"])\n",
    "\n",
    "writer=pd.ExcelWriter(output_folder+\"sorted_600_stores_T1B_T2C_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_output_600_stores_selected_with_result.to_excel(writer,\"sorted_600_stores\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_data=df_output_600_stores_selected_with_result[['location_id','result_combined_store']]\n",
    "df_ta_store_result_pairs=pd.DataFrame(columns=['TA','location_id'])\n",
    "df_data=df_data.reset_index()\n",
    "del df_data['index']\n",
    "\n",
    "ta=0\n",
    "for i,row in df_data.iterrows():\n",
    "    location_hold=row['location_id']\n",
    "    location_associatd=row['result_combined_store']\n",
    "    intersection_existing=set(location_associatd).intersection(set(df_ta_store_result_pairs['location_id'].tolist()))\n",
    "    \n",
    "    if len(intersection_existing)==0:\n",
    "        ta+=1\n",
    "        df=pd.DataFrame({\"TA\":[ta]*len(location_associatd),\"location_id\":location_associatd},index=[ta]*len(location_associatd))\n",
    "        df_ta_store_result_pairs=df_ta_store_result_pairs.append(df)\n",
    "    else:\n",
    "        TA_list_overlapped=df_ta_store_result_pairs[df_ta_store_result_pairs['location_id'].isin(intersection_existing)]['TA'].unique().tolist()\n",
    "        grouped_ta=df_ta_store_result_pairs[df_ta_store_result_pairs['TA'].isin(TA_list_overlapped)]\n",
    "        grouped_ta_others=df_ta_store_result_pairs[~df_ta_store_result_pairs['TA'].isin(TA_list_overlapped)]\n",
    "        \n",
    "        grouped_ta['TA']=grouped_ta['TA'].min()\n",
    "        \n",
    "        new_stores_added=[x for x in location_associatd if x not in grouped_ta['location_id'].tolist()]\n",
    "        df=pd.DataFrame({\"TA\":[grouped_ta['TA'].min()]*len(new_stores_added),\"location_id\":new_stores_added},index=[grouped_ta['TA'].min()]*len(new_stores_added))\n",
    "        grouped_ta=grouped_ta.append(df)\n",
    "        df_ta_store_result_pairs=grouped_ta_others.append(grouped_ta)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644, 2)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ta_store_result_pairs=df_ta_store_result_pairs[df_ta_store_result_pairs['location_id'].isin(df_output_600_stores_selected_with_result['location_id'].tolist())]\n",
    "df_ta_store_result_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_600_stores_selected_with_result=pd.merge(df_output_600_stores_selected_with_result,df_ta_store_result_pairs,on=\"location_id\",how=\"left\")\n",
    "\n",
    "summary_df_600_stores=df_output_600_stores_selected_with_result.groupby(\"TA\")['location_id'].count().to_frame().reset_index().sort_values(\"location_id\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_600_stores_selected_with_result=df_output_600_stores_selected_with_result[['TA']+[x for x in df_output_600_stores_selected_with_result.columns.tolist() if x!=\"TA\"]]\n",
    "df_output_600_stores_selected_with_result=df_output_600_stores_selected_with_result.sort_values(['TA','state_nm','CTY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rename_TA=df_output_600_stores_selected_with_result[['TA']].drop_duplicates()\n",
    "df_rename_TA['new_name']=[x+1 for x in range(len(df_rename_TA))]\n",
    "dict_rename_TA=df_rename_TA.set_index(\"TA\").to_dict()[\"new_name\"]\n",
    "\n",
    "\n",
    "df_output_600_stores_selected_with_result['TA']=df_output_600_stores_selected_with_result['TA'].apply(lambda x: dict_rename_TA[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"initial_TA_output.xlsx\",engine=\"xlsxwriter\")\n",
    "\n",
    "df_output_600_stores_selected_with_result.to_excel(writer,\"with_TA\",index=False)\n",
    "summary_df_600_stores.to_excel(writer,\"summary\",index=False)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 4)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_600_TA_zips=df_output_600_stores_selected_with_result.groupby(\"TA\")['All_P&S_zips_50_miles','All_P&S_zips'].sum().reset_index()\n",
    "\n",
    "df_output_600_TA_zips=df_output_600_TA_zips.rename(columns={\"All_P&S_zips_50_miles\":\"zip_cd_50\",\"All_P&S_zips\":\"zip_cd_all\",\"location_id\":\"store_list\"})\n",
    "df_output_600_TA_zips['zip_cd_50']=df_output_600_TA_zips['zip_cd_50'].apply(lambda x: list(set(x)))\n",
    "df_output_600_TA_zips['zip_cd_all']=df_output_600_TA_zips['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "\n",
    "df_output_600_TA_zips_2=df_output_600_stores_selected_with_result.groupby(\"TA\")['location_id'].apply(list).reset_index()\n",
    "df_output_600_TA_zips_2=df_output_600_TA_zips_2.rename(columns={\"location_id\":\"store_list\"})\n",
    "df_output_600_TA_zips_2['store_list']=df_output_600_TA_zips_2['store_list'].apply(lambda x: list(set(x)))\n",
    "\n",
    "df_output_600_TA_zips=pd.merge(df_output_600_TA_zips,df_output_600_TA_zips_2,on=\"TA\")\n",
    "df_output_600_TA_zips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4715 in new_stores['location_id'].astype(int).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Store TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 3)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stores=new_stores.reset_index()\n",
    "\n",
    "df_new_store_zips=pd.DataFrame()\n",
    "\n",
    "del new_stores['index']\n",
    "\n",
    "for ind,row in new_stores.iterrows():\n",
    "    store_num=row['location_id']\n",
    "    store_center=[row['latitude_meas'],row['longitude_meas']]\n",
    "    \n",
    "    for zip_cd in zip_centers.keys():\n",
    "        dist=haversine(store_center,zip_centers[zip_cd],unit=\"mi\")\n",
    "        \n",
    "        if dist<=10:\n",
    "\n",
    "            df=pd.DataFrame({\"location_id\":store_num,\"zips_in_10\":zip_cd,\"dist_miles\":dist},index=[store_num])\n",
    "            df_new_store_zips=df_new_store_zips.append(df)\n",
    "        \n",
    "df_new_store_zips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>All_P&amp;S_zips_50_miles</th>\n",
       "      <th>All_P&amp;S_zips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1198</td>\n",
       "      <td>[35044, 35151, 35032, 35183, 35150, 35082, 35149]</td>\n",
       "      <td>[35044, 35151, 35032, 35183, 35150, 35082, 35149]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1241</td>\n",
       "      <td>[22812, 22840, 22802, 24471, 22850, 22821, 228...</td>\n",
       "      <td>[22812, 22840, 22802, 24471, 22850, 22821, 228...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id                              All_P&S_zips_50_miles  \\\n",
       "0        1198  [35044, 35151, 35032, 35183, 35150, 35082, 35149]   \n",
       "1        1241  [22812, 22840, 22802, 24471, 22850, 22821, 228...   \n",
       "\n",
       "                                        All_P&S_zips  \n",
       "0  [35044, 35151, 35032, 35183, 35150, 35082, 35149]  \n",
       "1  [22812, 22840, 22802, 24471, 22850, 22821, 228...  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_store_zips_wide=df_new_store_zips.groupby(\"location_id\")['zips_in_10'].apply(list).to_frame().reset_index()\n",
    "df_new_store_zips_wide['zips_in_10']=df_new_store_zips_wide['zips_in_10'].apply(lambda x: list(set(x)))\n",
    "\n",
    "\n",
    "df_new_store_zips_wide_copy=df_new_store_zips_wide.copy()\n",
    "df_new_store_zips_wide_copy['All_P&S_zips_50_miles']=df_new_store_zips_wide_copy['zips_in_10']\n",
    "df_new_store_zips_wide_copy['All_P&S_zips']=df_new_store_zips_wide_copy['zips_in_10']\n",
    "del df_new_store_zips_wide_copy['zips_in_10']\n",
    "\n",
    "df_new_store_zips_wide_copy.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_store_zips_wide_copy=pd.merge(df_new_store_zips_wide_copy,store_list,on=\"location_id\",how=\"left\")\n",
    "df_new_store_zips_wide_copy=pd.merge(df_new_store_zips_wide_copy,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "df_new_store_zips_wide_copy['DMA']=df_new_store_zips_wide_copy['DMA'].astype(str)\n",
    "df_new_store_zips_wide_copy['CTY']=df_new_store_zips_wide_copy['CTY'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(378, 4)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sing_store_zips_wide=df_all_single_store_TA[['location_id','All_P&S_zips_50_miles','All_P&S_zips']]\n",
    "\n",
    "df_sing_store_zips_wide=df_sing_store_zips_wide.sort_values(\"location_id\")\n",
    "df_sing_store_zips_wide=df_sing_store_zips_wide.rename(columns={\"All_P&S_zips_50_miles\":\"zip_cd_50\",\n",
    "                                                                                               \"All_P&S_zips\":\"zip_cd_all\",\n",
    "                                                                                               \"location_id\":\"store_list\"})\n",
    "df_sing_store_zips_wide['store_list']=df_sing_store_zips_wide['store_list'].apply(lambda x: [x])\n",
    "df_sing_store_zips_wide['TA']=[x+1+df_output_600_TA_zips['TA'].max() for x in range(len(df_sing_store_zips_wide))]\n",
    "\n",
    "all_defined_TA=df_output_600_TA_zips.append(df_sing_store_zips_wide)\n",
    "all_defined_stores=all_defined_TA['store_list'].sum()\n",
    "print(len(all_defined_stores))\n",
    "\n",
    "all_defined_TA=all_defined_TA.reset_index()\n",
    "del all_defined_TA['index']\n",
    "\n",
    "all_defined_TA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining stores\n",
    "\n",
    "df_remain_stores=store_list[['location_id']].drop_duplicates()\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(df_new_store_zips_wide_copy['location_id'].tolist())]\n",
    "df_remain_stores=df_remain_stores[df_remain_stores['location_id']!=\"145\"]\n",
    "df_remain_stores=df_remain_stores[df_remain_stores['location_id']!=\"6990\"]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(all_defined_stores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remain_stores=pd.merge(df_remain_stores,store_list,on=\"location_id\",how=\"left\")\n",
    "df_remain_stores=pd.merge(df_remain_stores,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "\n",
    "df_remain_stores['DMA']=df_remain_stores['DMA'].astype(str)\n",
    "df_remain_stores['CTY']=df_remain_stores['CTY'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remain_stores=pd.merge(df_remain_stores,df_P_S_zips_by_store_copy,on=\"location_id\",how=\"inner\")\n",
    "\n",
    "df_remain_stores['nearest_store']=df_remain_stores['location_id'].apply(lambda x: find_nearest_store(x)[0])\n",
    "df_remain_stores['dist_to_nearest_store']=df_remain_stores['location_id'].apply(lambda x: find_nearest_store(x)[1])\n",
    "\n",
    "df_remain_stores=pd.merge(df_remain_stores,store_PS_50_near,on=\"nearest_store\")\n",
    "\n",
    "df_remain_stores['nearest_intersection_zips']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[0],axis=1)\n",
    "df_remain_stores['nearest_pair_overlap_with_hold']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[1],axis=1)\n",
    "df_remain_stores['nearest_pair_overlap_with_nearest']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['near_store_all_PS_50'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remain_stores['min_overlap_pctg']=df_remain_stores['location_id'].apply(lambda x: find_overlaped_stores(x)[0])\n",
    "df_remain_stores['min_overlap_store']=df_remain_stores['location_id'].apply(lambda x: find_overlaped_stores(x)[1])\n",
    "df_remain_stores['max_overlap_pctg']=df_remain_stores['location_id'].apply(lambda x: find_overlaped_stores(x)[2])\n",
    "df_remain_stores['max_overlap_store']=df_remain_stores['location_id'].apply(lambda x: find_overlaped_stores(x)[3])\n",
    "\n",
    "\n",
    "df_remain_stores['min_overlap_store']=df_remain_stores['min_overlap_store'].apply(lambda x: eval(x))\n",
    "df_remain_stores['max_overlap_store']=df_remain_stores['max_overlap_store'].apply(lambda x: eval(x))\n",
    "\n",
    "df_remain_stores['min_paired_store']=df_remain_stores.apply(lambda x: remove_the_hold_store(x['min_overlap_store'],x['location_id']),axis=1)\n",
    "df_remain_stores['max_paired_store']=df_remain_stores.apply(lambda x: remove_the_hold_store(x['max_overlap_store'],x['location_id']),axis=1)\n",
    "\n",
    "df_remain_stores['min_overlap_store']=df_remain_stores['min_overlap_store'].astype(str)\n",
    "df_remain_stores['max_overlap_store']=df_remain_stores['max_overlap_store'].astype(str)\n",
    "\n",
    "df_remain_stores['dist_min_overlap_pairs']=df_remain_stores['min_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "df_remain_stores['dist_max_overlap_pairs']=df_remain_stores['max_overlap_store'].apply(lambda x: dist_of_2_str_stores(x))\n",
    "\n",
    "\n",
    "df_remain_stores=pd.merge(df_remain_stores,store_PS_50_min,on=\"min_paired_store\")\n",
    "df_remain_stores=pd.merge(df_remain_stores,store_PS_50_max,on=\"max_paired_store\")\n",
    "\n",
    "\n",
    "df_remain_stores['max_intersection_zips']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[0],axis=1)\n",
    "df_remain_stores['max_pair_overlap_with_hold']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[1],axis=1)\n",
    "df_remain_stores['max_pair_overlap_with_max']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['max_store_all_PS_50'])[2],axis=1)\n",
    "\n",
    "df_remain_stores['min_intersection_zips']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[0],axis=1)\n",
    "df_remain_stores['min_pair_overlap_with_hold']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[1],axis=1)\n",
    "df_remain_stores['min_pair_overlap_with_min']=df_remain_stores.apply(lambda x: intersection_2_list(x['All_P&S_zips_50_miles'],x['min_store_all_PS_50'])[2],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remain_stores=df_remain_stores.append(df_new_store_zips_wide_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_covered_TA(zip_list_store):\n",
    "    max_intersect_count=0\n",
    "    max_intersect_list=[]\n",
    "    intersect_TA=0\n",
    "    for ind,row in all_defined_TA.iterrows():\n",
    "        ta_50_zips=row['zip_cd_50']\n",
    "        intersection_zips_P_S_50=list(set(zip_list_store).intersection(set(ta_50_zips)))\n",
    "        intersection_zips_P_S_50_len=len(intersection_zips_P_S_50)\n",
    "        if intersection_zips_P_S_50_len>max_intersect_count:\n",
    "            max_intersect_count=intersection_zips_P_S_50_len\n",
    "            max_intersect_list=intersection_zips_P_S_50\n",
    "            intersect_TA=row['TA']\n",
    "    max_intersect_pctc=max_intersect_count/len(zip_list_store)\n",
    "            \n",
    "    return intersect_TA,max_intersect_list,max_intersect_count,max_intersect_pctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_50']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_all_single_store_TA['dist_group']\n",
    "df_sing_store_zips_wide_copy=df_sing_store_zips_wide.copy()\n",
    "df_sing_store_zips_wide_copy=df_sing_store_zips_wide_copy[['store_list','TA']]\n",
    "df_sing_store_zips_wide_copy['location_id']=df_sing_store_zips_wide_copy['store_list'].apply(lambda x: x[0])\n",
    "df_sing_store_zips_wide_copy=df_sing_store_zips_wide_copy[['location_id',\"TA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_single_store_TA=pd.merge(df_all_single_store_TA,df_sing_store_zips_wide_copy,on=\"location_id\",how=\"left\")\n",
    "df_all_single_store_TA=df_all_single_store_TA[[\"TA\"]+[x for x in df_all_single_store_TA.columns.tolist() if x!=\"TA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_all_single_store_TA_cols_1=[x for x in df_output_600_stores_selected_with_result.columns.tolist() if x in df_all_single_store_TA.columns.tolist()]\n",
    "df_all_single_store_TA_cols_2=[x for x in df_all_single_store_TA.columns.tolist() if x not in df_all_single_store_TA_cols_1]\n",
    "df_all_single_store_TA=df_all_single_store_TA[df_all_single_store_TA_cols_1+df_all_single_store_TA_cols_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_remain_stores_cols_1=[x for x in df_output_600_stores_selected_with_result.columns.tolist() if x in df_remain_stores.columns.tolist()]\n",
    "df_remain_stores_cols_2=[x for x in df_remain_stores.columns.tolist() if x not in df_remain_stores_cols_1]\n",
    "df_remain_stores=df_remain_stores[df_remain_stores_cols_1+df_remain_stores_cols_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"BL_remaining_stores_and_defined_TA_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_remain_stores.to_excel(writer,\"df_remain_stores\",index=False)\n",
    "all_defined_TA.to_excel(writer,\"all_defined_TA\",index=False)\n",
    "df_output_600_stores_selected_with_result.to_excel(writer,\"TA_by_store_multiple\",index=False)\n",
    "df_all_single_store_TA.to_excel(writer,\"TA_by_store_single\",index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>store_list</th>\n",
       "      <th>zip_cd_50</th>\n",
       "      <th>zip_cd_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[4196, 4652, 1966, 1245, 4144]</td>\n",
       "      <td>[75225, 75233, 75134, 75062, 75001, 75204, 751...</td>\n",
       "      <td>[75225, 75233, 75134, 75062, 75001, 75204, 751...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[4170, 4155, 4686, 4025, 4699]</td>\n",
       "      <td>[90012, 90023, 90026, 91024, 91016, 90040, 900...</td>\n",
       "      <td>[90012, 90023, 90026, 91024, 91016, 90040, 900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[1897, 4564, 4296, 4483]</td>\n",
       "      <td>[92675, 92656, 92780, 92679, 92651, 92688, 926...</td>\n",
       "      <td>[92675, 92656, 92780, 92679, 92651, 92688, 926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[4136, 4328]</td>\n",
       "      <td>[90813, 90717, 90278, 90277, 90732, 90504, 907...</td>\n",
       "      <td>[90813, 90717, 90278, 90277, 90732, 90504, 907...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TA                      store_list  \\\n",
       "0   1  [4196, 4652, 1966, 1245, 4144]   \n",
       "1   2  [4170, 4155, 4686, 4025, 4699]   \n",
       "2   3        [1897, 4564, 4296, 4483]   \n",
       "3   4                    [4136, 4328]   \n",
       "\n",
       "                                           zip_cd_50  \\\n",
       "0  [75225, 75233, 75134, 75062, 75001, 75204, 751...   \n",
       "1  [90012, 90023, 90026, 91024, 91016, 90040, 900...   \n",
       "2  [92675, 92656, 92780, 92679, 92651, 92688, 926...   \n",
       "3  [90813, 90717, 90278, 90277, 90732, 90504, 907...   \n",
       "\n",
       "                                          zip_cd_all  \n",
       "0  [75225, 75233, 75134, 75062, 75001, 75204, 751...  \n",
       "1  [90012, 90023, 90026, 91024, 91016, 90040, 900...  \n",
       "2  [92675, 92656, 92780, 92679, 92651, 92688, 926...  \n",
       "3  [90813, 90717, 90278, 90277, 90732, 90504, 907...  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_defined_TA.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-22 21:55:50.679742\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iter the balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iter 1 - >=40% \n",
    "\n",
    "df_remain_stores_Iter1_50=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.4]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50[['location_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_50_miles']]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "df_remain_stores_Iter1_50['location_id']=df_remain_stores_Iter1_50['location_id'].apply(lambda x: [x])\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.groupby(\"TA\")['location_id','All_P&S_zips','All_P&S_zips_50_miles'].sum().reset_index()\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    df_remain_stores_Iter1_50[col]=df_remain_stores_Iter1_50[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "###\n",
    "all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_50,on=\"TA\",how=\"left\")\n",
    "\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "    all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "    all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "    \n",
    "all_defined_TA['store_list']=all_defined_TA[['store_list','location_id']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA[['zip_cd_50','All_P&S_zips_50_miles']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA['zip_cd_50'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_50','zip_cd_all']]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_50']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iter 2 - >=30% \n",
    "\n",
    "df_remain_stores_Iter1_50=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.3]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50[['location_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_50_miles']]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "df_remain_stores_Iter1_50['location_id']=df_remain_stores_Iter1_50['location_id'].apply(lambda x: [x])\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.groupby(\"TA\")['location_id','All_P&S_zips','All_P&S_zips_50_miles'].sum().reset_index()\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    df_remain_stores_Iter1_50[col]=df_remain_stores_Iter1_50[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "###\n",
    "all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_50,on=\"TA\",how=\"left\")\n",
    "\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "    all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "    all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "    \n",
    "all_defined_TA['store_list']=all_defined_TA[['store_list','location_id']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA[['zip_cd_50','All_P&S_zips_50_miles']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA['zip_cd_50'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_50','zip_cd_all']]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_50']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iter 3 - >=20% \n",
    "\n",
    "df_remain_stores_Iter1_50=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.2]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50[['location_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_50_miles']]\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "df_remain_stores_Iter1_50['location_id']=df_remain_stores_Iter1_50['location_id'].apply(lambda x: [x])\n",
    "df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.groupby(\"TA\")['location_id','All_P&S_zips','All_P&S_zips_50_miles'].sum().reset_index()\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    df_remain_stores_Iter1_50[col]=df_remain_stores_Iter1_50[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "###\n",
    "all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_50,on=\"TA\",how=\"left\")\n",
    "\n",
    "for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "    all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "    all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "    all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "    \n",
    "all_defined_TA['store_list']=all_defined_TA[['store_list','location_id']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA[['zip_cd_50','All_P&S_zips_50_miles']].sum(axis=1)\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "all_defined_TA['zip_cd_50']=all_defined_TA['zip_cd_50'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_50','zip_cd_all']]\n",
    "\n",
    "df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "df_remain_stores['Overlap_zips_with_TA_50']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276, 42)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>0.2].shape[0]>0:\n",
    "    df_remain_stores_Iter1_50=df_remain_stores[df_remain_stores['Overlap_zips_Pctg']>=0.2]\n",
    "    df_remain_stores_Iter1_50=df_remain_stores_Iter1_50[['location_id','Max_overlap_TA','All_P&S_zips','All_P&S_zips_50_miles']]\n",
    "    df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.rename(columns={\"Max_overlap_TA\":\"TA\"})\n",
    "    df_remain_stores_Iter1_50['location_id']=df_remain_stores_Iter1_50['location_id'].apply(lambda x: [x])\n",
    "    df_remain_stores_Iter1_50=df_remain_stores_Iter1_50.groupby(\"TA\")['location_id','All_P&S_zips','All_P&S_zips_50_miles'].sum().reset_index()\n",
    "    for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "        df_remain_stores_Iter1_50[col]=df_remain_stores_Iter1_50[col].apply(lambda x: list(set(x)))\n",
    "\n",
    "    ###\n",
    "    all_defined_TA=pd.merge(all_defined_TA,df_remain_stores_Iter1_50,on=\"TA\",how=\"left\")\n",
    "\n",
    "    for col in ['location_id','All_P&S_zips','All_P&S_zips_50_miles']:\n",
    "        all_defined_TA[col]=all_defined_TA[col].fillna(\"[]\")\n",
    "        all_defined_TA[col]=all_defined_TA[col].astype(str)\n",
    "        all_defined_TA[col]=all_defined_TA[col].apply(lambda x: eval(x))\n",
    "\n",
    "    all_defined_TA['store_list']=all_defined_TA[['store_list','location_id']].sum(axis=1)\n",
    "    all_defined_TA['zip_cd_50']=all_defined_TA[['zip_cd_50','All_P&S_zips_50_miles']].sum(axis=1)\n",
    "    all_defined_TA['zip_cd_all']=all_defined_TA[['zip_cd_all','All_P&S_zips']].sum(axis=1)\n",
    "\n",
    "    all_defined_TA['zip_cd_50']=all_defined_TA['zip_cd_50'].apply(lambda x: list(set(x)))\n",
    "    all_defined_TA['zip_cd_all']=all_defined_TA['zip_cd_all'].apply(lambda x: list(set(x)))\n",
    "    all_defined_TA=all_defined_TA[['TA','store_list','zip_cd_50','zip_cd_all']]\n",
    "\n",
    "    df_remain_stores=df_remain_stores[~df_remain_stores['location_id'].isin(all_defined_TA['store_list'].sum())]\n",
    "\n",
    "    df_remain_stores['Max_overlap_TA']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[0])\n",
    "    df_remain_stores['Overlap_zips_with_TA_50']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[1])\n",
    "    df_remain_stores['Overlap_zips_count']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[2])\n",
    "    df_remain_stores['Overlap_zips_Pctg']=df_remain_stores['All_P&S_zips_50_miles'].apply(lambda x: find_max_covered_TA(x)[3])\n",
    "df_remain_stores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1126"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_defined_TA['store_count']=all_defined_TA['store_list'].apply(lambda x: len(x))\n",
    "all_defined_TA['store_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(output_folder+\"BL_remaining_stores_and_defined_2_TA_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_remain_stores.to_excel(writer,\"df_remain_stores\",index=False)\n",
    "all_defined_TA.to_excel(writer,\"all_defined_TA\",index=False)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_list [<class 'list'>]\n",
      "zip_cd_all [<class 'list'>]\n",
      "zip_cd_50 [<class 'list'>]\n",
      "TA [<class 'int'>]\n",
      "TA [<class 'int'>]\n",
      "store_list [<class 'list'>]\n",
      "zip_cd_50 [<class 'list'>]\n",
      "zip_cd_all [<class 'list'>]\n",
      "store_count [<class 'int'>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_remain_stores_single_TA=df_remain_stores[['location_id','All_P&S_zips','All_P&S_zips_50_miles']]\n",
    "df_remain_stores_single_TA['TA']=[all_defined_TA['TA'].max()+x+1 for x in range(len(df_remain_stores_single_TA))]\n",
    "df_remain_stores_single_TA=df_remain_stores_single_TA.rename(columns={\"location_id\":\"store_list\"})\n",
    "df_remain_stores_single_TA=df_remain_stores_single_TA.rename(columns={\"All_P&S_zips_50_miles\":\"zip_cd_50\"})\n",
    "df_remain_stores_single_TA=df_remain_stores_single_TA.rename(columns={\"All_P&S_zips\":\"zip_cd_all\"})\n",
    "df_remain_stores_single_TA['store_list']=df_remain_stores_single_TA['store_list'].apply(lambda x: [x])\n",
    "df_remain_stores_single_TA.head(2)\n",
    "\n",
    "for col in df_remain_stores_single_TA.columns.tolist():\n",
    "    print(col,df_remain_stores_single_TA[col].apply(lambda x: type(x)).unique())\n",
    "    \n",
    "for col in all_defined_TA.columns.tolist():\n",
    "    print(col,all_defined_TA[col].apply(lambda x: type(x)).unique())\n",
    "    \n",
    "all_defined_TA=all_defined_TA.append(df_remain_stores_single_TA)\n",
    "\n",
    "all_defined_TA['store_count']=all_defined_TA['store_list'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_defined_TA['store_count']=all_defined_TA['store_list'].apply(lambda x: len(x))\n",
    "\n",
    "all_defined_TA['temp_1st_store']=all_defined_TA['store_list'].apply(lambda x: \"single_\"+str(x[0]))\n",
    "all_defined_TA['temp_TA_str']=all_defined_TA['TA'].apply(lambda x: \"multiple_\"+str(x))\n",
    "\n",
    "all_defined_TA['ta_name']=np.where(all_defined_TA['store_count']==1,all_defined_TA['temp_1st_store'],all_defined_TA['temp_TA_str'])\n",
    "\n",
    "del all_defined_TA['temp_1st_store']\n",
    "del all_defined_TA['temp_TA_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_store_count_TA=all_defined_TA.groupby(\"store_count\")['TA'].count().to_frame().reset_index().sort_values(\"store_count\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=pd.DataFrame(columns={\"location_id\",\"TA\",\"ta_name\"})\n",
    "\n",
    "for ind,row in all_defined_TA.iterrows():\n",
    "    store_list_in_TA=row['store_list']\n",
    "    TA_num=row['TA']\n",
    "    TA_name=row['ta_name']\n",
    "    df=pd.DataFrame({\"location_id\":store_list_in_TA,\"TA\":[TA_num]*len(store_list_in_TA),\"ta_name\":[TA_name]*len(store_list_in_TA)},index=range(len(store_list_in_TA)))\n",
    "    df_output_by_store=df_output_by_store.append(df)\n",
    "df_output_by_store=df_output_by_store.sort_values([\"TA\",\"location_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous_zip_by_store_copy=df_sales_by_zip[df_sales_by_zip['location_id'].isin(df_output_by_store['location_id'].tolist())]\n",
    "df_previous_zip_by_store_copy=df_previous_zip_by_store_copy[['location_id','customer_zip_code','trans_label']]\n",
    "df_previous_zip_by_store_copy=df_previous_zip_by_store_copy[df_previous_zip_by_store_copy['trans_label'].isin([\"P\",\"S\"])]\n",
    "df_previous_zip_by_store_copy=df_previous_zip_by_store_copy.rename(columns={\"customer_zip_code\":\"zip_cd\"})\n",
    "\n",
    "df_previous_zip_by_store_copy.shape\n",
    "\n",
    "df_trans_zips=df_previous_zip_by_store_copy.groupby([\"location_id\",\"trans_label\"])['zip_cd'].apply(list).to_frame().reset_index()\n",
    "\n",
    "df_trans_zips=df_trans_zips.pivot(index=\"location_id\",columns=\"trans_label\",values=\"zip_cd\").reset_index()\n",
    "df_trans_zips=df_trans_zips.rename(columns={\"P\":\"all_trans_P_zips\",\"S\":\"all_trans_S_zips\"})\n",
    "df_10_zips=df_new_store_zips.groupby(\"location_id\")['zips_in_10'].apply(list).to_frame().reset_index()\n",
    "df_output_by_store_zips=df_trans_zips.append(df_10_zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=pd.merge(df_output_by_store,store_list,on=\"location_id\",how=\"left\")\n",
    "df_output_by_store=pd.merge(df_output_by_store,DMA_nielsen,on=\"zip_cd\",how=\"left\")\n",
    "df_output_by_store=pd.merge(df_output_by_store,df_output_by_store_zips,on=\"location_id\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store['all_trans_P_zips']=df_output_by_store['all_trans_P_zips'].fillna(\"[]\")\n",
    "df_output_by_store['all_trans_S_zips']=df_output_by_store['all_trans_S_zips'].fillna(\"[]\")\n",
    "df_output_by_store['zips_in_10']=df_output_by_store['zips_in_10'].fillna(\"[]\")\n",
    "\n",
    "df_output_by_store['all_trans_P_zips']=df_output_by_store['all_trans_P_zips'].astype(str)\n",
    "df_output_by_store['all_trans_S_zips']=df_output_by_store['all_trans_S_zips'].astype(str)\n",
    "df_output_by_store['zips_in_10']=df_output_by_store['zips_in_10'].astype(str)\n",
    "\n",
    "df_output_by_store['all_trans_P_zips']=df_output_by_store['all_trans_P_zips'].apply(lambda x: eval(x))\n",
    "df_output_by_store['all_trans_S_zips']=df_output_by_store['all_trans_S_zips'].apply(lambda x: eval(x))\n",
    "df_output_by_store['zips_in_10']=df_output_by_store['zips_in_10'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit 70 miles zips to the associated stores\n",
    "df_output_by_store_copy=df_output_by_store.copy()\n",
    "df_output_by_store_copy=df_output_by_store_copy.reset_index()\n",
    "del df_output_by_store_copy['index']\n",
    "\n",
    "location_lat_long_dict=df_output_by_store_copy[['location_id','latitude_meas','longitude_meas']].drop_duplicates()\n",
    "location_lat_long_dict['store_center']=location_lat_long_dict[['latitude_meas','longitude_meas']].values.tolist()\n",
    "location_lat_long_dict=location_lat_long_dict.set_index(\"location_id\")['store_center']\n",
    "\n",
    "\n",
    "df_output_by_store_1=pd.DataFrame()\n",
    "df_output_by_store_copy['trans_P_zips_70_within_TA']=np.nan\n",
    "df_output_by_store_copy['trans_S_zips_70_within_TA']=np.nan\n",
    "\n",
    "\n",
    "\n",
    "for TA,df_group in df_output_by_store_copy.groupby(\"TA\"):\n",
    "    store_list=df_group['location_id'].tolist()\n",
    "    df_group=df_group.reset_index()\n",
    "    del df_group['index']\n",
    "    \n",
    "    for ind,row in df_group.iterrows():\n",
    "        all_P_zips_list=row['all_trans_P_zips']\n",
    "        all_S_zips_list=row['all_trans_S_zips']\n",
    "        P_zips_list_70_in_TA=[]\n",
    "        S_zips_list_70_in_TA=[]\n",
    "        \n",
    "        for zip_P in all_P_zips_list:\n",
    "            if zip_P in zip_centers.keys():\n",
    "                for store in store_list:\n",
    "                    store_center=location_lat_long_dict[store]\n",
    "                    dist=haversine(store_center, zip_centers[zip_P],unit=\"mi\")\n",
    "                    if dist<=70:\n",
    "                        P_zips_list_70_in_TA=P_zips_list_70_in_TA+[zip_P]\n",
    "                \n",
    "        for zip_S in all_S_zips_list:\n",
    "            if zip_S in zip_centers.keys():\n",
    "                for store in store_list:\n",
    "                    store_center=location_lat_long_dict[store]\n",
    "                    dist=haversine(store_center, zip_centers[zip_S],unit=\"mi\")\n",
    "                    if dist<=70:\n",
    "                        S_zips_list_70_in_TA=S_zips_list_70_in_TA+[zip_S]\n",
    "                    \n",
    "        P_zips_list_70_in_TA=list(set(P_zips_list_70_in_TA))\n",
    "        S_zips_list_70_in_TA=list(set(S_zips_list_70_in_TA))\n",
    "        \n",
    "        df_group.loc[ind,'trans_P_zips_70_within_TA']=str(P_zips_list_70_in_TA)\n",
    "        df_group.loc[ind,'trans_S_zips_70_within_TA']=str(S_zips_list_70_in_TA)\n",
    "        \n",
    "    df_output_by_store_1=df_output_by_store_1.append(df_group)\n",
    "        \n",
    "df_output_by_store_1['trans_P_zips_70_within_TA']=df_output_by_store_1['trans_P_zips_70_within_TA'].apply(lambda x: eval(x))\n",
    "df_output_by_store_1['trans_S_zips_70_within_TA']=df_output_by_store_1['trans_S_zips_70_within_TA'].apply(lambda x: eval(x))\n",
    "\n",
    "df_output_by_store=df_output_by_store_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=df_output_by_store.reset_index()\n",
    "del df_output_by_store['index']\n",
    "\n",
    "df_output_by_store_zip_long=pd.DataFrame(columns=[\"TA\",\"ta_name\",\"location_id\",'zip_cd','zip_type'])\n",
    "\n",
    "for ind,row in df_output_by_store.iterrows():\n",
    "    TA=row['TA']\n",
    "    ta_name=row['ta_name']\n",
    "    location_id=row['location_id']\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    all_P_zips=row['trans_P_zips_70_within_TA']\n",
    "    all_S_zips=row['trans_S_zips_70_within_TA']\n",
    "    all_10_zips=row['zips_in_10']\n",
    "    \n",
    "    df_P=pd.DataFrame({\"location_id\":[location_id]*len(all_P_zips),'zip_cd':all_P_zips})\n",
    "    df_P['zip_type']=\"trans_P\"\n",
    "    \n",
    "    df_S=pd.DataFrame({\"location_id\":[location_id]*len(all_S_zips),'zip_cd':all_S_zips})\n",
    "    df_S['zip_type']=\"trans_S\"\n",
    "    \n",
    "    df_10=pd.DataFrame({\"location_id\":[location_id]*len(all_10_zips),'zip_cd':all_10_zips})\n",
    "    df_10['zip_type']=\"zips_10\"\n",
    "    \n",
    "    df=df_P.append(df_S).append(df_10)\n",
    "    df['TA']=TA\n",
    "    df['ta_name']=ta_name\n",
    "    df_output_by_store_zip_long=df_output_by_store_zip_long.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>store_list</th>\n",
       "      <th>trans_P_zips</th>\n",
       "      <th>trans_S_zips</th>\n",
       "      <th>distance_10_zips</th>\n",
       "      <th>store_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>multiple_1</td>\n",
       "      <td>[1245, 1966, 4144, 4196, 4632, 4652]</td>\n",
       "      <td>[75006, 75061, 75062, 75104, 75115, 75146, 751...</td>\n",
       "      <td>[75001, 75007, 75019, 75038, 75039, 75040, 750...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>multiple_2</td>\n",
       "      <td>[4025, 4049, 4155, 4170, 4275, 4686, 4699]</td>\n",
       "      <td>[90022, 90023, 90031, 90032, 90033, 90042, 900...</td>\n",
       "      <td>[90011, 90012, 90026, 90040, 90041, 90065, 902...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TA     ta_name                                  store_list  \\\n",
       "0  1  multiple_1        [1245, 1966, 4144, 4196, 4632, 4652]   \n",
       "1  2  multiple_2  [4025, 4049, 4155, 4170, 4275, 4686, 4699]   \n",
       "\n",
       "                                        trans_P_zips  \\\n",
       "0  [75006, 75061, 75062, 75104, 75115, 75146, 751...   \n",
       "1  [90022, 90023, 90031, 90032, 90033, 90042, 900...   \n",
       "\n",
       "                                        trans_S_zips distance_10_zips  \\\n",
       "0  [75001, 75007, 75019, 75038, 75039, 75040, 750...              NaN   \n",
       "1  [90011, 90012, 90026, 90040, 90041, 90065, 902...              NaN   \n",
       "\n",
       "   store_count  \n",
       "0            6  \n",
       "1            7  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_TA=df_output_by_store_zip_long.sort_values([\"TA\",'ta_name','zip_type','zip_cd'])\n",
    "df_output_by_TA=df_output_by_TA.drop_duplicates([\"TA\",'ta_name','zip_cd'])\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.groupby([\"TA\",\"ta_name\",\"zip_type\"])['zip_cd'].apply(list).to_frame().reset_index()\n",
    "df_output_by_TA=df_output_by_TA.pivot(index=\"TA\",columns=\"zip_type\",values=\"zip_cd\").reset_index()\n",
    "\n",
    "\n",
    "ta_name=df_output_by_store_zip_long[['TA','ta_name']].drop_duplicates()\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_name,on=\"TA\",how=\"left\")\n",
    "\n",
    "ta_store_list=df_output_by_store.groupby(\"TA\")['location_id'].apply(list).to_frame().reset_index()\n",
    "\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_store_list,on='TA',how=\"left\")\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.rename(columns={\"location_id\":\"store_list\",\"trans_P\":\"trans_P_zips\",\"trans_S\":\"trans_S_zips\",\"zips_10\":\"distance_10_zips\"})\n",
    "df_output_by_TA=df_output_by_TA[['TA','ta_name','store_list','trans_P_zips','trans_S_zips','distance_10_zips']]\n",
    "df_output_by_TA['store_count']=df_output_by_TA['store_list'].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "df_output_by_TA.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge multiple TA with 30% overlap + \n",
    "df_output_by_TA['trans_P_zips']=df_output_by_TA['trans_P_zips'].fillna(\"[]\").astype(str).apply(lambda x: eval(x))\n",
    "df_output_by_TA['trans_S_zips']=df_output_by_TA['trans_S_zips'].fillna(\"[]\").astype(str).apply(lambda x: eval(x))\n",
    "df_output_by_TA['distance_10_zips']=df_output_by_TA['distance_10_zips'].fillna(\"[]\").astype(str).apply(lambda x: eval(x))\n",
    "\n",
    "\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.reset_index()\n",
    "del df_output_by_TA['index']\n",
    "df_output_by_TA['all_zips']=df_output_by_TA['trans_P_zips']+df_output_by_TA['trans_S_zips']+df_output_by_TA['distance_10_zips']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qc_overlap_1=df_output_by_TA[['TA','ta_name','all_zips']].rename(columns={\"TA\":\"TA_1\",\"all_zips\":\"all_zips_1\"})\n",
    "df_qc_overlap_1=df_qc_overlap_1[df_qc_overlap_1['ta_name'].apply(lambda x: x.split(\"_\")[0]==\"multiple\")]\n",
    "df_qc_overlap_1['temp']=1\n",
    "del df_qc_overlap_1['ta_name']\n",
    "\n",
    "df_qc_overlap_2=df_output_by_TA[['TA','ta_name','all_zips']].rename(columns={\"TA\":\"TA_2\",\"all_zips\":\"all_zips_2\"})\n",
    "df_qc_overlap_2=df_qc_overlap_2[df_qc_overlap_2['ta_name'].apply(lambda x: x.split(\"_\")[0]==\"multiple\")]\n",
    "df_qc_overlap_2['temp']=1\n",
    "del df_qc_overlap_2['ta_name']\n",
    "\n",
    "df_qc_overlap=pd.merge(df_qc_overlap_1,df_qc_overlap_2,on=\"temp\",how=\"outer\")\n",
    "df_qc_overlap=df_qc_overlap[df_qc_overlap['TA_1']!=df_qc_overlap['TA_2']]\n",
    "del df_qc_overlap['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intsection_pctg_qc_TA(list_1,list_2):\n",
    "    intersection_list=list(set(list_1).intersection(set(list_2)))\n",
    "    intersection_pctg=len(intersection_list)/len(set(list_1+list_2))\n",
    "    return intersection_pctg\n",
    "\n",
    "df_qc_overlap['intersecion_pctg']=df_qc_overlap.apply(lambda x: intsection_pctg_qc_TA(x['all_zips_1'],x['all_zips_2']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_overlap_high_TA=df_qc_overlap[df_qc_overlap['intersecion_pctg']>0.3]\n",
    "df_overlap_high_TA['pairs']=df_overlap_high_TA[['TA_1','TA_2']].values.tolist()\n",
    "df_overlap_high_TA['pairs']=df_overlap_high_TA['pairs'].apply(lambda x: str(sorted(x)))\n",
    "df_overlap_high_TA=df_overlap_high_TA[['TA_1','TA_2','pairs']].drop_duplicates()\n",
    "\n",
    "df_overlap_high_TA_all_pairs=df_overlap_high_TA['pairs'].unique().tolist()\n",
    "df_overlap_high_TA_all_pairs=[eval(x) for x in df_overlap_high_TA_all_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{24: 6, 10: 7, 65: 30, 112: 34, 77: 65, 124: 70, 130: 83, 103: 88}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_M_M_TA_dict={}\n",
    "for pair_list in df_overlap_high_TA_all_pairs:\n",
    "    merge_M_M_TA_dict.update({pair_list[1]:pair_list[0]}) \n",
    "    \n",
    "merge_M_M_TA_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "del df_output_by_store['ta_name']\n",
    "df_output_by_store_1=df_output_by_store[df_output_by_store['TA'].isin(merge_M_M_TA_dict.keys())]\n",
    "df_output_by_store_2=df_output_by_store[~df_output_by_store['TA'].isin(merge_M_M_TA_dict.keys())]\n",
    "\n",
    "df_output_by_store_1['TA']=df_output_by_store_1['TA'].apply(lambda x: merge_M_M_TA_dict[x])\n",
    "df_output_by_store=df_output_by_store_1.append(df_output_by_store_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ta_name=df_output_by_store.groupby(\"TA\")['location_id'].apply(list).to_frame().reset_index()\n",
    "df_ta_name['store_count']=df_ta_name['location_id'].apply(lambda x: len(x))\n",
    "df_ta_name=df_ta_name.sort_values(\"store_count\",ascending=False)\n",
    "df_ta_name['TA_num']=[str(x+1) for x in range(len(df_ta_name))]\n",
    "df_ta_name['location_id_0_temp']=df_ta_name['location_id'].apply(lambda x: x[0])\n",
    "df_ta_name['location_id_0_temp']=\"single_\"+df_ta_name['location_id_0_temp']\n",
    "df_ta_name['multiple_temp']=\"multiple_\"+df_ta_name['TA_num']\n",
    "\n",
    "df_ta_name['ta_name']=np.where(df_ta_name['store_count']==1,df_ta_name['location_id_0_temp'],df_ta_name['multiple_temp'])\n",
    "\n",
    "df_ta_name=df_ta_name[['TA','TA_num','ta_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=pd.merge(df_output_by_store,df_ta_name,on=\"TA\",how=\"left\")\n",
    "df_output_by_store=df_output_by_store[['TA_num','ta_name']+[x for x in df_output_by_store.columns.tolist() if x not in ['TA_num','ta_name']]]\n",
    "\n",
    "del df_output_by_store['TA']\n",
    "df_output_by_store['TA_num']=df_output_by_store['TA_num'].astype(int)\n",
    "df_output_by_store=df_output_by_store.sort_values(\"TA_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_by_store=df_output_by_store.reset_index()\n",
    "del df_output_by_store['index']\n",
    "\n",
    "df_output_by_store_zip_long=pd.DataFrame(columns=[\"TA_num\",\"ta_name\",\"location_id\",'zip_cd','zip_type'])\n",
    "\n",
    "for ind,row in df_output_by_store.iterrows():\n",
    "    TA=row['TA_num']\n",
    "    ta_name=row['ta_name']\n",
    "    location_id=row['location_id']\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    all_P_zips=row['trans_P_zips_70_within_TA']\n",
    "    all_S_zips=row['trans_S_zips_70_within_TA']\n",
    "    all_10_zips=row['zips_in_10']\n",
    "    \n",
    "    df_P=pd.DataFrame({\"location_id\":[location_id]*len(all_P_zips),'zip_cd':all_P_zips})\n",
    "    df_P['zip_type']=\"trans_P\"\n",
    "    \n",
    "    df_S=pd.DataFrame({\"location_id\":[location_id]*len(all_S_zips),'zip_cd':all_S_zips})\n",
    "    df_S['zip_type']=\"trans_S\"\n",
    "    \n",
    "    df_10=pd.DataFrame({\"location_id\":[location_id]*len(all_10_zips),'zip_cd':all_10_zips})\n",
    "    df_10['zip_type']=\"zips_10\"\n",
    "    \n",
    "    df=df_P.append(df_S).append(df_10)\n",
    "    df['TA_num']=TA\n",
    "    df['ta_name']=ta_name\n",
    "    df_output_by_store_zip_long=df_output_by_store_zip_long.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_num</th>\n",
       "      <th>ta_name</th>\n",
       "      <th>store_list</th>\n",
       "      <th>trans_P_zips</th>\n",
       "      <th>trans_S_zips</th>\n",
       "      <th>distance_10_zips</th>\n",
       "      <th>store_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>multiple_1</td>\n",
       "      <td>[4526, 5142, 4622, 4589, 4566, 4543, 1027, 107...</td>\n",
       "      <td>[73401, 73449, 74701, 74729, 74730, 75002, 750...</td>\n",
       "      <td>[73030, 73086, 73402, 73432, 73438, 73439, 734...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>multiple_2</td>\n",
       "      <td>[5119, 315, 1961, 1892, 1690, 1643, 1588, 1138...</td>\n",
       "      <td>[28012, 28016, 28025, 28027, 28031, 28043, 280...</td>\n",
       "      <td>[27013, 27028, 27054, 27106, 27107, 27265, 272...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TA_num     ta_name                                         store_list  \\\n",
       "0      1  multiple_1  [4526, 5142, 4622, 4589, 4566, 4543, 1027, 107...   \n",
       "1      2  multiple_2  [5119, 315, 1961, 1892, 1690, 1643, 1588, 1138...   \n",
       "\n",
       "                                        trans_P_zips  \\\n",
       "0  [73401, 73449, 74701, 74729, 74730, 75002, 750...   \n",
       "1  [28012, 28016, 28025, 28027, 28031, 28043, 280...   \n",
       "\n",
       "                                        trans_S_zips distance_10_zips  \\\n",
       "0  [73030, 73086, 73402, 73432, 73438, 73439, 734...              NaN   \n",
       "1  [27013, 27028, 27054, 27106, 27107, 27265, 272...              NaN   \n",
       "\n",
       "   store_count  \n",
       "0           23  \n",
       "1           18  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_by_TA=df_output_by_store_zip_long.sort_values([\"TA_num\",'ta_name','zip_type','zip_cd'])\n",
    "df_output_by_TA=df_output_by_TA.drop_duplicates([\"TA_num\",'ta_name','zip_cd'])\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.groupby([\"TA_num\",\"ta_name\",\"zip_type\"])['zip_cd'].apply(list).to_frame().reset_index()\n",
    "df_output_by_TA=df_output_by_TA.pivot(index=\"TA_num\",columns=\"zip_type\",values=\"zip_cd\").reset_index()\n",
    "\n",
    "\n",
    "ta_name=df_output_by_store_zip_long[['TA_num','ta_name']].drop_duplicates()\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_name,on=\"TA_num\",how=\"left\")\n",
    "\n",
    "ta_store_list=df_output_by_store.groupby(\"TA_num\")['location_id'].apply(list).to_frame().reset_index()\n",
    "\n",
    "df_output_by_TA=pd.merge(df_output_by_TA,ta_store_list,on='TA_num',how=\"left\")\n",
    "\n",
    "df_output_by_TA=df_output_by_TA.rename(columns={\"location_id\":\"store_list\",\"trans_P\":\"trans_P_zips\",\"trans_S\":\"trans_S_zips\",\"zips_10\":\"distance_10_zips\"})\n",
    "df_output_by_TA=df_output_by_TA[['TA_num','ta_name','store_list','trans_P_zips','trans_S_zips','distance_10_zips']]\n",
    "df_output_by_TA['store_count']=df_output_by_TA['store_list'].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "df_output_by_TA.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12805, 2)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_unique_zips=df_output_by_store_zip_long[['zip_type','zip_cd']].drop_duplicates()\n",
    "df_output_unique_zips=df_output_unique_zips.sort_values(\"zip_type\")\n",
    "df_output_unique_zips=df_output_unique_zips.drop_duplicates(\"zip_cd\")\n",
    "df_output_unique_zips.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_list=pd.read_table(latest_store_list,\n",
    "                        dtype=str,sep=\"|\")\n",
    "store_list['latitude_meas']=store_list['latitude_meas'].astype(float)\n",
    "store_list['longitude_meas']=store_list['longitude_meas'].astype(float)\n",
    "store_list=update_store_location(store_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_lat_long=store_list[['location_id','latitude_meas','longitude_meas']]\n",
    "df_output_by_store_zip_long=pd.merge(df_output_by_store_zip_long,location_lat_long,on=\"location_id\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_store_missing=[x for x in store_list['location_id'].tolist() if x not in df_output_by_store['location_id'].tolist()]\n",
    "list_store_missing=[x for x in list_store_missing if x not in ['145','6990']]\n",
    "list_store_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(list_store_missing)==0:\n",
    "    writer=pd.ExcelWriter(output_folder+\"BL_final_TA_updated_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "    df_output_unique_zips.to_excel(writer,\"unique_zips_full_footprint\",index=False)\n",
    "    df_output_by_TA.to_excel(writer,\"view_by_TA\",index=False)\n",
    "    df_output_by_store.to_excel(writer,\"view_by_store\",index=False)\n",
    "    df_output_by_store_zip_long.to_excel(writer,\"view_for_Tableau\",index=False)\n",
    "    writer.save()\n",
    "else:\n",
    "    print(\"checking stores misssing: \\n%s\"%list_store_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1_ta_view=df_output_by_TA['store_list'].sum()\n",
    "list_2_store_view=df_output_by_store['location_id'].unique().tolist()\n",
    "list_3_whole=store_list['location_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'145', '6990'}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list_3_whole)-set(list_1_ta_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
