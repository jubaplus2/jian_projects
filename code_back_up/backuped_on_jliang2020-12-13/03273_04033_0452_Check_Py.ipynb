{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Do the last kernel above (Read output above)\\ndata_all_46_full_weeks=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/sales_of_loyalty_member/sales_by_zip_20180529.csv\",dtype=str)\\ndata_all_46_full_weeks[\\'total_transaction_count\\']=data_all_46_full_weeks[\\'total_transaction_count\\'].astype(int)\\ndata_all_46_full_weeks[\\'total_transaction_amt\\']=data_all_46_full_weeks[\\'total_transaction_amt\\'].astype(float)\\ndata_all_46_full_weeks_agg=data_all_46_full_weeks.groupby([\\'customer_zip_code\\',\\'week_end_date\\'])[\\'total_transaction_amt\\',\\'total_transaction_count\\'].sum().reset_index()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "gc.collect()\n",
    "import datetime\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "today_str=str(datetime.datetime.now().date())\n",
    "writer_folder=\"/home/jian/Projects/Big_Lots/Loyal_members/sales_of_loyalty_member/\"+today_str+\"/\"\n",
    "try:\n",
    "    os.stat(writer_folder)\n",
    "except:\n",
    "    os.mkdir(writer_folder)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "logging.basicConfig(filename='merge_sales_with_signing_up_location_id.log', level=logging.INFO)\n",
    "logging.info(\"Start Running: \"+str(datetime.datetime.now()))\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "df_id_zip=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/Email_Zips/output_loyalty_member_by_id.csv\",dtype=str)\n",
    "del df_id_zip['sign_up_date']\n",
    "\n",
    "df_id_zip=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/Email_Zips/output_loyalty_member_by_id.csv\",dtype=str)\n",
    "del df_id_zip['sign_up_date']\n",
    "df_id_zip['customer_zip_code']=df_id_zip['customer_zip_code'].apply(lambda x: str(x).replace(\" \",\"\"))\n",
    "df_id_zip['customer_zip_code']=df_id_zip['customer_zip_code'].apply(lambda x: str(x).replace(\" \",\"\"))\n",
    "df_id_zip['customer_zip_code']=df_id_zip['customer_zip_code'].apply(lambda x: str(x).replace(\".\",\"\"))\n",
    "df_id_zip['customer_zip_code']=df_id_zip['customer_zip_code'].apply(lambda x: str(x).replace(\"-\",\"\"))\n",
    "df_id_zip['customer_zip_code']=df_id_zip['customer_zip_code'].apply(lambda x: str(x).replace(\"nan\",\"\"))\n",
    "\n",
    "df_id_zip['customer_zip_code']=df_id_zip['customer_zip_code'].fillna(\"00000\")\n",
    "df_id_zip['customer_zip_code']=df_id_zip['customer_zip_code'].apply(lambda x: x.zfill(5)[0:5])\n",
    "logging.info(\"Finished Reading Zip by member: \"+str(datetime.datetime.now()))\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "data_1=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/sales_of_loyalty_member/MediaStormCustDtl.txt\",header=None,dtype=str,nrows=100000)\n",
    "logging.info(\"Finished Reading Sales Data 1: \"+str(datetime.datetime.now()))\n",
    "\n",
    "data_2=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/sales_of_loyalty_member/MediaStorm customer transaction details - 2018-01-09 - 2018-03-31.txt\",dtype=str,nrows=100000)\n",
    "logging.info(\"Finished Reading Sales Data 2: \"+str(datetime.datetime.now()))\n",
    "\n",
    "data_3=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/sales_of_loyalty_member/MediaStorm customer transaction details - 2018-04-01 - 2018-04-15.txt\",dtype=str,nrows=100000)\n",
    "logging.info(\"Finished Reading Sales Data 3: \"+str(datetime.datetime.now()))\n",
    "\n",
    "data_1.columns=data_2.columns.tolist()  \n",
    "data_1['customer_id_hashed']=data_1['customer_id_hashed'].apply(lambda x: hashlib.sha256(x.encode('UTF-8')).hexdigest())\n",
    "logging.info(\"Finished Hashing: \"+str(datetime.datetime.now()))\n",
    "gc.collect()\n",
    "\n",
    "def clean_data(df):\n",
    "    del df['merch_cat']\n",
    "    df=df[df['location_id']!=\"6990\"]\n",
    "    df=df[df['location_id']!=\"145\"]\n",
    "    df['total_transaction_amt']=df['total_transaction_amt'].astype(float)\n",
    "    df=df.drop_duplicates()    \n",
    "    df['transaction_date']=df['transaction_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "    df=df[['customer_id_hashed','location_id','transaction_date','total_transaction_amt']]\n",
    "    df_sales=df.groupby(['customer_id_hashed','location_id','transaction_date'])['total_transaction_amt'].sum().to_frame().reset_index()\n",
    "    df_trans=df[df['total_transaction_amt']>0]\n",
    "    df_trans=df.groupby(['customer_id_hashed','location_id','transaction_date'])['total_transaction_amt'].count().to_frame().reset_index()\n",
    "    df_trans=df_trans.rename(columns={\"total_transaction_amt\":\"total_transaction_count\"})\n",
    "    df=pd.merge(df_sales,df_trans,on=['customer_id_hashed','location_id','transaction_date'],how=\"left\")\n",
    "    return df\n",
    "data_1=clean_data(data_1)\n",
    "data_2=clean_data(data_2)\n",
    "data_3=clean_data(data_3)\n",
    "data_all=data_1.append(data_2).append(data_3).drop_duplicates()\n",
    "data_all=data_all.drop_duplicates()\n",
    "\n",
    "del data_1\n",
    "del data_2\n",
    "del data_3\n",
    "gc.collect()\n",
    "\n",
    "data_all=data_all[data_all['transaction_date']>=datetime.datetime(2017,5,7).date()]\n",
    "data_all['weekday']=data_all['transaction_date'].apply(lambda x: x.weekday())\n",
    "\n",
    "data_all['week_end_date']=np.where(data_all['weekday']==6,\n",
    "                                   data_all['transaction_date'].apply(lambda x: x+datetime.timedelta(days=6)),\n",
    "                                  data_all['transaction_date'].apply(lambda x: x+datetime.timedelta(days=5-x.weekday()))\n",
    "                                  )\n",
    "\n",
    "full_weeks_only=data_all[['week_end_date','transaction_date','location_id']].drop_duplicates()\n",
    "full_weeks_only=full_weeks_only.groupby(['location_id','week_end_date'])['transaction_date'].count().to_frame().reset_index()\n",
    "full_weeks_only=full_weeks_only[full_weeks_only['transaction_date']==7]\n",
    "full_weeks_only.to_csv(writer_folder+\"full_46_weeks_loyalty_before.csv\",index=False)\n",
    "    \n",
    "full_weeks_only['str_week_end_dt']=full_weeks_only['week_end_date'].apply(lambda x: str(x))\n",
    "full_weeks_only['key']=full_weeks_only['location_id']+\"|\"+full_weeks_only['str_week_end_dt']\n",
    "\n",
    "data_all['str_week_end_dt']=data_all['week_end_date'].apply(lambda x: str(x))\n",
    "data_all['key']=data_all['location_id']+\"|\"+data_all['str_week_end_dt']\n",
    "del data_all['str_week_end_dt']\n",
    "del data_all['transaction_date']\n",
    "del data_all['weekday']\n",
    "\n",
    "data_all=data_all[data_all['key'].isin(full_weeks_only['key'])]\n",
    "data_all_key=data_all['key'].unique().tolist() # clean with common key later\n",
    "# del data_all['key']\n",
    "logging.info(\"Total weeks: \"+str(len(data_all['week_end_date'].unique())))\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "logging.info(\"Finished Reading Sales by member: \"+str(datetime.datetime.now()))\n",
    "\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "sales_by_store_both=pd.read_csv(\"/home/jian/BiglotsCode/outputs/combined_sales_long_2018-06-09.csv\",dtype=str)\n",
    "sales_by_store_both['sales']=sales_by_store_both['sales'].astype(float)\n",
    "sales_by_store_both=sales_by_store_both[sales_by_store_both['sales']>0]\n",
    "\n",
    "sales_by_store_both['key']=sales_by_store_both['location_id']+\"|\"+sales_by_store_both['week_end_date']\n",
    "sales_long_key=sales_by_store_both['key'].unique().tolist()\n",
    "\n",
    "common_key=list(set(data_all_key).intersection(sales_long_key))\n",
    "\n",
    "sales_by_store_both=sales_by_store_both[sales_by_store_both['key'].isin(common_key)]\n",
    "sales_by_store_both=sales_by_store_both.groupby(['location_id'])['sales'].sum().reset_index()\n",
    "logging.info(\"Store Sales Common done: \"+str(datetime.datetime.now()))\n",
    "\n",
    "full_weeks_only['str_week_end_dt']=full_weeks_only['week_end_date'].apply(lambda x: str(x))\n",
    "full_weeks_only['key']=full_weeks_only['location_id']+\"|\"+full_weeks_only['str_week_end_dt']\n",
    "full_weeks_only=full_weeks_only[full_weeks_only['key'].isin(common_key)]\n",
    "full_weeks_only.to_csv(writer_folder+\"full_46_weeks_common_after.csv\",index=False)\n",
    "\n",
    "data_all_exception=data_all[~data_all['key'].isin(common_key)]\n",
    "data_all_exception=data_all_exception.groupby(['customer_id_hashed','week_end_date','location_id'])['total_transaction_amt','total_transaction_count'].sum()\n",
    "data_all_exception_store=data_all_exception.groupby(['week_end_date','location_id'])['total_transaction_amt','total_transaction_count'].sum()\n",
    "data_all_exception.to_csv(writer_folder+\"exception_store_id\"+today_str+\".csv\",index=False)\n",
    "data_all_exception_store.to_csv(writer_folder+\"exception_store_level\"+today_str+\".csv\",index=False)\n",
    "\n",
    "\n",
    "data_all=data_all[data_all['key'].isin(common_key)]\n",
    "data_all=data_all.groupby(['customer_id_hashed','week_end_date','location_id'])['total_transaction_amt','total_transaction_count'].sum()\n",
    "\n",
    "try:\n",
    "    data_all=data_all.to_frame()\n",
    "except:\n",
    "    logging.info(\"No need to do 'to_frame' in data_all: \"+str(datetime.datetime.now()))\n",
    "\n",
    "\n",
    "data_all=data_all.reset_index()\n",
    "    \n",
    "try:\n",
    "    del data_all['index']\n",
    "except:\n",
    "    logging.info(\"No index deleted: in data_all\"+str(datetime.datetime.now()))\n",
    "    \n",
    "logging.info(\"Finished aggregating by zip by week: \"+str(datetime.datetime.now()))\n",
    "logging.info(\"Loyalty Sales Common done: \"+str(datetime.datetime.now()))\n",
    "logging.info(\"Good to go: \"+str(datetime.datetime.now()))\n",
    "# In[9]:\n",
    "\n",
    "logging.info(\"Start Merging: \"+str(datetime.datetime.now()))\n",
    "data_all=pd.merge(data_all,df_id_zip,on=\"customer_id_hashed\",how=\"left\")\n",
    "logging.info(\"Finished merging: \"+str(datetime.datetime.now()))\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "logging.info(\"Start Groupby on zip and location: \"+str(datetime.datetime.now()))\n",
    "data_all_46_full_weeks_zip_location=data_all.groupby(['customer_zip_code','location_id'])['total_transaction_amt'].sum().reset_index()\n",
    "data_all_46_full_weeks_location=data_all_46_full_weeks_zip_location.groupby(['location_id'])['total_transaction_amt'].sum().reset_index()\n",
    "\n",
    "data_all_46_full_weeks_zip_location=data_all_46_full_weeks_zip_location.rename(columns={\"total_transaction_amt\":\"loyal_sales_zip\"})\n",
    "gc.collect()\n",
    "data_all_46_full_weeks_location=data_all_46_full_weeks_location.rename(columns={\"total_transaction_amt\":\"loyal_sales_total\"})\n",
    "data_all_46_full_weeks_location=pd.merge(data_all_46_full_weeks_location,sales_by_store_both,on=\"location_id\",how=\"left\")\n",
    "data_all_46_full_weeks_location['non_loyalty_sales_total']=data_all_46_full_weeks_location['sales']-data_all_46_full_weeks_location['loyal_sales_total']\n",
    "# data_all_46_full_weeks_location['non_loyalty_trans_total']=data_all_46_full_weeks_location['transactions']-data_all_46_full_weeks_location['loyal_trans_total']\n",
    "# non_loyalty_sales=data_all_46_full_weeks_location[['location_id','non_loyalty_sales_total']]\n",
    "# del data_all_46_full_weeks_location['sales']\n",
    "data_all_46_full_weeks_location=data_all_46_full_weeks_location.rename(columns={'sales':'total_sales_both'})\n",
    "\n",
    "# In[16]:\n",
    "# customer_zip_code\n",
    "data_all_46_full_weeks_zip_location=pd.merge(data_all_46_full_weeks_zip_location,data_all_46_full_weeks_location,on=\"location_id\",how=\"left\")\n",
    "data_all_46_full_weeks_zip_location['loyal_sales_pctg']=data_all_46_full_weeks_zip_location['loyal_sales_zip']/data_all_46_full_weeks_zip_location['loyal_sales_total']\n",
    "data_all_46_full_weeks_zip_location['non_loyalty_sales_zip']=data_all_46_full_weeks_zip_location['non_loyalty_sales_total']*data_all_46_full_weeks_zip_location['loyal_sales_pctg']\n",
    "data_all_46_full_weeks_location['total_sales_both_zip']=data_all_46_full_weeks_zip_location['total_sales_both']*data_all_46_full_weeks_zip_location['loyal_sales_pctg']\n",
    "data_all_46_full_weeks_zip_location.to_csv(writer_folder+\"/sales_by_location_id_agg_\"+today_str+\".csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "'''\n",
    "# Do the last kernel above (Read output above)\n",
    "data_all_46_full_weeks=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/sales_of_loyalty_member/sales_by_zip_20180529.csv\",dtype=str)\n",
    "data_all_46_full_weeks['total_transaction_count']=data_all_46_full_weeks['total_transaction_count'].astype(int)\n",
    "data_all_46_full_weeks['total_transaction_amt']=data_all_46_full_weeks['total_transaction_amt'].astype(float)\n",
    "data_all_46_full_weeks_agg=data_all_46_full_weeks.groupby(['customer_zip_code','week_end_date'])['total_transaction_amt','total_transaction_count'].sum().reset_index()\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
