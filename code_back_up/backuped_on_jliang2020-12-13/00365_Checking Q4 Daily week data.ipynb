{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_saturday=datetime.datetime.now().date()-datetime.timedelta(days=datetime.datetime.now().date().weekday()+2)\n",
    "\n",
    "First_week_ending_Q4_2018=datetime.date(2018,11,10)\n",
    "Q4_2018_weeks=[First_week_ending_Q4_2018+datetime.timedelta(days=x*7) for x in range(13)]\n",
    "\n",
    "Q4_2018_weeks=[x for x in Q4_2018_weeks if x <=last_saturday]\n",
    "\n",
    "Q4_2017_weeks=[x-datetime.timedelta(days=52*7) for x in Q4_2018_weeks]\n",
    "len_Q4_weeks=len(Q4_2018_weeks)\n",
    "\n",
    "write_folder=\"/home/jian/celery/Quadrants_Dashboard/Checking_Daily_Data_\"+str(last_saturday)+\"/\"\n",
    "try:\n",
    "    os.stat(write_folder)\n",
    "except:\n",
    "    os.mkdir(write_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_all=pd.read_csv(\"/home/jian/BiglotsCode/outputs/combined_sales_long_\"+str(last_saturday)+\".csv\",dtype=str,usecols=['location_id','sales','transactions','week_end_date'])\n",
    "sales_all['sales']=sales_all['sales'].astype(float)\n",
    "sales_all['transactions']=sales_all['transactions'].astype(float).astype(int)\n",
    "sales_all=sales_all[sales_all['sales']>0]\n",
    "sales_all_Q4_2017=sales_all[sales_all['week_end_date'].isin([str(x) for x in Q4_2017_weeks])]\n",
    "sales_all_Q4_2018=sales_all[sales_all['week_end_date'].isin([str(x) for x in Q4_2018_weeks])]\n",
    "\n",
    "sales_all_Q4_2018=sales_all_Q4_2018.rename(columns={\"sales\":\"sales_weekly_data\",\"transactions\":\"trans_weekly_data\"})\n",
    "sales_all_Q4_2017=sales_all_Q4_2017.rename(columns={\"sales\":\"sales_weekly_data\",\"transactions\":\"trans_weekly_data\"})\n",
    "\n",
    "sales_all_Q4_weekly=sales_all_Q4_2018.append(sales_all_Q4_2017)\n",
    "sales_all_Q4_weekly['week_end_date']=sales_all_Q4_weekly['week_end_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking for the recent weeks that haven't moved to the folder\n",
    "possible_recent_folders=[\"/home/jian/BigLots/MediaStorm_\"+str(x)+\"/\" for x in Q4_2018_weeks]\n",
    "recent_daily_list=[]\n",
    "for dirc in possible_recent_folders:\n",
    "    list_recent=[x for x in list(recursive_file_gen(dirc)) if (\"aily\" in x) & (\".txt\" in x) ]\n",
    "    recent_daily_list=recent_daily_list+list_recent\n",
    "recent_daily_df=pd.DataFrame({\"path\":recent_daily_list,\"date\":[datetime.datetime.strptime(x.split(\"MediaStormDailySales\")[1][:8],\"%Y%m%d\").date()-datetime.timedelta(days=3) for x in recent_daily_list]},index=[x for x in range(len(recent_daily_list))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_1_after_201806=[x for x in list(recursive_file_gen(\"/home/jian/BigLots/2018_by_weeks/\")) if (\"aily\" in x) & (\".txt\" in x) ]\n",
    "folder_date=[datetime.datetime.strptime(x.split(\"/\")[len(x.split(\"/\"))-2].split(\"_\")[1],\"%Y-%m-%d\").date() for x in list_1_after_201806]\n",
    "df_1_after_201806=pd.DataFrame({\"date\":folder_date,\"path\":list_1_after_201806},index=[x for x in range(len(list_1_after_201806))])\n",
    "df_1_after_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "df_1_after_201806=df_1_after_201806.sort_values(\"date\").reset_index()\n",
    "del df_1_after_201806['index']\n",
    "\n",
    "list_2_before_201806=list(recursive_file_gen(\"/home/jian/BigLots/hist_daily_data/\"))\n",
    "folder_date=[datetime.datetime.strptime(x.split(\"/\")[len(x.split(\"/\"))-1].split(\"_\")[3].split(\".\")[0],\"%Y-%m-%d\").date() for x in list_2_before_201806]\n",
    "df_2_before_201806=pd.DataFrame({\"date\":folder_date,\"path\":list_2_before_201806},index=[x for x in range(len(list_2_before_201806))])\n",
    "df_2_before_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "df_2_before_201806=df_2_before_201806.sort_values('date').reset_index()\n",
    "del df_2_before_201806['index']\n",
    "df_2_before_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "\n",
    "df_Q4_2017=df_2_before_201806[df_2_before_201806['date'].isin(Q4_2017_weeks)]\n",
    "df_Q4_2018=df_1_after_201806[df_1_after_201806['date'].isin(Q4_2018_weeks)]\n",
    "df_Q4_2018=df_Q4_2018.append(recent_daily_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_week_end_dt(x):\n",
    "    if x.weekday()==6:\n",
    "        y=x+datetime.timedelta(days=6)\n",
    "    else:\n",
    "        y=x+datetime.timedelta(days=5-x.weekday())\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-20 16:57:10.802541\n",
      "2018-12-20 17:02:10.646637\n",
      "2018-12-20 17:09:49.943456\n",
      "2018-12-20 17:19:13.934604\n",
      "2018-12-20 17:25:47.101760\n",
      "2018-12-20 17:32:55.778431\n",
      "2018-12-20 17:36:08.383100\n",
      "2018-12-20 17:40:46.845579\n",
      "2018-12-20 17:47:38.363430\n",
      "2018-12-20 17:53:53.176310\n",
      "2018-12-20 18:00:53.051423\n",
      "2018-12-20 18:07:28.365525\n"
     ]
    }
   ],
   "source": [
    "agg_daily_data=pd.DataFrame()\n",
    "for file_path in df_Q4_2017['path'].tolist()+df_Q4_2018['path'].tolist():\n",
    "    df=pd.read_table(file_path,dtype=str,sep=\"|\",usecols=['location_id','customer_id_hashed','transaction_id','transaction_dt','subclass_transaction_amt'])\n",
    "    df['subclass_transaction_amt']=df['subclass_transaction_amt'].astype(float)\n",
    "    df['transaction_dt']=df['transaction_dt'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "    df['week_end_date']=df['transaction_dt'].apply(lambda x: add_week_end_dt(x))\n",
    "\n",
    "    df_sales=df.groupby(['location_id','week_end_date'])['subclass_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"subclass_transaction_amt\":\"sales_daily_data\"})\n",
    "    del df['subclass_transaction_amt']\n",
    "    df=df.drop_duplicates()\n",
    "    df_trans=df.groupby(['location_id','week_end_date'])['transaction_id'].count().to_frame().reset_index().rename(columns={\"transaction_id\":\"trans_daily_data\"})\n",
    "    df=pd.merge(df_sales,df_trans,on=['location_id','week_end_date'],how=\"outer\")\n",
    "    agg_daily_data=agg_daily_data.append(df)\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compared_df=pd.merge(sales_all_Q4_weekly,agg_daily_data,on=['location_id','week_end_date'],how=\"outer\")\n",
    "compared_df.to_csv(write_folder+\"BL_QC_Q4_daily_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/celery/Quadrants_Dashboard/Checking_Daily_Data_2018-12-15/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
