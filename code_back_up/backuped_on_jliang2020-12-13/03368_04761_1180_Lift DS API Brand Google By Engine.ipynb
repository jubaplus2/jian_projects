{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Brand and Non_Brand in the filter when download, plz make modification when the name of campaigns change\n",
    "# Google is also defined in the filter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 6\n",
    "\n",
    "import argparse\n",
    "import httplib2\n",
    "import pprint\n",
    "import time\n",
    "import datetime\n",
    "from io import StringIO\n",
    "\n",
    "from apiclient.discovery import build\n",
    "from oauth2client import GOOGLE_TOKEN_URI\n",
    "from oauth2client.client import OAuth2Credentials\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "\n",
    "def create_credentials():\n",
    "    \"\"\"Create Google OAuth2 credentials.\n",
    "\n",
    "    Args:\n",
    "        client_id: Client id of a Google Cloud console project.\n",
    "        client_secret: Client secret of a Google Cloud console project.\n",
    "        refresh_token: A refresh token authorizing the Google Cloud console project\n",
    "          to access the DS data of some Google user.\n",
    "    Returns:\n",
    "        OAuth2Credentials\n",
    "    \"\"\"\n",
    "    return OAuth2Credentials(access_token=None,\n",
    "                           client_id='549790627766-qnth4m8qvuimg87pnsp4b82lhte7dk5a.apps.googleusercontent.com',\n",
    "                           client_secret='Vta4lQLOL49vVYvktkcPGRNb',\n",
    "                           refresh_token='1/ab7pCGMu3K5AveG0UOUpQ0J08vCp6uM357O8qmoPDMs',\n",
    "                           token_expiry=None,\n",
    "                           token_uri=\"https://accounts.google.com/o/oauth2/token\",\n",
    "                           user_agent=None)\n",
    "\n",
    "def get_service(credentials):\n",
    "    \"\"\"Set up a new DoubleClick Search service.\n",
    "\n",
    "    Args:\n",
    "        credentials: An OAuth2Credentials generated with create_credentials, or\n",
    "        flows in the oatuh2client.client package.\n",
    "    Returns:\n",
    "        An authorized Doubleclicksearch serivce.\n",
    "    \"\"\"\n",
    "    # Use the authorize() function of OAuth2Credentials to apply necessary credential\n",
    "    # headers to all requests.\n",
    "    http = credentials.authorize(http = httplib2.Http())\n",
    "\n",
    "    # Construct the service object for the interacting with the DoubleClick Search API.\n",
    "    service = build('doubleclicksearch', 'v2', http=http)\n",
    "    return service\n",
    "\n",
    "def poll_report(service, report_id):\n",
    "    \"\"\"Poll the API with the reportId until the report is ready, up to ten times.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        report_id: The ID DS has assigned to a report.\n",
    "    Returns:\n",
    "        pd.DataFrame, report file\n",
    "    \"\"\"\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            request = service.reports().get(reportId=report_id)\n",
    "            json_data = request.execute()\n",
    "            if json_data['isReportReady']:\n",
    "                pprint.pprint('The report is ready.')\n",
    "\n",
    "                # For large reports, DS automatically fragments the report into multiple\n",
    "                # files. The 'files' property in the JSON object that DS returns contains\n",
    "                # the list of URLs for file fragment. To download a report, DS needs to\n",
    "                # know the report ID and the index of a file fragment.\n",
    "                report = pd.DataFrame()\n",
    "                for i in range(len(json_data['files'])):\n",
    "                    pprint.pprint('Downloading fragment ' + str(i) + ' for report ' + report_id)\n",
    "                    report = report.append(download_files(service, report_id, str(i)), ignore_index = True) # See Download the report.\n",
    "                return report\n",
    "\n",
    "            else:\n",
    "                pprint.pprint('Report is not ready. I will try again.')\n",
    "                time.sleep(10)\n",
    "        except HttpError as e:\n",
    "            error = simplejson.loads(e.content)['error']['errors'][0]\n",
    "\n",
    "            # See Response Codes\n",
    "            pprint.pprint('HTTP code %d, reason %s' % (e.resp.status, error['reason']))\n",
    "            break\n",
    "        \n",
    "def download_files(service, report_id, report_fragment):\n",
    "    \"\"\"Generate and print sample report.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        report_id: The ID DS has assigned to a report.\n",
    "        report_fragment: The 0-based index of the file fragment from the files array.\n",
    "    Returns:\n",
    "        pd.DataFrame report file\n",
    "    \"\"\"\n",
    "    request = service.reports().getFile(reportId=report_id, reportFragment=report_fragment)\n",
    "    return pd.read_csv(StringIO(request.execute().decode('utf-8')))\n",
    "\n",
    "def request_report(service, start_date, end_date, columns):\n",
    "    \"\"\"Request sample report and print the report ID that DS returns. See Set Up Your Application.\n",
    "\n",
    "    Args:\n",
    "        service: An authorized Doublelcicksearch service.\n",
    "        columns: list of columns will be in the report\n",
    "    Returns:\n",
    "        The report id.\n",
    "    \"\"\"\n",
    "    request = service.reports().request(\n",
    "        body={\n",
    "                \"reportScope\": {\n",
    "                    \"agencyId\": \"20100000000000932\",\n",
    "                    \"advertiserId\": \"21700000001445074\",\n",
    "                    #\"advertiserId\": \"21700000001406447\", # Callaway Apparel - Perry Ellis International\n",
    "                    #\"engineAccountId\": \"700000001564770\" # Google - Callaway Apparel\n",
    "                    #\"advertiserId\": \"21700000001131725\", # Celebrity Cruise\n",
    "                    #\"engineAccountId\": \"700000001217833\" # Celebrity Cruise\n",
    "                    #\"engineAccountId\": \"700000001561242\" # Celebrity Cruise - Juba Plus\n",
    "                },\n",
    "                \"reportType\": \"keyword\",\n",
    "                \"columns\": [{'columnName': column} for column in columns],   \n",
    "                \"timeRange\" : {\n",
    "                    \"startDate\" : start_date,\n",
    "                    \"endDate\" : end_date\n",
    "                    },\n",
    "                \n",
    "                \"filters\": [\n",
    "                   {\n",
    "                        \"column\" : { \"columnName\": \"campaign\" },\n",
    "                        \"operator\" : \"containsSubstring\",\n",
    "                        \"values\" : [\"2856_LIFT Brands_Snap Fitness_Brand\"]\n",
    "                    },\n",
    "                    {\n",
    "                        \"column\" : { \"columnName\": 'accountType' },\n",
    "                        \"operator\" : \"equals\",\n",
    "                        \"values\" : ['Google AdWords']\n",
    "                    }\n",
    "                ],\n",
    "                \n",
    "                \"downloadFormat\": \"csv\",\n",
    "                \"maxRowsPerFile\": 100000000,\n",
    "                \"statisticsCurrency\": \"agency\",\n",
    "                \"verifySingleTimeZone\": \"false\",\n",
    "                \"includeRemovedEntities\": \"false\"\n",
    "            }\n",
    "    )\n",
    "    json_data = request.execute()\n",
    "    return json_data['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017-09-25', '2017-10-02']\n",
      "'Report is not ready. I will try again.'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAnqrYvVw62Ui59'\n",
      "'The report is ready.'\n",
      "'Downloading fragment 0 for report AAAnSYupuvY4Hyxp'\n"
     ]
    }
   ],
   "source": [
    "# download reports\n",
    "creds = create_credentials()\n",
    "\n",
    "service = get_service(creds)\n",
    "\n",
    "end_date = \"2017-10-02\"\n",
    "start_date = \"2017-09-25\"\n",
    "\n",
    "print ([start_date, end_date])\n",
    "\n",
    "REPORTID_nonHVA = request_report(service, start_date, end_date, \n",
    "                                 ['campaign', 'adGroup', 'keywordText', 'date', 'deviceSegment', \n",
    "                                  'status', 'keywordMatchType', 'keywordMaxCpc', \n",
    "                                  'topOfPageBidCurrent', 'topOfPageBidAvg',\n",
    "                                  'effectiveKeywordMaxCpc', 'impr', 'clicks', 'cost',\n",
    "                                  'avgCpc', 'avgPos'])\n",
    "REPORTID_HVA = request_report(service, start_date, end_date, \n",
    "                              ['campaign', 'adGroup', 'keywordText', 'date', 'deviceSegment', \n",
    "                               'floodlightActivity', 'dfaActions', 'effectiveLabels'])\n",
    "\n",
    "non_hva = poll_report(service, REPORTID_nonHVA)\n",
    "hva = poll_report(service, REPORTID_HVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merged hva and non_hva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_hva_and_non_hva(hva, non_hva):\n",
    "    '''merge two reports downloaded by download_reports().\n",
    "    Args:\n",
    "        hva: pd.DataFrame\n",
    "        non_hva: pd.DataFrame\n",
    "        columns_hva: list of string\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    '''   \n",
    "    columns_hva= [\n",
    "        'Snap Fitness - Franchise - Choose a Country',\n",
    "        'Snap Fitness - Franchise - Email',\n",
    "        'Snap Fitness - Franchise - First Name',\n",
    "        'Snap Fitness - Franchise - I Attest Checkbox',\n",
    "        'Snap Fitness - Franchise - Last Name',\n",
    "        'Snap Fitness - Franchise - Phone Number',\n",
    "        'Snap Fitness - Franchise - Select Country First',\n",
    "        'Snap Fitness - Franchise - Take the First Step Button',\n",
    "        'Snap Fitness - Franchise - What is This? Link',\n",
    "        'Snap Fitness - Franchise Opportunities',\n",
    "        'Snap Fitness - Franchise Request Info',\n",
    "        'Snap Fitness - Franchise Thank You',\n",
    "        'Snap Fitness - International Franchise',\n",
    "        'Snap Fitness - International Franchise - Choose a Country',\n",
    "        'Snap Fitness - International Franchise - Email',\n",
    "        'Snap Fitness - International Franchise - First Name',\n",
    "        'Snap Fitness - International Franchise - I Attest Checkbox',\n",
    "        'Snap Fitness - International Franchise - Last Name',\n",
    "        'Snap Fitness - International Franchise - Phone Number',\n",
    "        'Snap Fitness - International Franchise - Select Country First',\n",
    "        'Snap Fitness - International Franchise - Take the First Step Buton',\n",
    "        'Snap Fitness - International Franchise - What is This? Link',\n",
    "        'Snap Fitness - International Franchise Thank You']\n",
    "    \n",
    "    result = pd.DataFrame(columns=['keywordText', 'date', 'deviceSegment',]+columns_hva)\n",
    "    \n",
    "    for (keyword, date, device), group in hva.groupby(['keywordText', 'date', 'deviceSegment',]):\n",
    "        df = pd.DataFrame([{\n",
    "            #'campaign': campaign,\n",
    "            #'adGroup': ad_group,\n",
    "            'keywordText' : keyword,\n",
    "            'date': date,\n",
    "            'deviceSegment': device\n",
    "        }])\n",
    "\n",
    "        for column in columns_hva:\n",
    "            if column in group['floodlightActivity'].values:\n",
    "                df[column] = group[group['floodlightActivity'] == column]['dfaActions'].values[0]\n",
    "            else:\n",
    "                df[column] = 0\n",
    "                \n",
    "        result = result.append(df, ignore_index = True)\n",
    "\n",
    "    # combine hva and non_hva\n",
    "    merged = non_hva.merge(result, \n",
    "                           on = ['keywordText', 'date', 'deviceSegment'], \n",
    "                           how = 'left')\n",
    "\n",
    "    # generate baseline and resid compare\n",
    "    merged = merged.fillna(value = 0)\n",
    "    \n",
    "    # generate new fields\n",
    "    merged['HVA'] = merged[columns_hva].sum(axis=1).apply(int)   \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = merge_hva_and_non_hva(hva, non_hva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekdays='Monday Tuesday Wednesday Thursday Friday Saturday Sunday'.split()\n",
    "df['weekday'] = df['date'].apply(lambda x:weekdays[datetime.datetime.strptime(x, '%Y-%m-%d').weekday()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kw_meta = non_hva.drop_duplicates('keywordText')[['campaign', 'adGroup', 'status', 'keywordMatchType', \n",
    "                                        'keywordMaxCpc', 'topOfPageBidCurrent', 'topOfPageBidAvg',\n",
    "                                        'avgPos', 'keywordText']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_cum = ['impr', 'clicks', 'cost', 'HVA',\n",
    "        'Snap Fitness - Franchise Thank You',\n",
    "        'Snap Fitness - International Franchise Thank You',\n",
    "        'Snap Fitness - Franchise - Choose a Country',\n",
    "        'Snap Fitness - Franchise - Email',\n",
    "        'Snap Fitness - Franchise - First Name',\n",
    "        'Snap Fitness - Franchise - I Attest Checkbox',\n",
    "        'Snap Fitness - Franchise - Last Name',\n",
    "        'Snap Fitness - Franchise - Phone Number',\n",
    "        'Snap Fitness - Franchise - Select Country First',\n",
    "        'Snap Fitness - Franchise - Take the First Step Button',\n",
    "        'Snap Fitness - Franchise - What is This? Link',\n",
    "        'Snap Fitness - Franchise Opportunities',\n",
    "        'Snap Fitness - Franchise Request Info',\n",
    "        'Snap Fitness - International Franchise',\n",
    "        'Snap Fitness - International Franchise - Choose a Country',\n",
    "        'Snap Fitness - International Franchise - Email',\n",
    "        'Snap Fitness - International Franchise - First Name',\n",
    "        'Snap Fitness - International Franchise - I Attest Checkbox',\n",
    "        'Snap Fitness - International Franchise - Last Name',\n",
    "        'Snap Fitness - International Franchise - Phone Number',\n",
    "        'Snap Fitness - International Franchise - Select Country First',\n",
    "        'Snap Fitness - International Franchise - Take the First Step Buton',\n",
    "        'Snap Fitness - International Franchise - What is This? Link']\n",
    "\n",
    "writer = pd.ExcelWriter('/Users/JayLiang/Desktop/Media Storm/LIFT/Lift/SEM/Output/Brand_Google_SEM_%s_%s.xlsx'%(start_date, end_date))\n",
    "for view in ['keywordText', 'date', 'weekday', 'deviceSegment']:\n",
    "    result = df.groupby(view)[columns_cum].sum()\n",
    "    result.insert(4, 'CPThankYou', result['cost']/(result['Snap Fitness - Franchise Thank You']+ result['Snap Fitness - International Franchise Thank You']))\n",
    "    result.insert(4, 'cphva', result['cost']/result['HVA'])\n",
    "    result.insert(4, 'cpc', result['cost']/result['clicks'])\n",
    "    result.insert(4, 'cpm', result['cost']/result['impr'])\n",
    "    result.insert(4, 'ctr', result['clicks']/result['impr'])\n",
    "    \n",
    "    if view == 'keywordText':\n",
    "        result = kw_meta.merge(result, left_on='keywordText', right_index=True)\n",
    "        result.index = result['keywordText']\n",
    "        del result['keywordText']\n",
    "    if view !='date':\n",
    "        result.sort_values(by='CPThankYou', inplace=True)\n",
    "    result.to_excel(writer, view)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# manually run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows=6\n",
    "\n",
    "hva_hour = pd.read_excel('/Users/JayLiang/Desktop/Media Storm/LIFT/Lift/SEM/Hour_Download/Hour 2 by Engine.xlsx')\n",
    "non_hva_hour = pd.read_excel('/Users/JayLiang/Desktop/Media Storm/LIFT/Lift/SEM/Hour_Download/Hour 1 by Engine.xlsx')\n",
    "#Google\n",
    "hva_hour=hva_hour[hva_hour['Engine']=='Google AdWords']\n",
    "non_hva_hour=non_hva_hour[non_hva_hour['Engine']=='Google AdWords']\n",
    "#Brand\n",
    "hva_hour = hva_hour[hva_hour['Campaign']=='EST# 2856_LIFT Brands_Snap Fitness_Brand']\n",
    "non_hva_hour = non_hva_hour[non_hva_hour['Campaign']=='EST# 2856_LIFT Brands_Snap Fitness_Brand']\n",
    "\n",
    "\n",
    "hva_hour = hva_hour.loc[:,['Hour of day','Floodlight activity','Actions']]\n",
    "non_hva_hour = non_hva_hour.loc[:,['Hour of day','Cost','Impr','Clicks']]\n",
    "\n",
    "#non_hva_hour['Cost'] = non_hva_hour['Cost'].apply(lambda x: float(x.replace(',', '')))\n",
    "\n",
    "result_non_hva = non_hva_hour.groupby('Hour of day')['Clicks', 'Impr', 'Cost'].sum()\n",
    "result_non_hva.columns =result_non_hva.columns.get_level_values(0)\n",
    "result_non_hva.reset_index(inplace=True)\n",
    "hva_hour=hva_hour.groupby(['Hour of day','Floodlight activity'],as_index=False)['Actions'].sum()\n",
    "hva_hour=hva_hour.pivot_table(index=['Hour of day'],columns=['Floodlight activity'],values=['Actions'])\n",
    "hva_hour.columns =hva_hour.columns.get_level_values(1)\n",
    "hva_hour.reset_index(inplace=True)\n",
    "\n",
    "# result_non_hva.insert(0, 'hour', result_non_hva.index)\n",
    "\n",
    "columns_hva= ['Snap Fitness - Franchise Thank You',\n",
    "        'Snap Fitness - International Franchise Thank You',\n",
    "        'Snap Fitness - Franchise - Choose a Country',\n",
    "        'Snap Fitness - Franchise - Email',\n",
    "        'Snap Fitness - Franchise - First Name',\n",
    "        'Snap Fitness - Franchise - I Attest Checkbox',\n",
    "        'Snap Fitness - Franchise - Last Name',\n",
    "        'Snap Fitness - Franchise - Phone Number',\n",
    "        'Snap Fitness - Franchise - Select Country First',\n",
    "        'Snap Fitness - Franchise - Take the First Step Button',\n",
    "        'Snap Fitness - Franchise - What is This? Link',\n",
    "        'Snap Fitness - Franchise Opportunities',\n",
    "        'Snap Fitness - Franchise Request Info',\n",
    "        'Snap Fitness - International Franchise',\n",
    "        'Snap Fitness - International Franchise - Choose a Country',\n",
    "        'Snap Fitness - International Franchise - Email',\n",
    "        'Snap Fitness - International Franchise - First Name',\n",
    "        'Snap Fitness - International Franchise - I Attest Checkbox',\n",
    "        'Snap Fitness - International Franchise - Last Name',\n",
    "        'Snap Fitness - International Franchise - Phone Number',\n",
    "        'Snap Fitness - International Franchise - Select Country First',\n",
    "        'Snap Fitness - International Franchise - Take the First Step Buton',\n",
    "        'Snap Fitness - International Franchise - What is This? Link']\n",
    "\n",
    "result_hva = hva_hour.loc[:,['Hour of day']+columns_hva]\n",
    "\n",
    "\n",
    "'''\n",
    "for hour, group in hva_hour.groupby('Hour of day'):\n",
    "    df = pd.DataFrame([{\n",
    "        'hour': hour\n",
    "    }])\n",
    "\n",
    "    for column in columns_hva:\n",
    "        if column in group['Floodlight activity'].values:\n",
    "            df[column] = group[group['Floodlight activity'] == column]['Actions'].values[0]\n",
    "        else:\n",
    "            df[column] = 0\n",
    "\n",
    "    result_hva = result_hva.append(df, ignore_index = True)\n",
    "'''\n",
    "\n",
    "result = result_non_hva.merge(result_hva, on='Hour of day', how='left')\n",
    "\n",
    "result.fillna(value=0)\n",
    "result[np.isnan(result)] = 0\n",
    "\n",
    "\n",
    "result.insert(4, 'HVA', result[columns_hva].sum(axis=1))\n",
    "\n",
    "result['Snap Fitness - Franchise Thank You'] = result['Snap Fitness - Franchise Thank You'].astype(np.float64)\n",
    "result['Cost'] = result['Cost'].astype(np.float64)\n",
    "result['Snap Fitness - International Franchise Thank You'] = result['Snap Fitness - International Franchise Thank You'].astype(np.float64)\n",
    "\n",
    "\n",
    "result.insert(4, 'CPThankYou', result['Cost']/(result['Snap Fitness - Franchise Thank You']+ result['Snap Fitness - International Franchise Thank You']))\n",
    "result.insert(4, 'cphva', result['Cost']/result['HVA'])\n",
    "result.insert(4, 'cpc', result['Cost']/result['Clicks'])\n",
    "result.insert(4, 'cpm', result['Cost']/result['Impr'])\n",
    "result.insert(4, 'ctr', result['Clicks']/result['Impr'])\n",
    "\n",
    "\n",
    "\n",
    "result.sort_values(by='CPThankYou', inplace=True)\n",
    "result.to_csv('/Users/JayLiang/Desktop/Media Storm/LIFT/Lift/SEM/Output/Brand_Google_hour_%s_%s.csv'%(start_date, end_date), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
