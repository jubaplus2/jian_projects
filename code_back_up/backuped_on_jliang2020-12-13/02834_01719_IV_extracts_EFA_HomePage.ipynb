{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_file=\"/home/jian/Projects/Saatva/MMM/URL_models/input/URL_SM_input_tabs_data_JL_2019-05-06.xlsx\"\n",
    "excel_file=pd.ExcelFile(excel_file)\n",
    "excel_file.sheet_names\n",
    "\n",
    "tab_list=[x for x in excel_file.sheet_names if \"Stat\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data=excel_file.parse('Home Page')\n",
    "df_ivs=df_data.copy()\n",
    "df_ivs.drop(['date','trans_net','sales_net', 'Users', 'Sessions','ga:goal11Completions','Time on Page','Transactions'],axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rotation_methods_list=['varimax','promax','oblimin','oblimax','quartimin','quartimax','equamax']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10386.769576877074, 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_square_value,p_value=calculate_bartlett_sphericity(df_ivs)\n",
    "chi_square_value, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmo_all_ivs: 0.846048719485\n",
      "kmo_by_variable: [ 0.87213852  0.87526528  0.89824781  0.81614876  0.74854401  0.80875286\n",
      "  0.5720416   0.90397856  0.89417893  0.8610752   0.69680254  0.9268563\n",
      "  0.74850947  0.77042943  0.92060286  0.83679093  0.89013907  0.8121889\n",
      "  0.83850682  0.84143357  0.71010519  0.89058918  0.81752437  0.91968752\n",
      "  0.77529737  0.85952808  0.88547238  0.84796858  0.85545715  0.84121155\n",
      "  0.72158802  0.87468988  0.56013039  0.81743091  0.91050535  0.6943214\n",
      "  0.75851238  0.9001076   0.90349207  0.86015329  0.87106576  0.79220214\n",
      "  0.79302715  0.82963755  0.6764021   0.90119048  0.85104514  0.87406245\n",
      "  0.85242156  0.86931145  0.84435511]\n"
     ]
    }
   ],
   "source": [
    "kmo_by_variable,kmo_all_ivs=calculate_kmo(df_ivs)\n",
    "\n",
    "print(\"kmo_all_ivs:\",kmo_all_ivs)\n",
    "print(\"kmo_by_variable:\",kmo_by_variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varimax 2019-05-07 18:09:14.133319\n",
      "promax 2019-05-07 18:09:16.483023\n",
      "oblimin 2019-05-07 18:09:19.157491\n",
      "oblimax 2019-05-07 18:09:25.101820\n",
      "quartimin 2019-05-07 18:09:27.750970\n",
      "quartimax 2019-05-07 18:09:30.730852\n",
      "equamax 2019-05-07 18:09:33.700306\n"
     ]
    }
   ],
   "source": [
    "factors_num=30\n",
    "i_counter=0\n",
    "columns_list=[\"method\",\"factors_set\",'original_eigen_values','common_factor_eigen_values','nth_original_factor_at_least_1','nth_common_factor_at_least_1']\n",
    "df_method_eigen_values=pd.DataFrame(columns=columns_list)\n",
    "\n",
    "dict_method_factor_num={}\n",
    "for method in rotation_methods_list:\n",
    "\n",
    "    fa = FactorAnalyzer(rotation=method,n_factors=factors_num)\n",
    "    fa.fit(df_ivs)\n",
    "    original_eigen_values,common_factor_eigen_values=fa.get_eigenvalues()\n",
    "\n",
    "    df=pd.DataFrame({\"method\":method,\"factors_set\":factors_num,\"original_eigen_values\":[original_eigen_values],\"common_factor_eigen_values\":[common_factor_eigen_values],'nth_original_factor_at_least_1':len([x for x in original_eigen_values if x >1]),'nth_common_factor_at_least_1':len([x for x in common_factor_eigen_values if x >1])},index=[i_counter])\n",
    "    i_counter+=1\n",
    "    df_method_eigen_values=df_method_eigen_values.append(df)\n",
    "    print(method,datetime.datetime.now())\n",
    "    dict_method_factor_num.update({method:len([x for x in common_factor_eigen_values if x >1])})\n",
    "df_method_eigen_values=df_method_eigen_values[columns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'equamax': 8,\n",
       " 'oblimax': 8,\n",
       " 'oblimin': 7,\n",
       " 'promax': 9,\n",
       " 'quartimax': 8,\n",
       " 'quartimin': 7,\n",
       " 'varimax': 8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_method_factor_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# decrypt the algebra\\n# varima\\nmethod=\"varimax\"\\nfa = FactorAnalyzer(rotation=method,n_factors=dict_method_factor_num[method])\\nfa.fit(df_ivs)\\ndf_commnu_uniqueness=pd.DataFrame({\"iv\":df_ivs.columns.tolist(),\"communalities\":fa.get_communalities(),\"uniquenesses\":fa.get_uniquenesses()})\\ndf_factor_variance=pd.DataFrame({\"factor\":[x for x in range(dict_method_factor_num[method])],\\n                                 \"variance\":fa.get_factor_variance()[0],\\n                                 \"proportional_variance\":fa.get_factor_variance()[1],\\n                                 \"cumulative_variances\":fa.get_factor_variance()[2]})\\ndf_commnu_uniqueness=df_commnu_uniqueness[[\\'iv\\',\\'communalities\\',\\'uniquenesses\\']]\\ndf_factor_variance=df_factor_variance[[\\'factor\\',\\'variance\\',\\'proportional_variance\\',\\'cumulative_variances\\']]\\ndf_loadings=pd.DataFrame(fa.loadings_,index=[df_ivs.columns.tolist()])\\ndf_loadings=df_loadings.reset_index()\\ndf_transform_data=pd.DataFrame(fa.transform(df_ivs))\\ndf_transform_data.index=df_data[\\'date\\'].tolist()\\ndf_transform_data=df_transform_data.reset_index()\\n\\nif fa.structure_ is not None:\\n    structure = fa.structure_\\nelse:\\n    structure = fa.loadings_\\n    \\nweights = np.linalg.solve(fa.corr_, structure)\\n\\nif isinstance(df_ivs, pd.DataFrame):\\n    X = df_ivs.copy().values\\nelse:\\n    X = df_ivs.copy()\\n\\n\\n\\n# see if we saved the original mean and std\\nif fa.mean_ is None or fa.std_ is None:\\n    warnings.warn(\\'Could not find original mean and standard deviation; using\\'\\n                  \\'the mean and standard deviation from the current data set.\\')\\n    mean = np.mean(X, axis=0)\\n    std = np.std(X, axis=0)\\nelse:\\n    mean = fa.mean_\\n    std = fa.std_\\n\\n# get the scaled data\\nX_scale = (X - mean) / std\\nnp.dot(X_scale, weights)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# decrypt the algebra\n",
    "# varima\n",
    "method=\"varimax\"\n",
    "fa = FactorAnalyzer(rotation=method,n_factors=dict_method_factor_num[method])\n",
    "fa.fit(df_ivs)\n",
    "df_commnu_uniqueness=pd.DataFrame({\"iv\":df_ivs.columns.tolist(),\"communalities\":fa.get_communalities(),\"uniquenesses\":fa.get_uniquenesses()})\n",
    "df_factor_variance=pd.DataFrame({\"factor\":[x for x in range(dict_method_factor_num[method])],\n",
    "                                 \"variance\":fa.get_factor_variance()[0],\n",
    "                                 \"proportional_variance\":fa.get_factor_variance()[1],\n",
    "                                 \"cumulative_variances\":fa.get_factor_variance()[2]})\n",
    "df_commnu_uniqueness=df_commnu_uniqueness[['iv','communalities','uniquenesses']]\n",
    "df_factor_variance=df_factor_variance[['factor','variance','proportional_variance','cumulative_variances']]\n",
    "df_loadings=pd.DataFrame(fa.loadings_,index=[df_ivs.columns.tolist()])\n",
    "df_loadings=df_loadings.reset_index()\n",
    "df_transform_data=pd.DataFrame(fa.transform(df_ivs))\n",
    "df_transform_data.index=df_data['date'].tolist()\n",
    "df_transform_data=df_transform_data.reset_index()\n",
    "\n",
    "if fa.structure_ is not None:\n",
    "    structure = fa.structure_\n",
    "else:\n",
    "    structure = fa.loadings_\n",
    "    \n",
    "weights = np.linalg.solve(fa.corr_, structure)\n",
    "\n",
    "if isinstance(df_ivs, pd.DataFrame):\n",
    "    X = df_ivs.copy().values\n",
    "else:\n",
    "    X = df_ivs.copy()\n",
    "\n",
    "\n",
    "\n",
    "# see if we saved the original mean and std\n",
    "if fa.mean_ is None or fa.std_ is None:\n",
    "    warnings.warn('Could not find original mean and standard deviation; using'\n",
    "                  'the mean and standard deviation from the current data set.')\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "else:\n",
    "    mean = fa.mean_\n",
    "    std = fa.std_\n",
    "\n",
    "# get the scaled data\n",
    "X_scale = (X - mean) / std\n",
    "np.dot(X_scale, weights)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.is_corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# factors_num=12\\ni_counter=0\\n\\ndic_df_evaluation={}\\nfor method in rotation_methods_list:\\n    fa = FactorAnalyzer(rotation=method,n_factors=dict_method_factor_num[method])\\n    fa.fit(df_ivs)\\n    df_commnu_uniqueness=pd.DataFrame({\"iv\":df_ivs.columns.tolist(),\"communalities\":fa.get_communalities(),\"uniquenesses\":fa.get_uniquenesses()})\\n    df_factor_variance=pd.DataFrame({\"factor\":[x for x in range(dict_method_factor_num[method])],\\n                                     \"variance\":fa.get_factor_variance()[0],\\n                                     \"proportional_variance\":fa.get_factor_variance()[1],\\n                                     \"cumulative_variances\":fa.get_factor_variance()[2]})\\n    df_commnu_uniqueness=df_commnu_uniqueness[[\\'iv\\',\\'communalities\\',\\'uniquenesses\\']]\\n    df_factor_variance=df_factor_variance[[\\'factor\\',\\'variance\\',\\'proportional_variance\\',\\'cumulative_variances\\']]\\n    df_loadings=pd.DataFrame(fa.loadings_,index=[df_ivs.columns.tolist()])\\n    df_loadings=df_loadings.reset_index()\\n    df_transform_data=pd.DataFrame(fa.transform(df_ivs))\\n    df_transform_data.index=df_data[\\'date\\'].tolist()\\n    df_transform_data=df_transform_data.reset_index()\\n    dic_df_evaluation.update({method:{\"df_commnu_uniqueness\":df_commnu_uniqueness,\"df_factor_variance\":df_factor_variance,\"df_loadings\":df_loadings,\"transform_data\":df_transform_data}})\\n\\n##########\\nwriter=pd.ExcelWriter(\"/home/jian/Projects/Saatva/MMM/URL_models/input/EFA_HomePage_evaluation_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\\npd.DataFrame({\"kmo_by_variable\":kmo_by_variable}).to_excel(writer,\"kmo_by_variable\",index=False)\\ndf_method_eigen_values.to_excel(writer,\"eigen_values_by_rotation\",index=False)\\nfor method in dic_df_evaluation.keys():\\n    for key_df in dic_df_evaluation[method].keys():\\n        dic_df_evaluation[method][key_df].to_excel(writer,method+\"|\"+key_df.replace(\"df_\",\"\"),index=False)\\n\\nwriter.save()\\n\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# factors_num=12\n",
    "i_counter=0\n",
    "\n",
    "dic_df_evaluation={}\n",
    "for method in rotation_methods_list:\n",
    "    fa = FactorAnalyzer(rotation=method,n_factors=dict_method_factor_num[method])\n",
    "    fa.fit(df_ivs)\n",
    "    df_commnu_uniqueness=pd.DataFrame({\"iv\":df_ivs.columns.tolist(),\"communalities\":fa.get_communalities(),\"uniquenesses\":fa.get_uniquenesses()})\n",
    "    df_factor_variance=pd.DataFrame({\"factor\":[x for x in range(dict_method_factor_num[method])],\n",
    "                                     \"variance\":fa.get_factor_variance()[0],\n",
    "                                     \"proportional_variance\":fa.get_factor_variance()[1],\n",
    "                                     \"cumulative_variances\":fa.get_factor_variance()[2]})\n",
    "    df_commnu_uniqueness=df_commnu_uniqueness[['iv','communalities','uniquenesses']]\n",
    "    df_factor_variance=df_factor_variance[['factor','variance','proportional_variance','cumulative_variances']]\n",
    "    df_loadings=pd.DataFrame(fa.loadings_,index=[df_ivs.columns.tolist()])\n",
    "    df_loadings=df_loadings.reset_index()\n",
    "    df_transform_data=pd.DataFrame(fa.transform(df_ivs))\n",
    "    df_transform_data.index=df_data['date'].tolist()\n",
    "    df_transform_data=df_transform_data.reset_index()\n",
    "    dic_df_evaluation.update({method:{\"df_commnu_uniqueness\":df_commnu_uniqueness,\"df_factor_variance\":df_factor_variance,\"df_loadings\":df_loadings,\"transform_data\":df_transform_data}})\n",
    "\n",
    "##########\n",
    "writer=pd.ExcelWriter(\"/home/jian/Projects/Saatva/MMM/URL_models/input/EFA_HomePage_evaluation_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "pd.DataFrame({\"kmo_by_variable\":kmo_by_variable}).to_excel(writer,\"kmo_by_variable\",index=False)\n",
    "df_method_eigen_values.to_excel(writer,\"eigen_values_by_rotation\",index=False)\n",
    "for method in dic_df_evaluation.keys():\n",
    "    for key_df in dic_df_evaluation[method].keys():\n",
    "        dic_df_evaluation[method][key_df].to_excel(writer,method+\"|\"+key_df.replace(\"df_\",\"\"),index=False)\n",
    "\n",
    "writer.save()\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method=\"varimax\"\n",
    "\n",
    "fa = FactorAnalyzer(rotation=method,n_factors=dict_method_factor_num[method])\n",
    "fa.fit(df_ivs)\n",
    "df_commnu_uniqueness=pd.DataFrame({\"iv\":df_ivs.columns.tolist(),\"communalities\":fa.get_communalities(),\"uniquenesses\":fa.get_uniquenesses()})\n",
    "df_factor_variance=pd.DataFrame({\"factor\":[x for x in range(dict_method_factor_num[method])],\n",
    "                                 \"variance\":fa.get_factor_variance()[0],\n",
    "                                 \"proportional_variance\":fa.get_factor_variance()[1],\n",
    "                                 \"cumulative_variances\":fa.get_factor_variance()[2]})\n",
    "df_commnu_uniqueness=df_commnu_uniqueness[['iv','communalities','uniquenesses']]\n",
    "df_factor_variance=df_factor_variance[['factor','variance','proportional_variance','cumulative_variances']]\n",
    "df_loadings=pd.DataFrame(fa.loadings_,index=[df_ivs.columns.tolist()])\n",
    "df_loadings=df_loadings.reset_index()\n",
    "df_transform_data=pd.DataFrame(fa.transform(df_ivs))\n",
    "df_transform_data.index=df_data['date'].tolist()\n",
    "df_transform_data=df_transform_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales_net</th>\n",
       "      <th>trans_net</th>\n",
       "      <th>Users</th>\n",
       "      <th>Sessions</th>\n",
       "      <th>ga:goal11Completions</th>\n",
       "      <th>Time on Page</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>www.saatvamattress.com/made-in-america.html</th>\n",
       "      <th>www.saatvamattress.com/foundations.html</th>\n",
       "      <th>...</th>\n",
       "      <th>www.saatvamattress.com/saatva-reviews</th>\n",
       "      <th>www.saatvamattress.com/mattress-for-back-pain-relief</th>\n",
       "      <th>www.saatvamattress.com/saatva-mattress.html</th>\n",
       "      <th>www.saatvamattress.com/sitemap</th>\n",
       "      <th>www.saatvamattress.com/mattress-comparison-chart.html</th>\n",
       "      <th>www.saatvamattress.com/saatva-mattress-reviews</th>\n",
       "      <th>www.saatvamattress.com/our-comfort-zone.html</th>\n",
       "      <th>www.saatvamattress.com/the-mattresses.html</th>\n",
       "      <th>www.saatvamattress.com</th>\n",
       "      <th>www.saatvamattress.com/shop-pla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>330007.80</td>\n",
       "      <td>232</td>\n",
       "      <td>27488</td>\n",
       "      <td>31733</td>\n",
       "      <td>727</td>\n",
       "      <td>3859793</td>\n",
       "      <td>185</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>1228</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>153</td>\n",
       "      <td>232</td>\n",
       "      <td>442</td>\n",
       "      <td>22331</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>316132.57</td>\n",
       "      <td>227</td>\n",
       "      <td>28227</td>\n",
       "      <td>32226</td>\n",
       "      <td>677</td>\n",
       "      <td>3670182</td>\n",
       "      <td>156</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>1204</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>132</td>\n",
       "      <td>181</td>\n",
       "      <td>500</td>\n",
       "      <td>21763</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sales_net  trans_net  Users  Sessions  ga:goal11Completions  \\\n",
       "0  2018-01-01  330007.80        232  27488     31733                   727   \n",
       "1  2018-01-02  316132.57        227  28227     32226                   677   \n",
       "\n",
       "   Time on Page  Transactions  www.saatvamattress.com/made-in-america.html  \\\n",
       "0       3859793           185                                            5   \n",
       "1       3670182           156                                           11   \n",
       "\n",
       "   www.saatvamattress.com/foundations.html               ...                 \\\n",
       "0                                        0               ...                  \n",
       "1                                        0               ...                  \n",
       "\n",
       "   www.saatvamattress.com/saatva-reviews  \\\n",
       "0                                      0   \n",
       "1                                      0   \n",
       "\n",
       "   www.saatvamattress.com/mattress-for-back-pain-relief  \\\n",
       "0                                                294      \n",
       "1                                                309      \n",
       "\n",
       "   www.saatvamattress.com/saatva-mattress.html  \\\n",
       "0                                         1228   \n",
       "1                                         1204   \n",
       "\n",
       "   www.saatvamattress.com/sitemap  \\\n",
       "0                               2   \n",
       "1                               0   \n",
       "\n",
       "   www.saatvamattress.com/mattress-comparison-chart.html  \\\n",
       "0                                                 50       \n",
       "1                                                 44       \n",
       "\n",
       "   www.saatvamattress.com/saatva-mattress-reviews  \\\n",
       "0                                             153   \n",
       "1                                             132   \n",
       "\n",
       "   www.saatvamattress.com/our-comfort-zone.html  \\\n",
       "0                                           232   \n",
       "1                                           181   \n",
       "\n",
       "   www.saatvamattress.com/the-mattresses.html  www.saatvamattress.com  \\\n",
       "0                                         442                   22331   \n",
       "1                                         500                   21763   \n",
       "\n",
       "   www.saatvamattress.com/shop-pla  \n",
       "0                              429  \n",
       "1                              393  \n",
       "\n",
       "[2 rows x 59 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "DVs=df_data[['date','trans_net','Users','Sessions','ga:goal11Completions']]\n",
    "DVs['Trans_Per_Usr']=DVs['trans_net']/DVs['Users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "varimax_MMM_input=df_transform_data.rename(columns={\"index\":\"date\"})\n",
    "\n",
    "for col in range(8):\n",
    "    varimax_MMM_input=varimax_MMM_input.rename(columns={col:\"Factor_\"+str(col)})\n",
    "varimax_MMM_input=pd.merge(DVs,varimax_MMM_input,on=\"date\")\n",
    "varimax_MMM_input.to_csv(\"/home/jian/Projects/Saatva/MMM/URL_models/input/EFA_Varimax_HomePage_MMM_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "                         \n",
    "                         \n",
    "                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
