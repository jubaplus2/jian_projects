{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 11, 14, 11, 58)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime(1970,1,1) + dt.timedelta(0,1510660680)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 11, 14, 12, 56)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime(1970,1,1) + dt.timedelta(0,1510664160) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-422eff0c2132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mul\u001b[0m \u001b[0;31m#url.request lib for handling the url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m \u001b[0;31m#bs for parsing the page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#url = \"http://www.hallmarkchannel.com/schedule?mode=&day=0&week=0&tz=EST\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#url_response=ul.urlopen(url,timeout=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import urllib.request as ul #url.request lib for handling the url\n",
    "from bs4 import BeautifulSoup #bs for parsing the page\n",
    "#url = \"http://www.hallmarkchannel.com/schedule?mode=&day=0&week=0&tz=EST\"\n",
    "#url_response=ul.urlopen(url,timeout=5)\n",
    "#soup = BeautifulSoup(url_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "name = []\n",
    "time = []\n",
    "description = []\n",
    "for i in range(0,30):\n",
    "    url_page = \"http://www.hallmarkchannel.com/schedule?mode=&day=\"+str(i)+\"&week=0&tz=EST\"\n",
    "    soup= BeautifulSoup(ul.urlopen(url_page,timeout=5))\n",
    "    name_box = soup.find_all('a', attrs={'class': 'schedule-daily-table-show-details-title'})\n",
    "    time_box = soup.find_all('div', attrs={'class': 'schedule-daily-table-time'})\n",
    "    show_info = [div.attrs['data-show-info'] for div in soup.find_all('div') if div.has_attr('data-show-info')]\n",
    "    for j in range(len(show_info)):\n",
    "        name.append(name_box[j].text.strip())\n",
    "        time.append(time_box[j].text.strip())\n",
    "        description.append(ast.literal_eval([div.attrs['data-show-info'] for div in soup.find_all('div') if div.has_attr('data-show-info')][j])['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = {'Showname': name, 'Showtime': time, 'Description':description}\n",
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('/Users/siyang/Dropbox/2017intern/jubaplus/Hallmark_schedule/schedule.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = []\n",
    "time = []\n",
    "description = []\n",
    "name_box = soup.find_all('a', attrs={'class': 'schedule-daily-table-show-details-title'})\n",
    "time_box = soup.find_all('div', attrs={'class': 'schedule-daily-table-time'})\n",
    "show_info = [div.attrs['data-show-info'] for div in soup.find_all('div') if div.has_attr('data-show-info')]\n",
    "for i in range(len(show_info)):\n",
    "    name.append(name_box[i].text.strip())\n",
    "    time.append(time_box[i].text.strip())\n",
    "    description.append(ast.literal_eval([div.attrs['data-show-info'] for div in soup.find_all('div') if div.has_attr('data-show-info')][i])['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Boyfriend for Christmas\n",
      "A Very Merry Mix-Up\n",
      "A Heavenly Christmas\n"
     ]
    }
   ],
   "source": [
    "for name in name_box:\n",
    "    name = name.text.strip()\n",
    "    print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
