{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(filename='/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/Activity_table_per_month/monthly_Activity_Table_Initiation_BL_id_only_log.log', level=logging.INFO)\n",
    "\n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy new mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paramiko\n",
    "\n",
    "host = \"64.237.51.251\" #hard-coded\n",
    "port = 22\n",
    "transport = paramiko.Transport((host, port))\n",
    "\n",
    "password = \"jian@juba2017\" #hard-coded\n",
    "username = \"jian\" #hard-coded\n",
    "transport.connect(username = username, password = password)\n",
    "sftp = paramiko.SFTPClient.from_transport(transport)\n",
    "\n",
    "remote_mapping_list=sftp.listdir(\"/mnt/drv5/lr_biglots_data/download_logs/others/\")\n",
    "remote_mapping_list.sort()\n",
    "\n",
    "###\n",
    "remote_mapping_list_1=[x for x in remote_mapping_list if \"allrewards\" in x]\n",
    "remote_mapping_list_1_0908=[x for x in remote_mapping_list_1 if \"0908\" in x]\n",
    "remote_mapping_list_1_0908=remote_mapping_list_1_0908[-1]\n",
    "\n",
    "remote_mapping_list_1_1011=[x for x in remote_mapping_list_1 if \"1011\" in x]\n",
    "remote_mapping_list_1_1011=remote_mapping_list_1_1011[-1]\n",
    "\n",
    "remote_mapping_list_1=[remote_mapping_list_1_0908,remote_mapping_list_1_1011]\n",
    "\n",
    "\n",
    "remote_mapping_list_2=[x for x in remote_mapping_list if \"mapping\" in x]\n",
    "remote_mapping_list_2.sort()\n",
    "remote_mapping_list_2.pop(0)\n",
    "\n",
    "# \n",
    "remote_mapping_list=remote_mapping_list_1+remote_mapping_list_2\n",
    "local_mapping_existing_list=[os.path.basename(y) for y in glob.glob(\"/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/*.gz\")]\n",
    "remote_mapping_list=[x for x in remote_mapping_list if x not in local_mapping_existing_list]\n",
    "remote_mapping_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in remote_mapping_list:\n",
    "    remote_path=\"/mnt/drv5/lr_biglots_data/download_logs/others/\"+file\n",
    "    local_path=\"/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/\"+file\n",
    "    sftp.get(remote_path,local_path)\n",
    "    print(\"New mapping copied to the local as: \"+str(local_path))\n",
    "    logging.info(\"New mapping copied to the local as: \"+str(local_path))\n",
    "sftp.close()\n",
    "transport.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_local_mapping=glob.glob(\"/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/*.psv.gz\")\n",
    "df_all_mapping_file=pd.DataFrame({\"file_path\":list_local_mapping})\n",
    "df_all_mapping_file['mapping_up_to_date']=df_all_mapping_file['file_path'].apply(lambda x: x.split(\"_\")[-3])\n",
    "df_all_mapping_fil=df_all_mapping_file.sort_values(\"mapping_up_to_date\")\n",
    "df_all_mapping_fil=df_all_mapping_fil.reset_index()\n",
    "del df_all_mapping_fil['index']\n",
    "# Ascending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update the all time LR IDL_BL_id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the update and aggregated not here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38226704, 3)\n",
      "36944095\n",
      "32575028\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Link</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>date_up_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XY1468---077tVclzugrAPADjYKKd1D3ZebCh26abPI1mraTs</td>\n",
       "      <td>c038e1b89f0bf1902d4c365d001b9a19b3a739358d1ee7...</td>\n",
       "      <td>20200215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XY1468---0pTSu_zfDGheJ-qYQPfvwhCI1e7f_joTNdovjomE</td>\n",
       "      <td>1b5cda9e5ca0af148177d6a317905639cb35d744e0ff2d...</td>\n",
       "      <td>20200215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XY1468---1i3EbLRBAPuKc2mSWy4bIs6QvBbFwWavuATdTTQI</td>\n",
       "      <td>0d95ec6248ba4fb596378678e36c1a0453b8ff84862b76...</td>\n",
       "      <td>20200215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XY1468---1kVQT3iPqthySc6GJ53sp2-h3GwT4_4bYAJk__eI</td>\n",
       "      <td>d449269735be97a927b7236184082861ecd4a74810e181...</td>\n",
       "      <td>20200215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XY1468---2HCWhlYC73t__zvlTPujqfK2YR9dz6MAg64po5hM</td>\n",
       "      <td>96457a5c6aeb15284a930557afdf3032933a1510257b62...</td>\n",
       "      <td>20200215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XY1468---2Lpewd2wQcUpWwH177TLrtS7CY2j703yOv6MJ6Lk</td>\n",
       "      <td>0fe3858f393b63931a48cb0a11665cc15e78869df39db7...</td>\n",
       "      <td>20190207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XY1468---2X7UQqC1vASJx-IeoLZoXp3vxApZpE6um4fesQsU</td>\n",
       "      <td>5c701b9026542480dc97b4535bf751b665106396f9a6b3...</td>\n",
       "      <td>20191125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XY1468---2eCOjc0YWoD7YeA3caYqs9co13bn5GbXVVsLNKhs</td>\n",
       "      <td>e7599bf13053e3a3b444da6330ff1cff49579c9ea53c73...</td>\n",
       "      <td>20200215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XY1468---2yhYvOTg1BNenE00-7L1WPENGOjZhJ5YVd8bKzTE</td>\n",
       "      <td>21ad9af4897aece7f81910a8e5bf7d4f92409f31c734e0...</td>\n",
       "      <td>20200215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XY1468---4MVMx_4NhiHNoYG0Ee9uHc0JtD9JochFalgSMIbw</td>\n",
       "      <td>d3f7f025574ae8fd84aa451c6a81d4c93da5c835540b17...</td>\n",
       "      <td>20200215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Customer_Link  \\\n",
       "0  XY1468---077tVclzugrAPADjYKKd1D3ZebCh26abPI1mraTs   \n",
       "1  XY1468---0pTSu_zfDGheJ-qYQPfvwhCI1e7f_joTNdovjomE   \n",
       "2  XY1468---1i3EbLRBAPuKc2mSWy4bIs6QvBbFwWavuATdTTQI   \n",
       "3  XY1468---1kVQT3iPqthySc6GJ53sp2-h3GwT4_4bYAJk__eI   \n",
       "4  XY1468---2HCWhlYC73t__zvlTPujqfK2YR9dz6MAg64po5hM   \n",
       "5  XY1468---2Lpewd2wQcUpWwH177TLrtS7CY2j703yOv6MJ6Lk   \n",
       "6  XY1468---2X7UQqC1vASJx-IeoLZoXp3vxApZpE6um4fesQsU   \n",
       "7  XY1468---2eCOjc0YWoD7YeA3caYqs9co13bn5GbXVVsLNKhs   \n",
       "8  XY1468---2yhYvOTg1BNenE00-7L1WPENGOjZhJ5YVd8bKzTE   \n",
       "9  XY1468---4MVMx_4NhiHNoYG0Ee9uHc0JtD9JochFalgSMIbw   \n",
       "\n",
       "                                  customer_id_hashed date_up_to  \n",
       "0  c038e1b89f0bf1902d4c365d001b9a19b3a739358d1ee7...   20200215  \n",
       "1  1b5cda9e5ca0af148177d6a317905639cb35d744e0ff2d...   20200215  \n",
       "2  0d95ec6248ba4fb596378678e36c1a0453b8ff84862b76...   20200215  \n",
       "3  d449269735be97a927b7236184082861ecd4a74810e181...   20200215  \n",
       "4  96457a5c6aeb15284a930557afdf3032933a1510257b62...   20200215  \n",
       "5  0fe3858f393b63931a48cb0a11665cc15e78869df39db7...   20190207  \n",
       "6  5c701b9026542480dc97b4535bf751b665106396f9a6b3...   20191125  \n",
       "7  e7599bf13053e3a3b444da6330ff1cff49579c9ea53c73...   20200215  \n",
       "8  21ad9af4897aece7f81910a8e5bf7d4f92409f31c734e0...   20200215  \n",
       "9  d3f7f025574ae8fd84aa451c6a81d4c93da5c835540b17...   20200215  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_IDL_BLid=pd.read_csv(\"/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/df_total_mapping_IDL_BLid_JL_2020-03-02.csv\",\n",
    "                            dtype=str)\n",
    "\n",
    "print(mapping_IDL_BLid.shape)\n",
    "print(mapping_IDL_BLid['Customer_Link'].nunique())\n",
    "print(mapping_IDL_BLid['customer_id_hashed'].nunique())\n",
    "\n",
    "logging.info(\"mapping_IDL_BLid.shape: \"+str(mapping_IDL_BLid.shape))\n",
    "logging.info(\"mapping_IDL_BLid['Customer_Link'].nunique(): \"+str(mapping_IDL_BLid['Customer_Link'].nunique()))\n",
    "logging.info(\"mapping_IDL_BLid['customer_id_hashed'].nunique(): \"+str(mapping_IDL_BLid['customer_id_hashed'].nunique()))\n",
    "\n",
    "mapping_IDL_BLid.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180524 20191231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Link</th>\n",
       "      <th>User ID</th>\n",
       "      <th>valid_since_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XY1468hPv3C6LUplcc9AOQzxWzY1udaza4Ln32X1741yLNDek</td>\n",
       "      <td>AMsySZYwlmbsf4rsAWEdAeTInPJe</td>\n",
       "      <td>20180524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xi1468eM-c0d-GBhe0kva9Sv6cGyyAH_7WvdJSUyiRQJUq...</td>\n",
       "      <td>AMsySZbGHLhJxKnEGwG4yrTXarSO</td>\n",
       "      <td>20180524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XY1468dnvwCzHXgvKJd09Ngnlx8UNDKg6CY0iJTYcx04u4cG4</td>\n",
       "      <td>AMsySZYUiAwu0NWGt8xW144UK2rq</td>\n",
       "      <td>20180524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XY1468K_-yH0zRPT3BJGQ7Y4j1BeR26cw_sYp5F63Z-r91lJY</td>\n",
       "      <td>AMsySZYA7KfqPfG73RFmixBa8neT</td>\n",
       "      <td>20180524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Customer_Link  \\\n",
       "0  XY1468hPv3C6LUplcc9AOQzxWzY1udaza4Ln32X1741yLNDek   \n",
       "1  Xi1468eM-c0d-GBhe0kva9Sv6cGyyAH_7WvdJSUyiRQJUq...   \n",
       "2  XY1468dnvwCzHXgvKJd09Ngnlx8UNDKg6CY0iJTYcx04u4cG4   \n",
       "3  XY1468K_-yH0zRPT3BJGQ7Y4j1BeR26cw_sYp5F63Z-r91lJY   \n",
       "\n",
       "                        User ID valid_since_dt  \n",
       "0  AMsySZYwlmbsf4rsAWEdAeTInPJe       20180524  \n",
       "1  AMsySZbGHLhJxKnEGwG4yrTXarSO       20180524  \n",
       "2  AMsySZYUiAwu0NWGt8xW144UK2rq       20180524  \n",
       "3  AMsySZYA7KfqPfG73RFmixBa8neT       20180524  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_file_uid_idl=pd.read_csv(\"/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/UID_IDL_mapping/BL_GoogleID_IDL_mapping_20180524_20191231_JL_2020-02-23.csv\",\n",
    "                                nrows=None,dtype=str)\n",
    "mapping_file_uid_idl=mapping_file_uid_idl.rename(columns={\"file_date\":\"valid_since_dt\"})\n",
    "\n",
    "logging.info(\"mapping_file_uid_idl['valid_since_dt'].min(): \"+str(mapping_file_uid_idl['valid_since_dt'].min()))\n",
    "logging.info(\"mapping_file_uid_idl['valid_since_dt'].max(): \"+str(mapping_file_uid_idl['valid_since_dt'].max()))\n",
    "logging.info(\"mapping_IDL_BLid['customer_id_hashed'].nunique(): \"+str(mapping_IDL_BLid['customer_id_hashed'].nunique()))\n",
    "\n",
    "\n",
    "print(mapping_file_uid_idl['valid_since_dt'].min(),mapping_file_uid_idl['valid_since_dt'].max())\n",
    "mapping_file_uid_idl.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/CL_BigLots_allrewards_combined1011_20181026_232208_0000.psv.gz',\n",
       " '/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/CL_BigLots_allrewards_combined0908_20181029_171317_0000.psv.gz',\n",
       " '/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/CL_BigLots_BL_mapping_file_2018Q4_JL_2019-02-01_20190207_025237_0000.psv.gz',\n",
       " '/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/CL_BigLots_BL_mapping_file_2019Q1_JL_2019-05-14_20190516_111931_0000.psv.gz',\n",
       " '/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/CL_BigLots_BL_mapping_file_2019Q2_JL_2019-09-23_20190926_084457_0000.psv.gz',\n",
       " '/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/CL_BigLots_BL_mapping_file_2019Q3_JL_2019-11-20_20191125_232935_0000.psv.gz',\n",
       " '/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/CL_BigLots_BL_mapping_file_2019Q4_JL_2020-02-14_20200215_020719_0000.psv.gz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_mapping_files=glob.glob(\"/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/*.psv.gz\")\n",
    "list_mapping_files=sorted(list_mapping_files,key = lambda x: x.split(\"_\")[-3])\n",
    "list_mapping_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_files_lr_returned_act=glob.glob(\"/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/LR_returned_logs_BL/activities/*.gz\")\n",
    "list_dcm_logs_act=glob.glob(\"/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/DCM_raw_logs_BL/activities/*.tsv\")\n",
    "df_log_files_by_date=pd.DataFrame({\"file_path\":list_dcm_logs_act})\n",
    "df_log_files_by_date['date']=df_log_files_by_date['file_path'].apply(lambda x: os.path.basename(x).split(\"utc_\")[1][:8])\n",
    "df_log_files_by_date['month']=df_log_files_by_date['date'].apply(lambda x: x[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "# max_term_length=256\n",
    "def get_url_and_kwd(url):\n",
    "    res = urlparse(url)\n",
    "    if url.startswith('u2=') or url.startswith('~oref='):\n",
    "        term_detail='not defined'\n",
    "        return term_detail\n",
    "\n",
    "    elif 'ntt=' in res.query:\n",
    "        term_detail=res.query.split('ntt=')[-1].split('&')[0]\n",
    "    elif '_/n-' in url:\n",
    "        term_detail=url.split('/c/')[-1].split('?')[0]\n",
    "    else:\n",
    "        term_detail='not defined'\n",
    "        return term_detail\n",
    "        \n",
    "    if '?ntt' in url:\n",
    "        term_detail=term_detail.replace('+',' ').replace('=',' ').replace('-',' ').strip()\n",
    "        if len(term_detail)>=256:\n",
    "            return \"term_parsed_but_longer_than_256\"\n",
    "        return term_detail\n",
    "    \n",
    "    else:\n",
    "        if '_/n-' in url:\n",
    "            term_detail=term_detail[:-14]\n",
    "        term_detail=term_detail.replace(\"_\",\"\")\n",
    "        if not term_detail:\n",
    "            term_detail=\"/\"\n",
    "        elif term_detail[-1]!=\"/\":\n",
    "            term_detail=term_detail+\"/\"\n",
    "            \n",
    "        term_detail=term_detail.split('/')[-2]\n",
    "        term_detail=term_detail.replace('+',' ').replace('=',' ').replace('-',' ').strip()\n",
    "        if len(term_detail)>=256:\n",
    "            return \"term_parsed_but_longer_than_256\"\n",
    "        return term_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sessions(df_input,id_col,df_previous_session_count,session_len=1800):\n",
    "    df=df_input[['Event Time',id_col]].drop_duplicates()\n",
    "    df=df.sort_values([id_col,'Event Time'])\n",
    "    df=df.reset_index()\n",
    "    del df['index']\n",
    "    df=df.reset_index()\n",
    "\n",
    "    df_shift=df.copy()\n",
    "    df_shift['index']=df_shift['index']+1\n",
    "    df_shift['index']=df_shift['index'].astype(int)\n",
    "    df_shift=df_shift.rename(columns={\"Event Time\":\"shift_time\"})\n",
    "\n",
    "    df_merge=pd.merge(df,df_shift,on=[id_col,\"index\"],how=\"left\")\n",
    "    df_merge['diff']=df_merge['Event Time']-df_merge['shift_time']\n",
    "    df_1=df_merge[pd.isnull(df_merge['diff'])]\n",
    "    df_2=df_merge[pd.notnull(df_merge['diff'])]\n",
    "    df_2=df_2[df_2['diff']>=session_len*10**6]\n",
    "    df_ind=df_1.append(df_2).sort_values([id_col,\"Event Time\"]).reset_index()\n",
    "    del df_ind['index']\n",
    "    df_ind['seq_in_month']=df_ind.groupby(id_col).cumcount()\n",
    "    df_ind=df_ind[['Event Time',id_col,'seq_in_month']]\n",
    "    df_output=pd.merge(df_input,df_ind,on=['Event Time',id_col],how=\"left\")\n",
    "    df_output=df_output.sort_values([id_col,'Event Time'])\n",
    "    df_output['seq_in_month']=df_output['seq_in_month'].fillna(method=\"ffill\")\n",
    "    df_output['seq_in_month']=df_output['seq_in_month'].astype(int)+1\n",
    "    df_output=pd.merge(df_output,df_previous_session_count,on=id_col,how=\"left\")\n",
    "    df_output['session_sequence']=df_output['session_sequence'].fillna(0)\n",
    "    df_output['session_sequence']=df_output['session_sequence']+df_output['seq_in_month']\n",
    "    \n",
    "    df_output['date_time']=pd.to_datetime(df_output['Event Time'],unit=\"us\")\n",
    "    df_output['date_utc']=df_output['date_time'].dt.date\n",
    "    df_output['time_utc']=df_output['date_time'].dt.time    \n",
    "    del df_output['date_time']\n",
    "    df_output=df_output.sort_values(['Event Time',id_col])\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jian/Projects/Big_Lots/Analysis/2019_Q4/...</td>\n",
       "      <td>20180523</td>\n",
       "      <td>201805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jian/Projects/Big_Lots/Analysis/2019_Q4/...</td>\n",
       "      <td>20180524</td>\n",
       "      <td>201805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path      date   month\n",
       "0  /home/jian/Projects/Big_Lots/Analysis/2019_Q4/...  20180523  201805\n",
       "1  /home/jian/Projects/Big_Lots/Analysis/2019_Q4/...  20180524  201805"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log_files_by_date.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py:166: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-21 16:17:26.804921 (788202, 2)\n"
     ]
    }
   ],
   "source": [
    "df_previous_session_count_BLID=pd.read_sql(\"select customer_id_hashed, max(session_sequence) as session_sequence from Pred_Activity_BL_id \\\n",
    "group by customer_id_hashed\",con=BL_engine)\n",
    "print(datetime.datetime.now(),df_previous_session_count_BLID.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8f218bb11251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_date_utc_in_sql_BL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select max(date_utc) from Pred_Activity_BL_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBL_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_date_utc_in_sql_BL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_date_utc_in_sql_BL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max(date_utc)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_date_utc_in_sql_BL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_log_files_by_date_remaining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_log_files_by_date\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_log_files_by_date\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_date_utc_in_sql_BL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "max_date_utc_in_sql_BL=pd.read_sql(\"select max(date_utc) from Pred_Activity_BL_id\",con=BL_engine)\n",
    "max_date_utc_in_sql_BL=max_date_utc_in_sql_BL['max(date_utc)'].tolist()[0]\n",
    "print(max_date_utc_in_sql_BL)\n",
    "\n",
    "df_log_files_by_date_remaining=df_log_files_by_date[df_log_files_by_date['month']>=str(max_date_utc_in_sql_BL).replace(\"-\",\"\")[:6]]\n",
    "print(df_log_files_by_date_remaining.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>session_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001dadc0265bf9d250566d74e0006323f18b5826641...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000435bfb3bf42e3beb4c9b3942c552d09f0e49e5a75...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000950dea4a869e9fe70d823444d418c5abebbd8e830...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed  session_sequence\n",
       "0  000001dadc0265bf9d250566d74e0006323f18b5826641...                 8\n",
       "1  00000435bfb3bf42e3beb4c9b3942c552d09f0e49e5a75...                 6\n",
       "2  00000950dea4a869e9fe70d823444d418c5abebbd8e830...                 8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_previous_session_count_BLID.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72024810, 7)\n",
      "2020-03-21 19:13:02.707195 201912 (2308944, 7) (2308944, 7) 0.0321\n",
      "2020-03-21 19:15:23.874011 File wrote of df_month_act_BLID\n",
      "2020-03-21 19:19:08.270237 File wrote to MySQL df_month_act_BLID\n",
      "2020-03-21 19:19:08.271310 Done of the month:  201912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_previous_session_count_GUID=pd.DataFrame(columns=[\"User ID\",\"session_sequence\"])\n",
    "# df_previous_session_count_BLID=pd.DataFrame(columns=[\"customer_id_hashed\",\"session_sequence\"])\n",
    "\n",
    "for month, df_file_month in df_log_files_by_date_remaining.groupby(\"month\"):\n",
    "    list_files=df_file_month['file_path'].tolist()\n",
    "    df_month_act=pd.DataFrame()\n",
    "    for file in list_files:\n",
    "        date_file=file.split(\"_utc_\")[1][:8] #str\n",
    "        df=pd.read_csv(file,dtype=str,sep=\"\\t\",usecols=['Event Time','User ID','Other Data','Activity ID'])\n",
    "        df['Other Data']=df['Other Data'].astype(str)\n",
    "        df=df[df['Event Time'].str.isdigit()]\n",
    "        df['Event Time']=df['Event Time'].astype(int)\n",
    "        \n",
    "        list_uid_day=df['User ID'].unique().tolist()\n",
    "        \n",
    "        df['url']=df['Other Data'].apply(lambda x: x.split('u1=')[-1].split(';')[0])\n",
    "        df['url']=df['url'].astype(str)\n",
    "        df['search_term'] =df['url'].apply(get_url_and_kwd)\n",
    "        df['url']=df['url'].str.slice(stop=2048)\n",
    "        \n",
    "        # match in idl\n",
    "        # ago(later>earlier)>after(earlier>later)\n",
    "        df_day_mapping_uid_idl=mapping_file_uid_idl[mapping_file_uid_idl['User ID'].isin(list_uid_day)]\n",
    "        \n",
    "        df_day_mapping_uid_idl_ago=df_day_mapping_uid_idl[df_day_mapping_uid_idl['valid_since_dt']<=date_file] #8-digit-str\n",
    "        df_day_mapping_uid_idl_after=df_day_mapping_uid_idl[df_day_mapping_uid_idl['valid_since_dt']>date_file] #8-digit-str\n",
    "        \n",
    "        df_day_mapping_uid_idl_ago=df_day_mapping_uid_idl_ago.sort_values([\"User ID\",\"valid_since_dt\"],ascending=[True,False]).drop_duplicates(\"User ID\")\n",
    "        df_day_mapping_uid_idl_after=df_day_mapping_uid_idl_after.sort_values([\"User ID\",\"valid_since_dt\"],ascending=[True,True]).drop_duplicates(\"User ID\")\n",
    "        df_day_mapping_uid_idl=df_day_mapping_uid_idl_ago.append(df_day_mapping_uid_idl_after).drop_duplicates(\"User ID\")\n",
    "        del df_day_mapping_uid_idl['valid_since_dt']\n",
    "        df=pd.merge(df,df_day_mapping_uid_idl,how=\"left\",on=\"User ID\")\n",
    "        # match in BL id\n",
    "        list_idl_day=df['Customer_Link'].unique().tolist()\n",
    "        df_day_mapping_IDL_BLid=mapping_IDL_BLid[mapping_IDL_BLid['Customer_Link'].isin(list_idl_day)]\n",
    "        \n",
    "        df_day_mapping_idl_blid_ago=df_day_mapping_IDL_BLid[df_day_mapping_IDL_BLid['date_up_to']<date_file] #8-digit-str\n",
    "        df_day_mapping_idl_blid_after=df_day_mapping_IDL_BLid[df_day_mapping_IDL_BLid['date_up_to']>=date_file] #8-digit-str\n",
    "        \n",
    "        df_day_mapping_idl_blid_ago=df_day_mapping_idl_blid_ago.sort_values([\"Customer_Link\",'date_up_to'],ascending=[True,False]).drop_duplicates(\"Customer_Link\")\n",
    "        df_day_mapping_idl_blid_after=df_day_mapping_idl_blid_after.sort_values([\"Customer_Link\",'date_up_to'],ascending=[True,True]).drop_duplicates(\"Customer_Link\")\n",
    "        df_day_mapping_IDL_BLid=df_day_mapping_idl_blid_after.append(df_day_mapping_idl_blid_ago).drop_duplicates(\"Customer_Link\")\n",
    "        del df_day_mapping_IDL_BLid['date_up_to']\n",
    "        df=pd.merge(df,df_day_mapping_IDL_BLid,how=\"left\",on=\"Customer_Link\")\n",
    "        \n",
    "        #loop in above\n",
    "        df_month_act=df_month_act.append(df)\n",
    "        del df_month_act['Other Data'] \n",
    "        \n",
    "        # print(os.path.basename(file).split(\"utc_\")[1][:8],datetime.datetime.now())\n",
    "    print(df_month_act.shape)\n",
    "    logging.info(\"df_month_act.shape: \"+str(df_month_act.shape))\n",
    "\n",
    "    del df\n",
    "    \n",
    "    del df_day_mapping_uid_idl_ago\n",
    "    del df_day_mapping_uid_idl_after\n",
    "    \n",
    "    del df_day_mapping_idl_blid_ago\n",
    "    del df_day_mapping_idl_blid_after\n",
    "    \n",
    "    df_month_act_BLID=df_month_act[pd.notnull(df_month_act['customer_id_hashed'])]\n",
    "    df_month_act_GUID=df_month_act[pd.isnull(df_month_act['customer_id_hashed'])]\n",
    "    print(datetime.datetime.now(),month,df_month_act_BLID.shape,df_month_act_BLID.shape,np.round(df_month_act_BLID.shape[0]/df_month_act.shape[0],4))\n",
    "    logging.info(str(datetime.datetime.now())+\" month: \"+str(month))\n",
    "    logging.info(\"df_month_act_BLID.shape\"+str(df_month_act_BLID.shape))\n",
    "    logging.info(str(np.round(df_month_act_BLID.shape[0]/df_month_act.shape[0],4)))\n",
    "    '''\n",
    "    df_month_act_GUID=count_sessions(df_month_act_GUID,\"User ID\",df_previous_session_count_GUID)\n",
    "    df_month_act_GUID['activity_sequence']=df_month_act_GUID.groupby([\"User ID\",\"session_sequence\"]).cumcount()+1\n",
    "    df_month_act_GUID=df_month_act_GUID[['Event Time','date_utc','time_utc',\n",
    "                                 'User ID','Customer_Link','customer_id_hashed',\n",
    "                                 'Activity ID','url','search_term',\n",
    "                                'session_sequence','activity_sequence']]\n",
    "    df_previous_session_count_GUID=df_month_act_GUID[['User ID',\"session_sequence\"]].drop_duplicates().sort_values(\"session_sequence\",ascending=False).drop_duplicates(\"User ID\").append(df_previous_session_count_GUID).drop_duplicates(\"User ID\")\n",
    "    for col in df_month_act_GUID.columns.tolist():\n",
    "        df_month_act_GUID=df_month_act_GUID.rename(columns={col:col.replace(\" \",\"_\")})\n",
    "    df_month_act_GUID.to_csv(\"/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/actative_table_output/BL_act_table_Google_id_\"+str(month)+\".csv\",index=False)\n",
    "    print(datetime.datetime.now(),\"File wrote of df_month_act_GUID\")\n",
    "    logging.info(str(datetime.datetime.now())+\": File wrote of df_month_act_GUID\")\n",
    "    \n",
    "    df_month_act_GUID.to_sql(\"Pred_Activity_GU_id\",if_exists='append', con=BL_engine, index=False,chunksize=300000,\n",
    "                    dtype={\n",
    "                        'Event_Time':sqlalchemy.types.BigInteger(),\n",
    "                        'date_utc':sqlalchemy.types.Date(),\n",
    "                        'time_utc':sqlalchemy.types.Time(),\n",
    "                        'User_ID':sqlalchemy.types.VARCHAR(length=64),\n",
    "                        'Customer_Link':sqlalchemy.types.VARCHAR(length=64),\n",
    "                        'customer_id_hashed':sqlalchemy.types.VARCHAR(length=64),\n",
    "                        'Activity_ID':sqlalchemy.types.VARCHAR(length=16),\n",
    "                        'url':sqlalchemy.types.VARCHAR(length=2048),\n",
    "                        'search_term':sqlalchemy.types.VARCHAR(length=256),\n",
    "                        'session_sequence':sqlalchemy.types.INTEGER(),\n",
    "                        'activity_sequence':sqlalchemy.types.INTEGER()\n",
    "                    })\n",
    "    print(datetime.datetime.now(),\"File wrote to MySQL df_month_act_GUID\")\n",
    "    logging.info(str(datetime.datetime.now())+\": File wrote to MySQL df_month_act_GUID\")\n",
    "    '''\n",
    "\n",
    "    df_month_act_BLID=count_sessions(df_month_act_BLID,\"customer_id_hashed\",df_previous_session_count_BLID)\n",
    "    df_month_act_BLID['activity_sequence']=df_month_act_BLID.groupby([\"customer_id_hashed\",\"session_sequence\"]).cumcount()+1\n",
    "    df_month_act_BLID=df_month_act_BLID[['Event Time','date_utc','time_utc',\n",
    "                                     'User ID','Customer_Link','customer_id_hashed',\n",
    "                                     'Activity ID','url','search_term',\n",
    "                                    'session_sequence','activity_sequence']]\n",
    "    df_previous_session_count_BLID=df_month_act_BLID[['customer_id_hashed',\"session_sequence\"]].drop_duplicates().sort_values(\"session_sequence\",ascending=False).drop_duplicates(\"customer_id_hashed\").append(df_previous_session_count_BLID).drop_duplicates(\"customer_id_hashed\")\n",
    "    for col in df_month_act_BLID.columns.tolist():\n",
    "        df_month_act_BLID=df_month_act_BLID.rename(columns={col:col.replace(\" \",\"_\")})\n",
    "    df_month_act_BLID.to_csv(\"/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/save_dcm_lr_to_mysql/actative_table_output/BL_act_table_BL_id_\"+str(month)+\".csv\",index=False)\n",
    "    print(datetime.datetime.now(),\"File wrote of df_month_act_BLID\")\n",
    "    logging.info(str(datetime.datetime.now())+\": File wrote of df_month_act_BLID\")\n",
    "    df_month_act_BLID.to_sql(\"Pred_Activity_BL_id\",if_exists='append', con=BL_engine, index=False,chunksize=300000,\n",
    "                    dtype={\n",
    "                        'Event_Time':sqlalchemy.types.BigInteger(),\n",
    "                        'date_utc':sqlalchemy.types.Date(),\n",
    "                        'time_utc':sqlalchemy.types.Time(),\n",
    "                        'User_ID':sqlalchemy.types.VARCHAR(length=64),\n",
    "                        'Customer_Link':sqlalchemy.types.VARCHAR(length=64),\n",
    "                        'customer_id_hashed':sqlalchemy.types.VARCHAR(length=64),\n",
    "                        'Activity_ID':sqlalchemy.types.VARCHAR(length=16),\n",
    "                        'url':sqlalchemy.types.VARCHAR(length=2048),\n",
    "                        'search_term':sqlalchemy.types.VARCHAR(length=256),\n",
    "                        'session_sequence':sqlalchemy.types.INTEGER(),\n",
    "                        'activity_sequence':sqlalchemy.types.INTEGER()\n",
    "                    })\n",
    "    print(datetime.datetime.now(),\"File wrote to MySQL df_month_act_BLID\")\n",
    "    logging.info(str(datetime.datetime.now())+\": File wrote to MySQL df_month_act_BLID\")\n",
    "    \n",
    "    \n",
    "    print(datetime.datetime.now(),\"Done of the month: \",month)\n",
    "    logging.info(str(datetime.datetime.now())+\"Done of the month: \"+str(month))\n",
    "\n",
    "    del df_month_act\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
