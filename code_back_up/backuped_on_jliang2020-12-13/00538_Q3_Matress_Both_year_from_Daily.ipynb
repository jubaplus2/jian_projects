{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_1_after_201806=[x for x in list(recursive_file_gen(\"/home/jian/BigLots/2018_by_weeks/\")) if (\"aily\" in x) & (\".txt\" in x) ]\n",
    "folder_date=[datetime.datetime.strptime(x.split(\"/\")[len(x.split(\"/\"))-2].split(\"_\")[1],\"%Y-%m-%d\").date() for x in list_1_after_201806]\n",
    "df_1_after_201806=pd.DataFrame({\"date\":folder_date,\"path\":list_1_after_201806},index=[x for x in range(len(list_1_after_201806))])\n",
    "df_1_after_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "df_1_after_201806=df_1_after_201806.sort_values(\"date\").reset_index()\n",
    "del df_1_after_201806['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_2_before_201806=list(recursive_file_gen(\"/home/jian/BigLots/hist_daily_data/\"))\n",
    "folder_date=[datetime.datetime.strptime(x.split(\"/\")[len(x.split(\"/\"))-1].split(\"_\")[3].split(\".\")[0],\"%Y-%m-%d\").date() for x in list_2_before_201806]\n",
    "df_2_before_201806=pd.DataFrame({\"date\":folder_date,\"path\":list_2_before_201806},index=[x for x in range(len(list_2_before_201806))])\n",
    "df_2_before_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "df_2_before_201806=df_2_before_201806.sort_values('date').reset_index()\n",
    "del df_2_before_201806['index']\n",
    "df_2_before_201806['date'].apply(lambda x: x.weekday()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_2017_Q3=[datetime.date(2017,8,12)+datetime.timedelta(days=x*7) for x in range(13)]\n",
    "date_2018_Q3=[datetime.date(2018,8,11)+datetime.timedelta(days=x*7) for x in range(13)]\n",
    "\n",
    "df_1_after_201806_Q3=df_1_after_201806[df_1_after_201806['date'].isin(date_2018_Q3)]\n",
    "df_2_before_201806_Q3=df_2_before_201806[df_2_before_201806['date'].isin(date_2017_Q3)]\n",
    "df_all_Q3_txt=df_1_after_201806_Q3.append(df_2_before_201806_Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['61501', '61502', '61503', '61504', '61505']\n"
     ]
    }
   ],
   "source": [
    "mattress_class_ids=[str(x) for x in range(61501,61506)]\n",
    "print(mattress_class_ids)\n",
    "\n",
    "def func_week_end_date(x):\n",
    "    if x.weekday()==6:\n",
    "        y=x+datetime.timedelta(days=6)\n",
    "    else:\n",
    "        y=x+datetime.timedelta(days=5-x.weekday())\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2018-12-17 16:33:37.177675\n",
      "2 2018-12-17 16:36:19.277390\n",
      "3 2018-12-17 16:39:07.360461\n",
      "4 2018-12-17 16:41:54.763943\n",
      "5 2018-12-17 16:44:48.232750\n",
      "6 2018-12-17 16:47:32.338697\n",
      "7 2018-12-17 16:50:04.205717\n",
      "8 2018-12-17 16:53:16.461945\n",
      "9 2018-12-17 16:56:54.842336\n",
      "10 2018-12-17 16:59:28.589125\n",
      "11 2018-12-17 17:02:05.889094\n",
      "12 2018-12-17 17:04:55.715139\n",
      "13 2018-12-17 17:07:51.950017\n",
      "14 2018-12-17 17:10:54.385906\n",
      "15 2018-12-17 17:13:56.907480\n",
      "16 2018-12-17 17:16:58.143463\n",
      "17 2018-12-17 17:20:04.275334\n",
      "18 2018-12-17 17:23:35.388383\n",
      "19 2018-12-17 17:26:33.144070\n",
      "20 2018-12-17 17:29:28.883015\n",
      "21 2018-12-17 17:33:25.065118\n",
      "22 2018-12-17 17:37:34.478112\n",
      "23 2018-12-17 17:40:31.287971\n",
      "24 2018-12-17 17:43:15.705396\n",
      "25 2018-12-17 17:46:05.934967\n",
      "26 2018-12-17 17:49:18.043142\n"
     ]
    }
   ],
   "source": [
    "agg_mattress_all_stores=pd.DataFrame()\n",
    "count_i=0\n",
    "for file_path in df_all_Q3_txt['path'].unique().tolist():\n",
    "    df=pd.read_table(file_path,dtype=str,sep=\"|\")\n",
    "    \n",
    "    df['transaction_dt']=df['transaction_dt'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "    week_end_date=df['transaction_dt'].max()\n",
    "    \n",
    "    df['rewards_label']=np.where(pd.isnull(df['customer_id_hashed']),\"Non_Rewards\",\"Rewards\")\n",
    "    df['subclass_transaction_amt']=df['subclass_transaction_amt'].astype(float)\n",
    "    df_mattress=df[df['class_code_id'].isin(mattress_class_ids)]\n",
    "    df_mattress['week_end_date']=df_mattress['transaction_dt'].apply(lambda x: func_week_end_date(x))\n",
    "    if df_mattress['week_end_date'].unique().tolist()==[week_end_date]:\n",
    "        df_mattress_sales=df_mattress.groupby(['location_id','rewards_label','week_end_date'])['subclass_transaction_amt'].sum().to_frame().reset_index()\n",
    "        \n",
    "        df_mattress_sales_rewards=df_mattress_sales[df_mattress_sales['rewards_label']==\"Rewards\"]\n",
    "        df_mattress_sales_rewards=df_mattress_sales_rewards.rename(columns={\"subclass_transaction_amt\":\"rewards_mattress_sales\"})\n",
    "        del df_mattress_sales_rewards['rewards_label']\n",
    "        df_mattress_sales_Nonrewards=df_mattress_sales[df_mattress_sales['rewards_label']==\"Non_Rewards\"]\n",
    "        df_mattress_sales_Nonrewards=df_mattress_sales_Nonrewards.rename(columns={\"subclass_transaction_amt\":\"Non_rewards_mattress_sales\"})\n",
    "        del df_mattress_sales_Nonrewards['rewards_label']\n",
    "        df_output=pd.merge(df_mattress_sales_rewards,df_mattress_sales_Nonrewards,on=['location_id','week_end_date'],how=\"outer\")\n",
    "        df_output=df_output.fillna(0)\n",
    "        # \n",
    "        df_mattress=df_mattress[df_mattress['subclass_transaction_amt']>=0]\n",
    "        df_mattress_trans=df_mattress.groupby(['location_id','rewards_label','week_end_date'])['subclass_transaction_amt'].count().to_frame().reset_index()\n",
    "        \n",
    "        df_mattress_trans_rewards=df_mattress_trans[df_mattress_trans['rewards_label']==\"Rewards\"]\n",
    "        df_mattress_trans_rewards=df_mattress_trans_rewards.rename(columns={\"subclass_transaction_amt\":\"rewards_mattress_trans\"})\n",
    "        del df_mattress_trans_rewards['rewards_label']\n",
    "        df_mattress_trans_Nonrewards=df_mattress_trans[df_mattress_trans['rewards_label']==\"Non_Rewards\"]\n",
    "        df_mattress_trans_Nonrewards=df_mattress_trans_Nonrewards.rename(columns={\"subclass_transaction_amt\":\"Non_rewards_mattress_trans\"})\n",
    "        del df_mattress_trans_Nonrewards['rewards_label']\n",
    "        df_output=pd.merge(df_mattress_sales_rewards,df_mattress_sales_Nonrewards,on=['location_id','week_end_date'],how=\"outer\")\n",
    "        df_output=pd.merge(df_output,df_mattress_trans_rewards,on=['location_id','week_end_date'],how=\"outer\")\n",
    "        df_output=pd.merge(df_output,df_mattress_trans_Nonrewards,on=['location_id','week_end_date'],how=\"outer\")\n",
    "        \n",
    "        df_output=df_output.fillna(0)\n",
    "        agg_mattress_all_stores=agg_mattress_all_stores.append(df_output)\n",
    "        count_i+=1\n",
    "        print(count_i,datetime.datetime.now())\n",
    "    else:\n",
    "        print(\"Date Error: \",week_end_date)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_mattress_all_stores.to_csv('/home/jian/Projects/Big_Lots/Analysis/2018_Q3/Mattress_Since_Aug/mattress_5_class_codes_data_JL_'+str(datetime.datetime.now().date())+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
