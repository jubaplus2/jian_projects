{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# No use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newspaper FSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FSI_file_list=glob.glob(\"/home/jian/Projects/Big_Lots/TMR/Circulation/Newspaper/circ_2018Q4/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of cost:  743012.00449 2018-11-03\n",
      "Sum of cost:  756239.16165 2018-11-10\n",
      "Sum of cost:  2038721.72017 2018-11-22\n",
      "Sum of cost:  1138034.71377 2018-11-24\n",
      "Sum of cost:  1835451.82146 2018-11-15\n",
      "Sum of cost:  995251.59279 2018-12-01\n",
      "Sum of cost:  987318.02921 2018-12-08\n",
      "Sum of cost:  997837.78698 2018-12-16\n",
      "Sum of cost:  607041.47692 2019-01-05\n"
     ]
    }
   ],
   "source": [
    "newspaper=pd.DataFrame()\n",
    "for file in FSI_file_list:\n",
    "    month=file.split(\"/\")[9].split(\" \")[0]\n",
    "    day=file.split(\"/\")[9].split(\" \")[1]\n",
    "    year=file.split(\"/\")[9].split(\" \")[2]\n",
    "    if month==\"Feb\":\n",
    "        month=\"February\"\n",
    "    if month==\"Nov\":\n",
    "        month=\"November\"\n",
    "    date_str=month+\" \"+day+\" \"+year\n",
    "    try:\n",
    "        date_in_file=datetime.datetime.strptime(date_str,\"%B %d %Y\").date()\n",
    "    except:\n",
    "        print(\"file_name_error: \"+date_str)\n",
    "    if date_in_file>=datetime.date(2016,10,2):\n",
    "        df=pd.read_excel(file,dtype=str)\n",
    "        df.columns=[x.upper() for x in df.columns.tolist()]\n",
    "        \n",
    "        try:\n",
    "            df=df[['DMA','CONFIRMED CIRCULATION','MEDIA COST','PRINT COST']]\n",
    "        except:\n",
    "            print(\"columns_name_error: \"+date_str)\n",
    "        df=df[df['DMA']!='nan']\n",
    "        \n",
    "        df['CONFIRMED CIRCULATION']=df['CONFIRMED CIRCULATION'].astype(float)\n",
    "        df['MEDIA COST']=df['MEDIA COST'].astype(float)\n",
    "        df['PRINT COST']=df['PRINT COST'].astype(float)\n",
    "        df['cost']=df['MEDIA COST']+df['PRINT COST']\n",
    "        del df['MEDIA COST']\n",
    "        del df['PRINT COST']\n",
    "        \n",
    "        df=df.groupby(['DMA'])['CONFIRMED CIRCULATION','cost'].sum().reset_index()\n",
    "        \n",
    "        \n",
    "        if date_in_file.weekday()==6:\n",
    "            week_start_date=date_in_file\n",
    "            week_end_saturday=date_in_file+datetime.timedelta(days=6)\n",
    "        else:\n",
    "            week_start_date=date_in_file-datetime.timedelta(days= date_in_file.weekday()+1)\n",
    "            week_end_saturday=week_start_date+datetime.timedelta(days=6)\n",
    "        df['week_start_date']=week_start_date\n",
    "        df['week_end_date']=week_end_saturday\n",
    "        df['file_date']=date_in_file\n",
    "        newspaper=newspaper.append(df)\n",
    "        print(\"Sum of cost: \",str(df['cost'].sum()),date_in_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newspaper_DMA=newspaper.copy()\n",
    "del newspaper_DMA['file_date']\n",
    "newspaper_DMA['media']='Circulation'\n",
    "newspaper_DMA['submedia']='FSI+Instore'\n",
    "newspaper_DMA['placement']=\"xx\"\n",
    "newspaper_DMA=newspaper_DMA.rename(columns={\"CONFIRMED CIRCULATION\":\"impression\"})\n",
    "newspaper_DMA=newspaper_DMA[['week_start_date','week_end_date','DMA','media','submedia','placement','impression','cost']]\n",
    "\n",
    "\n",
    "newspaper_national=newspaper.groupby(['week_start_date','week_end_date'])['CONFIRMED CIRCULATION','cost'].sum().reset_index()\n",
    "newspaper_national=newspaper_national.rename(columns={\"CONFIRMED CIRCULATION\":\"impression\"})\n",
    "newspaper_national['media']='Circulation'\n",
    "newspaper_national['submedia']='FSI+Instore'\n",
    "newspaper_national['placement']=\"xx\"\n",
    "newspaper_national=newspaper_national[['week_start_date','week_end_date','media','submedia','placement','impression','cost']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2018, 10, 28), datetime.date(2018, 11, 4),\n",
       "       datetime.date(2018, 11, 11), datetime.date(2018, 11, 18),\n",
       "       datetime.date(2018, 11, 25), datetime.date(2018, 12, 2),\n",
       "       datetime.date(2018, 12, 16), datetime.date(2018, 12, 30)], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspaper_national['week_start_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10098908.307440002"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newspaper_national['cost'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valassis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Valassis_file_list=glob.glob(\"/home/jian/Projects/Big_Lots/TMR/Circulation/Valassis/circ_2018Q4/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valassis=pd.DataFrame()\n",
    "for file in Valassis_file_list:\n",
    "    file_name=file.split(\"/\")[9]\n",
    "    if file_name[3]==\"_\":\n",
    "        file_date_name=file_name[9:]\n",
    "        month=file_date_name.split(\" \")[0]\n",
    "        day=file_date_name.split(\" \")[1]\n",
    "        year=file_date_name.split(\" \")[2]\n",
    "        if len(year)==2:\n",
    "            year=\"20\"+year\n",
    "        if ((len(month)==2) & (month[0]=='0')):\n",
    "            month=month[1]\n",
    "        if ((len(day)==2) & (day[0]=='0')):\n",
    "            day=day[1]\n",
    "        date_in_file=datetime.date(int(year),int(month),int(day))\n",
    "    elif file_name[3]==\" \":\n",
    "        file_date_name=file_name[9:].split(\" \")[0]\n",
    "        month=file_date_name.split(\".\")[0]\n",
    "        day=file_date_name.split(\".\")[1]\n",
    "        year=file_date_name.split(\".\")[2]\n",
    "        if len(year)==2:\n",
    "            year=\"20\"+year\n",
    "        if ((len(month)==2) & (month[0]=='0')):\n",
    "            month=month[1]\n",
    "        if ((len(day)==2) & (day[0]=='0')):\n",
    "            day=day[1]\n",
    "        date_in_file=datetime.date(int(year),int(month),int(day))\n",
    "    else:\n",
    "        print(\"file date detect failed: \"+str(file))\n",
    "    if date_in_file>=datetime.date(2016,10,2):\n",
    "        df=pd.read_excel(file,dtype=str)\n",
    "        start_row=df[df.iloc[:,0].apply(lambda x: x.lower())==\"name\"].reset_index()['index'].tolist()[0]\n",
    "        df=pd.read_excel(file,dtype=str,skiprows=(start_row+1))\n",
    "        df.columns=[x.lower() for x in df.columns.tolist()]\n",
    "        df=df[df['description']!='nan']\n",
    "        if \"shared count\" in df.columns.tolist():\n",
    "            df=df[['description','shared count']].rename(columns={\"description\":\"DMA\",\"shared count\":\"impression\"})\n",
    "            df['date_in_file']=date_in_file\n",
    "            df['impression']=df['impression'].astype(float)\n",
    "            df=df.groupby(['date_in_file','DMA'])['impression'].sum().to_frame().reset_index()\n",
    "            \n",
    "            if date_in_file.weekday()==6:\n",
    "                week_start_date=date_in_file\n",
    "                week_end_saturday=date_in_file+datetime.timedelta(days=6)\n",
    "            else:\n",
    "                week_start_date=date_in_file-datetime.timedelta(days= date_in_file.weekday()+1)\n",
    "                week_end_saturday=week_start_date+datetime.timedelta(days=6)\n",
    "            df['week_start_date']=week_start_date\n",
    "            df['week_end_date']=week_end_saturday\n",
    "            valassis=valassis.append(df)\n",
    "            \n",
    "        elif \"shared counts\" in df.columns.tolist():\n",
    "            df=df[['description','shared counts']].rename(columns={\"description\":\"DMA\",\"shared counts\":\"impression\"})\n",
    "            df['date_in_file']=date_in_file\n",
    "            df['impression']=df['impression'].astype(float)\n",
    "            df=df.groupby(['date_in_file','DMA'])['impression'].sum().to_frame().reset_index()\n",
    "\n",
    "            if date_in_file.weekday()==6:\n",
    "                week_start_date=date_in_file\n",
    "                week_end_saturday=date_in_file+datetime.timedelta(days=6)\n",
    "            else:\n",
    "                week_start_date=date_in_file-datetime.timedelta(days= date_in_file.weekday()+1)\n",
    "                week_end_saturday=week_start_date+datetime.timedelta(days=6)\n",
    "            df['week_start_date']=week_start_date\n",
    "            df['week_end_date']=week_end_saturday\n",
    "            valassis=valassis.append(df)\n",
    "        else:\n",
    "            print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valassis['cost']=0\n",
    "valassis_DMA=valassis.copy()\n",
    "del valassis_DMA['date_in_file']\n",
    "valassis_DMA['media']='Circulation'\n",
    "valassis_DMA['submedia']='Valassis'\n",
    "valassis_DMA['placement']=\"xx\"\n",
    "\n",
    "valassis_DMA=valassis_DMA[['week_start_date','week_end_date','DMA','media','submedia','placement','impression','cost']]\n",
    "\n",
    "\n",
    "valassis_national=valassis.groupby(['week_start_date','week_end_date'])['impression','cost'].sum().reset_index()\n",
    "valassis_national['media']='Circulation'\n",
    "valassis_national['submedia']='Valassis'\n",
    "valassis_national['placement']=\"xx\"\n",
    "valassis_national=valassis_national[['week_start_date','week_end_date','media','submedia','placement','impression','cost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10098908.307440002"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valassis_national['cost'].sum()+newspaper_national['cost'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175431250.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valassis_national['impression'].sum()+newspaper_national['impression'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
