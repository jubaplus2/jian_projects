{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "from haversine import haversine\n",
    "\n",
    "import gc\n",
    "import sqlalchemy\n",
    "import json\n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_store_list=\"/home/jian/BigLots/static_files/Store_list/\"\n",
    "folder_email_unsubscription=\"/home/jian/BigLots/unsubscribe/\"\n",
    "\n",
    "path_json_zip_centers=\"/home/jian/Docs/Geo_mapping/updated_zip_centers_JL_2019-05-23.json\"\n",
    "output_folder=\"./output_%s/\"%(datetime.datetime.now().date())\n",
    "path_excel_ta=\"/home/jian/Projects/Big_Lots/New_TA/package_to_run_TA_every_quarter/output_2020-07-22/BL_final_TA_updated_JL_2020-07-22.xlsx\"\n",
    "dict_update_location_latlng={}\n",
    "path_SOTF_dom=\"/home/jian/BigLots/static_files/store_list_from_Dom/Store List Report 07.10.20 425PM.xlsx\"\n",
    "try:\n",
    "    os.stat(output_folder)\n",
    "except:\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type in lat and lng: %d, %d\n",
      "4525 N ORACLE RD, TUCSON, AZ, 85705-1637, US\n",
      "32.2885745,-110.9797533\n",
      "260 REMOUNT RD, FRONT ROYAL, VA, 22630-2145, US\n",
      "38.9093159,-78.1832176\n",
      "dict_update_location_latlng: \n",
      " {'4715': {'lat': 32.2885745, 'lng': -110.9797533}, '5416': {'lat': 38.9093159, 'lng': -78.1832176}}\n"
     ]
    }
   ],
   "source": [
    "zip_centers=json.load(open(path_json_zip_centers,\"r\"))\n",
    "\n",
    "latest_store_list=glob.glob(folder_store_list+\"*.txt\")\n",
    "latest_store_list=sorted(latest_store_list,key=lambda x: os.stat(x).st_mtime)\n",
    "latest_store_list=latest_store_list[-1]\n",
    "\n",
    "def revise_store_lat_lng(path_store_list_input=latest_store_list):\n",
    "    df=pd.read_csv(path_store_list_input,sep=\"|\",dtype=str)\n",
    "    df['latitude_meas']=df['latitude_meas'].astype(float)\n",
    "    df=df[~df['location_id'].isin(['145','6990'])]\n",
    "    df=df[df['latitude_meas']==0]\n",
    "    print(\"type in lat and lng: %d, %d\")\n",
    "    for i,row in df.iterrows():\n",
    "        store_num=row['location_id']\n",
    "        address=row['address_line_1']+\", \"+row['city_nm']+\", \"+row['state_nm']+\", \"+row['zip_cd']+\", US\"\n",
    "        print(address)\n",
    "        \n",
    "        google_lat_long=str(input())\n",
    "        lat=eval(google_lat_long)[0]\n",
    "        lng=eval(google_lat_long)[1]\n",
    "        dict_update_location_latlng.update({store_num:{\"lat\":lat,\"lng\":lng}})\n",
    "    print(\"dict_update_location_latlng: \\n %s\"%dict_update_location_latlng)\n",
    "        \n",
    "revise_store_lat_lng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py:166: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "lastdate_date = pd.read_sql(\"select max(transaction_dt) from Pred_POS_Department;\",con=BL_engine).iloc[0,0]\n",
    "Beginning_12_months_ago = str(lastdate_date-datetime.timedelta(days=52*7-1)) # Sunday\n",
    "Beginning_18_months_ago=str(lastdate_date-datetime.timedelta(days=52*7*1.5-1)) # Sunday\n",
    "Beginning_48_months_ago=str(lastdate_date-datetime.timedelta(days=52*7*4-1)) # Sunday\n",
    "\n",
    "folder_write='/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2020Q3/output_%s/'%str(datetime.datetime.now().date())\n",
    "try:\n",
    "    os.stat(folder_write)\n",
    "except:\n",
    "    os.mkdir(folder_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lastdate_date: 2020-07-18\n",
      "Active Start on: 2019-07-21\n",
      "Lapsed & Store_allocation Start on: 2019-01-20\n",
      "Lapsed 19-48 Start on: 2016-07-24\n"
     ]
    }
   ],
   "source": [
    "lastdate_str=str(lastdate_date)\n",
    "print(\"lastdate_date: %s\"%lastdate_str)\n",
    "print(\"Active Start on: %s\"%Beginning_12_months_ago) #>=\n",
    "print(\"Lapsed & Store_allocation Start on: %s\"%Beginning_18_months_ago) #>=\n",
    "print(\"Lapsed 19-48 Start on: %s\"%Beginning_48_months_ago) #>="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'2019-01-20'\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_sql_Beginning_18_months_ago=\"'\"+Beginning_18_months_ago+\"'\"\n",
    "str_sql_Beginning_18_months_ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfm_query: \n",
      "select customer_id_hashed, max(transaction_dt) as max_trans_date, sum(sales) as sales, count(distinct trans_order_since_18Q1) as transactions from Pred_POS_Department where transaction_dt>='2019-01-20' group by customer_id_hashed;\n"
     ]
    }
   ],
   "source": [
    "rfm_query=\"select customer_id_hashed, max(transaction_dt) as max_trans_date, sum(sales) as sales, count(distinct trans_order_since_18Q1) as transactions \\\n",
    "from Pred_POS_Department \\\n",
    "where transaction_dt>=%s \\\n",
    "group by customer_id_hashed;\"%str_sql_Beginning_18_months_ago\n",
    "print(\"rfm_query: \\n\"+rfm_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query started:  2020-07-23 00:33:24.411358\n",
      "query done:  2020-07-23 03:27:14.327466\n"
     ]
    }
   ],
   "source": [
    "print(\"query started: \",datetime.datetime.now())\n",
    "dftotal=pd.read_sql(rfm_query,con=BL_engine)\n",
    "dftotal=dftotal[pd.notnull(dftotal['customer_id_hashed'])]\n",
    "print(\"query done: \",datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal.to_csv(folder_write + 'dftotal.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal=pd.read_csv(folder_write + 'dftotal.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal['max_trans_date']=pd.to_datetime(dftotal['max_trans_date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal['recency']=lastdate_date - dftotal['max_trans_date']\n",
    "dftotal['recency']=dftotal['recency'].apply(lambda x:x.days)\n",
    "dftotal['recency']=np.ceil((dftotal['recency']+1)/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The blow is corrected, due to the ascending & decending for each KPI. The higher the better, or the lower the better\n",
    "\n",
    "dftotal=dftotal.sort_values(['transactions','recency','sales'],ascending=[0,1,0])\n",
    "dftotal.reset_index(drop=True, inplace=True)\n",
    "dftotal.reset_index(inplace=True)\n",
    "dftotal=dftotal.rename(columns={'index':'Transindex'})\n",
    "\n",
    "dftotal=dftotal.sort_values(['sales','recency','transactions'],ascending=[0,1,0])\n",
    "dftotal.reset_index(drop=True, inplace=True)\n",
    "dftotal.reset_index(inplace=True)\n",
    "dftotal=dftotal.rename(columns={'index':'Amtindex'})\n",
    "\n",
    "dftotal=dftotal.sort_values(['recency','transactions','sales'],ascending=[1,0,0])\n",
    "dftotal.reset_index(drop=True, inplace=True)\n",
    "dftotal.reset_index(inplace=True)\n",
    "dftotal=dftotal.rename(columns={'index':'recencyindex'})\n",
    "\n",
    "c_ids=len(dftotal.index)\n",
    "\n",
    "c_ids=np.ceil(c_ids/5.0)\n",
    "\n",
    "dftotal['Transindex']=np.ceil((dftotal['Transindex']+1)/c_ids)\n",
    "dftotal['Amtindex']=np.ceil((dftotal['Amtindex']+1)/c_ids)\n",
    "dftotal['recencyindex']=np.ceil((dftotal['recencyindex']+1)/c_ids)\n",
    "\n",
    "dftotal['RFM']=dftotal['recencyindex']*100 + dftotal['Transindex']*10 + dftotal['Amtindex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal.to_csv(folder_write+\"dftotal_with_index_all_EmailNotMergedYet.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-20 2020-07-18\n"
     ]
    }
   ],
   "source": [
    "print(dftotal['max_trans_date'].min(),dftotal['max_trans_date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-23 10:39:04.803955\n",
      "dfiddetail.shape (37118435, 3)\n",
      "dfiddetail['customer_id_hashed'].nunique() 37118435\n",
      "dfiddetail['email_address_hash'].nunique() 37109259\n",
      "2020-07-23 11:36:51.171764\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "dfiddetail=pd.read_sql('select customer_id_hashed,email_address_hash,customer_zip_code from BL_Rewards_Master order by sign_up_date desc',con=BL_engine)\n",
    "dfiddetail=dfiddetail.drop_duplicates(\"customer_id_hashed\")\n",
    "print(\"dfiddetail.shape \"+str(dfiddetail.shape))\n",
    "print(\"dfiddetail['customer_id_hashed'].nunique() \"+str(dfiddetail['customer_id_hashed'].nunique()))\n",
    "print(\"dfiddetail['email_address_hash'].nunique() \"+str(dfiddetail['email_address_hash'].nunique()))\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491 491\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allocated_store</th>\n",
       "      <th>Store_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SOTF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49</td>\n",
       "      <td>SOTF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  allocated_store Store_Type\n",
       "0               1       SOTF\n",
       "7              49       SOTF"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_type=pd.ExcelFile(path_SOTF_dom)\n",
    "df_store_type=df_store_type.parse(\"Store List\",dtype=str)\n",
    "df_store_type=df_store_type[[\"Store\",'SOTF']]\n",
    "df_store_type=df_store_type[df_store_type['SOTF'].str.lower()==\"yes\"]\n",
    "df_store_type=df_store_type[df_store_type['Store']!=\"TBD\"]\n",
    "print(len(df_store_type),df_store_type['Store'].nunique())\n",
    "df_store_type=df_store_type.rename(columns={\"Store\":\"allocated_store\",\"SOTF\":\"Store_Type\"})\n",
    "df_store_type['Store_Type']=\"SOTF\"\n",
    "df_store_type.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258899, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_unique_zip_cd=dfiddetail[['customer_zip_code']].drop_duplicates()\n",
    "customer_unique_zip_cd=customer_unique_zip_cd[~pd.isnull(customer_unique_zip_cd['customer_zip_code'])]\n",
    "customer_unique_zip_cd['cleaned_zip_cd']=customer_unique_zip_cd['customer_zip_code'].apply(lambda x: x.split(\"-\")[0][:5].zfill(5))\n",
    "customer_unique_zip_cd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73449, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_zip5=customer_unique_zip_cd[['cleaned_zip_cd']].drop_duplicates()\n",
    "df_unique_zip5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1402, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_list=pd.read_table(latest_store_list,\n",
    "                        dtype=str,sep=\"|\")\n",
    "store_list=store_list[['location_id','latitude_meas','longitude_meas']]\n",
    "store_list=store_list[store_list['location_id']!=\"6990\"]\n",
    "store_list=store_list[store_list['location_id']!=\"145\"]\n",
    "store_list['latitude_meas']=store_list['latitude_meas'].astype(float)\n",
    "store_list['longitude_meas']=store_list['longitude_meas'].astype(float)\n",
    "store_list['store_coor']=store_list[['latitude_meas','longitude_meas']].values.tolist()\n",
    "dict_store_lat=store_list.set_index(\"location_id\").to_dict()['store_coor']\n",
    "\n",
    "store_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocated_closet_store_to_zip(zip_input):\n",
    "    try:\n",
    "        zip_c=zip_centers[zip_input]\n",
    "    except:\n",
    "        return np.nan\n",
    "    min_dist=np.inf\n",
    "    for store,v in dict_store_lat.items():\n",
    "        dist=haversine(zip_c,v,unit=\"mi\")\n",
    "        if dist<min_dist:\n",
    "            min_dist=dist\n",
    "            closet_store=store\n",
    "    return closet_store\n",
    "\n",
    "df_unique_zip5['closet_store']=df_unique_zip5['cleaned_zip_cd'].apply(lambda x: allocated_closet_store_to_zip(x))\n",
    "customer_unique_zip_cd=pd.merge(customer_unique_zip_cd,df_unique_zip5,on=\"cleaned_zip_cd\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37118435, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8615"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfiddetail=pd.merge(dfiddetail,customer_unique_zip_cd,on=\"customer_zip_code\",how=\"left\")\n",
    "print(dfiddetail.shape)\n",
    "del df_unique_zip5\n",
    "del customer_unique_zip_cd\n",
    "del dfiddetail['customer_zip_code']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiddetail.to_csv(output_folder+\"dfiddetail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores of top sales\n",
    "query_top_store_per_id=\"select customer_id_hashed, location_id, count(distinct trans_order_since_18Q1) as trans, sum(sales) as sales \\\n",
    "from Pred_POS_Department \\\n",
    "where transaction_dt>=%s \\\n",
    "group by customer_id_hashed, location_id;\"%str_sql_Beginning_18_months_ago\n",
    "\n",
    "df_top_store_per_id=pd.read_sql(query_top_store_per_id,con=BL_engine)\n",
    "df_top_store_per_id=df_top_store_per_id.sort_values([\"customer_id_hashed\",\"trans\",\"sales\"],ascending=[True,False,False])\n",
    "df_top_store_per_id=df_top_store_per_id.drop_duplicates(\"customer_id_hashed\")\n",
    "del df_top_store_per_id['trans']\n",
    "del df_top_store_per_id['sales']\n",
    "gc.collect()\n",
    "df_top_store_per_id.columns=['customer_id_hashed','top_sales_store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-23 14:02:18.834640\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_store_per_id.to_csv(output_folder+'df_top_store_per_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>top_sales_store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>000000ebcf6c6a2f4302291cc9babb0760208fc683b3b5...</td>\n",
       "      <td>1606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>00000135f48c68690ad3d5fc9ada41bb5cd687452007e8...</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     customer_id_hashed  top_sales_store\n",
       "1467  000000ebcf6c6a2f4302291cc9babb0760208fc683b3b5...             1606\n",
       "1468  00000135f48c68690ad3d5fc9ada41bb5cd687452007e8...              563"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_store_per_id.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>cleaned_zip_cd</th>\n",
       "      <th>closet_store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6eda8691dfa43b24667d029fd49f53573d71d5ee73f5f2...</td>\n",
       "      <td>eb198f52d4f3700c0d89055afb85c451e565e34bbb4104...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>598821b25589bbb82103c4fb6cdbe81b82945ece95afbc...</td>\n",
       "      <td>b52ebdabf65ff5da91156e03016764ec83edab5573e5d8...</td>\n",
       "      <td>45330</td>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed  \\\n",
       "0  6eda8691dfa43b24667d029fd49f53573d71d5ee73f5f2...   \n",
       "1  598821b25589bbb82103c4fb6cdbe81b82945ece95afbc...   \n",
       "\n",
       "                                  email_address_hash cleaned_zip_cd  \\\n",
       "0  eb198f52d4f3700c0d89055afb85c451e565e34bbb4104...            NaN   \n",
       "1  b52ebdabf65ff5da91156e03016764ec83edab5573e5d8...          45330   \n",
       "\n",
       "  closet_store  \n",
       "0          NaN  \n",
       "1         1118  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfiddetail.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recencyindex</th>\n",
       "      <th>Amtindex</th>\n",
       "      <th>Transindex</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>max_trans_date</th>\n",
       "      <th>sales</th>\n",
       "      <th>transactions</th>\n",
       "      <th>recency</th>\n",
       "      <th>RFM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>114265.03</td>\n",
       "      <td>7369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>152169.41</td>\n",
       "      <td>6575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recencyindex  Amtindex  Transindex  \\\n",
       "0           1.0       1.0         1.0   \n",
       "1           1.0       1.0         1.0   \n",
       "\n",
       "                                  customer_id_hashed max_trans_date  \\\n",
       "0  b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...     2020-07-15   \n",
       "1  cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...     2020-07-06   \n",
       "\n",
       "       sales  transactions  recency    RFM  \n",
       "0  114265.03          7369      1.0  111.0  \n",
       "1  152169.41          6575      1.0  111.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23101395, 9) 23101395\n",
      "(37118435, 4) 37118435\n",
      "(23101396, 2) 23101395\n"
     ]
    }
   ],
   "source": [
    "print(dftotal.shape,dftotal['customer_id_hashed'].nunique())\n",
    "print(dfiddetail.shape,dfiddetail['customer_id_hashed'].nunique())\n",
    "print(df_top_store_per_id.shape,df_top_store_per_id['customer_id_hashed'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dftotal['recencyindex']\n",
    "del dftotal['Amtindex']\n",
    "del dftotal['Transindex']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal=pd.merge(dftotal,dfiddetail,on=\"customer_id_hashed\",how=\"left\")\n",
    "del dfiddetail\n",
    "gc.collect()\n",
    "dftotal=pd.merge(dftotal,df_top_store_per_id,on=\"customer_id_hashed\",how=\"left\")\n",
    "del df_top_store_per_id\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23101395, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>max_trans_date</th>\n",
       "      <th>sales</th>\n",
       "      <th>transactions</th>\n",
       "      <th>recency</th>\n",
       "      <th>RFM</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>cleaned_zip_cd</th>\n",
       "      <th>closet_store</th>\n",
       "      <th>top_sales_store</th>\n",
       "      <th>allocated_store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>114265.03</td>\n",
       "      <td>7369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...</td>\n",
       "      <td>28607</td>\n",
       "      <td>1684</td>\n",
       "      <td>1684</td>\n",
       "      <td>1684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>152169.41</td>\n",
       "      <td>6575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>04e179d3e08f65382d320eaff61a2eb3edc874ea355003...</td>\n",
       "      <td>11726</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed max_trans_date  \\\n",
       "0  b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...     2020-07-15   \n",
       "1  cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...     2020-07-06   \n",
       "\n",
       "       sales  transactions  recency    RFM  \\\n",
       "0  114265.03          7369      1.0  111.0   \n",
       "1  152169.41          6575      1.0  111.0   \n",
       "\n",
       "                                  email_address_hash cleaned_zip_cd  \\\n",
       "0  4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...          28607   \n",
       "1  04e179d3e08f65382d320eaff61a2eb3edc874ea355003...          11726   \n",
       "\n",
       "  closet_store  top_sales_store allocated_store  \n",
       "0         1684             1684            1684  \n",
       "1         1753             1753            1753  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal['allocated_store']=np.where(pd.notnull(dftotal['top_sales_store']),\n",
    "                                    dftotal['top_sales_store'],\n",
    "                                    dftotal['closet_store'])\n",
    "print(dftotal.shape)\n",
    "dftotal.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23101395, 11)\n",
      "(20917437, 11)\n"
     ]
    }
   ],
   "source": [
    "# Remove no email ids\n",
    "print(dftotal.shape)\n",
    "dftotal=dftotal[pd.notnull(dftotal['email_address_hash'])]\n",
    "print(dftotal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal['allocated_store']=dftotal['allocated_store'].astype(int)\n",
    "df_store_type['allocated_store']=df_store_type['allocated_store'].astype(int)\n",
    "dftotal=pd.merge(dftotal,df_store_type,on=\"allocated_store\",how=\"left\")\n",
    "dftotal['Store_Type']=dftotal['Store_Type'].fillna(\"Legacy\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trans_P' 'trans_S' 'zips_10']\n",
      "[5]\n",
      "['P' 'S']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_type</th>\n",
       "      <th>cleaned_zip_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>76248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>23185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>23168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>23608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>23607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_type cleaned_zip_cd\n",
       "0        P          76248\n",
       "1        P          23185\n",
       "2        P          23168\n",
       "3        P          23608\n",
       "4        P          23607"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel=pd.ExcelFile(path_excel_ta)\n",
    "df_zip_label=excel.parse(\"unique_zips_full_footprint\",dtype=str)\n",
    "print(df_zip_label['zip_type'].unique())\n",
    "print(df_zip_label['zip_cd'].apply(len).unique())\n",
    "df_zip_label=df_zip_label.rename(columns={\"zip_cd\":\"cleaned_zip_cd\"})\n",
    "df_zip_label['zip_type']=df_zip_label['zip_type'].replace(\"zips_10\",\"trans_P\")\n",
    "df_zip_label['zip_type']=df_zip_label['zip_type'].apply(lambda x: x.split(\"_\")[1])\n",
    "del excel\n",
    "gc.collect()\n",
    "print(df_zip_label['zip_type'].unique())\n",
    "\n",
    "df_zip_label.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20917437, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>max_trans_date</th>\n",
       "      <th>sales</th>\n",
       "      <th>transactions</th>\n",
       "      <th>recency</th>\n",
       "      <th>RFM</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>cleaned_zip_cd</th>\n",
       "      <th>closet_store</th>\n",
       "      <th>top_sales_store</th>\n",
       "      <th>allocated_store</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>zip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>114265.03</td>\n",
       "      <td>7369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...</td>\n",
       "      <td>28607</td>\n",
       "      <td>1684</td>\n",
       "      <td>1684</td>\n",
       "      <td>1684</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>152169.41</td>\n",
       "      <td>6575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>04e179d3e08f65382d320eaff61a2eb3edc874ea355003...</td>\n",
       "      <td>11726</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>SOTF</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02cdd41af5ee82b39607416b74290152b00183fbce3068...</td>\n",
       "      <td>2020-07-18</td>\n",
       "      <td>179698.84</td>\n",
       "      <td>6110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>295e2ee597ca9fce3fa6fd8abbd947a93bb4eb4732e6e2...</td>\n",
       "      <td>14075</td>\n",
       "      <td>1839</td>\n",
       "      <td>1839</td>\n",
       "      <td>1839</td>\n",
       "      <td>SOTF</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed max_trans_date  \\\n",
       "0  b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...     2020-07-15   \n",
       "1  cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...     2020-07-06   \n",
       "2  02cdd41af5ee82b39607416b74290152b00183fbce3068...     2020-07-18   \n",
       "\n",
       "       sales  transactions  recency    RFM  \\\n",
       "0  114265.03          7369      1.0  111.0   \n",
       "1  152169.41          6575      1.0  111.0   \n",
       "2  179698.84          6110      1.0  111.0   \n",
       "\n",
       "                                  email_address_hash cleaned_zip_cd  \\\n",
       "0  4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...          28607   \n",
       "1  04e179d3e08f65382d320eaff61a2eb3edc874ea355003...          11726   \n",
       "2  295e2ee597ca9fce3fa6fd8abbd947a93bb4eb4732e6e2...          14075   \n",
       "\n",
       "  closet_store  top_sales_store  allocated_store Store_Type zip_type  \n",
       "0         1684             1684             1684     Legacy        P  \n",
       "1         1753             1753             1753       SOTF        P  \n",
       "2         1839             1839             1839       SOTF        P  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal=pd.merge(dftotal,df_zip_label,on=\"cleaned_zip_cd\",how=\"left\")\n",
    "dftotal['zip_type']=dftotal['zip_type'].fillna(\"T\")\n",
    "print(dftotal.shape)\n",
    "dftotal.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>max_trans_date</th>\n",
       "      <th>sales</th>\n",
       "      <th>transactions</th>\n",
       "      <th>recency</th>\n",
       "      <th>RFM</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>cleaned_zip_cd</th>\n",
       "      <th>closet_store</th>\n",
       "      <th>top_sales_store</th>\n",
       "      <th>allocated_store</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>zip_type</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>114265.03</td>\n",
       "      <td>7369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...</td>\n",
       "      <td>28607</td>\n",
       "      <td>1684</td>\n",
       "      <td>1684</td>\n",
       "      <td>1684</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>P</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>152169.41</td>\n",
       "      <td>6575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>04e179d3e08f65382d320eaff61a2eb3edc874ea355003...</td>\n",
       "      <td>11726</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>SOTF</td>\n",
       "      <td>P</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed max_trans_date  \\\n",
       "0  b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...     2020-07-15   \n",
       "1  cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...     2020-07-06   \n",
       "\n",
       "       sales  transactions  recency    RFM  \\\n",
       "0  114265.03          7369      1.0  111.0   \n",
       "1  152169.41          6575      1.0  111.0   \n",
       "\n",
       "                                  email_address_hash cleaned_zip_cd  \\\n",
       "0  4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...          28607   \n",
       "1  04e179d3e08f65382d320eaff61a2eb3edc874ea355003...          11726   \n",
       "\n",
       "  closet_store  top_sales_store  allocated_store Store_Type zip_type  Status  \n",
       "0         1684             1684             1684     Legacy        P  Active  \n",
       "1         1753             1753             1753       SOTF        P  Active  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_Beginning_12_months_ago=datetime.datetime.strptime(Beginning_12_months_ago,\"%Y-%m-%d\").date()\n",
    "\n",
    "dftotal['Status']=np.where(dftotal['max_trans_date']>=date_Beginning_12_months_ago,\"Active\",\"Lapsed1318\")\n",
    "dftotal.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20917437, 14)\n",
      "drop_duplicates('email_address_hash') (20915869, 14)\n",
      "Done with the RFM scoring, 2020-07-23 15:58:14.174661\n"
     ]
    }
   ],
   "source": [
    "dftotal = dftotal.sort_values(['RFM','recency','transactions',\n",
    "                               'sales'],ascending = [1,1,0,0])\n",
    "\n",
    "print(dftotal.shape)\n",
    "dftotal=dftotal.drop_duplicates(\"email_address_hash\") ####### Email duplications also dropped\n",
    "print(\"drop_duplicates('email_address_hash')\",dftotal.shape) \n",
    "\n",
    "dftotal.reset_index(drop = True, inplace = True)\n",
    "dftotal.reset_index(inplace = True)\n",
    "\n",
    "dftotal = dftotal.rename(columns = {'index':'frmindex'})\n",
    "c_ids = len(dftotal.index)\n",
    "c_ids = np.ceil(c_ids/10.0)\n",
    "dftotal['frmindex'] = np.ceil((dftotal['frmindex']+1)/c_ids)\n",
    "\n",
    "print(\"Done with the RFM scoring, \"+str(datetime.datetime.now()))\n",
    "\n",
    "dftotal['frmindex']=dftotal['frmindex'].apply(lambda x: \"D\"+str(int(float(x))).zfill(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_H=pd.DataFrame({\"frmindex\":['D01','D02','D03','D04']})\n",
    "df_H['HML_Group']=\"H\"\n",
    "\n",
    "df_M=pd.DataFrame({\"frmindex\":['D05','D06','D07']})\n",
    "df_M['HML_Group']=\"M\"\n",
    "\n",
    "df_L=pd.DataFrame({\"frmindex\":['D08','D09','D10']})\n",
    "df_L['HML_Group']=\"L\"\n",
    "\n",
    "df_HML=df_H.append(df_M).append(df_L)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal=pd.merge(dftotal,df_HML,on='frmindex',how=\"left\")\n",
    "\n",
    "dftotal.to_csv(output_folder+\"dftotal_details_full.csv\",index=False)\n",
    "del df_HML\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frmindex</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>max_trans_date</th>\n",
       "      <th>sales</th>\n",
       "      <th>transactions</th>\n",
       "      <th>recency</th>\n",
       "      <th>RFM</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>cleaned_zip_cd</th>\n",
       "      <th>closet_store</th>\n",
       "      <th>top_sales_store</th>\n",
       "      <th>allocated_store</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>zip_type</th>\n",
       "      <th>Status</th>\n",
       "      <th>HML_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D01</td>\n",
       "      <td>b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...</td>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>114265.03</td>\n",
       "      <td>7369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...</td>\n",
       "      <td>28607</td>\n",
       "      <td>1684</td>\n",
       "      <td>1684</td>\n",
       "      <td>1684</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>P</td>\n",
       "      <td>Active</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D01</td>\n",
       "      <td>cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>152169.41</td>\n",
       "      <td>6575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>04e179d3e08f65382d320eaff61a2eb3edc874ea355003...</td>\n",
       "      <td>11726</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>SOTF</td>\n",
       "      <td>P</td>\n",
       "      <td>Active</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  frmindex                                 customer_id_hashed max_trans_date  \\\n",
       "0      D01  b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...     2020-07-15   \n",
       "1      D01  cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...     2020-07-06   \n",
       "\n",
       "       sales  transactions  recency    RFM  \\\n",
       "0  114265.03          7369      1.0  111.0   \n",
       "1  152169.41          6575      1.0  111.0   \n",
       "\n",
       "                                  email_address_hash cleaned_zip_cd  \\\n",
       "0  4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...          28607   \n",
       "1  04e179d3e08f65382d320eaff61a2eb3edc874ea355003...          11726   \n",
       "\n",
       "  closet_store  top_sales_store  allocated_store Store_Type zip_type  Status  \\\n",
       "0         1684             1684             1684     Legacy        P  Active   \n",
       "1         1753             1753             1753       SOTF        P  Active   \n",
       "\n",
       "  HML_Group  \n",
       "0         H  \n",
       "1         H  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart for lapsed 18-49, checkpoint 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py:166: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "from haversine import haversine\n",
    "\n",
    "import gc\n",
    "import sqlalchemy\n",
    "import json\n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )\n",
    "str_ending=\"RFM20Q3\"\n",
    "\n",
    "folder_store_list=\"/home/jian/BigLots/static_files/Store_list/\"\n",
    "folder_email_unsubscription=\"/home/jian/BigLots/unsubscribe/\"\n",
    "path_json_zip_centers=\"/home/jian/Docs/Geo_mapping/updated_zip_centers_JL_2019-05-23.json\"\n",
    "output_folder=\"./output_%s/\"%(datetime.datetime.now().date())\n",
    "path_excel_ta=\"/home/jian/Projects/Big_Lots/New_TA/package_to_run_TA_every_quarter/output_2020-07-22/BL_final_TA_updated_JL_2020-07-22.xlsx\"\n",
    "dict_update_location_latlng={}\n",
    "path_SOTF_dom=\"/home/jian/BigLots/static_files/store_list_from_Dom/Store List Report 07.10.20 425PM.xlsx\"\n",
    "\n",
    "\n",
    "output_folder=\"./output_%s/\"%(datetime.datetime.now().date())\n",
    "lastdate_date = pd.read_sql(\"select max(transaction_dt) from Pred_POS_Department;\",con=BL_engine).iloc[0,0]\n",
    "Beginning_12_months_ago = str(lastdate_date-datetime.timedelta(days=52*7-1)) # Sunday\n",
    "Beginning_18_months_ago=str(lastdate_date-datetime.timedelta(days=52*7*1.5-1)) # Sunday\n",
    "Beginning_48_months_ago=str(lastdate_date-datetime.timedelta(days=52*7*4-1)) # Sunday\n",
    "\n",
    "\n",
    "zip_centers=json.load(open(path_json_zip_centers,\"r\"))\n",
    "\n",
    "latest_store_list=glob.glob(folder_store_list+\"*.txt\")\n",
    "latest_store_list=sorted(latest_store_list,key=lambda x: os.stat(x).st_mtime)\n",
    "latest_store_list=latest_store_list[-1]\n",
    "########\n",
    "def revise_store_lat_lng(path_store_list_input=latest_store_list):\n",
    "    df=pd.read_csv(path_store_list_input,sep=\"|\",dtype=str)\n",
    "    df['latitude_meas']=df['latitude_meas'].astype(float)\n",
    "    df=df[~df['location_id'].isin(['145','6990'])]\n",
    "    df=df[df['latitude_meas']==0]\n",
    "    print(\"type in lat and lng: %d, %d\")\n",
    "    for i,row in df.iterrows():\n",
    "        store_num=row['location_id']\n",
    "        address=row['address_line_1']+\", \"+row['city_nm']+\", \"+row['state_nm']+\", \"+row['zip_cd']+\", US\"\n",
    "        print(address)\n",
    "        \n",
    "        google_lat_long=str(input())\n",
    "        lat=eval(google_lat_long)[0]\n",
    "        lng=eval(google_lat_long)[1]\n",
    "        dict_update_location_latlng.update({store_num:{\"lat\":lat,\"lng\":lng}})\n",
    "    print(\"dict_update_location_latlng: \\n %s\"%dict_update_location_latlng)\n",
    "        \n",
    "        \n",
    "def update_store_location(df):\n",
    "    for store_num, store_revised_loc in dict_update_location_latlng.items():\n",
    "\n",
    "        df.loc[df['location_id']==store_num,'latitude_meas']=store_revised_loc['lat']\n",
    "        df.loc[df['location_id']==store_num,'longitude_meas']=store_revised_loc['lng']\n",
    "    \n",
    "    return df\n",
    "\n",
    "########\n",
    "store_list=pd.read_table(latest_store_list,\n",
    "                        dtype=str,sep=\"|\")\n",
    "store_list=store_list[['location_id','latitude_meas','longitude_meas']]\n",
    "store_list=store_list[store_list['location_id']!=\"6990\"]\n",
    "store_list=store_list[store_list['location_id']!=\"145\"]\n",
    "store_list['latitude_meas']=store_list['latitude_meas'].astype(float)\n",
    "store_list['longitude_meas']=store_list['longitude_meas'].astype(float)\n",
    "store_list=update_store_location(store_list)\n",
    "\n",
    "\n",
    "store_list['store_coor']=store_list[['latitude_meas','longitude_meas']].values.tolist()\n",
    "dict_store_lat=store_list.set_index(\"location_id\").to_dict()['store_coor']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lastdate_date: 2020-07-18\n",
      "Active Start on: 2019-07-21\n",
      "Lapsed & Store_allocation Start on: 2019-01-20\n",
      "Lapsed 19-48 Start on: 2016-07-24\n",
      "first_date_mysql: 2018-02-04\n"
     ]
    }
   ],
   "source": [
    "lastdate_str=str(lastdate_date)\n",
    "print(\"lastdate_date: %s\"%lastdate_str)\n",
    "print(\"Active Start on: %s\"%Beginning_12_months_ago) #>=\n",
    "print(\"Lapsed & Store_allocation Start on: %s\"%Beginning_18_months_ago) #>=\n",
    "print(\"Lapsed 19-48 Start on: %s\"%Beginning_48_months_ago) #>=\n",
    "\n",
    "def recursive_file_gen(root_folder):\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "            \n",
    "            \n",
    "            \n",
    "first_date_mysql = pd.read_sql(\"select min(transaction_dt) from Pred_POS_Department;\",con=BL_engine).iloc[0,0]\n",
    "print(\"first_date_mysql: %s\"%first_date_mysql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-30 2018-02-03\n",
      "min_date_sub_data 2016-07-30\n",
      "nan nan\n",
      "2016-07-30 2018-02-03\n",
      "(80, 2) 80\n"
     ]
    }
   ],
   "source": [
    "subclass_file_list=glob.glob(\"/home/jian/BigLots/hist_daily_data_subclasslevel/*.txt\")\n",
    "df_subclass_file=pd.DataFrame({\"file_path\":subclass_file_list})\n",
    "df_subclass_file['week_end_dt']=df_subclass_file['file_path'].apply(lambda x: x.split(\"es_week_ending_\")[1][:10])\n",
    "df_subclass_file=df_subclass_file[df_subclass_file['week_end_dt']>=Beginning_48_months_ago]\n",
    "df_subclass_file=df_subclass_file[df_subclass_file['week_end_dt']<str(first_date_mysql)]\n",
    "\n",
    "df_subclass_file=df_subclass_file.sort_values(\"week_end_dt\")\n",
    "print(df_subclass_file['week_end_dt'].min(),df_subclass_file['week_end_dt'].max())\n",
    "\n",
    "min_date_sub_data=df_subclass_file['week_end_dt'].min()\n",
    "print(\"min_date_sub_data\",min_date_sub_data)\n",
    "\n",
    "################\n",
    "daily_sub_file=list(recursive_file_gen(\"/home/jian/BigLots/2018_by_weeks/\"))\n",
    "daily_sub_file=[x for x in daily_sub_file if \"dailysales\" in x.lower()]\n",
    "daily_sub_file=[x for x in daily_sub_file if \"eks/MediaStorm_\" in x]\n",
    "df_daily_sub_file=pd.DataFrame({\"file_path\":daily_sub_file})\n",
    "\n",
    "df_daily_sub_file['week_end_dt']=df_daily_sub_file['file_path'].apply(lambda x: x.split(\"s/MediaStorm_\")[1][:10])\n",
    "df_daily_sub_file=df_daily_sub_file[df_daily_sub_file['week_end_dt']>=df_subclass_file['week_end_dt'].max()]\n",
    "df_daily_sub_file=df_daily_sub_file[df_daily_sub_file['week_end_dt']<str(first_date_mysql)]\n",
    "df_daily_sub_file=df_daily_sub_file.sort_values(\"week_end_dt\")\n",
    "\n",
    "print(df_daily_sub_file['week_end_dt'].min(),df_daily_sub_file['week_end_dt'].max())\n",
    "\n",
    "\n",
    "################\n",
    "df_sub_data_files=df_subclass_file.append(df_daily_sub_file)\n",
    "df_sub_data_files=df_sub_data_files.sort_values(\"week_end_dt\")\n",
    "del df_subclass_file\n",
    "del df_daily_sub_file\n",
    "\n",
    "print(df_sub_data_files['week_end_dt'].min(),df_sub_data_files['week_end_dt'].max())\n",
    "\n",
    "min_date_sub_data=df_sub_data_files['week_end_dt'].min()\n",
    "\n",
    "print(df_sub_data_files.shape,df_sub_data_files['week_end_dt'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2020-07-23 16:55:02.167015\n",
      "11 2020-07-23 17:00:09.841604\n",
      "21 2020-07-23 17:09:09.025228\n",
      "31 2020-07-23 17:14:23.088793\n",
      "41 2020-07-23 17:33:22.196739\n",
      "51 2020-07-23 17:41:51.563652\n",
      "61 2020-07-23 17:44:07.928797\n",
      "71 2020-07-23 17:47:01.398079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 \n",
    "list_historical_19_48_weekly_ids=[]\n",
    "i_counter=0\n",
    "for file in df_sub_data_files['file_path'].tolist():\n",
    "    df=pd.read_table(file,dtype=str,sep=\"|\",usecols=['customer_id_hashed'])\n",
    "    df=df[pd.notnull(df['customer_id_hashed'])].drop_duplicates()\n",
    "    \n",
    "    list_historical_19_48_weekly_ids.append(df)\n",
    "    i_counter+=1\n",
    "    if i_counter%10==1:\n",
    "        print(i_counter,datetime.datetime.now())\n",
    "lapsed_part1=pd.concat(list_historical_19_48_weekly_ids).drop_duplicates()\n",
    "del list_historical_19_48_weekly_ids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "str_query_up_to=\"'\"+str(Beginning_18_months_ago)+\"'\"\n",
    "query=\"select distinct customer_id_hashed as customer_id_hashed from Pred_POS_Department where transaction_dt <%s\"%str_query_up_to\n",
    "lapsed_part2=pd.read_sql(query,con=BL_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lapsed=lapsed_part1.append(lapsed_part2)\n",
    "del lapsed_part1\n",
    "del lapsed_part2\n",
    "df_lapsed_1948_ids=df_lapsed_1948_ids.drop_duplicates()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>zip_type</th>\n",
       "      <th>Status</th>\n",
       "      <th>HML_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...</td>\n",
       "      <td>4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>P</td>\n",
       "      <td>Active</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...</td>\n",
       "      <td>04e179d3e08f65382d320eaff61a2eb3edc874ea355003...</td>\n",
       "      <td>SOTF</td>\n",
       "      <td>P</td>\n",
       "      <td>Active</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed  \\\n",
       "0  b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...   \n",
       "1  cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...   \n",
       "\n",
       "                                  email_address_hash Store_Type zip_type  \\\n",
       "0  4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...     Legacy        P   \n",
       "1  04e179d3e08f65382d320eaff61a2eb3edc874ea355003...       SOTF        P   \n",
       "\n",
       "   Status HML_Group  \n",
       "0  Active         H  \n",
       "1  Active         H  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal=pd.read_csv(output_folder+\"dftotal_details_full.csv\",\n",
    "                    usecols=['customer_id_hashed','email_address_hash','Store_Type','Status','HML_Group','zip_type'])\n",
    "dftotal.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_unique_18_ids=dftotal['customer_id_hashed'].tolist()\n",
    "df_lapsed_1948_ids=df_lapsed_1948_ids[~df_lapsed_1948_ids['customer_id_hashed'].isin(list_unique_18_ids)]\n",
    "del list_unique_18_ids\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-23 20:46:04.976713\n",
      "dfiddetail.shape (37118435, 3)\n",
      "dfiddetail['customer_id_hashed'].nunique() 37118435\n",
      "dfiddetail['email_address_hash'].nunique() 37109259\n",
      "2020-07-23 21:07:06.877399\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "dfiddetail=pd.read_sql('select customer_id_hashed,email_address_hash,customer_zip_code from BL_Rewards_Master order by sign_up_date desc',con=BL_engine)\n",
    "dfiddetail=dfiddetail.drop_duplicates(\"customer_id_hashed\")\n",
    "print(\"dfiddetail.shape \"+str(dfiddetail.shape))\n",
    "print(\"dfiddetail['customer_id_hashed'].nunique() \"+str(dfiddetail['customer_id_hashed'].nunique()))\n",
    "print(\"dfiddetail['email_address_hash'].nunique() \"+str(dfiddetail['email_address_hash'].nunique()))\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_unique_zip_cd=dfiddetail[['customer_zip_code']].drop_duplicates()\n",
    "customer_unique_zip_cd=customer_unique_zip_cd[~pd.isnull(customer_unique_zip_cd['customer_zip_code'])]\n",
    "customer_unique_zip_cd['cleaned_zip_cd']=customer_unique_zip_cd['customer_zip_code'].apply(lambda x: x.split(\"-\")[0][:5].zfill(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73449, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_zip5=customer_unique_zip_cd[['cleaned_zip_cd']].drop_duplicates()\n",
    "df_unique_zip5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocated_closet_store_to_zip(zip_input):\n",
    "    try:\n",
    "        zip_c=zip_centers[zip_input]\n",
    "    except:\n",
    "        return np.nan\n",
    "    min_dist=np.inf\n",
    "    for store,v in dict_store_lat.items():\n",
    "        dist=haversine(zip_c,v,unit=\"mi\")\n",
    "        if dist<min_dist:\n",
    "            min_dist=dist\n",
    "            closet_store=store\n",
    "    return closet_store\n",
    "\n",
    "df_unique_zip5['closest_store']=df_unique_zip5['cleaned_zip_cd'].apply(lambda x: allocated_closet_store_to_zip(x))\n",
    "customer_unique_zip_cd=pd.merge(customer_unique_zip_cd,df_unique_zip5,on=\"cleaned_zip_cd\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37118435, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfiddetail=pd.merge(dfiddetail,customer_unique_zip_cd,on=\"customer_zip_code\",how=\"left\")\n",
    "print(dfiddetail.shape)\n",
    "\n",
    "del df_unique_zip5\n",
    "del customer_unique_zip_cd\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9492336, 5) 9492336\n"
     ]
    }
   ],
   "source": [
    "df_lapsed_1948_ids=pd.merge(df_lapsed_1948_ids,dfiddetail,on=\"customer_id_hashed\",how=\"left\")\n",
    "df_lapsed_1948_ids=df_lapsed_1948_ids[pd.notnull(df_lapsed_1948_ids['email_address_hash'])]\n",
    "print(df_lapsed_1948_ids.shape,df_lapsed_1948_ids['customer_id_hashed'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491 491\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closest_store</th>\n",
       "      <th>Store_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SOTF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49</td>\n",
       "      <td>SOTF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  closest_store Store_Type\n",
       "0             1       SOTF\n",
       "7            49       SOTF"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_type=pd.ExcelFile(path_SOTF_dom)\n",
    "df_store_type=df_store_type.parse(\"Store List\",dtype=str)\n",
    "df_store_type=df_store_type[[\"Store\",'SOTF']]\n",
    "df_store_type=df_store_type[df_store_type['SOTF'].str.lower()==\"yes\"]\n",
    "df_store_type=df_store_type[df_store_type['Store']!=\"TBD\"]\n",
    "print(len(df_store_type),df_store_type['Store'].nunique())\n",
    "df_store_type=df_store_type.rename(columns={\"Store\":\"closest_store\",\"SOTF\":\"Store_Type\"})\n",
    "df_store_type['Store_Type']=\"SOTF\"\n",
    "df_store_type.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>cleaned_zip_cd</th>\n",
       "      <th>closest_store</th>\n",
       "      <th>Store_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2faa361a6ca66e22bcd73d3279434a188ae8ec3f5dd9f4...</td>\n",
       "      <td>8a3ed6d103341b01977ee50f96e404ca40fe68e70f0f46...</td>\n",
       "      <td>16858</td>\n",
       "      <td>16858</td>\n",
       "      <td>1725</td>\n",
       "      <td>Legacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90f72bf4728e737900cc459a97b248fd01327e3b523e61...</td>\n",
       "      <td>3e022296a6aadeefc9681a7a3cfff13ed82c33ed220574...</td>\n",
       "      <td>30907</td>\n",
       "      <td>30907</td>\n",
       "      <td>5299</td>\n",
       "      <td>Legacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c85a2c338c6910677c11769ef9397e1fb248b972218b49...</td>\n",
       "      <td>5f7888169c354c078d89246cbc59db9b3a7557bcb4d684...</td>\n",
       "      <td>18201</td>\n",
       "      <td>18201</td>\n",
       "      <td>1741</td>\n",
       "      <td>SOTF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed  \\\n",
       "0  2faa361a6ca66e22bcd73d3279434a188ae8ec3f5dd9f4...   \n",
       "1  90f72bf4728e737900cc459a97b248fd01327e3b523e61...   \n",
       "2  c85a2c338c6910677c11769ef9397e1fb248b972218b49...   \n",
       "\n",
       "                                  email_address_hash customer_zip_code  \\\n",
       "0  8a3ed6d103341b01977ee50f96e404ca40fe68e70f0f46...             16858   \n",
       "1  3e022296a6aadeefc9681a7a3cfff13ed82c33ed220574...             30907   \n",
       "2  5f7888169c354c078d89246cbc59db9b3a7557bcb4d684...             18201   \n",
       "\n",
       "  cleaned_zip_cd closest_store Store_Type  \n",
       "0          16858          1725     Legacy  \n",
       "1          30907          5299     Legacy  \n",
       "2          18201          1741       SOTF  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lapsed_1948_ids=pd.merge(df_lapsed_1948_ids,df_store_type,on=\"closest_store\",how=\"left\")\n",
    "df_lapsed_1948_ids['Store_Type']=df_lapsed_1948_ids['Store_Type'].fillna(\"Legacy\")\n",
    "df_lapsed_1948_ids.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trans_P' 'trans_S' 'zips_10']\n",
      "[5]\n",
      "['P' 'S']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_type</th>\n",
       "      <th>cleaned_zip_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>76248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>23185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>23168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>23608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>23607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_type cleaned_zip_cd\n",
       "0        P          76248\n",
       "1        P          23185\n",
       "2        P          23168\n",
       "3        P          23608\n",
       "4        P          23607"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel=pd.ExcelFile(path_excel_ta)\n",
    "df_zip_label=excel.parse(\"unique_zips_full_footprint\",dtype=str)\n",
    "print(df_zip_label['zip_type'].unique())\n",
    "print(df_zip_label['zip_cd'].apply(len).unique())\n",
    "df_zip_label=df_zip_label.rename(columns={\"zip_cd\":\"cleaned_zip_cd\"})\n",
    "df_zip_label['zip_type']=df_zip_label['zip_type'].replace(\"zips_10\",\"trans_P\")\n",
    "df_zip_label['zip_type']=df_zip_label['zip_type'].apply(lambda x: x.split(\"_\")[1])\n",
    "del excel\n",
    "gc.collect()\n",
    "print(df_zip_label['zip_type'].unique())\n",
    "\n",
    "df_zip_label.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9492336, 7)\n"
     ]
    }
   ],
   "source": [
    "df_lapsed_1948_ids=pd.merge(df_lapsed_1948_ids,df_zip_label,on=\"cleaned_zip_cd\",how=\"left\")\n",
    "df_lapsed_1948_ids['zip_type']=df_lapsed_1948_ids['zip_type'].fillna(\"T\")\n",
    "df_lapsed_1948_ids['Status']=\"Lapsed1948\"\n",
    "print(df_lapsed_1948_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal['segment']=dftotal['Store_Type']+\"_\"+dftotal['Status']+\"_\"+dftotal['HML_Group']+\"_\"+dftotal['zip_type']+\"_\"+str_ending\n",
    "df_lapsed_1948_ids['segment']=df_lapsed_1948_ids['Store_Type']+\"_\"+df_lapsed_1948_ids['Status']+\"_\"+['NA']+\"_\"+df_lapsed_1948_ids['zip_type']+\"_\"+str_ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal.to_csv(output_folder+\"dftotal_with_segment.csv\",index=False)\n",
    "df_lapsed_1948_ids.to_csv(output_folder+\"df_lapsed_1948_ids_with_segment.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal=pd.read_csv(output_folder+\"dftotal_with_segment.csv\")\n",
    "df_lapsed_1948_ids=pd.read_csv(output_folder+\"df_lapsed_1948_ids_with_segment.csv\")\n",
    "\n",
    "dftotal['segment']=dftotal['segment'].apply(lambda x: x.replace(\"__\",\"_\"))\n",
    "df_lapsed_1948_ids['segment']=df_lapsed_1948_ids['segment'].apply(lambda x: x.replace(\"__\",\"_\"))\n",
    "\n",
    "dftotal.to_csv(output_folder+\"dftotal_with_segment.csv\",index=False)\n",
    "df_lapsed_1948_ids.to_csv(output_folder+\"df_lapsed_1948_ids_with_segment.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_0_18=dftotal.groupby(['segment','Store_Type','Status','HML_Group','zip_type'])['customer_id_hashed','email_address_hash'].nunique().reset_index()\n",
    "df_summary_0_18=df_summary_0_18.rename(columns={\"customer_id_hashed\":\"unique_ids\",\"email_address_hash\":\"unique_emails\"})\n",
    "\n",
    "df_summary_19_48=df_lapsed_1948_ids.groupby(['segment','Store_Type','Status','zip_type'])['customer_id_hashed','email_address_hash'].nunique().reset_index()\n",
    "df_summary_19_48=df_summary_19_48.rename(columns={\"customer_id_hashed\":\"unique_ids\",\"email_address_hash\":\"unique_emails\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"BL_%s_segmentation_summary_before_splitTandC_JL_%s\"%(str_ending,str(datetime.datetime.now().date()))+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_summary_0_18.to_excel(writer,\"aud_0_to_18_months\",index=False)\n",
    "df_summary_19_48.to_excel(writer,\"aud_19_to_48_months\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20915869\n",
      "9491704\n"
     ]
    }
   ],
   "source": [
    "print(df_summary_0_18['unique_emails'].sum())\n",
    "print(df_summary_19_48['unique_emails'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart for Email subsription, checkpoint 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-24 12:09:49.665235\n",
      "2020-07-24 12:20:26.805446\n",
      "(30408205, 5) 30408205 30402577\n"
     ]
    }
   ],
   "source": [
    "# Load the libraries above\n",
    "print(datetime.datetime.now())\n",
    "sample_rows=None\n",
    "old_output_folder='./output_2020-07-23/'\n",
    "list_col=['customer_id_hashed','email_address_hash','Store_Type','HML_Group','Status']\n",
    "dftotal=pd.read_csv(old_output_folder+\"dftotal_with_segment.csv\",nrows=sample_rows,\n",
    "                    usecols=['customer_id_hashed','email_address_hash','Store_Type','HML_Group','Status'])\n",
    "df_lapsed_1948_ids=pd.read_csv(old_output_folder+\"df_lapsed_1948_ids_with_segment.csv\",\n",
    "                               nrows=sample_rows,usecols=['customer_id_hashed','email_address_hash','Store_Type','Status'])\n",
    "df_lapsed_1948_ids['HML_Group']=\"NA\"\n",
    "\n",
    "df_all_ids=dftotal.append(df_lapsed_1948_ids)\n",
    "df_all_ids=df_all_ids[list_col]\n",
    "print(datetime.datetime.now())\n",
    "print(df_all_ids.shape,df_all_ids['customer_id_hashed'].nunique(),df_all_ids['email_address_hash'].nunique())\n",
    "df_all_ids=df_all_ids.drop_duplicates(\"customer_id_hashed\").drop_duplicates(\"email_address_hash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_latest_unsub=glob.glob(folder_email_unsubscription+\"*.csv\")\n",
    "path_latest_unsub=[x for x in path_latest_unsub if \"unsubscriber\" in x.lower() and \"refresh\" in x.lower()]\n",
    "path_latest_unsub=sorted(path_latest_unsub, key=lambda x: os.stat(x).st_mtime)\n",
    "path_latest_unsub=path_latest_unsub[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unsub=pd.read_csv(path_latest_unsub,usecols=['customersummary_emailhash','customersummary_c_primaryscnhash'])\n",
    "list_unsub_id=df_unsub['customersummary_c_primaryscnhash'].to_list()\n",
    "list_unsub_email=df_unsub['customersummary_emailhash'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>HML_Group</th>\n",
       "      <th>Status</th>\n",
       "      <th>EmailSub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...</td>\n",
       "      <td>4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...</td>\n",
       "      <td>Legacy</td>\n",
       "      <td>H</td>\n",
       "      <td>Active</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...</td>\n",
       "      <td>04e179d3e08f65382d320eaff61a2eb3edc874ea355003...</td>\n",
       "      <td>SOTF</td>\n",
       "      <td>H</td>\n",
       "      <td>Active</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed  \\\n",
       "0  b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...   \n",
       "1  cea60a4c9703abd6cd8081bfae9f2420e7e5bd8bba0fd4...   \n",
       "\n",
       "                                  email_address_hash Store_Type HML_Group  \\\n",
       "0  4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...     Legacy         H   \n",
       "1  04e179d3e08f65382d320eaff61a2eb3edc874ea355003...       SOTF         H   \n",
       "\n",
       "   Status EmailSub  \n",
       "0  Active        Y  \n",
       "1  Active        Y  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_ids['EmailSub']=np.where(df_all_ids['customer_id_hashed'].isin(list_unsub_id),\"N\",\n",
    "                               np.where(df_all_ids['email_address_hash'].isin(list_unsub_email),\"N\",\"Y\"))\n",
    "df_all_ids.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Active', 'Lapsed1318', 'Lapsed1948'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_ids['Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "976"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal=df_all_ids[df_all_ids['Status']!=\"Lapsed1948\"]\n",
    "df_lapsed_1948_ids=df_all_ids[df_all_ids['Status']==\"Lapsed1948\"]\n",
    "del df_all_ids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftotal['segment']=dftotal['Store_Type']+\"_\"+dftotal['HML_Group']+\"_\"+dftotal['Status']+\"_\"+dftotal['EmailSub']\n",
    "df_lapsed_1948_ids['segment']=df_lapsed_1948_ids['Store_Type']+\"_\"+df_lapsed_1948_ids['HML_Group']+\"_\"+df_lapsed_1948_ids['Status']+\"_\"+df_lapsed_1948_ids['EmailSub']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split T vs C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(list_seg_small_0_to_18) 0\n",
      "len(list_seg_small_19_to_48) 0\n"
     ]
    }
   ],
   "source": [
    "df_0_to_18_count_PS=dftotal.groupby(\"segment\")['customer_id_hashed'].count().to_frame().reset_index()\n",
    "df_19_to_48_count_P=df_lapsed_1948_ids.groupby(\"segment\")['customer_id_hashed'].count().to_frame().reset_index()\n",
    "df_0_to_18_count_PS=df_0_to_18_count_PS.sort_values(\"segment\")\n",
    "df_19_to_48_count_P=df_19_to_48_count_P.sort_values(\"segment\")\n",
    "\n",
    "list_seg_small_0_to_18=df_0_to_18_count_PS[df_0_to_18_count_PS['customer_id_hashed']<=3600]['segment'].unique().tolist()\n",
    "list_seg_small_19_to_48=df_19_to_48_count_P[df_19_to_48_count_P['customer_id_hashed']<=3600]['segment'].unique().tolist()\n",
    "print(\"len(list_seg_small_0_to_18)\",len(list_seg_small_0_to_18))\n",
    "print(\"len(list_seg_small_19_to_48)\",len(list_seg_small_19_to_48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-24 12:37:15.838883 start splitting\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(datetime.datetime.now(),\"start splitting\")\n",
    "random.seed(0)\n",
    "\n",
    "df_test_all=pd.DataFrame()\n",
    "df_control_all=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pctg_0_18 0.023905\n",
      "pctg_19_48 0.010541\n"
     ]
    }
   ],
   "source": [
    "count_control_0_to_18=500000\n",
    "count_control_19_to_48=100000\n",
    "pctg_0_18=np.round(count_control_0_to_18/dftotal.shape[0],6)\n",
    "print(\"pctg_0_18\",pctg_0_18)\n",
    "pctg_19_48=np.round(count_control_19_to_48/df_lapsed_1948_ids.shape[0],6)\n",
    "print(\"pctg_19_48\",pctg_19_48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_folder_all_wanted=\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_20%s/wanted_segment_files/\"%str_ending[-4:]\n",
    "try:\n",
    "    os.stat(writer_folder_all_wanted)\n",
    "except:\n",
    "    os.mkdir(writer_folder_all_wanted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_Legacy_H_Active_N (714213, 7)\n",
      "C_Legacy_H_Active_N (17491, 7)\n",
      "1 2020-07-24 12:38:34.980738\n",
      "T_Legacy_H_Active_Y (4566738, 7)\n",
      "C_Legacy_H_Active_Y (111841, 7)\n",
      "T_Legacy_L_Active_N (337171, 7)\n",
      "C_Legacy_L_Active_N (8257, 7)\n",
      "T_Legacy_L_Active_Y (1777547, 7)\n",
      "C_Legacy_L_Active_Y (43532, 7)\n",
      "T_Legacy_L_Lapsed1318_N (333765, 7)\n",
      "C_Legacy_L_Lapsed1318_N (8174, 7)\n",
      "T_Legacy_L_Lapsed1318_Y (1655051, 7)\n",
      "C_Legacy_L_Lapsed1318_Y (40532, 7)\n",
      "T_Legacy_M_Active_N (608266, 7)\n",
      "C_Legacy_M_Active_N (14896, 7)\n",
      "T_Legacy_M_Active_Y (3407990, 7)\n",
      "C_Legacy_M_Active_Y (83463, 7)\n",
      "T_SOTF_H_Active_N (392898, 7)\n",
      "C_SOTF_H_Active_N (9622, 7)\n",
      "T_SOTF_H_Active_Y (2492503, 7)\n",
      "C_SOTF_H_Active_Y (61042, 7)\n",
      "T_SOTF_L_Active_N (180215, 7)\n",
      "C_SOTF_L_Active_N (4413, 7)\n",
      "11 2020-07-24 12:42:49.197853\n",
      "T_SOTF_L_Active_Y (917122, 7)\n",
      "C_SOTF_L_Active_Y (22460, 7)\n",
      "T_SOTF_L_Lapsed1318_N (161690, 7)\n",
      "C_SOTF_L_Lapsed1318_N (3959, 7)\n",
      "T_SOTF_L_Lapsed1318_Y (762206, 7)\n",
      "C_SOTF_L_Lapsed1318_Y (18666, 7)\n",
      "T_SOTF_M_Active_N (322793, 7)\n",
      "C_SOTF_M_Active_N (7905, 7)\n",
      "T_SOTF_M_Active_Y (1785716, 7)\n",
      "C_SOTF_M_Active_Y (43732, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/jian/.local/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_Legacy_NA_Lapsed1948_N (1055428, 7)\n",
      "C_Legacy_NA_Lapsed1948_N (11243, 7)\n",
      "1 2020-07-24 12:44:24.650689\n",
      "T_Legacy_NA_Lapsed1948_Y (5259772, 7)\n",
      "C_Legacy_NA_Lapsed1948_Y (56033, 7)\n",
      "T_SOTF_NA_Lapsed1948_N (534504, 7)\n",
      "C_SOTF_NA_Lapsed1948_N (5694, 7)\n",
      "T_SOTF_NA_Lapsed1948_Y (2537007, 7)\n",
      "C_SOTF_NA_Lapsed1948_Y (27027, 7)\n"
     ]
    }
   ],
   "source": [
    "df_test_all=pd.DataFrame()\n",
    "df_control_all=pd.DataFrame()\n",
    "i=0\n",
    "for seg, group in dftotal.groupby(\"segment\"):\n",
    "    group=group.reset_index()\n",
    "    del group['index']\n",
    "    group=group.reset_index()\n",
    "    len_group=len(group)\n",
    "    \n",
    "    ind_control=random.sample(range(len_group),int(len_group*pctg_0_18))\n",
    "    df_group_T=group[~group['index'].isin(ind_control)]\n",
    "    df_group_C=group[group['index'].isin(ind_control)]\n",
    "    \n",
    "    del df_group_T['index']\n",
    "    del df_group_C['index']\n",
    "    \n",
    "    new_T_seg=\"T_\"+seg\n",
    "    new_C_seg=\"C_\"+seg\n",
    "    del df_group_T['segment']\n",
    "    del df_group_C['segment']\n",
    "    df_group_T['segment_20%s'%str_ending[-4:]]=new_T_seg\n",
    "    df_group_C['segment_20%s'%str_ending[-4:]]=new_C_seg\n",
    "    \n",
    "    df_test_all=df_test_all.append(df_group_T)\n",
    "    df_control_all=df_control_all.append(df_group_C)\n",
    "    \n",
    "    df_group_T.to_csv(writer_folder_all_wanted+new_T_seg+\".csv\",index=False)\n",
    "    df_group_C.to_csv(writer_folder_all_wanted+new_C_seg+\".csv\",index=False)\n",
    "    print(new_T_seg,df_group_T.shape)\n",
    "    print(new_C_seg,df_group_C.shape)\n",
    "    del df_group_T\n",
    "    del df_group_C\n",
    "    i+=1\n",
    "    if i%10==1:\n",
    "        print(i,datetime.datetime.now())\n",
    "        \n",
    "i=0\n",
    "for seg, group in df_lapsed_1948_ids.groupby(\"segment\"):\n",
    "    group=group.reset_index()\n",
    "    del group['index']\n",
    "    group=group.reset_index()\n",
    "    len_group=len(group)\n",
    "    \n",
    "    ind_control=random.sample(range(len_group),int(len_group*pctg_19_48))\n",
    "    df_group_T=group[~group['index'].isin(ind_control)]\n",
    "    df_group_C=group[group['index'].isin(ind_control)]\n",
    "    \n",
    "    del df_group_T['index']\n",
    "    del df_group_C['index']\n",
    "    \n",
    "    new_T_seg=\"T_\"+seg\n",
    "    new_C_seg=\"C_\"+seg\n",
    "    \n",
    "    del df_group_T['segment']\n",
    "    del df_group_C['segment']\n",
    "    df_group_T['segment_20%s'%str_ending[-4:]]=new_T_seg\n",
    "    df_group_C['segment_20%s'%str_ending[-4:]]=new_C_seg\n",
    "    \n",
    "    df_test_all=df_test_all.append(df_group_T)\n",
    "    df_control_all=df_control_all.append(df_group_C)\n",
    "    \n",
    "    df_group_T.to_csv(writer_folder_all_wanted+new_T_seg+\".csv\",index=False)\n",
    "    df_group_C.to_csv(writer_folder_all_wanted+new_C_seg+\".csv\",index=False)\n",
    "\n",
    "    print(new_T_seg,df_group_T.shape)\n",
    "    print(new_C_seg,df_group_C.shape)\n",
    "    \n",
    "    del df_group_T\n",
    "    del df_group_C\n",
    "    i+=1\n",
    "    if i%10==1:\n",
    "        print(i,datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_test=df_test_all.groupby(['segment_20%s'%str_ending[-4:]])['customer_id_hashed','email_address_hash'].nunique().reset_index()\n",
    "df_summary_control=df_control_all.groupby(['segment_20%s'%str_ending[-4:]])['customer_id_hashed','email_address_hash'].nunique().reset_index()\n",
    "\n",
    "for col in df_summary_test.columns.tolist():\n",
    "    df_summary_test=df_summary_test.rename(columns={col:\"T_\"+col})\n",
    "    \n",
    "for col in df_summary_control.columns.tolist():\n",
    "    df_summary_control=df_summary_control.rename(columns={col:\"C_\"+col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_test.insert(0,\"segment\",df_summary_test['T_segment_2020Q3'].apply(lambda x: x[2:]))\n",
    "df_summary_test['T/C_group']=df_summary_test['T_segment_2020Q3'].apply(lambda x: x.split(\"_\")[0])\n",
    "df_summary_test['Store_Type']=df_summary_test['T_segment_2020Q3'].apply(lambda x: x.split(\"_\")[1])\n",
    "df_summary_test['RFM_group']=df_summary_test['T_segment_2020Q3'].apply(lambda x: x.split(\"_\")[2])\n",
    "df_summary_test['status']=df_summary_test['T_segment_2020Q3'].apply(lambda x: x.split(\"_\")[3])\n",
    "df_summary_test['Email_Sub']=df_summary_test['T_segment_2020Q3'].apply(lambda x: x.split(\"_\")[4])\n",
    "\n",
    "df_summary_test=df_summary_test.rename(columns={\"T_segment_2020Q3\":\"audience_name\",\"T_customer_id_hashed\":\"unique_id_count\",\"T_email_address_hash\":\"unique_email_count\"})\n",
    "###\n",
    "df_summary_control.insert(0,\"segment\",df_summary_control['C_segment_2020Q3'].apply(lambda x: x[2:]))\n",
    "df_summary_control['T/C_group']=df_summary_control['C_segment_2020Q3'].apply(lambda x: x.split(\"_\")[0])\n",
    "df_summary_control['Store_Type']=df_summary_control['C_segment_2020Q3'].apply(lambda x: x.split(\"_\")[1])\n",
    "df_summary_control['RFM_group']=df_summary_control['C_segment_2020Q3'].apply(lambda x: x.split(\"_\")[2])\n",
    "df_summary_control['status']=df_summary_control['C_segment_2020Q3'].apply(lambda x: x.split(\"_\")[3])\n",
    "df_summary_control['Email_Sub']=df_summary_control['C_segment_2020Q3'].apply(lambda x: x.split(\"_\")[4])\n",
    "\n",
    "df_summary_control=df_summary_control.rename(columns={\"C_segment_2020Q3\":\"audience_name\",\"C_customer_id_hashed\":\"unique_id_count\",\"C_email_address_hash\":\"unique_email_count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary=df_summary_test.append(df_summary_control)\n",
    "df_summary=df_summary.sort_values(\"audience_name\")\n",
    "\n",
    "writer=pd.ExcelWriter(output_folder+\"BL_summary_20%s_rewards_audience_JL_%s.xlsx\"%(str_ending[-4:],str(datetime.datetime.now().date())),engine=\"xlsxwriter\")\n",
    "df_summary.to_excel(writer,\"summary_both\",index=False)\n",
    "df_summary_test.to_excel(writer,\"summary_T\",index=False)\n",
    "df_summary_control.to_excel(writer,\"summary_C\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
