{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import hashlib\n",
    "import gc\n",
    "import glob\n",
    "logging.basicConfig(filename='crmnewscore.log', level=logging.INFO)\n",
    "logging.info('Started')\n",
    "\n",
    "samplerows = None\n",
    "activemos = '2018-12-29'\n",
    "lapsed = '2017-12-29'\n",
    "lastdate = '2018-12-29'\n",
    "\n",
    "\n",
    "folder_write = '/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/crm_newscore_20190107/'\n",
    "try:\n",
    "    os.stat(folder_write)\n",
    "except:\n",
    "    os.mkdir(folder_write)\n",
    "    \n",
    "# Adding control members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunksize_num = 10**7\n",
    "filename='/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/crm_newscore_0922/combinedtransactions_0922.csv'\n",
    "dftrans_before_20180922=pd.DataFrame()\n",
    "count_i=0\n",
    "\n",
    "for chunk in pd.read_csv(filename, chunksize=chunksize_num,dtype=str):\n",
    "    chunk['total_transaction_amt']=chunk['total_transaction_amt'].astype(float)\n",
    "    chunk['total_transaction_units']=chunk['total_transaction_units'].astype(float)\n",
    "    chunk = chunk[['customer_id_hashed','transaction_date','transaction_time',\n",
    "                   'transaction_id','location_id','total_transaction_units',\n",
    "                   'total_transaction_amt']].drop_duplicates()\n",
    "    dftrans_before_20180922=dftrans_before_20180922.append(chunk)\n",
    "    count_i+=1\n",
    "    print(count_i,datetime.datetime.now())\n",
    "    \n",
    "\n",
    "'''\n",
    "dftrans_before_20180922 = pd.read_csv('/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/crm_newscore_0922/combinedtransactions_0922.csv',dtype=str)\n",
    "#dftrans = dftrans[dftrans['transaction_date']>=lapsed]\n",
    "dftrans_before_20180922['total_transaction_amt']=dftrans_before_20180922['total_transaction_amt'].astype(float)\n",
    "dftrans_before_20180922['total_transaction_units']=dftrans_before_20180922['total_transaction_units'].astype(float)\n",
    "\n",
    "dftrans_before_20180922 = dftrans_before_20180922[['customer_id_hashed','transaction_date','transaction_time',\n",
    "                   'transaction_id','location_id','total_transaction_units',\n",
    "                   'total_transaction_amt']].drop_duplicates()\n",
    "'''\n",
    "\n",
    "del chunk\n",
    "\n",
    "dftrans_before_20180922=dftrans_before_20180922.drop_duplicates()\n",
    "\n",
    "print(\"Deduped\",datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "\n",
    "weeks_after_20180922=[datetime.date(2018,9,29)+datetime.timedelta(days=x*7) for x in range(999)]\n",
    "possible_recent_folders=[\"/home/jian/BigLots/MediaStorm_\"+str(x)+\"/\" for x in weeks_after_20180922]\n",
    "recent_file_list=[]\n",
    "for dirc in possible_recent_folders:\n",
    "    list_recent=[x for x in list(recursive_file_gen(dirc)) if (\"DailySales\" in x) & (\".txt\" in x) ]\n",
    "    recent_file_list=recent_file_list+list_recent\n",
    "recent_file_df=pd.DataFrame({\"path\":recent_file_list,\"date\":[datetime.datetime.strptime(x.split(\"DailySales\")[1][:8],\"%Y%m%d\").date()-datetime.timedelta(days=3) for x in recent_file_list]},index=[x for x in range(len(recent_file_list))])\n",
    "\n",
    "\n",
    "list_1_after_201806=[x for x in list(recursive_file_gen(\"/home/jian/BigLots/2018_by_weeks/\")) if (\"DailySales\" in x) & (\".txt\" in x) ]\n",
    "folder_date=[datetime.datetime.strptime(x.split(\"/\")[len(x.split(\"/\"))-2].split(\"_\")[1],\"%Y-%m-%d\").date() for x in list_1_after_201806]\n",
    "df_1_after_201806=pd.DataFrame({\"date\":folder_date,\"path\":list_1_after_201806},index=[x for x in range(len(list_1_after_201806))])\n",
    "df_1_after_201806['date'].apply(lambda x: x.weekday()).unique()\n",
    "df_1_after_201806=df_1_after_201806.sort_values(\"date\").reset_index()\n",
    "del df_1_after_201806['index']\n",
    "new_dailysales_files=df_1_after_201806.append(recent_file_df)\n",
    "\n",
    "new_dailysales_files=new_dailysales_files[new_dailysales_files['date']>datetime.date(2018,9,22)]\n",
    "new_dailysales_files=new_dailysales_files[new_dailysales_files['date']<=datetime.date(2018,12,29)]\n",
    "\n",
    "print(len(new_dailysales_files))\n",
    "new_dailysales_files=new_dailysales_files['path'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_rewards_transaction_after_20180922_agg=pd.DataFrame()\n",
    "count_i=1\n",
    "print(\"Total Files: \"+str(len(new_dailysales_files)))\n",
    "for file_daily in new_dailysales_files:\n",
    "    df=pd.read_table(file_daily,nrows = None,sep= '|',dtype =str)\n",
    "    df['subclass_transaction_amt']=df['subclass_transaction_amt'].astype(float)\n",
    "    df['subclass_transaction_units']=df['subclass_transaction_units'].astype(float)\n",
    "    df=df[~pd.isnull(df['customer_id_hashed'])]\n",
    "    df_sales=df.groupby(['location_id','transaction_dt','customer_id_hashed'])['subclass_transaction_amt','subclass_transaction_units'].sum().reset_index().rename(columns={\"subclass_transaction_amt\":\"total_transaction_amt\",\"subclass_transaction_units\":\"total_transaction_units\"})\n",
    "    df_trans=df[['location_id','transaction_dt','transaction_id','customer_id_hashed']].drop_duplicates().groupby(['location_id','transaction_dt','customer_id_hashed'])['transaction_id'].count().to_frame().reset_index().rename(columns={\"transaction_id\":\"transactions\"})\n",
    "    df=pd.merge(df_sales,df_trans,on=['location_id','transaction_dt','customer_id_hashed'],how=\"left\")\n",
    "    combined_rewards_transaction_after_20180922_agg=combined_rewards_transaction_after_20180922_agg.append(df)\n",
    "    print(count_i,\"done\",datetime.datetime.now())\n",
    "    count_i+=1\n",
    "    \n",
    "combined_rewards_transaction_after_20180922_agg=combined_rewards_transaction_after_20180922_agg.rename(columns={\"transaction_dt\":\"transaction_date\"})\n",
    "\n",
    "# combined_rewards_transaction_after_20180922_agg.to_csv(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/combined_agged_rewards_transactions_20180929_20181229.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting the store for an id\n",
    "\n",
    "df_2018_transaction_by_id_1=dftrans_before_20180922[dftrans_before_20180922['transaction_date'].apply(lambda x: x[:4]==\"2018\")]\n",
    "df_2018_transaction_by_id_1=df_2018_transaction_by_id_1[df_2018_transaction_by_id_1['total_transaction_amt']>0]\n",
    "df_2018_transaction_by_id_1=df_2018_transaction_by_id_1.groupby(['customer_id_hashed','location_id'])['total_transaction_amt'].count().to_frame().reset_index()\n",
    "df_2018_transaction_by_id_1=df_2018_transaction_by_id_1.rename(columns={\"total_transaction_amt\":\"trans\"})\n",
    "\n",
    "\n",
    "df_2018_transaction_by_id_2=combined_rewards_transaction_after_20180922_agg[combined_rewards_transaction_after_20180922_agg['total_transaction_amt']>0]\n",
    "df_2018_transaction_by_id_2=df_2018_transaction_by_id_2.groupby(['customer_id_hashed','location_id'])['transactions'].sum().to_frame().reset_index().rename(columns={\"transactions\":\"trans\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2018_transaction_by_id=df_2018_transaction_by_id_1.append(df_2018_transaction_by_id_2)\n",
    "df_2018_transaction_by_id=df_2018_transaction_by_id.groupby(['customer_id_hashed','location_id'])['trans'].sum().to_frame().reset_index()\n",
    "df_2018_transaction_by_id=df_2018_transaction_by_id.sort_values(['customer_id_hashed','trans'],ascending=[True,False]).drop_duplicates(['customer_id_hashed'])\n",
    "df_2018_transaction_by_id.to_csv(folder_write+\"id_by_store_based_on_2018_trans.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
