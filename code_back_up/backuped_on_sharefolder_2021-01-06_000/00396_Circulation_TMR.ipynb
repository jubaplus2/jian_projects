{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newspaper FSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FSI_file_list=glob.glob(\"/home/jian/Projects/Big_Lots/TMR/Circulation/Newspaper/circ_starting_2018Aug/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newspaper=pd.DataFrame()\n",
    "for file in FSI_file_list:\n",
    "    month=file.split(\"/\")[9].split(\" \")[0]\n",
    "    day=file.split(\"/\")[9].split(\" \")[1]\n",
    "    year=file.split(\"/\")[9].split(\" \")[2]\n",
    "    if month==\"Feb\":\n",
    "        month=\"February\"\n",
    "    if month==\"Nov\":\n",
    "        month=\"November\"\n",
    "    date_str=month+\" \"+day+\" \"+year\n",
    "    try:\n",
    "        date_in_file=datetime.datetime.strptime(date_str,\"%B %d %Y\").date()\n",
    "    except:\n",
    "        print(\"file_name_error: \"+date_str)\n",
    "    if date_in_file>=datetime.date(2016,10,2):\n",
    "        df=pd.read_excel(file,dtype=str)\n",
    "        df.columns=[x.upper() for x in df.columns.tolist()]\n",
    "        \n",
    "        try:\n",
    "            df=df[['DMA','CONFIRMED CIRCULATION','MEDIA COST','PRINT COST']]\n",
    "        except:\n",
    "            print(\"columns_name_error: \"+date_str)\n",
    "        df=df[df['DMA']!='nan']\n",
    "        \n",
    "        df['CONFIRMED CIRCULATION']=df['CONFIRMED CIRCULATION'].astype(float)\n",
    "        df['MEDIA COST']=df['MEDIA COST'].astype(float)\n",
    "        df['PRINT COST']=df['PRINT COST'].astype(float)\n",
    "        df['cost']=df['MEDIA COST']+df['PRINT COST']\n",
    "        del df['MEDIA COST']\n",
    "        del df['PRINT COST']\n",
    "        \n",
    "        df=df.groupby(['DMA'])['CONFIRMED CIRCULATION','cost'].sum().reset_index()\n",
    "        \n",
    "        \n",
    "        if date_in_file.weekday()==6:\n",
    "            week_start_date=date_in_file\n",
    "            week_end_saturday=date_in_file+datetime.timedelta(days=6)\n",
    "        else:\n",
    "            week_start_date=date_in_file-datetime.timedelta(days= date_in_file.weekday()+1)\n",
    "            week_end_saturday=week_start_date+datetime.timedelta(days=6)\n",
    "        df['week_start_date']=week_start_date\n",
    "        df['week_end_date']=week_end_saturday\n",
    "        df['file_date']=date_in_file\n",
    "        newspaper=newspaper.append(df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newspaper_DMA=newspaper.copy()\n",
    "del newspaper_DMA['file_date']\n",
    "newspaper_DMA['media']='Circulation'\n",
    "newspaper_DMA['submedia']='FSI+Instore'\n",
    "newspaper_DMA['placement']=\"xx\"\n",
    "newspaper_DMA=newspaper_DMA.rename(columns={\"CONFIRMED CIRCULATION\":\"impression\"})\n",
    "newspaper_DMA=newspaper_DMA[['week_start_date','week_end_date','DMA','media','submedia','placement','impression','cost']]\n",
    "\n",
    "\n",
    "newspaper_national=newspaper.groupby(['week_start_date','week_end_date'])['CONFIRMED CIRCULATION','cost'].sum().reset_index()\n",
    "newspaper_national=newspaper_national.rename(columns={\"CONFIRMED CIRCULATION\":\"impression\"})\n",
    "newspaper_national['media']='Circulation'\n",
    "newspaper_national['submedia']='FSI+Instore'\n",
    "newspaper_national['placement']=\"xx\"\n",
    "newspaper_national=newspaper_national[['week_start_date','week_end_date','media','submedia','placement','impression','cost']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valassis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Valassis_file_list=glob.glob(\"/home/jian/Projects/Big_Lots/TMR/Circulation/Valassis/valassis_starting_2018Aug/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valassis=pd.DataFrame()\n",
    "for file in Valassis_file_list:\n",
    "    file_name=file.split(\"/\")[9]\n",
    "    if file_name[3]==\"_\":\n",
    "        file_date_name=file_name[9:]\n",
    "        month=file_date_name.split(\" \")[0]\n",
    "        day=file_date_name.split(\" \")[1]\n",
    "        year=file_date_name.split(\" \")[2]\n",
    "        if len(year)==2:\n",
    "            year=\"20\"+year\n",
    "        if ((len(month)==2) & (month[0]=='0')):\n",
    "            month=month[1]\n",
    "        if ((len(day)==2) & (day[0]=='0')):\n",
    "            day=day[1]\n",
    "        date_in_file=datetime.date(int(year),int(month),int(day))\n",
    "    elif file_name[3]==\" \":\n",
    "        file_date_name=file_name[9:].split(\" \")[0]\n",
    "        month=file_date_name.split(\".\")[0]\n",
    "        day=file_date_name.split(\".\")[1]\n",
    "        year=file_date_name.split(\".\")[2]\n",
    "        if len(year)==2:\n",
    "            year=\"20\"+year\n",
    "        if ((len(month)==2) & (month[0]=='0')):\n",
    "            month=month[1]\n",
    "        if ((len(day)==2) & (day[0]=='0')):\n",
    "            day=day[1]\n",
    "        date_in_file=datetime.date(int(year),int(month),int(day))\n",
    "    else:\n",
    "        print(\"file date detect failed: \"+str(file))\n",
    "    if date_in_file>=datetime.date(2016,10,2):\n",
    "        df=pd.read_excel(file,dtype=str)\n",
    "        start_row=df[df.iloc[:,0].apply(lambda x: x.lower())==\"name\"].reset_index()['index'].tolist()[0]\n",
    "        df=pd.read_excel(file,dtype=str,skiprows=(start_row+1))\n",
    "        df.columns=[x.lower() for x in df.columns.tolist()]\n",
    "        df=df[df['description']!='nan']\n",
    "        if \"shared count\" in df.columns.tolist():\n",
    "            df=df[['description','shared count']].rename(columns={\"description\":\"DMA\",\"shared count\":\"impression\"})\n",
    "            df['date_in_file']=date_in_file\n",
    "            df['impression']=df['impression'].astype(float)\n",
    "            df=df.groupby(['date_in_file','DMA'])['impression'].sum().to_frame().reset_index()\n",
    "            \n",
    "            if date_in_file.weekday()==6:\n",
    "                week_start_date=date_in_file\n",
    "                week_end_saturday=date_in_file+datetime.timedelta(days=6)\n",
    "            else:\n",
    "                week_start_date=date_in_file-datetime.timedelta(days= date_in_file.weekday()+1)\n",
    "                week_end_saturday=week_start_date+datetime.timedelta(days=6)\n",
    "            df['week_start_date']=week_start_date\n",
    "            df['week_end_date']=week_end_saturday\n",
    "            valassis=valassis.append(df)\n",
    "            \n",
    "        elif \"shared counts\" in df.columns.tolist():\n",
    "            df=df[['description','shared counts']].rename(columns={\"description\":\"DMA\",\"shared counts\":\"impression\"})\n",
    "            df['date_in_file']=date_in_file\n",
    "            df['impression']=df['impression'].astype(float)\n",
    "            df=df.groupby(['date_in_file','DMA'])['impression'].sum().to_frame().reset_index()\n",
    "\n",
    "            if date_in_file.weekday()==6:\n",
    "                week_start_date=date_in_file\n",
    "                week_end_saturday=date_in_file+datetime.timedelta(days=6)\n",
    "            else:\n",
    "                week_start_date=date_in_file-datetime.timedelta(days= date_in_file.weekday()+1)\n",
    "                week_end_saturday=week_start_date+datetime.timedelta(days=6)\n",
    "            df['week_start_date']=week_start_date\n",
    "            df['week_end_date']=week_end_saturday\n",
    "            valassis=valassis.append(df)\n",
    "        else:\n",
    "            print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valassis['cost']=0\n",
    "valassis_DMA=valassis.copy()\n",
    "del valassis_DMA['date_in_file']\n",
    "valassis_DMA['media']='Circulation'\n",
    "valassis_DMA['submedia']='Valassis'\n",
    "valassis_DMA['placement']=\"xx\"\n",
    "\n",
    "valassis_DMA=valassis_DMA[['week_start_date','week_end_date','DMA','media','submedia','placement','impression','cost']]\n",
    "\n",
    "\n",
    "valassis_national=valassis.groupby(['week_start_date','week_end_date'])['impression','cost'].sum().reset_index()\n",
    "valassis_national['media']='Circulation'\n",
    "valassis_national['submedia']='Valassis'\n",
    "valassis_national['placement']=\"xx\"\n",
    "valassis_national=valassis_national[['week_start_date','week_end_date','media','submedia','placement','impression','cost']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "circulation_TMR_new=newspaper_DMA.append(valassis_DMA)\n",
    "circulation_TMR_old=pd.read_csv(\"/home/jian/Projects/Big_Lots/TMR/Circulation/output/circulation_TMR_JL_2018-08-14.csv\",dtype=str)\n",
    "circulation_TMR_old['week_start_date']=circulation_TMR_old['week_start_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "circulation_TMR_old['week_end_date']=circulation_TMR_old['week_end_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "circulation_TMR_old['impression']=circulation_TMR_old['impression'].astype(float)\n",
    "circulation_TMR_old['cost']=circulation_TMR_old['cost'].astype(float)\n",
    "circulation_TMR_all=circulation_TMR_old.append(circulation_TMR_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "circulation_TMR_all.to_csv(\"/home/jian/Projects/Big_Lots/TMR/Circulation/output/circulation_TMR_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "\n",
    "national_up_to_Q4_2018=circulation_TMR_all.groupby(['week_start_date','week_end_date'])['impression','cost'].sum().reset_index()\n",
    "national_up_to_Q4_2018.to_csv(\"/home/jian/Projects/Big_Lots/TMR/Circulation/output/circulation_natioanl_agged_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
