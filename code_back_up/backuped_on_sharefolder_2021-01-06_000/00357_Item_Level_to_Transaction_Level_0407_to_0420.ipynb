{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/celery/Google_LiveRamp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 weeks gap between 2019-04-06 to 2019-04-20\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import gc\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thismonday 2019-04-22\n",
      "last_week_end_saturday:  2019-04-20\n",
      "start_since_last_90_days:  2019-04-07\n"
     ]
    }
   ],
   "source": [
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "            \n",
    "\n",
    "\n",
    "thismonday=datetime.datetime.now().date()-datetime.timedelta(days=datetime.datetime.now().date().weekday())\n",
    "thismonday=datetime.date(2019,4,22)\n",
    "print(\"thismonday\", thismonday)\n",
    "\n",
    "last_week_end_saturday=thismonday-datetime.timedelta(days=2)\n",
    "\n",
    "print(\"last_week_end_saturday: \",last_week_end_saturday)\n",
    "\n",
    "start_since_last_90_days=last_week_end_saturday-datetime.timedelta(days=13)\n",
    "print(\"start_since_last_90_days: \",start_since_last_90_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 4, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_week_end_saturday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer_pather=\"/home/jian/celery/Google_LiveRamp/output/\"\n",
    "data_root_2019=\"/home/jian/BigLots/2019_by_weeks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jian/BigLots/2019_by_weeks/MediaStorm_2019-04-13/MediaStormDailySales20190416-112824-908.txt',\n",
       " '/home/jian/BigLots/2019_by_weeks/MediaStorm_2019-04-20/MediaStormDailySales20190423-112124-771.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_daily_list=[x for x in list(recursive_file_gen(data_root_2019)) if \"Daily\" in x]\n",
    "\n",
    "item_level_daily_df=pd.DataFrame({\"file_path\":files_daily_list})\n",
    "item_level_daily_df['week_end_dt']=item_level_daily_df['file_path'].apply(lambda x: x.split(\"_weeks/MediaStorm_\")[1][:10])\n",
    "item_level_daily_df=item_level_daily_df[(item_level_daily_df['week_end_dt']>=str(start_since_last_90_days)) & (item_level_daily_df['week_end_dt']<=str(last_week_end_saturday))]\n",
    "item_level_daily_df=item_level_daily_df.sort_values(\"week_end_dt\")\n",
    "item_level_daily_df\n",
    "\n",
    "item_level_daily_df['file_path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2019-04-26 15:32:34.603622\n",
      "2 2019-04-26 15:34:31.012155\n",
      "2019-04-07\n",
      "2019-04-20\n"
     ]
    }
   ],
   "source": [
    "i_counter=0\n",
    "data_to_upload=pd.DataFrame()\n",
    "\n",
    "for file_item_level in item_level_daily_df['file_path'].tolist():\n",
    "    df=pd.read_table(file_item_level,sep=\"|\",dtype=str,usecols=['location_id','customer_id_hashed','transaction_dt','item_transaction_amt'])\n",
    "    df=df[~pd.isnull(df['customer_id_hashed'])]\n",
    "    df=df[df['location_id']!=\"6990\"]\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    df=df.groupby(['customer_id_hashed','transaction_dt'])['item_transaction_amt'].sum().to_frame().reset_index()\n",
    "    df=df.rename(columns={\"transaction_dt\":\"transaction_timestamp\",\"item_transaction_amt\":\"Conversion_Amount\"})\n",
    "    df['transaction_timestamp']=df['transaction_timestamp'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "    data_to_upload=data_to_upload.append(df)\n",
    "    i_counter+=1\n",
    "    print(i_counter,datetime.datetime.now())\n",
    "print(data_to_upload['transaction_timestamp'].min())\n",
    "print(data_to_upload['transaction_timestamp'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path        date\n",
       "0  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-04-20\n",
       "1  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-04-13\n",
       "2  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-04-06\n",
       "3  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-30\n",
       "4  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_2019_weekly=[x for x in list(recursive_file_gen(\"/home/jian/BigLots/2019_by_weeks/\")) if (\"aster\" in x) & (\".txt\" in x) ]\n",
    "Master_2018_weekly=[x for x in list(recursive_file_gen(\"/home/jian/BigLots/2018_by_weeks/\")) if (\"aster\" in x) & (\".txt\" in x) ]\n",
    "\n",
    "\n",
    "weekly_df=pd.DataFrame({\"file_path\":Master_2019_weekly+Master_2018_weekly})\n",
    "weekly_df['date']=weekly_df['file_path'].apply(lambda x: x.split(\"_by_weeks/MediaStorm_\")[1][:10])\n",
    "weekly_df['date']=weekly_df['date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "weekly_df=weekly_df.sort_values(\"date\",ascending=False).reset_index()\n",
    "del weekly_df['index']\n",
    "weekly_df.head(5)\n",
    "\n",
    "# No need for the recent posibble file foloder, but added later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1873409, 3)\n"
     ]
    }
   ],
   "source": [
    "data_0=pd.read_table(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/MediaStorm_Lapsed_Reward_Member_Master_from2014-08-26to2017-02-26.zip\",\n",
    "                     dtype=str,sep=\"|\",usecols=['customer_id_hashed','email_address_hash','customer_zip_code']).drop_duplicates()\n",
    "print(data_0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19337597, 3)\n"
     ]
    }
   ],
   "source": [
    "data_1=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/MediaStormCustTot-hashed-email.txt\",\n",
    "                     dtype=str,header=None,usecols=[0,1,5])\n",
    "data_1.columns=['customer_id_hashed','email_address_hash','customer_zip_code']\n",
    "data_1['customer_id_hashed']=data_1['customer_id_hashed'].apply(lambda x: hashlib.sha256(x.encode('utf-8')).hexdigest())\n",
    "print(data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7255226, 3)\n",
      "(5759051, 3)\n",
      "(659127, 3)\n"
     ]
    }
   ],
   "source": [
    "data_2 = pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/'+'MediaStormCustomerTransactionTotals_2018-01-09_2018-03-31.txt',\n",
    "                     sep = ',',dtype = str,usecols=['customer_id_hashed','email_address_hash','customer_zip_code'])\n",
    "print(data_2.shape)\n",
    "data_3 = pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/'+'Existing Reward Member Master as of 2018-06-05.txt',\n",
    "                     dtype = str,sep = '|',usecols=['customer_id_hashed','email_address_hash','customer_zip_code'])\n",
    "print(data_3.shape)\n",
    "data_4 = pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/'+'New Reward Member Master as of 2018-06-05.txt',\n",
    "                     dtype = str,sep = '|',usecols=['customer_id_hashed','email_address_hash','customer_zip_code'])\n",
    "print(data_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_old=data_4.append(data_3).append(data_2).append(data_1).append(data_0).drop_duplicates()\n",
    "del data_4\n",
    "del data_3\n",
    "del data_2\n",
    "del data_1\n",
    "del data_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25262335, 3)\n",
      "25227572\n",
      "(25227572, 3)\n"
     ]
    }
   ],
   "source": [
    "all_weekly_biweekly_master_file=pd.DataFrame()\n",
    "for file_path in weekly_df['file_path'].tolist():\n",
    "    df=pd.read_table(file_path,dtype=str,usecols=['customer_id_hashed','email_address_hash','customer_zip_code'],sep=\"|\")\n",
    "    all_weekly_biweekly_master_file=all_weekly_biweekly_master_file.append(df)\n",
    "\n",
    "all_weekly_biweekly_master_file=all_weekly_biweekly_master_file.append(master_old)\n",
    "print(all_weekly_biweekly_master_file.shape)\n",
    "print(len(all_weekly_biweekly_master_file['customer_id_hashed'].unique()))\n",
    "\n",
    "all_weekly_biweekly_master_file=all_weekly_biweekly_master_file.drop_duplicates('customer_id_hashed')\n",
    "print(all_weekly_biweekly_master_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2834712, 3)\n",
      "(2834712, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>transaction_timestamp</th>\n",
       "      <th>Conversion_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000435bfb3bf42e3beb4c9b3942c552d09f0e49e5a75...</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>13.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001ccfc0c1cd025b75bb8463ecb11b85b1e4d632b13e...</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>21.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed transaction_timestamp  \\\n",
       "0  00000435bfb3bf42e3beb4c9b3942c552d09f0e49e5a75...            2019-04-07   \n",
       "1  00001ccfc0c1cd025b75bb8463ecb11b85b1e4d632b13e...            2019-04-07   \n",
       "\n",
       "   Conversion_Amount  \n",
       "0              13.04  \n",
       "1              21.38  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_to_upload.shape)\n",
    "print(data_to_upload[['customer_id_hashed','transaction_timestamp']].drop_duplicates().shape)\n",
    "\n",
    "data_to_upload.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_Raws: 2834712\n",
      "Null Email rows excluded: 182323\n",
      "Na_Email_Rows_Pctg:  0.06431799773663074\n"
     ]
    }
   ],
   "source": [
    "data_to_upload=pd.merge(data_to_upload,all_weekly_biweekly_master_file,on=\"customer_id_hashed\",how=\"left\").rename(columns={\"email_address_hash\":\"Email_1\",\"customer_zip_code\":\"Zip_Code\"})\n",
    "data_to_upload.head(2)\n",
    "\n",
    "total_rows_with_na_str=str(data_to_upload.shape[0])\n",
    "print(\"Total_Raws: \"+total_rows_with_na_str)\n",
    "na_emails_rows_count_str=str(data_to_upload[pd.isnull(data_to_upload['Email_1'])].shape[0])\n",
    "print(\"Null Email rows excluded: \"+na_emails_rows_count_str)\n",
    "data_to_upload=data_to_upload[~pd.isnull(data_to_upload['Email_1'])]\n",
    "del data_to_upload['customer_id_hashed']\n",
    "\n",
    "print(\"Na_Email_Rows_Pctg: \",int(na_emails_rows_count_str)/int(total_rows_with_na_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_timestamp</th>\n",
       "      <th>Conversion_Amount</th>\n",
       "      <th>Email_1</th>\n",
       "      <th>Zip_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>13.04</td>\n",
       "      <td>e7b239d884e48cdd957205e0ffb8e793bb7b8a391dc102...</td>\n",
       "      <td>21229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>b76d9f13b2d47726edf73e99c553857699217daee94187...</td>\n",
       "      <td>38301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_timestamp  Conversion_Amount  \\\n",
       "0            2019-04-07              13.04   \n",
       "5            2019-04-12               0.00   \n",
       "\n",
       "                                             Email_1 Zip_Code  \n",
       "0  e7b239d884e48cdd957205e0ffb8e793bb7b8a391dc102...    21229  \n",
       "5  b76d9f13b2d47726edf73e99c553857699217daee94187...    38301  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_upload.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_to_upload=data_to_upload[[\"Email_1\",\"Zip_Code\",\"transaction_timestamp\", \"Conversion_Amount\"]].rename(columns={\"Conversion_Amount\":\"transaction_amount\"})\n",
    "data_to_upload['transaction_amount']=data_to_upload['transaction_amount'].apply(lambda x: np.round(x,2)).astype(str)\n",
    "data_to_upload['transaction_amount']=data_to_upload['transaction_amount'].apply(lambda x: x.split(\".\")[0]+\".\"+x.split(\".\")[1].ljust(2,\"0\"))\n",
    "data_to_upload['transaction_category']=\"In_Store\"\n",
    "\n",
    "data_to_upload['Zip_Code']=\"00000\"\n",
    "\n",
    "data_to_upload=data_to_upload[['Zip_Code','Email_1','transaction_category','transaction_timestamp','transaction_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 4, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_max_date=data_to_upload['transaction_timestamp'].max()\n",
    "data_max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 4, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_min_date=data_to_upload['transaction_timestamp'].min()\n",
    "data_min_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2652389, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_upload.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_max_date-data_min_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_to_upload['transaction_timestamp'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/celery/Google_LiveRamp/output/'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer_pather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_path=writer_pather+\"BL_LR_GoogleStoreSales_2_weeks_\"+str(data_min_date)+\"_\"+str(data_max_date)+\"_JL_\"+str(datetime.datetime.now().date())+\".txt\"\n",
    "data_to_upload.columns.tolist()==['Zip_Code','Email_1','transaction_category','transaction_timestamp','transaction_amount']\n",
    "\n",
    "data_to_upload.to_csv(local_path,index=False,sep=\"|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121112921.32000002"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_upload['transaction_amount'].astype(float).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip_Code</th>\n",
       "      <th>Email_1</th>\n",
       "      <th>transaction_category</th>\n",
       "      <th>transaction_timestamp</th>\n",
       "      <th>transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000</td>\n",
       "      <td>e7b239d884e48cdd957205e0ffb8e793bb7b8a391dc102...</td>\n",
       "      <td>In_Store</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>13.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00000</td>\n",
       "      <td>b76d9f13b2d47726edf73e99c553857699217daee94187...</td>\n",
       "      <td>In_Store</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00000</td>\n",
       "      <td>7518e767bba85d75e674b111c6edfba4c99e55667dac57...</td>\n",
       "      <td>In_Store</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>22.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00000</td>\n",
       "      <td>1a9849562f60f238e3ebd2c89842113e5a1ff6e9bae9ee...</td>\n",
       "      <td>In_Store</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>78.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00000</td>\n",
       "      <td>3f029ca17f7d6d7c711c18b63ebd245798a8efd2b386d8...</td>\n",
       "      <td>In_Store</td>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Zip_Code                                            Email_1  \\\n",
       "0    00000  e7b239d884e48cdd957205e0ffb8e793bb7b8a391dc102...   \n",
       "5    00000  b76d9f13b2d47726edf73e99c553857699217daee94187...   \n",
       "6    00000  7518e767bba85d75e674b111c6edfba4c99e55667dac57...   \n",
       "7    00000  1a9849562f60f238e3ebd2c89842113e5a1ff6e9bae9ee...   \n",
       "8    00000  3f029ca17f7d6d7c711c18b63ebd245798a8efd2b386d8...   \n",
       "\n",
       "  transaction_category transaction_timestamp transaction_amount  \n",
       "0             In_Store            2019-04-07              13.04  \n",
       "5             In_Store            2019-04-12               0.00  \n",
       "6             In_Store            2019-04-10              22.43  \n",
       "7             In_Store            2019-04-07              78.26  \n",
       "8             In_Store            2019-04-12               8.00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_upload.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_path==\"/home/jian/celery/Google_LiveRamp/output/BL_LR_GoogleStoreSales_2_weeks_2019-04-07_2019-04-20_JL_2019-04-26.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56331591311627915"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Around\n",
    "data_to_upload['transaction_amount'].astype(float).sum()/215000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import paramiko\n",
    "\n",
    "host = \"sftp.liveramp.com\" #hard-coded\n",
    "port = 22\n",
    "transport = paramiko.Transport((host, port))\n",
    "\n",
    "password = \"Jubaplus2019!\" #hard-coded\n",
    "username = \"big-lots-ga-aw\" #hard-coded\n",
    "transport.connect(username = username, password = password)\n",
    "sftp = paramiko.SFTPClient.from_transport(transport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# local_path defined above before saving the local txt\n",
    "remote_path=\"/uploads/\"+os.path.basename(local_path)\n",
    "sftp.put(local_path,remote_path)\n",
    "sftp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
