{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lapsed Start on: 2015-04-05\n",
      "Active Start on: 2018-04-01\n",
      "Scoring Start on: 2017-10-01\n",
      "Last Saturday: 2019-03-30\n"
     ]
    }
   ],
   "source": [
    "# Changed back to the RFM scoring and using the old method\n",
    "# Fill the lapsed with \"L\" group\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import hashlib\n",
    "import gc\n",
    "import glob\n",
    "logging.basicConfig(filename='CRM_newscore_2019Q2.log', level=logging.INFO)\n",
    "logging.info('Started')\n",
    "\n",
    "samplerows = None\n",
    "\n",
    "lastdate = datetime.date(2019,3,30) # Recent Saturday\n",
    "active_Sunday = str(lastdate-datetime.timedelta(days=52*7-1))\n",
    "lapsed_Sunday = str(lastdate-datetime.timedelta(days=52*7*4-1))\n",
    "Beginning_18_months_ago=str(lastdate-datetime.timedelta(days=52*7*1.5-1))\n",
    "lastdate=str(lastdate)\n",
    "print(\"Lapsed Start on: \"+lapsed_Sunday) #>=\n",
    "print(\"Active Start on: \"+active_Sunday) #>=\n",
    "print(\"Scoring Start on: \"+Beginning_18_months_ago) #>=\n",
    "print(\"Last Saturday: \"+lastdate) #<=\n",
    "\n",
    "\n",
    "folder_write = '/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2019Q2/output_'+str(datetime.datetime.now().date())+'/'\n",
    "try:\n",
    "    os.stat(folder_write)\n",
    "except:\n",
    "    os.mkdir(folder_write)\n",
    "    \n",
    "# Adding control members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2019-04-12 10:45:24.459670\n",
      "2 2019-04-12 10:46:17.315953\n",
      "3 2019-04-12 10:47:02.558216\n",
      "4 2019-04-12 10:48:05.879345\n",
      "5 2019-04-12 10:49:14.009180\n",
      "6 2019-04-12 10:50:02.740514\n",
      "7 2019-04-12 10:50:46.684698\n",
      "8 2019-04-12 10:51:30.171693\n",
      "9 2019-04-12 10:52:14.589230\n",
      "10 2019-04-12 10:53:05.927263\n",
      "11 2019-04-12 10:54:01.709333\n",
      "12 2019-04-12 10:55:04.356556\n",
      "13 2019-04-12 10:56:08.963409\n",
      "14 2019-04-12 10:57:23.544976\n",
      "15 2019-04-12 10:58:22.686567\n",
      "Earliest Date:2016-06-26\n",
      "Deduped 2019-04-12 11:18:30.216930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the 1st date\n",
    "\n",
    "chunksize_num = 10**7\n",
    "filename='/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2019Q1/crm_newscore_0922/combinedtransactions_0922.csv'\n",
    "dftrans_before_20180922=pd.DataFrame()\n",
    "count_i=0\n",
    "\n",
    "for chunk in pd.read_csv(filename, chunksize=chunksize_num,dtype=str,usecols=['customer_id_hashed','transaction_date','transaction_time',\n",
    "                   'transaction_id','location_id','total_transaction_amt']): #Add back the transaction info\n",
    "    chunk['total_transaction_amt']=chunk['total_transaction_amt'].astype(float)\n",
    "    chunk = chunk.drop_duplicates()\n",
    "    \n",
    "    dftrans_before_20180922=dftrans_before_20180922.append(chunk)\n",
    "    count_i+=1\n",
    "    print(count_i,datetime.datetime.now())\n",
    "    \n",
    "\n",
    "'''\n",
    "dftrans_before_20180922 = pd.read_csv('/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update/crm_newscore_0922/combinedtransactions_0922.csv',dtype=str)\n",
    "#dftrans = dftrans[dftrans['transaction_date']>=lapsed]\n",
    "dftrans_before_20180922['total_transaction_amt']=dftrans_before_20180922['total_transaction_amt'].astype(float)\n",
    "dftrans_before_20180922['total_transaction_units']=dftrans_before_20180922['total_transaction_units'].astype(float)\n",
    "\n",
    "dftrans_before_20180922 = dftrans_before_20180922[['customer_id_hashed','transaction_date','transaction_time',\n",
    "                   'transaction_id','location_id','total_transaction_units',\n",
    "                   'total_transaction_amt']].drop_duplicates()\n",
    "'''\n",
    "\n",
    "del chunk\n",
    "print(\"Earliest Date:\" + str(dftrans_before_20180922['transaction_date'].min()))\n",
    "\n",
    "dftrans_before_20180922=dftrans_before_20180922.drop_duplicates()\n",
    "\n",
    "print(\"Deduped\",datetime.datetime.now())\n",
    "\n",
    "\n",
    "logging.info(\"Deduped: \"+str(datetime.datetime.now()))\n",
    "del dftrans_before_20180922['transaction_time']\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n",
      "Min_Date: 2018-09-29\n",
      "Max_Date: 2019-02-09\n"
     ]
    }
   ],
   "source": [
    "def recrusive_file_gen(root_folder):\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "# Up to 2019-03-30 \n",
    "historical_daily_data_folder=\"/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/\"\n",
    "historical_daily_data_list=list(recrusive_file_gen(historical_daily_data_folder))\n",
    "historical_daily_data_list=[x for x in historical_daily_data_list if (\".txt\" in x) & (\"DailySales\" in x)]\n",
    "historical_daily_df=pd.DataFrame({\"file_path\":historical_daily_data_list})\n",
    "historical_daily_df['week_end_dt']=historical_daily_df['file_path'].apply(lambda x: x.split(\".\")[0].split(\"MediaStormDailySalesHistory\")[1])\n",
    "historical_daily_df['week_end_dt']=historical_daily_df['week_end_dt'].apply(lambda x: datetime.datetime.strptime(x,\"%Y%m%d\").date())\n",
    "historical_daily_df=historical_daily_df[historical_daily_df['week_end_dt']<=datetime.date(2019,3,31)]\n",
    "historical_daily_df=historical_daily_df[historical_daily_df['week_end_dt']>datetime.date(2018,9,22)]\n",
    "print(historical_daily_df.shape)\n",
    "print(\"Min_Date: \"+str(historical_daily_df['week_end_dt'].min()))\n",
    "print(\"Max_Date: \"+str(historical_daily_df['week_end_dt'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2)\n",
      "Min_Date: 2019-02-16\n",
      "Max_Date: 2019-03-30\n"
     ]
    }
   ],
   "source": [
    "new_daily_data_folder=\"/home/jian/BigLots/2019_by_weeks/\"\n",
    "new_daily_data_list=list(recrusive_file_gen(new_daily_data_folder))\n",
    "new_daily_data_list=[x for x in new_daily_data_list if (\".txt\" in x) & (\"DailySales\" in x)]\n",
    "new_daily_data_list=[x for x in new_daily_data_list if \"hist\" not in x]\n",
    "\n",
    "new_daily_df=pd.DataFrame({\"file_path\":new_daily_data_list})\n",
    "\n",
    "new_daily_df['week_end_dt']=new_daily_df['file_path'].apply(lambda x: x.split(\".\")[0].split(\"2019_by_weeks/MediaStorm_\")[1][:10])\n",
    "new_daily_df['week_end_dt']=new_daily_df['week_end_dt'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "new_daily_df=new_daily_df[new_daily_df['week_end_dt']>historical_daily_df['week_end_dt'].max()]\n",
    "new_daily_df=new_daily_df[new_daily_df['week_end_dt']<=datetime.date(2019,3,31)]\n",
    "print(new_daily_df.shape)\n",
    "print(\"Min_Date: \"+str(new_daily_df['week_end_dt'].min()))\n",
    "print(\"Max_Date: \"+str(new_daily_df['week_end_dt'].max()))\n",
    "\n",
    "daily_df_file_after_20180922=historical_daily_df.append(new_daily_df)\n",
    "new_dailysales_files=daily_df_file_after_20180922['file_path'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 27\n",
      "1 done 2019-04-12 11:20:12.607483\n",
      "2 done 2019-04-12 11:21:05.715433\n",
      "3 done 2019-04-12 11:21:46.644834\n",
      "4 done 2019-04-12 11:22:29.117383\n",
      "5 done 2019-04-12 11:23:14.552269\n",
      "6 done 2019-04-12 11:24:02.240329\n",
      "7 done 2019-04-12 11:24:53.153709\n",
      "8 done 2019-04-12 11:25:52.811013\n",
      "9 done 2019-04-12 11:27:14.066929\n",
      "10 done 2019-04-12 11:28:34.582356\n",
      "11 done 2019-04-12 11:30:21.403691\n",
      "12 done 2019-04-12 11:32:03.484094\n",
      "13 done 2019-04-12 11:34:12.357863\n",
      "14 done 2019-04-12 11:35:30.620907\n",
      "15 done 2019-04-12 11:36:30.473861\n",
      "16 done 2019-04-12 11:37:24.836252\n",
      "17 done 2019-04-12 11:38:27.325814\n",
      "18 done 2019-04-12 11:39:39.233348\n",
      "19 done 2019-04-12 11:40:38.345814\n",
      "20 done 2019-04-12 11:41:38.082813\n",
      "21 done 2019-04-12 11:42:47.101810\n",
      "22 done 2019-04-12 11:43:57.876579\n",
      "23 done 2019-04-12 11:45:12.994440\n",
      "24 done 2019-04-12 11:46:23.356492\n",
      "25 done 2019-04-12 11:47:29.710666\n",
      "26 done 2019-04-12 11:48:38.063287\n",
      "27 done 2019-04-12 11:49:46.923144\n"
     ]
    }
   ],
   "source": [
    "combined_rewards_transaction_after_20180922_agg=pd.DataFrame() \n",
    "count_i=1\n",
    "print(\"Total Files: \"+str(len(new_dailysales_files)))\n",
    "for file_daily in new_dailysales_files:\n",
    "    df=pd.read_table(file_daily,nrows = None,sep= '|',dtype =str,usecols=['customer_id_hashed','transaction_dt','transaction_id','location_id','item_transaction_amt'])\n",
    "    df=df[~pd.isnull(df['customer_id_hashed'])]\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    df=df.groupby(['customer_id_hashed','transaction_dt','transaction_id','location_id'])['item_transaction_amt'].sum().to_frame().reset_index()\n",
    "    # df=df.drop_duplicates()\n",
    "\n",
    "    \n",
    "    combined_rewards_transaction_after_20180922_agg=combined_rewards_transaction_after_20180922_agg.append(df)\n",
    "    print(count_i,\"done\",datetime.datetime.now())\n",
    "    count_i+=1\n",
    "del df\n",
    "gc.collect()\n",
    "combined_rewards_transaction_after_20180922_agg=combined_rewards_transaction_after_20180922_agg.rename(columns={\"transaction_dt\":\"transaction_date\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "combined_rewards_transaction_after_20180922_agg=combined_rewards_transaction_after_20180922_agg.groupby(['customer_id_hashed','transaction_date','transaction_id','location_id'])['item_transaction_amt'].sum().to_frame().reset_index()\n",
    "combined_rewards_transaction_after_20180922_agg=combined_rewards_transaction_after_20180922_agg.rename(columns={\"item_transaction_amt\":\"total_transaction_amt\"})\n",
    "\n",
    "all_rewards_since_201606=dftrans_before_20180922.append(combined_rewards_transaction_after_20180922_agg)\n",
    "\n",
    "del dftrans_before_20180922\n",
    "del combined_rewards_transaction_after_20180922_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards_since_201606.to_csv(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2019Q2/BL_Rewards_Transactions_18_months_to_20190330_JL_\"+str(datetime.datetime.now().date())+\".csv\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>total_transaction_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74861588</th>\n",
       "      <td>00000135f48c68690ad3d5fc9ada41bb5cd687452007e8...</td>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>6044</td>\n",
       "      <td>1292</td>\n",
       "      <td>32.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148150940</th>\n",
       "      <td>000001dadc0265bf9d250566d74e0006323f18b5826641...</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>1317</td>\n",
       "      <td>4061</td>\n",
       "      <td>58.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          customer_id_hashed transaction_date  \\\n",
       "74861588   00000135f48c68690ad3d5fc9ada41bb5cd687452007e8...       2017-01-19   \n",
       "148150940  000001dadc0265bf9d250566d74e0006323f18b5826641...       2018-09-22   \n",
       "\n",
       "          transaction_id location_id  total_transaction_amt  \n",
       "74861588            6044        1292                   32.8  \n",
       "148150940           1317        4061                   58.7  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards_since_201606.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Lapsed data\\n\\nlapsed=pd.read_table(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_sales_data/lapsed20140826_20170226/MediaStormLapsedCustDtl.txt\",\\n                     sep=\",\",usecols=[\\'customer_id_hashed\\',\\'transaction_date\\'],dtype=str) # Doesn\\'t go to score at all, so no need to read all columns\\n\\nprint(\"Lapsed earliest:\" + lapsed[\\'transaction_date\\'].min())\\nprint(\"Lapsed newest:\" + lapsed[\\'transaction_date\\'].max())\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# Lapsed data\n",
    "\n",
    "lapsed=pd.read_table(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_sales_data/lapsed20140826_20170226/MediaStormLapsedCustDtl.txt\",\n",
    "                     sep=\",\",usecols=['customer_id_hashed','transaction_date'],dtype=str) # Doesn't go to score at all, so no need to read all columns\n",
    "\n",
    "print(\"Lapsed earliest:\" + lapsed['transaction_date'].min())\n",
    "print(\"Lapsed newest:\" + lapsed['transaction_date'].max())\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24905063, 4)\n",
      "(20569010, 2)\n"
     ]
    }
   ],
   "source": [
    "#Getting the store for an id\n",
    "\n",
    "frequently_visit_stores_18_months=all_rewards_since_201606[all_rewards_since_201606['transaction_date']>=Beginning_18_months_ago]\n",
    "\n",
    "frequently_visit_stores_2=frequently_visit_stores_18_months.groupby(['customer_id_hashed','location_id'])['total_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"total_transaction_amt\":\"sales\"})\n",
    "frequently_visit_stores_18_months=frequently_visit_stores_18_months.groupby(['customer_id_hashed','location_id'])['transaction_id'].count().to_frame().reset_index().rename(columns={\"transaction_id\":\"trans\"})\n",
    "\n",
    "frequently_visit_stores_18_months=pd.merge(frequently_visit_stores_18_months,frequently_visit_stores_2,on=['customer_id_hashed','location_id'],how=\"outer\")\n",
    "del frequently_visit_stores_2\n",
    "print(frequently_visit_stores_18_months.shape)\n",
    "frequently_visit_stores_18_months=frequently_visit_stores_18_months.sort_values(['customer_id_hashed','trans','sales'],ascending=[True,False,False])\n",
    "\n",
    "frequently_visit_stores_18_months=frequently_visit_stores_18_months[['customer_id_hashed','location_id']].drop_duplicates(\"customer_id_hashed\")\n",
    "print(frequently_visit_stores_18_months.shape)\n",
    "frequently_visit_stores_18_months.to_csv(folder_write+\"frequently_visit_stores_18_months.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the registeration master file to fetch the location_id when registers if no transactions recorded\n",
    "# To be added\n",
    "# Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-06-26\n",
      "2019-03-30\n"
     ]
    }
   ],
   "source": [
    "###get recency\n",
    "dfrecency=all_rewards_since_201606[['customer_id_hashed','transaction_date']].sort_values(\"transaction_date\",ascending=False).drop_duplicates()#Allready combined\n",
    "\n",
    "print (min(dfrecency['transaction_date']))\n",
    "print (max(dfrecency['transaction_date']))\n",
    "dfrecency = dfrecency.drop_duplicates('customer_id_hashed')\n",
    "dfrecency.to_csv(folder_write + 'dfrecency.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25770895, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfrecency['transaction_date'] = pd.to_datetime(dfrecency['transaction_date'])\n",
    "dfrecency['recency'] =  datetime.datetime.strptime(str(lastdate), '%Y-%m-%d').date() - dfrecency['transaction_date']\n",
    "dfrecency['recency'] = dfrecency['recency'].apply(lambda x:x.days)\n",
    "dfrecency['recency'] = np.ceil((dfrecency['recency']+1)/30)\n",
    "\n",
    "dfrecency = dfrecency[['customer_id_hashed','recency']]\n",
    "dfrecency = dfrecency.drop_duplicates('customer_id_hashed')\n",
    "dfrecency.to_csv(folder_write + 'dfrecency2.csv',index = False)\n",
    "\n",
    "dfrecency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-12 12:37:28.651520 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-01-12/MediaStormMasterBiWeekly20190115-132855-055.txt\n",
      "2019-04-12 12:37:34.832000 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-01-26/MediaStormMasterBiWeekly20190129-130902-016.txt\n",
      "2019-04-12 12:37:40.593709 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-02-02/MediaStormMasterWeekly20190205-111610-675.txt\n",
      "2019-04-12 12:37:46.546554 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-02-09/MediaStormMasterWeekly20190212-122428-267.txt\n",
      "2019-04-12 12:37:52.081384 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-02-16/MediaStormMasterWeekly20190219-113650-867.txt\n",
      "2019-04-12 12:37:57.978011 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-02-23/MediaStormMasterWeekly20190226-112921-061.txt\n",
      "2019-04-12 12:38:03.707337 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-03-02/MediaStormMasterWeekly20190305-112945-302.txt\n",
      "2019-04-12 12:38:09.461360 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-03-09/MediaStormMasterWeekly20190312-121512-232.txt\n",
      "2019-04-12 12:38:14.977940 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-03-16/MediaStormMasterWeekly20190319-112932-415.txt\n",
      "2019-04-12 12:38:20.607291 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-03-23/MediaStormMasterWeekly20190326-113052-887.txt\n",
      "2019-04-12 12:38:25.885679 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-03-30/MediaStormMasterWeekly20190402-113131-172.txt\n",
      "2019-04-12 12:38:32.115296 /home/jian/BigLots/2019_by_weeks/MediaStorm_2019-04-06/MediaStormMasterWeekly20190409-124125-588.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfiddetail = pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/combined_masterids_up_to_20181229_JL.csv',nrows = samplerows)\n",
    "dfiddetail = dfiddetail.drop_duplicates('customer_id_hashed')\n",
    "#####\n",
    "new_sign_ups_2019_list=list(recrusive_file_gen(\"/home/jian/BigLots/2019_by_weeks/\"))\n",
    "new_sign_ups_2019_list=sorted([x for x in new_sign_ups_2019_list if \"ster\" in x])\n",
    "for file_nnew_signups in new_sign_ups_2019_list:\n",
    "    df=pd.read_table(file_nnew_signups,dtype=str,usecols=['customer_id_hashed','email_address_hash','customer_zip_code'],sep=\"|\")\n",
    "    dfiddetail=df.append(dfiddetail) # Already sorted and newest kept on the top\n",
    "    print(datetime.datetime.now(),file_nnew_signups)\n",
    "dfiddetail=dfiddetail.drop_duplicates(\"customer_id_hashed\")\n",
    "\n",
    "######\n",
    "dfiddetail2 = pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/MediaStorm_Lapsed_Reward_Member_Master_from2014-08-26to2017-02-26.zip',\n",
    "                     nrows = samplerows,dtype = 'str',sep = '|',\n",
    "                       usecols = ['customer_id_hashed','email_address_hash','customer_zip_code'])\n",
    "dfiddetail = dfiddetail.append(dfiddetail2,ignore_index = True)\n",
    "dfiddetail = dfiddetail.drop_duplicates('customer_id_hashed')\n",
    "dfiddetail = dfiddetail.drop_duplicates('email_address_hash')\n",
    "\n",
    "del dfiddetail2\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards_since_201606['transactions'] = 1\n",
    "dftotal = all_rewards_since_201606[['customer_id_hashed','total_transaction_amt','transactions']].groupby(['customer_id_hashed']).sum().reset_index().rename(columns={\"total_transaction_amt\":\"sales\"})\n",
    "\n",
    "dftotal = pd.merge(dftotal,dfrecency,on = 'customer_id_hashed',how='outer')\n",
    "del dfrecency\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal = dftotal.sort_values(['transactions','recency','sales'],ascending = [0,1,0])\n",
    "dftotal.reset_index(drop = True, inplace = True)\n",
    "dftotal.reset_index(inplace = True)\n",
    "dftotal = dftotal.rename(columns = {'index':'Transindex'})\n",
    "\n",
    "dftotal = dftotal.sort_values(['sales','recency','transactions'],ascending = [0,1,0])\n",
    "dftotal.reset_index(drop = True, inplace = True)\n",
    "dftotal.reset_index(inplace = True)\n",
    "dftotal = dftotal.rename(columns = {'index':'Amtindex'})\n",
    "\n",
    "dftotal = dftotal.sort_values(['recency','transactions','sales'],ascending = [1,0,0])\n",
    "dftotal.reset_index(drop = True, inplace = True)\n",
    "dftotal.reset_index(inplace = True)\n",
    "dftotal = dftotal.rename(columns = {'index':'recencyindex'})\n",
    "\n",
    "c_ids = len(dftotal.index)\n",
    "logging.info('total customers from transaction and amt: ')\n",
    "logging.info(c_ids)\n",
    "c_ids = np.ceil(c_ids/5.0)\n",
    "\n",
    "dftotal['Transindex'] = np.ceil((dftotal['Transindex']+1)/c_ids)\n",
    "dftotal['Amtindex'] = np.ceil((dftotal['Amtindex']+1)/c_ids)\n",
    "dftotal['recencyindex'] = np.ceil((dftotal['recencyindex']+1)/c_ids)\n",
    "\n",
    "dftotal['RFM'] = dftotal['recencyindex']*100 + dftotal['Transindex']*10 + dftotal['Amtindex']\n",
    "'''\n",
    "dftotal = dftotal.sort_values(['RFM','recency','transactions',\n",
    "                               'sales'],ascending = [1,1,0,0])\n",
    "\n",
    "\n",
    "dftotal.reset_index(drop = True, inplace = True)\n",
    "dftotal.reset_index(inplace = True)\n",
    "dftotal = dftotal.rename(columns = {'index':'frmindex'})\n",
    "c_ids = len(dftotal.index)\n",
    "c_ids = np.ceil(c_ids/10.0)\n",
    "dftotal['frmindex'] = np.ceil((dftotal['frmindex']+1)/c_ids)\n",
    "\n",
    "dftotal.to_csv(folder_write + 'dfrfm.csv',index = False)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "dftotal = pd.read_csv(folder_write + 'dfrfm.csv')\n",
    "'''\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "dftotal = dftotal[['customer_id_hashed','RFM','recency','transactions','sales']]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['active' 'lapsed']\n",
      "25083173\n",
      "totalids_trans: 25770895\n",
      "totalids_trans_mergewithmaster: 24077565\n"
     ]
    }
   ],
   "source": [
    "# In[15]:\n",
    "dfrecency = pd.read_csv(folder_write + 'dfrecency.csv')\n",
    "dfrecency['active'] = np.where(dfrecency['transaction_date']>=active_Sunday,'active',\n",
    "                    np.where(dfrecency['transaction_date']>=lapsed_Sunday,'lapsed','other'))\n",
    "print(dfrecency['active'].unique())\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "dftotal = pd.merge(dftotal,dfrecency[['customer_id_hashed','active']],on = 'customer_id_hashed')\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "dfiddetail['customer_zip_code'] = dfiddetail['customer_zip_code'].astype('str')\n",
    "dfiddetail['customer_zip_code'] = dfiddetail['customer_zip_code'].str[0:5]\n",
    "dfiddetail['customer_zip_code'].fillna('00000',inplace = True)\n",
    "dfiddetail['customer_zip_code'] = dfiddetail['customer_zip_code'].apply(lambda x:x.zfill(5))\n",
    "print(len(dfiddetail.index))\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "print(\"totalids_trans:\",len(dftotal.index))\n",
    "dftotal = pd.merge(dftotal,dfiddetail,on = 'customer_id_hashed') #drop_duplicates with inner merge\n",
    "print(\"totalids_trans_mergewithmaster:\",len(dftotal.index))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>RFM</th>\n",
       "      <th>recency</th>\n",
       "      <th>transactions</th>\n",
       "      <th>sales</th>\n",
       "      <th>active</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>customer_zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1979</td>\n",
       "      <td>31812.53</td>\n",
       "      <td>active</td>\n",
       "      <td>4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...</td>\n",
       "      <td>28607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14b78c9088ecdbde7a771c49664157cfe588f86ae5ce5c...</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1919</td>\n",
       "      <td>42819.02</td>\n",
       "      <td>active</td>\n",
       "      <td>d72cf03e94da3a0f89abc29df597ff699420ab1c2671b3...</td>\n",
       "      <td>87501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed    RFM  recency  \\\n",
       "0  b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...  111.0      1.0   \n",
       "1  14b78c9088ecdbde7a771c49664157cfe588f86ae5ce5c...  111.0      1.0   \n",
       "\n",
       "   transactions     sales  active  \\\n",
       "0          1979  31812.53  active   \n",
       "1          1919  42819.02  active   \n",
       "\n",
       "                                  email_address_hash customer_zip_code  \n",
       "0  4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...             28607  \n",
       "1  d72cf03e94da3a0f89abc29df597ff699420ab1c2671b3...             87501  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P' 'S' nan 'T']\n",
      "['P' 'S' 'T']\n",
      "Final wemailcsv: (24077565, 10)\n"
     ]
    }
   ],
   "source": [
    "dftotal = dftotal.sort_values(['RFM','recency','transactions',\n",
    "                               'sales'],ascending = [1,1,0,0])\n",
    "dftotal.reset_index(drop = True, inplace = True)\n",
    "dftotal.reset_index(inplace = True)\n",
    "dftotal = dftotal.rename(columns = {'index':'frmindex'})\n",
    "c_ids = len(dftotal.index)\n",
    "c_ids = np.ceil(c_ids/10.0)\n",
    "dftotal['frmindex'] = np.ceil((dftotal['frmindex']+1)/c_ids)\n",
    "\n",
    "\n",
    "zipmap = pd.read_csv('/home/jian/Projects/Big_Lots/New_TA/zips_in_new_ta/zip_with_ta_dma.csv',dtype = 'str')\n",
    "zipmap['zipcodegroup'] = zipmap['revenue_flag']\n",
    "zipmap = zipmap[['zip','zipcodegroup']].drop_duplicates('zip')\n",
    "zipmap.columns = ['customer_zip_code','zipcodegroup']\n",
    "dftotal = pd.merge(dftotal,zipmap,on ='customer_zip_code',how = 'left' )\n",
    "print(dftotal['zipcodegroup'].unique())\n",
    "dftotal['zipcodegroup'].fillna('T',inplace = True)\n",
    "print(dftotal['zipcodegroup'].unique())\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "dftotal.to_csv(folder_write + 'dfrfm_wemail.csv',index = False)\n",
    "print(\"Final wemailcsv:\",dftotal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Walking Death before the learliest date in customer transaction data as 2016-06-26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the primary stores for each member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# frequently_visit_stores_18_months=pd.read_csv(folder_write+\"frequently_visit_stores_18_months.csv\",dtype=str)\n",
    "register_stores=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/output_sing_up_location/BL_id_by_register_store_JL_2019-04-09.csv\",dtype=str)\n",
    "register_stores=register_stores[['customer_id_hashed','sign_up_location']].rename(columns={\"sign_up_location\":\"location_id\"})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26754444, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_for_ids=frequently_visit_stores_18_months.append(register_stores)\n",
    "store_for_ids=store_for_ids.drop_duplicates(\"customer_id_hashed\")\n",
    "store_for_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del frequently_visit_stores_18_months\n",
    "del register_stores\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftotal=pd.merge(dftotal,store_for_ids,on=\"customer_id_hashed\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1361, 2)\n",
      "1361\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frmindex</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>RFM</th>\n",
       "      <th>recency</th>\n",
       "      <th>transactions</th>\n",
       "      <th>sales</th>\n",
       "      <th>active</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>zipcodegroup</th>\n",
       "      <th>location_id</th>\n",
       "      <th>Quadrant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1979</td>\n",
       "      <td>31812.53</td>\n",
       "      <td>active</td>\n",
       "      <td>4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...</td>\n",
       "      <td>28607</td>\n",
       "      <td>P</td>\n",
       "      <td>1684</td>\n",
       "      <td>Quadrant I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>14b78c9088ecdbde7a771c49664157cfe588f86ae5ce5c...</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1919</td>\n",
       "      <td>42819.02</td>\n",
       "      <td>active</td>\n",
       "      <td>d72cf03e94da3a0f89abc29df597ff699420ab1c2671b3...</td>\n",
       "      <td>87501</td>\n",
       "      <td>P</td>\n",
       "      <td>4147</td>\n",
       "      <td>Quadrant IV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frmindex                                 customer_id_hashed    RFM  \\\n",
       "0       1.0  b78dccfd64ce659af7061c5743b6b9305814336bc9ddec...  111.0   \n",
       "1       1.0  14b78c9088ecdbde7a771c49664157cfe588f86ae5ce5c...  111.0   \n",
       "\n",
       "   recency  transactions     sales  active  \\\n",
       "0      1.0          1979  31812.53  active   \n",
       "1      1.0          1919  42819.02  active   \n",
       "\n",
       "                                  email_address_hash customer_zip_code  \\\n",
       "0  4836bfc632a2a5987d47fa6bf0637c21c4466a0e99ddee...             28607   \n",
       "1  d72cf03e94da3a0f89abc29df597ff699420ab1c2671b3...             87501   \n",
       "\n",
       "  zipcodegroup location_id     Quadrant  \n",
       "0            P        1684   Quadrant I  \n",
       "1            P        4147  Quadrant IV  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the quadrant by store for 2018 Q4\n",
    "\n",
    "Q4_store_quadrant=pd.read_excel(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2019Q2/Excel_BL_2018_Q4_post_YoY_small_JL_2019-03-04.xlsx\",\n",
    "                                dtype=str,sheetname=\"Q4_Store_Quadrant_Defination\",usecols=['location_id','Quadrant'])\n",
    "print(Q4_store_quadrant.shape)\n",
    "print(len(Q4_store_quadrant['location_id'].unique()))\n",
    "\n",
    "dftotal=pd.merge(dftotal,Q4_store_quadrant,on=\"location_id\",how=\"left\")\n",
    "dftotal['Quadrant']=dftotal['Quadrant'].fillna(\"Quadrant III\")\n",
    "\n",
    "dftotal.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89437"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftotal['frmindex']=dftotal['frmindex'].apply(lambda x: str(int(float(x))).zfill(2))\n",
    "dftotal['customer_zip_code']=dftotal['customer_zip_code'].apply(lambda x: x.zfill(5))\n",
    "dftotal['frmindex']=dftotal['frmindex'].apply(lambda x:\"D\"+x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal.to_csv(folder_write + 'dfrfm_final_details_wemail_zip_StoreQuad.csv',index = False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random 500000 ids as control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D01', 'D02', 'D03', 'D04', 'D05', 'D06', 'D07', 'D08', 'D09', 'D10']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftotal['frmindex'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftotal['HML_Group']=np.where(dftotal['frmindex'].isin(['D01','D02','D03','D04']),\"H\",\n",
    "                                        np.where(dftotal['frmindex'].isin(['D05','D06','D07']),\"M\",\"L\"))\n",
    "\n",
    "dftotal['segment_2019Q2']=dftotal['Quadrant']+\"_\"+dftotal['zipcodegroup']+\"_\"+dftotal['HML_Group']+\"_2019Q2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2019-04-12 13:30:49.479493\n",
      "2 2019-04-12 13:31:03.016016\n",
      "3 2019-04-12 13:31:19.856100\n",
      "4 2019-04-12 13:31:38.489731\n",
      "5 2019-04-12 13:31:56.575115\n",
      "6 2019-04-12 13:32:16.333787\n",
      "7 2019-04-12 13:32:36.410781\n",
      "8 2019-04-12 13:32:57.330702\n",
      "9 2019-04-12 13:33:20.367770\n",
      "10 2019-04-12 13:33:46.178435\n",
      "11 2019-04-12 13:34:17.234605\n",
      "12 2019-04-12 13:34:49.034214\n",
      "13 2019-04-12 13:35:23.394224\n",
      "14 2019-04-12 13:35:57.082590\n",
      "15 2019-04-12 13:36:33.013831\n",
      "16 2019-04-12 13:37:08.212425\n",
      "17 2019-04-12 13:37:43.792461\n",
      "18 2019-04-12 13:38:18.709902\n",
      "19 2019-04-12 13:39:00.010782\n",
      "20 2019-04-12 13:39:45.935868\n",
      "21 2019-04-12 13:40:35.855834\n",
      "22 2019-04-12 13:41:27.110888\n",
      "23 2019-04-12 13:42:18.877307\n",
      "24 2019-04-12 13:43:11.959976\n",
      "25 2019-04-12 13:44:05.470911\n",
      "26 2019-04-12 13:44:59.725558\n",
      "27 2019-04-12 13:45:54.836471\n",
      "28 2019-04-12 13:47:08.922312\n",
      "29 2019-04-12 13:48:38.518706\n",
      "30 2019-04-12 13:50:18.444962\n",
      "31 2019-04-12 13:52:03.269632\n",
      "32 2019-04-12 13:53:47.641249\n",
      "33 2019-04-12 13:55:37.005274\n",
      "34 2019-04-12 13:57:29.323714\n",
      "35 2019-04-12 13:59:23.056140\n",
      "36 2019-04-12 14:01:23.841858\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "total_rows=len(dftotal)\n",
    "\n",
    "test_all_df=pd.DataFrame()\n",
    "control_all_df=pd.DataFrame()\n",
    "\n",
    "i_counter=0\n",
    "\n",
    "for seg,group in dftotal.groupby(['segment_2019Q2']):\n",
    "    random_list=random.sample(range(len(group)), int(np.round(len(group)/total_rows*500000)))\n",
    "\n",
    "    group=group.reset_index()\n",
    "    del group['index']\n",
    "    group=group.reset_index()\n",
    "    df_control=group[group['index'].isin(random_list)]\n",
    "    df_test=group[~group['index'].isin(random_list)]\n",
    "    \n",
    "    df_control['segment_2019Q2']=\"C_\"+df_control['segment_2019Q2']\n",
    "    df_test['segment_2019Q2']=\"T_\"+df_test['segment_2019Q2']\n",
    "    test_all_df=test_all_df.append(df_test)\n",
    "    control_all_df=control_all_df.append(df_control)\n",
    "    i_counter+=1\n",
    "    print(i_counter,datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dftotal\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_all_df.to_csv(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2019Q2/output_2019-04-12/all_test.csv\",index=False)\n",
    "control_all_df.to_csv(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2019Q2/output_2019-04-12/all_control.csv\",index=False)\n",
    "\n",
    "folder_write_inner = '/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2019Q2/output_2019-04-12/by_group/'\n",
    "try:\n",
    "    os.stat(folder_write_inner)\n",
    "except:\n",
    "    os.mkdir(folder_write_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 T_Quadrant III_P_H_2019Q2 2019-04-12 14:08:35.899690\n",
      "2 T_Quadrant III_P_L_2019Q2 2019-04-12 14:08:47.375873\n",
      "3 T_Quadrant III_P_M_2019Q2 2019-04-12 14:08:54.426114\n",
      "4 T_Quadrant III_S_H_2019Q2 2019-04-12 14:08:56.575794\n",
      "5 T_Quadrant III_S_L_2019Q2 2019-04-12 14:08:59.348704\n",
      "6 T_Quadrant III_S_M_2019Q2 2019-04-12 14:09:01.183223\n",
      "7 T_Quadrant III_T_H_2019Q2 2019-04-12 14:09:02.117560\n",
      "8 T_Quadrant III_T_L_2019Q2 2019-04-12 14:09:04.391562\n",
      "9 T_Quadrant III_T_M_2019Q2 2019-04-12 14:09:05.410305\n",
      "10 T_Quadrant II_P_H_2019Q2 2019-04-12 14:09:13.085480\n",
      "11 T_Quadrant II_P_L_2019Q2 2019-04-12 14:09:17.976533\n",
      "12 T_Quadrant II_P_M_2019Q2 2019-04-12 14:09:23.586020\n",
      "13 T_Quadrant II_S_H_2019Q2 2019-04-12 14:09:25.251105\n",
      "14 T_Quadrant II_S_L_2019Q2 2019-04-12 14:09:26.268041\n",
      "15 T_Quadrant II_S_M_2019Q2 2019-04-12 14:09:27.470851\n",
      "16 T_Quadrant II_T_H_2019Q2 2019-04-12 14:09:28.203779\n",
      "17 T_Quadrant II_T_L_2019Q2 2019-04-12 14:09:28.586831\n",
      "18 T_Quadrant II_T_M_2019Q2 2019-04-12 14:09:29.208656\n",
      "19 T_Quadrant IV_P_H_2019Q2 2019-04-12 14:09:38.576709\n",
      "20 T_Quadrant IV_P_L_2019Q2 2019-04-12 14:09:45.078933\n",
      "21 T_Quadrant IV_P_M_2019Q2 2019-04-12 14:09:51.732745\n",
      "22 T_Quadrant IV_S_H_2019Q2 2019-04-12 14:09:54.118839\n",
      "23 T_Quadrant IV_S_L_2019Q2 2019-04-12 14:09:55.774979\n",
      "24 T_Quadrant IV_S_M_2019Q2 2019-04-12 14:09:57.777963\n",
      "25 T_Quadrant IV_T_H_2019Q2 2019-04-12 14:09:58.816548\n",
      "26 T_Quadrant IV_T_L_2019Q2 2019-04-12 14:09:59.507918\n",
      "27 T_Quadrant IV_T_M_2019Q2 2019-04-12 14:10:00.456518\n",
      "28 T_Quadrant I_P_H_2019Q2 2019-04-12 14:10:30.404565\n",
      "29 T_Quadrant I_P_L_2019Q2 2019-04-12 14:10:47.145924\n",
      "30 T_Quadrant I_P_M_2019Q2 2019-04-12 14:11:07.173040\n",
      "31 T_Quadrant I_S_H_2019Q2 2019-04-12 14:11:13.872932\n",
      "32 T_Quadrant I_S_L_2019Q2 2019-04-12 14:11:18.076050\n",
      "33 T_Quadrant I_S_M_2019Q2 2019-04-12 14:11:22.977487\n",
      "34 T_Quadrant I_T_H_2019Q2 2019-04-12 14:11:25.814329\n",
      "35 T_Quadrant I_T_L_2019Q2 2019-04-12 14:11:27.471137\n",
      "36 T_Quadrant I_T_M_2019Q2 2019-04-12 14:11:29.912086\n"
     ]
    }
   ],
   "source": [
    "i_counter=0\n",
    "for seg,group in test_all_df.groupby(['segment_2019Q2']):\n",
    "    group=group[['customer_id_hashed','email_address_hash','segment_2019Q2']].rename(columns={\"segment_2019Q2\":\"segment\"})\n",
    "    group.to_csv(folder_write_inner+seg+\".csv\",index=False)\n",
    "    i_counter+=1\n",
    "    print(i_counter,seg,datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 C_Quadrant III_P_H_2019Q2 2019-04-12 14:11:32.243993\n",
      "2 C_Quadrant III_P_L_2019Q2 2019-04-12 14:11:32.457931\n",
      "3 C_Quadrant III_P_M_2019Q2 2019-04-12 14:11:32.583040\n",
      "4 C_Quadrant III_S_H_2019Q2 2019-04-12 14:11:32.622672\n",
      "5 C_Quadrant III_S_L_2019Q2 2019-04-12 14:11:32.677328\n",
      "6 C_Quadrant III_S_M_2019Q2 2019-04-12 14:11:32.711672\n",
      "7 C_Quadrant III_T_H_2019Q2 2019-04-12 14:11:32.730265\n",
      "8 C_Quadrant III_T_L_2019Q2 2019-04-12 14:11:32.773138\n",
      "9 C_Quadrant III_T_M_2019Q2 2019-04-12 14:11:32.793373\n",
      "10 C_Quadrant II_P_H_2019Q2 2019-04-12 14:11:32.937548\n",
      "11 C_Quadrant II_P_L_2019Q2 2019-04-12 14:11:33.026331\n",
      "12 C_Quadrant II_P_M_2019Q2 2019-04-12 14:11:33.126948\n",
      "13 C_Quadrant II_S_H_2019Q2 2019-04-12 14:11:33.157803\n",
      "14 C_Quadrant II_S_L_2019Q2 2019-04-12 14:11:33.177730\n",
      "15 C_Quadrant II_S_M_2019Q2 2019-04-12 14:11:33.201022\n",
      "16 C_Quadrant II_T_H_2019Q2 2019-04-12 14:11:33.215923\n",
      "17 C_Quadrant II_T_L_2019Q2 2019-04-12 14:11:33.225210\n",
      "18 C_Quadrant II_T_M_2019Q2 2019-04-12 14:11:33.238495\n",
      "19 C_Quadrant IV_P_H_2019Q2 2019-04-12 14:11:33.400756\n",
      "20 C_Quadrant IV_P_L_2019Q2 2019-04-12 14:11:33.514656\n",
      "21 C_Quadrant IV_P_M_2019Q2 2019-04-12 14:11:33.661911\n",
      "22 C_Quadrant IV_S_H_2019Q2 2019-04-12 14:11:33.706054\n",
      "23 C_Quadrant IV_S_L_2019Q2 2019-04-12 14:11:33.737227\n",
      "24 C_Quadrant IV_S_M_2019Q2 2019-04-12 14:11:33.772464\n",
      "25 C_Quadrant IV_T_H_2019Q2 2019-04-12 14:11:33.792886\n",
      "26 C_Quadrant IV_T_L_2019Q2 2019-04-12 14:11:33.807970\n",
      "27 C_Quadrant IV_T_M_2019Q2 2019-04-12 14:11:33.827036\n",
      "28 C_Quadrant I_P_H_2019Q2 2019-04-12 14:11:34.399153\n",
      "29 C_Quadrant I_P_L_2019Q2 2019-04-12 14:11:34.733850\n",
      "30 C_Quadrant I_P_M_2019Q2 2019-04-12 14:11:35.128805\n",
      "31 C_Quadrant I_S_H_2019Q2 2019-04-12 14:11:35.251330\n",
      "32 C_Quadrant I_S_L_2019Q2 2019-04-12 14:11:35.327209\n",
      "33 C_Quadrant I_S_M_2019Q2 2019-04-12 14:11:35.418152\n",
      "34 C_Quadrant I_T_H_2019Q2 2019-04-12 14:11:35.473741\n",
      "35 C_Quadrant I_T_L_2019Q2 2019-04-12 14:11:35.504548\n",
      "36 C_Quadrant I_T_M_2019Q2 2019-04-12 14:11:35.550616\n"
     ]
    }
   ],
   "source": [
    "i_counter=0\n",
    "for seg,group in control_all_df.groupby(['segment_2019Q2']):\n",
    "    group=group[['customer_id_hashed','email_address_hash','segment_2019Q2']].rename(columns={\"segment_2019Q2\":\"segment\"})\n",
    "    group.to_csv(folder_write_inner+seg+\".csv\",index=False)\n",
    "    i_counter+=1\n",
    "    print(i_counter,seg,datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1873409, 3)\n",
      "(1873954, 4)\n"
     ]
    }
   ],
   "source": [
    "lapsed_trans=pd.read_table(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_sales_data/lapsed20140826_20170226/MediaStormLapsedCustDtl.txt\",\n",
    "                     sep=\",\",usecols=['customer_id_hashed'],dtype=str).drop_duplicates() # Doesn't go to score at all, so no need to read all columns\n",
    "lapsed_trans['lapsed_trans']=True\n",
    "\n",
    "lapsed_master=pd.read_csv('/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/MediaStorm_Lapsed_Reward_Member_Master_from2014-08-26to2017-02-26.zip',\n",
    "                     nrows = samplerows,dtype = 'str',sep = '|',\n",
    "                       usecols = ['customer_id_hashed','email_address_hash','customer_zip_code'])\n",
    "\n",
    "lapsed_master=lapsed_master.drop_duplicates(\"customer_id_hashed\")\n",
    "print(lapsed_master.shape)\n",
    "\n",
    "lapsed_master=pd.merge(lapsed_master,lapsed_trans,on=\"customer_id_hashed\",how=\"outer\")\n",
    "print(lapsed_master.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832725, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lapsed_master=lapsed_master[~lapsed_master['customer_id_hashed'].isin(test_all_df['customer_id_hashed'])]\n",
    "lapsed_master=lapsed_master[~lapsed_master['customer_id_hashed'].isin(control_all_df['customer_id_hashed'])]\n",
    "lapsed_master=lapsed_master[~lapsed_master['email_address_hash'].isin(test_all_df['email_address_hash'])]\n",
    "lapsed_master=lapsed_master[~lapsed_master['email_address_hash'].isin(control_all_df['email_address_hash'])]\n",
    "\n",
    "lapsed_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lapsed_master=lapsed_master[['customer_id_hashed','email_address_hash']]\n",
    "lapsed_master['segment']=\"WalkingDead_2019Q2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lapsed_master.to_csv(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2019Q2/output_2019-04-12/by_group/WalkingDead_Group_before_20160626.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_test=test_all_df.groupby('segment_2019Q2')['customer_id_hashed'].count().to_frame().reset_index().rename(columns={\"customer_id_hashed\":\"id_count\",\"segment_2019Q2\":\"segment\"})\n",
    "summary_control=control_all_df.groupby('segment_2019Q2')['customer_id_hashed'].count().to_frame().reset_index().rename(columns={\"customer_id_hashed\":\"id_count\",\"segment_2019Q2\":\"segment\"})\n",
    "summary_WD=lapsed_master.groupby('segment')['customer_id_hashed'].count().to_frame().reset_index().rename(columns={\"customer_id_hashed\":\"id_count\"})\n",
    "\n",
    "summary_overll=summary_test.append(summary_control).append(summary_WD)\n",
    "summary_overll.to_csv(\"/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2019Q2/output_2019-04-12/test_control_groups_summary_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T_Quadrant III_P_H_2019Q2</td>\n",
       "      <td>1139050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T_Quadrant III_P_L_2019Q2</td>\n",
       "      <td>1524224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     segment  id_count\n",
       "0  T_Quadrant III_P_H_2019Q2   1139050\n",
       "1  T_Quadrant III_P_L_2019Q2   1524224"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_overll.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>frmindex</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>RFM</th>\n",
       "      <th>recency</th>\n",
       "      <th>transactions</th>\n",
       "      <th>sales</th>\n",
       "      <th>active</th>\n",
       "      <th>email_address_hash</th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>zipcodegroup</th>\n",
       "      <th>location_id</th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>HML_Group</th>\n",
       "      <th>segment_2019Q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>D01</td>\n",
       "      <td>b488318d6a842d9254a9ada4c9297f5ed1af3665876cd4...</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>350</td>\n",
       "      <td>9633.09</td>\n",
       "      <td>active</td>\n",
       "      <td>2e3f4dbfce053216b624f9e488f5319ab1fe28dc903a59...</td>\n",
       "      <td>70072</td>\n",
       "      <td>P</td>\n",
       "      <td>1180</td>\n",
       "      <td>Quadrant III</td>\n",
       "      <td>H</td>\n",
       "      <td>C_Quadrant III_P_H_2019Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>D01</td>\n",
       "      <td>fe5e360edd31f9cec0dd3f82d2c0d80c5dea6c68af78f4...</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95</td>\n",
       "      <td>534.98</td>\n",
       "      <td>active</td>\n",
       "      <td>02c1bde6666087a502f00f3d586f5d7ffe45bddd781c12...</td>\n",
       "      <td>75052</td>\n",
       "      <td>P</td>\n",
       "      <td>4622</td>\n",
       "      <td>Quadrant III</td>\n",
       "      <td>H</td>\n",
       "      <td>C_Quadrant III_P_H_2019Q2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index frmindex                                 customer_id_hashed    RFM  \\\n",
       "8        8      D01  b488318d6a842d9254a9ada4c9297f5ed1af3665876cd4...  111.0   \n",
       "108    108      D01  fe5e360edd31f9cec0dd3f82d2c0d80c5dea6c68af78f4...  111.0   \n",
       "\n",
       "     recency  transactions    sales  active  \\\n",
       "8        1.0           350  9633.09  active   \n",
       "108      1.0            95   534.98  active   \n",
       "\n",
       "                                    email_address_hash customer_zip_code  \\\n",
       "8    2e3f4dbfce053216b624f9e488f5319ab1fe28dc903a59...             70072   \n",
       "108  02c1bde6666087a502f00f3d586f5d7ffe45bddd781c12...             75052   \n",
       "\n",
       "    zipcodegroup location_id      Quadrant HML_Group  \\\n",
       "8              P        1180  Quadrant III         H   \n",
       "108            P        4622  Quadrant III         H   \n",
       "\n",
       "                segment_2019Q2  \n",
       "8    C_Quadrant III_P_H_2019Q2  \n",
       "108  C_Quadrant III_P_H_2019Q2  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_all_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frmindex\n",
       "D01    2357787\n",
       "D02    2357672\n",
       "D03    2357774\n",
       "D04    2357796\n",
       "D05    2357978\n",
       "D06    2357709\n",
       "D07    2357583\n",
       "D08    2357301\n",
       "D09    2357996\n",
       "D10    2357968\n",
       "Name: customer_id_hashed, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_all_df.groupby(['frmindex'])['customer_id_hashed'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frmindex\n",
       "D01    49970\n",
       "D02    50085\n",
       "D03    49983\n",
       "D04    49961\n",
       "D05    49779\n",
       "D06    50048\n",
       "D07    50174\n",
       "D08    50456\n",
       "D09    49761\n",
       "D10    49784\n",
       "Name: customer_id_hashed, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_all_df.groupby(['frmindex'])['customer_id_hashed'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
