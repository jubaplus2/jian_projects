{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_current_week_quarter_week(input_saturday):\n",
    "    weeks_since_19Q1= int((input_saturday-last_day_of_2018Q4).days/7)\n",
    "    \n",
    "    year_integer=2018+int(np.ceil(weeks_since_19Q1/52))\n",
    "    quarter_integer=int(np.ceil(weeks_since_19Q1/13))%4\n",
    "    if quarter_integer==0:\n",
    "        quarter_integer=4\n",
    "        \n",
    "    week_integer=int(np.ceil(weeks_since_19Q1%13))\n",
    "\n",
    " \n",
    "\n",
    "    if week_integer==0:\n",
    "        week_integer=13\n",
    "        \n",
    "    return str(year_integer), str(quarter_integer),week_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2020, 8, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "import sqlalchemy\n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )\n",
    "\n",
    "logging.basicConfig(filename='/home/jian/BL_weekly_crontab/cron_4_JT_rolling_rewards_tracker/fiscal_year_run_JT_rewards_rolling_id_count_logs.log', level=logging.INFO)\n",
    "\n",
    "datetime.datetime.now().date().weekday()\n",
    "\n",
    "def recursive_file_gen(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root,file)\n",
    "            \n",
    "last_sturday = (datetime.datetime.now()-datetime.timedelta(days=(datetime.datetime.now().weekday()+2))).date()\n",
    "last_sturday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # In[2]:\n",
    "\n",
    "\n",
    "# logging.info(\"last_sturday: \"+str(last_sturday))\n",
    "\n",
    "# last_day_of_2018Q4=datetime.date(2019,2,2)\n",
    "\n",
    "# year_of_quarter=(last_sturday-last_day_of_2018Q4).days/(52*7)\n",
    "# year_of_quarter=str(int(2019+np.floor(year_of_quarter)))\n",
    "# print(\"Year\",year_of_quarter)\n",
    "# logging.info(\"Year: \"+str(year_of_quarter))\n",
    "\n",
    "\n",
    "# quarter_of_quarter=(last_sturday-last_day_of_2018Q4).days/7\n",
    "# quarter_of_quarter=np.floor(quarter_of_quarter/13)%4\n",
    "# quarter_of_quarter=str(int(1+quarter_of_quarter))\n",
    "# print(\"Quarter\",quarter_of_quarter)\n",
    "# logging.info(\"Quarter: \"+str(quarter_of_quarter))\n",
    "\n",
    "\n",
    "# str_current_quarter=year_of_quarter+\"_Q\"+quarter_of_quarter\n",
    "\n",
    "# print(str_current_quarter)\n",
    "# logging.info(\"str_current_quarter: \"+str(str_current_quarter))\n",
    "\n",
    "# current_week=int((last_sturday-last_day_of_2018Q4).days/7%13)\n",
    "# print(\"current_week\",current_week)\n",
    "# logging.info(\"current_week: \"+str(current_week))\n",
    "\n",
    "# if current_week==0:\n",
    "#     quarter_of_quarter=int(quarter_of_quarter)-1\n",
    "#     str_current_quarter=year_of_quarter+\"_Q\"+str(quarter_of_quarter)\n",
    "#     current_week=13\n",
    "#     print(\"Quarter\",quarter_of_quarter)\n",
    "#     print(str_current_quarter)\n",
    "#     print(\"current_week\",current_week)\n",
    "#     logging.info(\"Quarter: \"+str(quarter_of_quarter))\n",
    "#     logging.info(\"str_current_quarter: \"+str(str_current_quarter))\n",
    "#     logging.info(\"current_week: \"+str(current_week))\n",
    "\n",
    "    \n",
    "# logging.info(\"quarter_of_quarter: \"+str(quarter_of_quarter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2020\n",
      "Quarter: 2\n",
      "Current_Quarter: 2020_Q2\n",
      "current_week: 13\n",
      "Final Quarter Name: 2\n"
     ]
    }
   ],
   "source": [
    "# In[3]:\n",
    "\n",
    "last_day_of_2018Q4=datetime.date(2019,2,2)\n",
    "\n",
    "# year_of_quarter=(last_sturday-last_day_of_2018Q4).days/(52*7)\n",
    "# year_of_quarter=str(int(2019+np.floor(year_of_quarter)))\n",
    "# logging.info(\"Year: \"+str(year_of_quarter))\n",
    "\n",
    "year_of_quarter, quarter_of_quarter, current_week= get_current_week_quarter_week(last_sturday)\n",
    "print(\"Year: \"+str(year_of_quarter))\n",
    "\n",
    "# quarter_of_quarter=(last_sturday-last_day_of_2018Q4).days/7\n",
    "# quarter_of_quarter=np.floor(quarter_of_quarter/13)%4\n",
    "# quarter_of_quarter=str(int(1+quarter_of_quarter))\n",
    "\n",
    "logging.info(\"Quarter: \"+str(quarter_of_quarter))\n",
    "print(\"Quarter: \"+str(quarter_of_quarter))\n",
    "str_current_quarter=year_of_quarter+\"_Q\"+quarter_of_quarter\n",
    "\n",
    "logging.info(\"Current_Quarter: \"+str(str_current_quarter))\n",
    "print(\"Current_Quarter: \"+str(str_current_quarter))\n",
    "\n",
    "# current_week=int((last_sturday-last_day_of_2018Q4).days/7%13)\n",
    "\n",
    "logging.info(\"current_week: \"+str(current_week))\n",
    "print(\"current_week: \"+str(current_week))\n",
    "    \n",
    "logging.info(\"Final Quarter Name: \"+str(quarter_of_quarter))\n",
    "print(\"Final Quarter Name: \"+str(quarter_of_quarter))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  years since 2018\n",
      "current_quarter_beginning 2020-05-03\n",
      "fiscal_year_start 2020-02-02\n"
     ]
    }
   ],
   "source": [
    "# In[3]:\n",
    "\n",
    "\n",
    "current_quarter_beginning=last_day_of_2018Q4+datetime.timedelta(days=(int(year_of_quarter)-2019)*52*7+(int(quarter_of_quarter)-1)*13*7+1)\n",
    "\n",
    "fiscal_year_diff=int(np.ceil((datetime.date(2020,2,2)-last_day_of_2018Q4).days/(52*7)))\n",
    "print(fiscal_year_diff,\" years since 2018\")\n",
    "date_2018Q1_start=datetime.date(2018,2,4)\n",
    "fiscal_year_start=date_2018Q1_start+datetime.timedelta(days=52*7*fiscal_year_diff)\n",
    "\n",
    "print(\"current_quarter_beginning\",current_quarter_beginning)\n",
    "print(\"fiscal_year_start\",fiscal_year_start)\n",
    "logging.info(\"current_quarter_beginning: \"+str(current_quarter_beginning))\n",
    "logging.info(\"fiscal_year_start: \"+str(fiscal_year_start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str_last_week_start: '2020-07-26'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py:166: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(list_ids_in_week): 172095\n",
      "str_quarter_start: '2020-05-03'\n",
      "len(list_ids_in_quater): 2565027\n",
      "str_FiscalYear_start: '2020-02-02'\n",
      "len(list_ids_in_year): 4526595\n"
     ]
    }
   ],
   "source": [
    "# In[4]:\n",
    "str_last_week_start=\"'\"+str(last_sturday-datetime.timedelta(days=6))+\"'\"\n",
    "print(\"str_last_week_start: \"+str_last_week_start)\n",
    "logging.info(\"str_last_week_start: \"+str_last_week_start)\n",
    "list_ids_in_week=pd.read_sql(\"select customer_id_hashed from BL_Rewards_Master where sign_up_date>=%s\"%str_last_week_start ,con=BL_engine)\n",
    "list_ids_in_week=list_ids_in_week.drop_duplicates()\n",
    "print(\"len(list_ids_in_week): \"+str(len(list_ids_in_week)))\n",
    "\n",
    "###\n",
    "str_quarter_start=\"'\"+str(current_quarter_beginning)+\"'\"\n",
    "print(\"str_quarter_start: \"+str_quarter_start)\n",
    "logging.info(\"str_quarter_start: \"+str_quarter_start)\n",
    "list_ids_in_quater=pd.read_sql(\"select customer_id_hashed from BL_Rewards_Master where sign_up_date>=%s\"%str_quarter_start ,con=BL_engine)\n",
    "print(\"len(list_ids_in_quater): \"+str(len(list_ids_in_quater)))\n",
    "\n",
    "###\n",
    "str_FiscalYear_start=\"'\"+str(fiscal_year_start)+\"'\"\n",
    "print(\"str_FiscalYear_start: \"+str_FiscalYear_start)\n",
    "logging.info(\"str_FiscalYear_start: \"+str_FiscalYear_start)\n",
    "list_ids_in_year=pd.read_sql(\"select customer_id_hashed from BL_Rewards_Master where sign_up_date>=%s\"%str_FiscalYear_start ,con=BL_engine)\n",
    "print(\"len(list_ids_in_year): \"+str(len(list_ids_in_year)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "all_daily_sales_since_20Q1=list(recursive_file_gen(\"/home/jian/BigLots/\"))\n",
    "all_daily_sales_since_20Q1=[x for x in all_daily_sales_since_20Q1 if \"aily\" in x]\n",
    "all_daily_sales_since_20Q1=[x for x in all_daily_sales_since_20Q1 if \"MediaStorm_\" in x]\n",
    "all_daily_sales_since_20Q1=[x for x in all_daily_sales_since_20Q1 if x.split(\"MediaStorm_\")[1][:10]>=\"2020-02-02\"]\n",
    "\n",
    "\n",
    "df_all_daily_sales_since_20Q1=pd.DataFrame({\"file_path\":all_daily_sales_since_20Q1})\n",
    "df_all_daily_sales_since_20Q1['week_end_dt']=df_all_daily_sales_since_20Q1['file_path'].apply(lambda x: x.split(\"/MediaStorm_\")[1][:10])\n",
    "df_all_daily_sales_since_20Q1=df_all_daily_sales_since_20Q1.sort_values(\"week_end_dt\",ascending=True)\n",
    "\n",
    "df_all_daily_sales_since_20Q1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-07 11:16:12.078229 1\n",
      "2020-08-07 11:17:50.943730 6\n",
      "2020-08-07 11:19:33.583932 11\n",
      "2020-08-07 11:21:27.407649 16\n",
      "2020-08-07 11:23:21.749824 21\n",
      "2020-08-07 11:25:26.209936 26\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "list_POS_daily_this_fiscal_year=df_all_daily_sales_since_20Q1[df_all_daily_sales_since_20Q1['week_end_dt']>=str(fiscal_year_start)]\n",
    "\n",
    "df_shoppers_in_year=pd.DataFrame()\n",
    "\n",
    "i=0\n",
    "for ind, row in list_POS_daily_this_fiscal_year.iterrows():\n",
    "    file_path=row['file_path']\n",
    "    week_end_dt=row['week_end_dt']\n",
    "    df=pd.read_csv(file_path,dtype=str,sep=\"|\",\n",
    "                   usecols=['customer_id_hashed']).drop_duplicates()\n",
    "    df=df[pd.notnull(df['customer_id_hashed'])]\n",
    "    \n",
    "    df['week_end_dt']=week_end_dt\n",
    "    df_shoppers_in_year=df_shoppers_in_year.append(df)\n",
    "    i+=1\n",
    "    if i%5==1:\n",
    "        print(datetime.datetime.now(),i)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_new_sign_ups_fiscal_year: 4526536\n",
      "count_shoppers_fiscal_year: 13598338\n",
      "count_new_shoppers_fiscal_year: 2219387\n"
     ]
    }
   ],
   "source": [
    "# In[7]:\n",
    "\n",
    "\n",
    "count_new_sign_ups_fiscal_year=list_ids_in_year['customer_id_hashed'].nunique()\n",
    "\n",
    "count_shoppers_fiscal_year=df_shoppers_in_year['customer_id_hashed'].nunique()\n",
    "\n",
    "count_new_shoppers_fiscal_year=df_shoppers_in_year[['customer_id_hashed']].drop_duplicates()\n",
    "count_new_shoppers_fiscal_year=pd.merge(list_ids_in_year,count_new_shoppers_fiscal_year,on=\"customer_id_hashed\",how=\"inner\")\n",
    "count_new_shoppers_fiscal_year=count_new_shoppers_fiscal_year['customer_id_hashed'].nunique()\n",
    "\n",
    "print(\"count_new_sign_ups_fiscal_year: \"+str(count_new_sign_ups_fiscal_year))\n",
    "logging.info(\"count_new_sign_ups_fiscal_year: \"+str(count_new_sign_ups_fiscal_year))\n",
    "\n",
    "print(\"count_shoppers_fiscal_year: \"+str(count_shoppers_fiscal_year))\n",
    "logging.info(\"count_shoppers_fiscal_year: \"+str(count_shoppers_fiscal_year))\n",
    "\n",
    "print(\"count_new_shoppers_fiscal_year: \"+str(count_new_shoppers_fiscal_year))\n",
    "logging.info(\"count_new_shoppers_fiscal_year: \"+str(count_new_shoppers_fiscal_year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_new_sign_ups_current_quarter: 2565001\n",
      "count_shoppers_current_quarter: 9827825\n",
      "count_new_shoppers_current_quater: 1239840\n"
     ]
    }
   ],
   "source": [
    "# In[8]:\n",
    "\n",
    "\n",
    "# over-wroten in as quarter only\n",
    "\n",
    "count_new_sign_ups_current_quarter=list_ids_in_quater['customer_id_hashed'].nunique()\n",
    "\n",
    "df_shoppers_in_year=df_shoppers_in_year[df_shoppers_in_year['week_end_dt']>=str(current_quarter_beginning)]\n",
    "count_shoppers_current_quarter=df_shoppers_in_year['customer_id_hashed'].nunique()\n",
    "\n",
    "count_new_shoppers_current_quater=df_shoppers_in_year[['customer_id_hashed']].drop_duplicates()\n",
    "count_new_shoppers_current_quater=pd.merge(list_ids_in_quater,count_new_shoppers_current_quater,on=\"customer_id_hashed\",how=\"inner\")\n",
    "count_new_shoppers_current_quater=count_new_shoppers_current_quater['customer_id_hashed'].nunique()\n",
    "\n",
    "print(\"count_new_sign_ups_current_quarter: \"+str(count_new_sign_ups_current_quarter))\n",
    "logging.info(\"count_new_sign_ups_current_quarter: \"+str(count_new_sign_ups_current_quarter))\n",
    "\n",
    "print(\"count_shoppers_current_quarter: \"+str(count_shoppers_current_quarter))\n",
    "logging.info(\"count_shoppers_current_quarter: \"+str(count_shoppers_current_quarter))\n",
    "\n",
    "print(\"count_new_shoppers_current_quater: \"+str(count_new_shoppers_current_quater))\n",
    "logging.info(\"count_new_shoppers_current_quater: \"+str(count_new_shoppers_current_quater))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_new_sign_ups_last_week: 172095\n",
      "count_shoppers_last_week: 1304165\n",
      "count_new_shoppers_last_week: 91427\n"
     ]
    }
   ],
   "source": [
    "# In[9]:\n",
    "\n",
    "\n",
    "# over-wroten in as last week only\n",
    "\n",
    "count_new_sign_ups_last_week=list_ids_in_week['customer_id_hashed'].nunique()\n",
    "\n",
    "df_shoppers_in_year=df_shoppers_in_year[df_shoppers_in_year['week_end_dt']>=str_last_week_start.replace(\"'\",\"\")]\n",
    "count_shoppers_last_week=df_shoppers_in_year['customer_id_hashed'].nunique()\n",
    "\n",
    "count_new_shoppers_last_week=df_shoppers_in_year[['customer_id_hashed']].drop_duplicates()\n",
    "count_new_shoppers_last_week=pd.merge(list_ids_in_week,count_new_shoppers_last_week,on=\"customer_id_hashed\",how=\"inner\")\n",
    "count_new_shoppers_last_week=count_new_shoppers_last_week['customer_id_hashed'].nunique()\n",
    "\n",
    "print(\"count_new_sign_ups_last_week: \"+str(count_new_sign_ups_last_week))\n",
    "logging.info(\"count_new_sign_ups_last_week: \"+str(count_new_sign_ups_last_week))\n",
    "\n",
    "print(\"count_shoppers_last_week: \"+str(count_shoppers_last_week))\n",
    "logging.info(\"count_shoppers_last_week: \"+str(count_shoppers_last_week))\n",
    "\n",
    "print(\"count_new_shoppers_last_week: \"+str(count_new_shoppers_last_week))\n",
    "logging.info(\"count_new_shoppers_last_week: \"+str(count_new_shoppers_last_week))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "df_output_this_week=pd.DataFrame({\"week_end_dt\":week_end_dt,\n",
    "                                 \"count_new_sign_ups_last_week\":count_new_sign_ups_last_week,\n",
    "                                 \"count_shoppers_last_week\":count_shoppers_last_week,\n",
    "                                 \"count_new_shoppers_last_week\":count_new_shoppers_last_week,\n",
    "                                  \n",
    "                                  \"count_new_sign_ups_current_quarter\":count_new_sign_ups_current_quarter,\n",
    "                                 \"count_shoppers_current_quarter\":count_shoppers_current_quarter,\n",
    "                                 \"count_new_shoppers_current_quater\":count_new_shoppers_current_quater,\n",
    "                                  \n",
    "                                  \"count_new_sign_ups_fiscal_year\":count_new_sign_ups_fiscal_year,\n",
    "                                 \"count_shoppers_fiscal_year\":count_shoppers_fiscal_year,\n",
    "                                 \"count_new_shoppers_fiscal_year\":count_new_shoppers_fiscal_year,\n",
    "                                  \n",
    "                                 \"date_begin_year\":fiscal_year_start,\n",
    "                                 \"date_begin_quarter\":current_quarter_beginning,\n",
    "                                 \"Current_Quarter\":str_current_quarter},index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_end_dt</th>\n",
       "      <th>count_new_sign_ups_last_week</th>\n",
       "      <th>count_shoppers_last_week</th>\n",
       "      <th>count_new_shoppers_last_week</th>\n",
       "      <th>count_new_sign_ups_current_quarter</th>\n",
       "      <th>count_shoppers_current_quarter</th>\n",
       "      <th>count_new_shoppers_current_quater</th>\n",
       "      <th>count_new_sign_ups_fiscal_year</th>\n",
       "      <th>count_shoppers_fiscal_year</th>\n",
       "      <th>count_new_shoppers_fiscal_year</th>\n",
       "      <th>date_begin_year</th>\n",
       "      <th>date_begin_quarter</th>\n",
       "      <th>Current_Quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>172095</td>\n",
       "      <td>1304165</td>\n",
       "      <td>91427</td>\n",
       "      <td>2565001</td>\n",
       "      <td>9827825</td>\n",
       "      <td>1239840</td>\n",
       "      <td>4526536</td>\n",
       "      <td>13598338</td>\n",
       "      <td>2219387</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>2020-05-03</td>\n",
       "      <td>2020_Q2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  week_end_dt  count_new_sign_ups_last_week  count_shoppers_last_week  \\\n",
       "0  2020-08-01                        172095                   1304165   \n",
       "\n",
       "   count_new_shoppers_last_week  count_new_sign_ups_current_quarter  \\\n",
       "0                         91427                             2565001   \n",
       "\n",
       "   count_shoppers_current_quarter  count_new_shoppers_current_quater  \\\n",
       "0                         9827825                            1239840   \n",
       "\n",
       "   count_new_sign_ups_fiscal_year  count_shoppers_fiscal_year  \\\n",
       "0                         4526536                    13598338   \n",
       "\n",
       "   count_new_shoppers_fiscal_year date_begin_year date_begin_quarter  \\\n",
       "0                         2219387      2020-02-02         2020-05-03   \n",
       "\n",
       "  Current_Quarter  \n",
       "0         2020_Q2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output_this_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str_previous_week_end: 2020-07-25\n"
     ]
    }
   ],
   "source": [
    "# In[11]:\n",
    "\n",
    "\n",
    "str_previous_week_end=str(last_sturday-datetime.timedelta(days=7))\n",
    "print(\"str_previous_week_end: \"+str_previous_week_end)\n",
    "logging.info(\"str_previous_week_end: \"+str_previous_week_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_output_previous_week=df_output_this_week.head(0)\\ndf_output_previous_week.to_csv()\\n\\ndf_output_previous_week.to_csv(\"/home/simeng/outputs_\"+str_previous_week_end+\"/\"+\"updated_New_rewards_as_fisical_year_\"+str_previous_week_end+\".csv\",index=False)\\ndf_output_previous_week.to_csv(\"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/output/\"+\"updated_New_rewards_as_fisical_year_\"+str_previous_week_end+\".csv\",index=False)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[12]:\n",
    "\n",
    "'''\n",
    "df_output_previous_week=df_output_this_week.head(0)\n",
    "df_output_previous_week.to_csv()\n",
    "\n",
    "df_output_previous_week.to_csv(\"/home/simeng/outputs_\"+str_previous_week_end+\"/\"+\"updated_New_rewards_as_fisical_year_\"+str_previous_week_end+\".csv\",index=False)\n",
    "df_output_previous_week.to_csv(\"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/output/\"+\"updated_New_rewards_as_fisical_year_\"+str_previous_week_end+\".csv\",index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-07-25'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_previous_week_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thisweeksdate=str(datetime.datetime.now().date()-datetime.timedelta(days=datetime.datetime.now().date().weekday()-1+3))\n",
    "recent_weekly_data_folder=\"/home/jian/BigLots/MediaStorm_\"+thisweeksdate+\"/\"\n",
    "Simeng_recent_weekly_data_folder=\"/home/simeng/outputs_\"+thisweeksdate+\"/\"\n",
    "\n",
    "Saturday_str=str(datetime.datetime.now().date()-datetime.timedelta(days=datetime.datetime.now().date().weekday()-1+3-7))\n",
    "\n",
    "if not os.path.exists(\"/home/jian/BiglotsCode/outputs/Output_\"+thisweeksdate+\"/By_Zip_weather_forecast_for_Saturday_\"+Saturday_str+\".csv\"):\n",
    "    del Saturday_str\n",
    "\n",
    "    try:\n",
    "        os.stat(recent_weekly_data_folder)\n",
    "    except:\n",
    "        os.mkdir(recent_weekly_data_folder)\n",
    "        \n",
    "    try:\n",
    "        os.stat(Simeng_recent_weekly_data_folder)\n",
    "    except:\n",
    "        os.mkdir(Simeng_recent_weekly_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[17]:\n",
    "\n",
    "df_output_previous_week=pd.read_csv(\"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/output/\"+\"updated_New_rewards_as_fisical_year_\"+str_previous_week_end+\".csv\")\n",
    "\n",
    "# df_output_previous_week=pd.read_csv(\"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/output/\"+\"New_rewards_df_this_week_\"+str_previous_week_end+\".csv\")\n",
    "\n",
    "df_output=df_output_previous_week.append(df_output_this_week)\n",
    "df_output.to_csv(\"/home/simeng/outputs_\"+str(last_sturday)+\"/\"+\"updated_New_rewards_as_fisical_year_\"+str(last_sturday)+\".csv\",index=False)\n",
    "df_output.to_csv(\"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/output/\"+\"updated_New_rewards_as_fisical_year_\"+str(last_sturday)+\".csv\",index=False)\n",
    "\n",
    "\n",
    "logging.info(\"done_of_file_creating, to send email: \"+str(datetime.datetime.now()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.read_csv('/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/output/updated_New_rewards_as_fisical_year_2020-04-11.csv',nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from os.path import basename\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.utils import COMMASPACE, formatdate\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "sender=\"jubapluscc@gmail.com\"\n",
    "receivers='jthomas@mediastorm.biz, jian@jubaplus.com, breznik@jubaplus.com,cchou@jubaplus.com'\n",
    "subject=\"Big Lots New Sign Ups Report Qumulative of Year/Quarter/Week\"\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "file = \"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/output/\"+\"updated_New_rewards_as_fisical_year_\"+str(last_sturday)+\".csv\"\n",
    "text_message_str=\"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/email_message_new_rewards_weekly.txt\"\n",
    "\n",
    "msg = MIMEMultipart()\n",
    "msg['From'] = sender\n",
    "msg['To'] = receivers\n",
    "msg['Date'] = formatdate(localtime=True)\n",
    "msg['Subject'] = subject\n",
    "with open(text_message_str,'r') as f:\n",
    "    text_mesaage = f.read()\n",
    "msg.attach(MIMEText(text_mesaage))\n",
    "\n",
    "with open(file,'rb') as attachment:\n",
    "    att = MIMEApplication(\n",
    "        attachment.read(),name=os.path.basename(file)\n",
    "    )\n",
    "    att['Content-Disposition'] = 'attachment; filename=\"%s\"' %os.path.basename(file)\n",
    "    msg.attach(att)\n",
    "\n",
    "\n",
    "\n",
    "smtp = smtplib.SMTP('smtp.gmail.com',587)\n",
    "smtp.ehlo()\n",
    "smtp.starttls()\n",
    "smtp.login(sender,\"mfppxsfikqmazbqj\")\n",
    "smtp.send_message(msg)\n",
    "\n",
    "smtp.close()\n",
    "\n",
    "logging.info(\"Email sent: \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "2020-08-07 11:30:22.106053 2020-05-09\n",
      "2020-08-07 11:31:16.276030 2020-05-16\n",
      "2020-08-07 11:32:16.994443 2020-05-23\n",
      "2020-08-07 11:33:12.595330 2020-05-30\n",
      "2020-08-07 11:34:03.468460 2020-06-06\n",
      "2020-08-07 11:34:53.252807 2020-06-13\n",
      "2020-08-07 11:35:41.181066 2020-06-20\n",
      "2020-08-07 11:36:28.684273 2020-06-27\n",
      "2020-08-07 11:37:20.646179 2020-07-04\n",
      "2020-08-07 11:38:12.027201 2020-07-11\n",
      "2020-08-07 11:39:03.853753 2020-07-18\n",
      "2020-08-07 11:39:50.215038 2020-07-25\n",
      "2020-08-07 11:40:37.564934 2020-08-01\n"
     ]
    }
   ],
   "source": [
    "# In[22]:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "import os\n",
    "\n",
    "def recursive_file_gen(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root,file)\n",
    "            \n",
    "# start_date_2019Q4=datetime.date(2019,11,3)\n",
    "# str current_quarter_beginning\n",
    "last_saturday=datetime.datetime.now().date()-datetime.timedelta(days=datetime.datetime.now().date().weekday()+2)\n",
    "\n",
    "pos_list=list(recursive_file_gen(\"/home/jian/BigLots/\"))\n",
    "pos_list=[x for x in pos_list if \"daily\" in x.lower() and \"s/MediaStorm_\" in x and x[-4:]==\".txt\"]\n",
    "pos_list=[x for x in pos_list if x.split(\"s/MediaStorm_\")[1][:10]>=str(current_quarter_beginning)]\n",
    "pos_list.sort()\n",
    "print(len(pos_list))\n",
    "\n",
    "df_all_POS_by_store=pd.DataFrame()\n",
    "for file in pos_list:\n",
    "    df=pd.read_csv(file,dtype=str,sep=\"|\")\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    df_rewards=df[pd.notnull(df['customer_id_hashed'])]\n",
    "    df_non_rewards=df[pd.isnull(df['customer_id_hashed'])]\n",
    "    \n",
    "    df_rewards_sales=df_rewards.groupby(['location_id','transaction_dt'])['item_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"item_transaction_amt\":\"rewards_sales\"})\n",
    "    df_rewards_trans=df_rewards[['location_id','transaction_dt','transaction_id','customer_id_hashed']].drop_duplicates()\n",
    "    df_rewards_trans['rewards_trans']=1\n",
    "    df_rewards_trans=df_rewards_trans.groupby(['location_id','transaction_dt'])['rewards_trans'].sum().to_frame().reset_index()\n",
    "    df_rewards=pd.merge(df_rewards_sales,df_rewards_trans,on=['location_id','transaction_dt'],how=\"outer\")\n",
    "    \n",
    "    df_non_rewards_sales=df_non_rewards.groupby(['location_id','transaction_dt'])['item_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"item_transaction_amt\":\"non_rewards_sales\"})\n",
    "    df_non_rewards_trans=df_non_rewards[['location_id','transaction_dt','transaction_id']].drop_duplicates()\n",
    "    df_non_rewards_trans['non_rewards_trans']=1\n",
    "    df_non_rewards_trans=df_non_rewards_trans.groupby(['location_id','transaction_dt'])['non_rewards_trans'].sum().to_frame().reset_index()\n",
    "    df_non_rewards=pd.merge(df_non_rewards_sales,df_non_rewards_trans,on=['location_id','transaction_dt'],how=\"outer\")\n",
    "    \n",
    "    df=pd.merge(df_rewards,df_non_rewards,on=['location_id','transaction_dt'],how=\"outer\")\n",
    "    df['week_end_dt']=df['transaction_dt'].max()\n",
    "    df_all_POS_by_store=df_all_POS_by_store.append(df)\n",
    "    print(datetime.datetime.now(),df['transaction_dt'].max())\n",
    "df_all_POS_by_store['store_type']=np.where(df_all_POS_by_store['location_id']==\"6990\",\"online\",\"instore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_all_POS_by_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Store\n",
       "0     1\n",
       "1    49"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOTF = pd.read_csv('/home/charles/Biglots/BL_weekly_crontab/BL SOTF Store List Report 04.23.20.csv',usecols=['Store'],dtype=str)\n",
    "SOTF['Store'] = SOTF['Store'].apply(lambda x: x.strip())\n",
    "SOTF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_SOTF_POS_by_store = df_all_POS_by_store[df_all_POS_by_store['location_id'].isin(SOTF['Store'].values)]\n",
    "df_Legacy_POS_by_store = df_all_POS_by_store[~df_all_POS_by_store['location_id'].isin(SOTF['Store'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408\n",
      "490\n",
      "918\n"
     ]
    }
   ],
   "source": [
    "print(df_all_POS_by_store['location_id'].nunique())\n",
    "print(df_SOTF_POS_by_store['location_id'].nunique())\n",
    "print(df_Legacy_POS_by_store['location_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_summary = df_all_POS_by_store.groupby([\"week_end_dt\",'store_type'])['rewards_sales','non_rewards_sales','rewards_trans','non_rewards_trans'].sum().reset_index()\n",
    "df_SOTF_summary = df_SOTF_POS_by_store.groupby([\"week_end_dt\",'store_type'])['rewards_sales','non_rewards_sales','rewards_trans','non_rewards_trans'].sum().reset_index()\n",
    "df_Legacy_summary = df_Legacy_POS_by_store.groupby([\"week_end_dt\",'store_type'])['rewards_sales','non_rewards_sales','rewards_trans','non_rewards_trans'].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16807550.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary['non_rewards_trans'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16807550.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_SOTF_summary['non_rewards_trans'].sum() + df_Legacy_summary['non_rewards_trans'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_summary.to_csv(\"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/output/sales_in_quarter_so_far_\"+week_end_dt+\".csv\",index=False)\n",
    "writer = pd.ExcelWriter(\"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/output/sales_in_quarter_so_far_\"+week_end_dt+\".xlsx\", engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_summary.to_excel(writer,sheet_name='All', index=False)\n",
    "df_SOTF_summary.to_excel(writer,sheet_name='SOTF', index=False)\n",
    "df_Legacy_summary.to_excel(writer,sheet_name='Legacy', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# week_end_dt = '2020-05-09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = \"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/output/sales_in_quarter_so_far_\"+week_end_dt+\".xlsx\"\n",
    "text_message_str=\"/home/jian/celery/JT_new_sing_ups_rewards_rolling_table/email_message_sales_in_quarter_so_far.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from os.path import basename\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.utils import COMMASPACE, formatdate\n",
    "import datetime\n",
    "import os\n",
    "msg = MIMEMultipart()\n",
    "msg['From'] = sender\n",
    "msg['To'] = receivers\n",
    "msg['Date'] = formatdate(localtime=True)\n",
    "msg['Subject'] = \"Big Lots sales in this quarter up to last week\"\n",
    "with open(text_message_str,'r') as f:\n",
    "    text_mesaage = f.read()\n",
    "msg.attach(MIMEText(text_mesaage))\n",
    "\n",
    "with open(file,'rb') as attachment:\n",
    "    att = MIMEApplication(\n",
    "        attachment.read(),name=os.path.basename(file)\n",
    "    )\n",
    "    att['Content-Disposition'] = 'attachment; filename=\"%s\"' %os.path.basename(file)\n",
    "    msg.attach(att)\n",
    "smtp = smtplib.SMTP('smtp.gmail.com',587)\n",
    "smtp.ehlo()\n",
    "smtp.starttls()\n",
    "smtp.login(sender,\"mfppxsfikqmazbqj\")\n",
    "smtp.send_message(msg)\n",
    "\n",
    "smtp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['updated_New_rewards_as_fisical_year_2020-05-09.csv',\n",
       " 'output_quadrant.csv',\n",
       " 'BL_weekly_audience_tracker_2020-05-09.xlsx',\n",
       " 'output1.csv',\n",
       " 'output3_converted 2020-05-09.csv',\n",
       " 'output2_new 2020-05-09.csv',\n",
       " 'highyoy_wowchangestores 2020-05-09.csv',\n",
       " 'nobothyeardatastores 2020-05-09.csv',\n",
       " 'combined_sales_long_2020-05-09.csv',\n",
       " 'weather_forecast_for_Saturday_2020-05-16.csv',\n",
       " 'By_Zip_weather_forecast_for_Saturday_2020-05-16.csv',\n",
       " 'BL_tracking_migration_status_JL_2020-05-09.xlsx']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/home/simeng/outputs_2020-05-09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
