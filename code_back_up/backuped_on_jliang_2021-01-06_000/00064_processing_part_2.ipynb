{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-07 11:16:09.073579\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "import os\n",
    "import sqlalchemy\n",
    "import json\n",
    "import glob\n",
    "from haversine import haversine\n",
    "print(datetime.datetime.now())\n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config=\"/home/jian/Projects/Big_Lots/Predictive_Model/extract_from_MySQL/config.json\"\n",
    "folder_mysqloutfile=\"/home/mysql/mysqloutfile/\"\n",
    "folder_store_list=\"/home/jian/BigLots/static_files/Store_list/\"\n",
    "folder_email_unsub=\"/home/jian/BigLots/Email_Subscription_Files/Unsubs/\"\n",
    "path_TA_excel=\"/home/jian/Projects/Big_Lots/New_TA/package_to_run_TA_every_quarter/output_2020-07-22/BL_final_TA_updated_JL_2020-07-22.xlsx\"\n",
    "path_json_zip_center=\"/home/jian/Docs/Geo_mapping/updated_zip_centers_JL_2019-05-23.json\"\n",
    "\n",
    "dict_config=json.load(open(path_config,\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_date=datetime.datetime.strptime(dict_config['crm_end_date'],\"%Y-%m-%d\").date()\n",
    "# sign_up_start_date=datetime.datetime.strptime(dict_config['crm_start_date'],\"%Y-%m-%d\").date()\n",
    "\n",
    "if dict_config['recent_n_month']:\n",
    "    recent_n_month=dict_config['recent_n_month']\n",
    "    pos_start_date_id_filter = str(high_date-datetime.timedelta(days=int(np.ceil(365*recent_n_month/12))))\n",
    "else:\n",
    "    pos_start_date_id_filter = dict_config[\"pos_start_date\"]\n",
    "            \n",
    "sql_str_high_date=\"'%s'\"%str(high_date)\n",
    "sql_str_lastweekstart_date=\"'%s'\"%str(high_date-datetime.timedelta(days=6))\n",
    "# sql_sign_up_start_date=\"'%s'\"%str(sign_up_start_date)\n",
    "sql_POS_start_date=\"'%s'\"%str(pos_start_date_id_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py:166: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NEall_id_pos_until_20200523',\n",
       " 'all_NEall_id_pred_pos_2_1_pos_until_20200523',\n",
       " 'all_NEall_id_pred_pos_2_2_pos_until_20200523',\n",
       " 'crm_NEall_id_pos_until_20200523',\n",
       " 'max_trans_NEall_id_pos_until_20200523',\n",
       " 'pred_pos_dept_NEall_id_pos_until_20200523']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_week_end_d=dict_config['pos_end_date'].replace(\"-\",\"\")\n",
    "list_tables=pd.read_sql(\"show tables\",con=BL_engine).iloc[:,0].values.tolist()\n",
    "list_tables=[x for x in list_tables if x[-8:]==str_week_end_d]\n",
    "list_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_name_contains(list_input_tables,pattern_unique):\n",
    "    res=[x for x in list_tables if pattern_unique in x]\n",
    "    if not res:\n",
    "        raise ValueError(\"not table found with the pattern: %s\" %pattern_unique)\n",
    "    elif len(res)>1:\n",
    "        raise ValueError(\"multiple tables found with the pattern: %s\" %pattern_unique)\n",
    "    else:\n",
    "        return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_2_1=get_table_name_contains(list_tables,\"pos_2_1\")\n",
    "t_2_2=get_table_name_contains(list_tables,\"pos_2_2\")\n",
    "\n",
    "t_crm_ids=get_table_name_contains(list_tables,\"crm_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'crm_NEall_id_pos_until_20200523'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_crm_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store list ahead and after the high date\n",
    "path_store_list=glob.glob(folder_store_list+\"*.txt\")\n",
    "\n",
    "path_store_list_ahead=[x for x in path_store_list if \"MediaStormStores%s\"%str_week_end_d[:6] in x][0]\n",
    "path_store_list_after=[x for x in path_store_list if \"MediaStormStores%s\"%str(int(str_week_end_d[:6])+1) in x][0]\n",
    "del path_store_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_list=pd.read_csv(path_store_list_ahead,sep=\"|\")\n",
    "df_store_list=df_store_list[['location_id','address_line_1','address_line_2','city_nm','state_nm','zip_cd','latitude_meas','longitude_meas']]\n",
    "df_store_list['latitude_meas']=df_store_list['latitude_meas'].astype(float)\n",
    "df_store_list['longitude_meas']=df_store_list['longitude_meas'].astype(float)\n",
    "df_store_list['zip_cd']=df_store_list['zip_cd'].apply(lambda x: x.split(\"-\")[0].zfill(5))\n",
    "df_store_list=df_store_list[~df_store_list['location_id'].isin(['145','6990'])]\n",
    "df_store_list['location_id']=df_store_list['location_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TA_zips=pd.ExcelFile(path_TA_excel)\n",
    "TA_zips=TA_zips.parse(\"view_by_store\",dtype=str)\n",
    "\n",
    "df_temporary=TA_zips[['location_id','trans_P_zips_70_within_TA','trans_S_zips_70_within_TA','zips_in_10']]\n",
    "df_zip_by_store=pd.DataFrame()\n",
    "\n",
    "for ind,row in df_temporary.iterrows():\n",
    "    location_id=str(row['location_id'])\n",
    "    P_zips=eval(row['trans_P_zips_70_within_TA'])\n",
    "    S_zips=eval(row['trans_S_zips_70_within_TA'])\n",
    "    zip_10=eval(row['zips_in_10'])\n",
    "    \n",
    "\n",
    "    df_P=pd.DataFrame(zip([location_id]*len(P_zips),P_zips))\n",
    "    if len(df_P)>0:\n",
    "        df_P.columns=['location_id','zip_cd']\n",
    "        df_P['zip_type']=\"P\"\n",
    "        \n",
    "    df_S=pd.DataFrame(zip([location_id]*len(S_zips),S_zips))\n",
    "    if len(df_S)>0:\n",
    "        df_S.columns=['location_id','zip_cd']\n",
    "        df_S['zip_type']=\"S\"\n",
    "    \n",
    "    df_10=pd.DataFrame(zip([location_id]*len(zip_10),zip_10))\n",
    "    if len(df_10)>0:\n",
    "        df_10.columns=['location_id','zip_cd']\n",
    "        df_10['zip_type']=\"zip_10\"\n",
    "    \n",
    "    df_zip_by_store=df_zip_by_store.append(df_P).append(df_S).append(df_10)\n",
    "df_zip_by_store['location_id']=df_zip_by_store['location_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>latitude_meas</th>\n",
       "      <th>longitude_meas</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>zip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>33.42157</td>\n",
       "      <td>-82.018921</td>\n",
       "      <td>30906</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>33.42157</td>\n",
       "      <td>-82.018921</td>\n",
       "      <td>30901</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id  latitude_meas  longitude_meas zip_cd zip_type\n",
       "0           3       33.42157      -82.018921  30906        P\n",
       "1           3       33.42157      -82.018921  30901        S"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_list=df_store_list[['location_id','latitude_meas','longitude_meas']]\n",
    "df_store_zip=pd.merge(df_store_list,df_zip_by_store,on=\"location_id\",how=\"left\")\n",
    "df_store_zip.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_zip_new=df_store_zip[pd.isnull(df_store_zip['zip_cd'])]\n",
    "df_store_zip_existing=df_store_zip[pd.notnull(df_store_zip['zip_cd'])]\n",
    "\n",
    "df_store_zip_new_no_loc=df_store_zip_new[df_store_zip_new['latitude_meas']==0]\n",
    "df_store_zip_new_with_loc=df_store_zip_new[df_store_zip_new['latitude_meas']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>latitude_meas</th>\n",
       "      <th>longitude_meas</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>zip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [location_id, latitude_meas, longitude_meas, zip_cd, zip_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_zip_new_no_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_zip_new_with_loc=df_store_zip_new_with_loc[['location_id','latitude_meas','longitude_meas']]\n",
    "df_store_zip_new_no_loc=df_store_zip_new_no_loc[['location_id','latitude_meas','longitude_meas']]\n",
    "\n",
    "if len(df_store_zip_new_no_loc)>0:\n",
    "    store_list_later=[x for x in list_store_list if x.split(\"MediaStormStores\")[1][:6]>str_week_end_d]\n",
    "    store_list_later=sorted(store_list_later,key=lambda x: os.stat(x).st_mtime)\n",
    "\n",
    "\n",
    "    for file in store_list_later:\n",
    "        df=pd.read_csv(file,dtype=str,sep=\"|\",usecols=['location_id','latitude_meas','longitude_meas'])\n",
    "        df=df[['location_id','latitude_meas','longitude_meas']]\n",
    "        df['latitude_meas']=df['latitude_meas'].astype(float)\n",
    "        df['longitude_meas']=df['longitude_meas'].astype(float)\n",
    "        df['location_id']=df['location_id'].astype(str)\n",
    "        df=df[df['location_id'].isin(df_store_zip_new_no_loc['location_id'].tolist())]\n",
    "        df=df[df['latitude_meas']!=0]\n",
    "        df_store_zip_new_with_loc=df_store_zip_new_with_loc.append(df)\n",
    "        df_store_zip_new_no_loc=df_store_zip_new_no_loc[~df_store_zip_new_no_loc['location_id'].isin(df['location_id'].tolist())]\n",
    "        if len(df_store_zip_new_no_loc)==0:\n",
    "            break\n",
    "\n",
    "    df_store_zip_new=df_store_zip_new_with_loc.reset_index()\n",
    "    del df_store_zip_new['index']\n",
    "    if df_store_zip_new_with_loc:\n",
    "        del df_store_zip_new_with_loc\n",
    "    if df_store_zip_new_no_loc:\n",
    "        del df_store_zip_new_no_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>latitude_meas</th>\n",
       "      <th>longitude_meas</th>\n",
       "      <th>zip_cd</th>\n",
       "      <th>zip_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7272</th>\n",
       "      <td>1786</td>\n",
       "      <td>34.086376</td>\n",
       "      <td>-84.542847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14767</th>\n",
       "      <td>4329</td>\n",
       "      <td>32.278485</td>\n",
       "      <td>-110.980012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18775</th>\n",
       "      <td>4583</td>\n",
       "      <td>40.764858</td>\n",
       "      <td>-111.880348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      location_id  latitude_meas  longitude_meas zip_cd zip_type\n",
       "7272         1786      34.086376      -84.542847    NaN      NaN\n",
       "14767        4329      32.278485     -110.980012    NaN      NaN\n",
       "18775        4583      40.764858     -111.880348    NaN      NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_zip_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_centers=json.load(open(path_json_zip_center,\"r\"))\n",
    "if len(df_store_zip_new)>0:\n",
    "    del df_store_zip_new['zip_cd']\n",
    "    del df_store_zip_new['zip_type']\n",
    "    \n",
    "    df_all_new_zip=pd.DataFrame()\n",
    "    for i,row in df_store_zip_new.iterrows():\n",
    "        store_coor=(row['latitude_meas'],row['longitude_meas'])\n",
    "        store_num=row['location_id']\n",
    "        list_store_zip=[]\n",
    "        for zip_cd, v in zip_centers.items():\n",
    "            dist=haversine(store_coor,v,unit=\"mi\")\n",
    "            if dist<=10:\n",
    "                list_store_zip.append(zip_cd)\n",
    "        df=pd.DataFrame({\"zip_cd\":list_store_zip,\"zip_type\":[\"zip_10\"]*len(list_store_zip)},index=[store_num]*len(list_store_zip))\n",
    "        df=df.reset_index().rename(columns={\"index\":\"location_id\"})\n",
    "        df_all_new_zip=df_all_new_zip.append(df)\n",
    "\n",
    "    df_store_zip_new=pd.merge(df_store_zip_new,df_all_new_zip,on=\"location_id\",how=\"left\")\n",
    "    \n",
    "    df_store_zip=df_store_zip_existing.append(df_store_zip_new)\n",
    "else:\n",
    "    df_store_zip=df_store_zip_existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'S', 'zip_10']\n"
     ]
    }
   ],
   "source": [
    "df_zip_type=df_store_zip[['zip_cd','zip_type']].drop_duplicates()\n",
    "df_zip_type=df_zip_type.sort_values(['zip_cd','zip_type'])\n",
    "print(df_zip_type['zip_type'].unique().tolist())\n",
    "df_unique_zip_type=df_zip_type.drop_duplicates(\"zip_cd\")\n",
    "\n",
    "list_P_zips=df_zip_type[df_zip_type['zip_type']==\"P\"]['zip_cd'].tolist()\n",
    "list_S_zips=df_zip_type[df_zip_type['zip_type']==\"S\"]['zip_cd'].tolist()\n",
    "list_10_zips=df_zip_type[df_zip_type['zip_type']==\"zip_10\"]['zip_cd'].tolist()\n",
    "\n",
    "df_store_list=df_store_zip[['location_id','latitude_meas','longitude_meas']].drop_duplicates().reset_index()\n",
    "del df_store_list['index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_store_list=df_store_zip[['location_id','latitude_meas','longitude_meas']].drop_duplicates().reset_index()\n",
    "del df_store_list['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "processors=20\n",
    "\n",
    "list_all_zips=list(zip_centers.keys())\n",
    "len_chunck=int(np.ceil(len(list_all_zips)/processors))\n",
    "list_of_input_all_us_zip_list=[]\n",
    "\n",
    "for i in range(processors):\n",
    "    l=list_all_zips[i*len_chunck:(i+1)*len_chunck]\n",
    "    list_of_input_all_us_zip_list.append(l)\n",
    "\n",
    "def get_dist_output_df(input_zip_list):\n",
    "    df_output=pd.DataFrame()\n",
    "    \n",
    "    for zip_cd in input_zip_list:\n",
    "        z_centroid=zip_centers[zip_cd]\n",
    "        min_dist=np.inf\n",
    "        nearest_store=None\n",
    "        \n",
    "        for i,row in df_store_list.iterrows():\n",
    "            store=row['location_id']\n",
    "            store_loc=(row['latitude_meas'], row['longitude_meas'])\n",
    "            dist=haversine(z_centroid,store_loc,unit=\"mi\")\n",
    "            if dist<=min_dist:\n",
    "                min_dist=dist\n",
    "                nearest_store=store\n",
    "        df=pd.DataFrame({\"nearest_BL_store\":nearest_store,\"nearest_BL_dist\":min_dist},index=[zip_cd])\n",
    "        df=df.reset_index().rename(columns={\"index\":\"zip_cd\"})\n",
    "        df_output=df_output.append(df)\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pool(processors)\n",
    "result=p.map(get_dist_output_df, list_of_input_all_us_zip_list)\n",
    "df_zips_with_BL_store=pd.DataFrame()\n",
    "for res in result:\n",
    "    if res is not None:\n",
    "        df_zips_with_BL_store=df_zips_with_BL_store.append(res)\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39647, 3) 39647 1403\n"
     ]
    }
   ],
   "source": [
    "print(df_zips_with_BL_store.shape,df_zips_with_BL_store['zip_cd'].nunique(),df_zips_with_BL_store['nearest_BL_store'].nunique())\n",
    "df_zips_with_BL_store['zip_cd']=df_zips_with_BL_store['zip_cd'].astype(str)\n",
    "df_zips_with_BL_store['zip_cd']=df_zips_with_BL_store['zip_cd'].apply(lambda x: x.zfill(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-07 11:32:13.555417\n",
      "df_1_len 1172966\n",
      "df_1_id_nunique 1172958\n",
      "2020-08-07 11:41:21.146687\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>sign_up_channel</th>\n",
       "      <th>sign_up_location</th>\n",
       "      <th>customer_zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000089103600e124943b7df1c8068baefed3386fcdaf0...</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>6990.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001eef71930f854218976070d33255b485c7efb1d56e...</td>\n",
       "      <td>STORE</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>87124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed sign_up_channel  \\\n",
       "0  0000089103600e124943b7df1c8068baefed3386fcdaf0...          ONLINE   \n",
       "1  00001eef71930f854218976070d33255b485c7efb1d56e...           STORE   \n",
       "\n",
       "   sign_up_location customer_zip_code  \n",
       "0            6990.0              None  \n",
       "1            1927.0             87124  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "df_1=pd.read_sql(\"select t1.customer_id_hashed, sign_up_channel, sign_up_location, customer_zip_code from BL_Rewards_Master as t1 \\\n",
    "right join %s as t2 on t1.customer_id_hashed=t2.customer_id_hashed;\"%t_crm_ids, con=BL_engine)\n",
    "\n",
    "\n",
    "df_1_len=df_1.shape[0]\n",
    "df_1_id_nunique=df_1['customer_id_hashed'].nunique()\n",
    "print(\"df_1_len\",df_1_len)\n",
    "print(\"df_1_id_nunique\",df_1_id_nunique)\n",
    "print(datetime.datetime.now())\n",
    "df_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-07 11:41:24.165152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>sign_up_location</th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>P_zip</th>\n",
       "      <th>S_zip</th>\n",
       "      <th>else_10_zip</th>\n",
       "      <th>signed_online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000089103600e124943b7df1c8068baefed3386fcdaf0...</td>\n",
       "      <td>6990</td>\n",
       "      <td>0None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001eef71930f854218976070d33255b485c7efb1d56e...</td>\n",
       "      <td>1927</td>\n",
       "      <td>87124</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed sign_up_location  \\\n",
       "0  0000089103600e124943b7df1c8068baefed3386fcdaf0...             6990   \n",
       "1  00001eef71930f854218976070d33255b485c7efb1d56e...             1927   \n",
       "\n",
       "  customer_zip_code  P_zip  S_zip  else_10_zip  signed_online  \n",
       "0             0None      0      0            0              1  \n",
       "1             87124      1      1            0              0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['customer_zip_code']=df_1['customer_zip_code'].astype(str)\n",
    "df_1['customer_zip_code']=df_1['customer_zip_code'].apply(lambda x: x.split(\"-\")[0].split(\" \")[0].zfill(5)[:5])\n",
    "# df_1['sign_up_date']=pd.to_datetime(df_1['sign_up_date'],format=\"%Y-%m-%d\").dt.date\n",
    "# df_1['weeks_since_sign_up']=df_1['sign_up_date'].apply(lambda x: int(np.ceil((high_date-x).days/7)))\n",
    "df_1['P_zip']=np.where(df_1['customer_zip_code'].isin(list_P_zips),1,0)\n",
    "df_1['S_zip']=np.where(df_1['customer_zip_code'].isin(list_S_zips),1,0)\n",
    "df_1['else_10_zip']=np.where(df_1['customer_zip_code'].isin(list_10_zips),1,0)\n",
    "# del df_1['customer_zip_code']\n",
    "df_1['signed_online']=np.where(df_1['sign_up_channel']==\"STORE\",0,1)\n",
    "del df_1['sign_up_channel']\n",
    "\n",
    "df_1['sign_up_location']=df_1['sign_up_location'].fillna(\"-1\")\n",
    "df_1['sign_up_location']=df_1['sign_up_location'].astype(float)\n",
    "df_1['sign_up_location']=df_1['sign_up_location'].astype(int).astype(str)\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "df_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_sign_up=df_1[['sign_up_location','customer_zip_code']].drop_duplicates()\n",
    "\n",
    "df_copy_sign_up=df_copy_sign_up.reset_index()\n",
    "del df_copy_sign_up['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance to sign up stores\n",
    "import glob\n",
    "df_store_all=pd.DataFrame(columns=['location_id','latitude_meas','longitude_meas'])\n",
    "\n",
    "list_all_stores=glob.glob(\"/home/jian/BigLots/static_files/Store_list/*.txt\")\n",
    "list_all_stores=[x for x in list_all_stores if \"MediaStormStores\" in x]\n",
    "list_all_stores=sorted(list_all_stores,key=lambda x :x.split(\"MediaStormStores\")[1][:8])\n",
    "list_all_stores=[x for x in list_all_stores if x.split(\"MediaStormStores\")[1][:8]<=str(high_date+datetime.timedelta(days=2)).replace(\"-\",\"\")]\n",
    "list_all_stores.reverse()\n",
    "\n",
    "for file in list_all_stores:\n",
    "    df=pd.read_table(file,dtype=str,sep=\"|\",usecols=['location_id','latitude_meas','longitude_meas'])\n",
    "    df=df[['location_id','latitude_meas','longitude_meas']]\n",
    "    df['latitude_meas']=df['latitude_meas'].astype(float)                   \n",
    "    df['longitude_meas']=df['longitude_meas'].astype(float)   \n",
    "    df=df[~df['location_id'].isin(['145','6990'])]\n",
    "    df=df[~df['location_id'].isin(df_store_all['location_id'].tolist())]\n",
    "    df_store_all=df_store_all.append(df)\n",
    "df_store_all['store_coor']=df_store_all[['latitude_meas','longitude_meas']].values.tolist()                      \n",
    "dict_store_all=df_store_all.set_index(\"location_id\").to_dict()['store_coor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_sign_up['distc_to_sign_up']=np.nan\n",
    "for i,row in df_copy_sign_up.iterrows():\n",
    "    try:\n",
    "        store_coor=dict_store_all[row['sign_up_location']]\n",
    "        zip_center=zip_centers[row['customer_zip_code']]\n",
    "        dist=haversine(store_coor,zip_center,unit=\"mi\")\n",
    "        df_copy_sign_up.loc[i,\"distc_to_sign_up\"]=dist\n",
    "        \n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-07 11:43:57.090304\n"
     ]
    }
   ],
   "source": [
    "df_1=pd.merge(df_1,df_copy_sign_up,on=['sign_up_location','customer_zip_code'],how=\"left\")\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6241656\n"
     ]
    }
   ],
   "source": [
    "list_unsub=glob.glob(folder_email_unsub+\"*.csv\")\n",
    "df_unsub_files=pd.DataFrame({\"file_path\":list_unsub})\n",
    "df_unsub_files['date']=df_unsub_files['file_path'].apply(lambda x: x.split(\"ile_Refresh__\")[1][:8])\n",
    "df_unsub_files['date']=pd.to_datetime(df_unsub_files['date']).dt.date\n",
    "df_unsub_files['day_diff']=abs(df_unsub_files['date']-high_date)\n",
    "path_unsub=df_unsub_files[df_unsub_files['day_diff']==df_unsub_files['day_diff'].min()]['file_path'].values.tolist()[0]\n",
    "###### \n",
    "list_unsunsribe_ids=pd.read_csv(path_unsub,\n",
    "                         dtype=str,usecols=['customersummary_c_primaryscnhash'])['customersummary_c_primaryscnhash'].unique().tolist()\n",
    "\n",
    "print(len(list_unsunsribe_ids))\n",
    "df_1['email_unsub_2020Feb']=np.where(df_1['customer_id_hashed'].isin(list_unsunsribe_ids),1,0)\n",
    "del list_unsunsribe_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zips_with_BL_store=df_zips_with_BL_store.rename(columns={\"zip_cd\":\"customer_zip_code\"})\n",
    "df_1=pd.merge(df_1,df_zips_with_BL_store,on=\"customer_zip_code\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>nearest_BL_store</th>\n",
       "      <th>nearest_BL_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11542</td>\n",
       "      <td>1789</td>\n",
       "      <td>7.033755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11547</td>\n",
       "      <td>1789</td>\n",
       "      <td>1.454990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_zip_code nearest_BL_store  nearest_BL_dist\n",
       "0             11542             1789         7.033755\n",
       "0             11547             1789         1.454990"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zips_with_BL_store.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1172966, 11) 1172958\n"
     ]
    }
   ],
   "source": [
    "print(df_1.shape,df_1['customer_id_hashed'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=df_1.reset_index()\n",
    "del df_1['index']\n",
    "df_1=df_1.reset_index()\n",
    "del df_1['index']\n",
    "df_1=df_1.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2020-05-24' '2020-06-20'\n"
     ]
    }
   ],
   "source": [
    "dv_start_date=high_date+datetime.timedelta(days=1)\n",
    "dv_end_date=high_date+datetime.timedelta(days=28)\n",
    "\n",
    "str_sql_dv_start_date=\"'\"+str(dv_start_date)+\"'\"\n",
    "str_sql_dv_end_date=\"'\"+str(dv_end_date)+\"'\"\n",
    "print(str_sql_dv_start_date,str_sql_dv_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-07 11:44:19.736014\n",
      "2020-08-07 11:53:29.481420\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "df_dvs=pd.read_sql(\"select customer_id_hashed, transaction_dt from Pred_POS_Department \\\n",
    "where transaction_dt between %s and %s and sales >0\"%(str_sql_dv_start_date,str_sql_dv_end_date),con=BL_engine).drop_duplicates()\n",
    "print(datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_end_dt(date_input):\n",
    "    weekday_int=date_input.weekday()\n",
    "    if weekday_int==6:\n",
    "        return date_input+datetime.timedelta(days=6)\n",
    "    else:\n",
    "        return date_input+datetime.timedelta(days=5-weekday_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dvs['week_end_dt']=df_dvs['transaction_dt'].apply(week_end_dt)\n",
    "df_dvs=df_dvs[['customer_id_hashed','week_end_dt']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-06 2020-08-07 11:53:59.405235\n",
      "2020-06-13 2020-08-07 11:54:16.288050\n",
      "2020-06-20 2020-08-07 11:54:36.006655\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>DV_cumulative_week_updated_1</th>\n",
       "      <th>DV_cumulative_week_updated_2</th>\n",
       "      <th>DV_cumulative_week_updated_3</th>\n",
       "      <th>DV_cumulative_week_updated_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000ebcf6c6a2f4302291cc9babb0760208fc683b3b5...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000358fbc9f7162c1acbfc88f1211ebec1245400631f1...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed  \\\n",
       "0  000000ebcf6c6a2f4302291cc9babb0760208fc683b3b5...   \n",
       "1  0000358fbc9f7162c1acbfc88f1211ebec1245400631f1...   \n",
       "\n",
       "   DV_cumulative_week_updated_1  DV_cumulative_week_updated_2  \\\n",
       "0                           1.0                           1.0   \n",
       "1                           1.0                           1.0   \n",
       "\n",
       "   DV_cumulative_week_updated_3  DV_cumulative_week_updated_4  \n",
       "0                           1.0                             1  \n",
       "1                           1.0                             1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_unique_weeks=df_dvs['week_end_dt'].unique().tolist()\n",
    "list_unique_weeks.sort()\n",
    "df_dv_binary=df_dvs[df_dvs['week_end_dt']==list_unique_weeks[0]][['customer_id_hashed']]\n",
    "df_dv_binary['DV_cumulative_week_updated_1']=1\n",
    "for i in range(1,4):\n",
    "    w=list_unique_weeks[i]\n",
    "    df=df_dvs[df_dvs['week_end_dt']<=w][['customer_id_hashed']].drop_duplicates()\n",
    "    df['DV_cumulative_week_updated_%d'%(i+1)]=1\n",
    "    df_dv_binary=pd.merge(df_dv_binary,df,on=\"customer_id_hashed\",how=\"outer\")\n",
    "    print(w,datetime.datetime.now())\n",
    "df_dv_binary=df_dv_binary.fillna(0)\n",
    "df_dv_binary.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1172966, 16) 1172958\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>DV_cumulative_week_updated_1</th>\n",
       "      <th>DV_cumulative_week_updated_2</th>\n",
       "      <th>DV_cumulative_week_updated_3</th>\n",
       "      <th>DV_cumulative_week_updated_4</th>\n",
       "      <th>index</th>\n",
       "      <th>sign_up_location</th>\n",
       "      <th>customer_zip_code</th>\n",
       "      <th>P_zip</th>\n",
       "      <th>S_zip</th>\n",
       "      <th>else_10_zip</th>\n",
       "      <th>signed_online</th>\n",
       "      <th>distc_to_sign_up</th>\n",
       "      <th>email_unsub_2020Feb</th>\n",
       "      <th>nearest_BL_store</th>\n",
       "      <th>nearest_BL_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000372a1070e1373197231102a69fab9a8d2bf6cf6dfdb...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>257</td>\n",
       "      <td>47421</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.408254</td>\n",
       "      <td>1</td>\n",
       "      <td>257</td>\n",
       "      <td>1.408254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000d1836c039b39db82d7a526f95db5a592478a9144658...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>92376</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.625677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001115b5ab2638de783893a633cf3a58e4ee636f3b7727...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>309</td>\n",
       "      <td>1775</td>\n",
       "      <td>08204</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211743</td>\n",
       "      <td>0</td>\n",
       "      <td>1775</td>\n",
       "      <td>0.211743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002659929bebe1dead00862170de9e170cbef05e2ab53c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>659</td>\n",
       "      <td>4507</td>\n",
       "      <td>85015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.248460</td>\n",
       "      <td>0</td>\n",
       "      <td>4507</td>\n",
       "      <td>1.248460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed  \\\n",
       "0  000372a1070e1373197231102a69fab9a8d2bf6cf6dfdb...   \n",
       "1  000d1836c039b39db82d7a526f95db5a592478a9144658...   \n",
       "2  001115b5ab2638de783893a633cf3a58e4ee636f3b7727...   \n",
       "3  002659929bebe1dead00862170de9e170cbef05e2ab53c...   \n",
       "\n",
       "   DV_cumulative_week_updated_1  DV_cumulative_week_updated_2  \\\n",
       "0                           1.0                           1.0   \n",
       "1                           1.0                           1.0   \n",
       "2                           1.0                           1.0   \n",
       "3                           1.0                           1.0   \n",
       "\n",
       "   DV_cumulative_week_updated_3  DV_cumulative_week_updated_4  index  \\\n",
       "0                           1.0                           1.0     59   \n",
       "1                           1.0                           1.0    236   \n",
       "2                           1.0                           1.0    309   \n",
       "3                           1.0                           1.0    659   \n",
       "\n",
       "  sign_up_location customer_zip_code  P_zip  S_zip  else_10_zip  \\\n",
       "0              257             47421      1      1            0   \n",
       "1                0             92376      1      1            0   \n",
       "2             1775             08204      1      0            0   \n",
       "3             4507             85015      1      1            0   \n",
       "\n",
       "   signed_online  distc_to_sign_up  email_unsub_2020Feb nearest_BL_store  \\\n",
       "0              0          1.408254                    1              257   \n",
       "1              1               NaN                    0             4274   \n",
       "2              0          0.211743                    0             1775   \n",
       "3              0          1.248460                    0             4507   \n",
       "\n",
       "   nearest_BL_dist  \n",
       "0         1.408254  \n",
       "1         0.625677  \n",
       "2         0.211743  \n",
       "3         1.248460  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1=pd.merge(df_dv_binary,df_1,on=\"customer_id_hashed\",how=\"right\")\n",
    "\n",
    "for i in range(4):\n",
    "    df_1['DV_cumulative_week_updated_%d'%(i+1)]=df_1['DV_cumulative_week_updated_%d'%(i+1)].fillna(0)\n",
    "    \n",
    "print(df_1.shape,df_1['customer_id_hashed'].nunique())\n",
    "df_1.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'table_pred_1_crm_from_up_to_20200523'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_crm_id_list_train=\"crm_table_id_list_train_%s\"%str_week_end_d\n",
    "table_crm_id_list_test=\"crm_table_id_list_test_%s\"%str_week_end_d\n",
    "tabl_1=\"table_pred_1_crm_from_up_to_%s\"%str_week_end_d\n",
    "\n",
    "tablename_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "len_df_1=len(df_1)\n",
    "train_sample_size=10**6\n",
    "test_ratio=0.25\n",
    "if len_df_1>train_sample_size/(1-test_ratio):\n",
    "    list_ind_train=random.sample(range(len_df_1), train_sample_size)\n",
    "else:\n",
    "    list_ind_train=random.sample(range(len_df_1), int(len_df_1*(1-test_ratio)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1_train.shape (879724, 1)\n",
      "df_1_test.shape (293242, 1)\n"
     ]
    }
   ],
   "source": [
    "df_1_train=df_1[['customer_id_hashed']][df_1['index'].isin(list_ind_train)]\n",
    "df_1_test=df_1[['customer_id_hashed']][~df_1['index'].isin(list_ind_train)]\n",
    "\n",
    "print(\"df_1_train.shape\",df_1_train.shape)\n",
    "print(\"df_1_test.shape\",df_1_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-07 12:05:09.704764\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000372a1070e1373197231102a69fab9a8d2bf6cf6dfdb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000d1836c039b39db82d7a526f95db5a592478a9144658...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed\n",
       "0  000372a1070e1373197231102a69fab9a8d2bf6cf6dfdb...\n",
       "1  000d1836c039b39db82d7a526f95db5a592478a9144658..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer_id_hashed',\n",
       " 'DV_cumulative_week_updated_1',\n",
       " 'DV_cumulative_week_updated_2',\n",
       " 'DV_cumulative_week_updated_3',\n",
       " 'DV_cumulative_week_updated_4',\n",
       " 'index',\n",
       " 'sign_up_location',\n",
       " 'customer_zip_code',\n",
       " 'P_zip',\n",
       " 'S_zip',\n",
       " 'else_10_zip',\n",
       " 'signed_online',\n",
       " 'distc_to_sign_up',\n",
       " 'email_unsub_2020Feb',\n",
       " 'nearest_BL_store',\n",
       " 'nearest_BL_dist']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_id_hashed [<class 'str'>]\n",
      "DV_cumulative_week_updated_1 [<class 'float'>]\n",
      "DV_cumulative_week_updated_2 [<class 'float'>]\n",
      "DV_cumulative_week_updated_3 [<class 'float'>]\n",
      "DV_cumulative_week_updated_4 [<class 'float'>]\n",
      "index [<class 'int'>]\n",
      "sign_up_location [<class 'str'>]\n",
      "customer_zip_code [<class 'str'>]\n",
      "P_zip [<class 'int'>]\n",
      "S_zip [<class 'int'>]\n",
      "else_10_zip [<class 'int'>]\n",
      "signed_online [<class 'int'>]\n",
      "distc_to_sign_up [<class 'float'>]\n",
      "email_unsub_2020Feb [<class 'int'>]\n",
      "nearest_BL_store [<class 'str'> <class 'float'>]\n",
      "nearest_BL_dist [<class 'float'>]\n"
     ]
    }
   ],
   "source": [
    "for col in df_1.columns.tolist():\n",
    "    print(col,df_1[col].apply(type).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
