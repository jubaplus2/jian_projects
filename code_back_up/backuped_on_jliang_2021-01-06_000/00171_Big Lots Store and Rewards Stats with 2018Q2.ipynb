{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import hashlib\n",
    "import logging\n",
    "import gc\n",
    "logging.basicConfig(filename='BL_Store_Rewards_Stats'+str(datetime.datetime.now().date())+'.log', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samplerows=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_info=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20180901-133640-935.txt\",sep=\"|\",dtype=str)\n",
    "store_info=store_info[['location_id','city_nm','state_nm','zip_cd','open_dt']]\n",
    "\n",
    "store_info_2=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20180801-133641-576.txt\",sep=\"|\",dtype=str)\n",
    "store_info_2=store_info_2[['location_id','city_nm','state_nm','zip_cd','open_dt']]\n",
    "store_info_2=store_info_2[~store_info_2['location_id'].isin(store_info['location_id'].tolist())]\n",
    "store_info=store_info.append(store_info_2)\n",
    "\n",
    "store_info_2=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20180703.txt\",sep=\"|\",dtype=str)\n",
    "store_info_2=store_info_2[['location_id','city_nm','state_nm','zip_cd','open_dt']]\n",
    "store_info_2=store_info_2[~store_info_2['location_id'].isin(store_info['location_id'].tolist())]\n",
    "store_info=store_info.append(store_info_2)\n",
    "\n",
    "store_info_2=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20171115.txt\",sep=\"|\",dtype=str)\n",
    "store_info_2=store_info_2[['location_id','city_nm','state_nm','zip_cd','open_dt']]\n",
    "store_info_2=store_info_2[~store_info_2['location_id'].isin(store_info['location_id'].tolist())]\n",
    "store_info=store_info.append(store_info_2)\n",
    "\n",
    "store_info_2=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20170913.txt\",sep=\"|\",dtype=str)\n",
    "store_info_2=store_info_2[['location_id','city_nm','state_nm','zip_cd','open_dt']]\n",
    "store_info_2=store_info_2[~store_info_2['location_id'].isin(store_info['location_id'].tolist())]\n",
    "store_info=store_info.append(store_info_2)\n",
    "store_info['zip_cd']=store_info['zip_cd'].apply(lambda x: x.split(\"-\")[0].zfill(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inclusion_stores_sales_data=pd.read_excel(\"/home/jian/BiglotsCode/outputs/Output_2018-09-01/wide_sales_date2018-09-01.xlsx\",dtype=str,sheetname=\"sales\")\n",
    "inclusion_stores_trans_data=pd.read_excel(\"/home/jian/BiglotsCode/outputs/Output_2018-09-01/wide_sales_date2018-09-01.xlsx\",dtype=str,sheetname=\"transactions\")\n",
    "\n",
    "inclusions_store_list=inclusion_stores_sales_data[inclusion_stores_sales_data['2018-09-01']!=\"0\"]['location_id'].tolist()\n",
    "\n",
    "inclusion_stores_sales_data=inclusion_stores_sales_data[inclusion_stores_sales_data['location_id'].isin(inclusions_store_list)]\n",
    "inclusion_stores_trans_data=inclusion_stores_trans_data[inclusion_stores_trans_data['location_id'].isin(inclusions_store_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q2_Start_week_2018=datetime.date(2018,5,12)\n",
    "Q2_End_week_2018=datetime.date(2018,8,4)\n",
    "Q2_Start_week_2017=datetime.date(2017,5,13)\n",
    "Q2_End_week_2017=datetime.date(2017,8,5)\n",
    "Q2_2017_Weeks=[str(Q2_Start_week_2017+datetime.timedelta(days=7*i)) for i in range(13)]\n",
    "Q2_2018_Weeks=[str(Q2_Start_week_2018+datetime.timedelta(days=7*i)) for i in range(13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inclusion_stores_sales_data=inclusion_stores_sales_data[['location_id']+Q2_2017_Weeks+Q2_2018_Weeks]\n",
    "inclusion_stores_trans_data=inclusion_stores_trans_data[['location_id']+Q2_2017_Weeks+Q2_2018_Weeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in Q2_2017_Weeks+Q2_2018_Weeks:\n",
    "    inclusion_stores_sales_data[col]=inclusion_stores_sales_data[col].astype(float)\n",
    "    inclusion_stores_trans_data[col]=inclusion_stores_trans_data[col].astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inclusion_stores_trans_data['2017_Q2_Trans']=inclusion_stores_trans_data[Q2_2017_Weeks].sum(axis=1)\n",
    "inclusion_stores_trans_data['2018_Q2_Trans']=inclusion_stores_trans_data[Q2_2018_Weeks].sum(axis=1)\n",
    "inclusion_stores_sales_data['2017_Q2_Sales']=inclusion_stores_sales_data[Q2_2017_Weeks].sum(axis=1)\n",
    "inclusion_stores_sales_data['2018_Q2_Sales']=inclusion_stores_sales_data[Q2_2018_Weeks].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q2_Sales_Trans=pd.merge(inclusion_stores_trans_data[['location_id','2017_Q2_Trans','2018_Q2_Trans']],\n",
    "                       inclusion_stores_sales_data[['location_id','2017_Q2_Sales','2018_Q2_Sales']],\n",
    "                       on=\"location_id\",how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DMA_Zip=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",skiprows=1,dtype=str)\n",
    "DMA_Zip=DMA_Zip.iloc[:,[0,2]]\n",
    "DMA_Zip.columns=['zip_cd','DMA']\n",
    "DMA_Zip=DMA_Zip.drop_duplicates(['zip_cd'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_info=pd.merge(store_info,DMA_Zip,on=\"zip_cd\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inclusion_store_list_set=set(Q2_Sales_Trans['location_id'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_1=store_info.copy()\n",
    "df_1=df_1[df_1['location_id'].isin(inclusion_store_list_set)]\n",
    "df_4=Q2_Sales_Trans.copy()\n",
    "del store_info\n",
    "df_4['Q2_Sales_YoY']=(df_4['2018_Q2_Sales']-df_4['2017_Q2_Sales'])/df_4['2017_Q2_Sales']\n",
    "df_4['Q2_Trans_YoY']=(df_4['2018_Q2_Trans']-df_4['2017_Q2_Trans'])/df_4['2017_Q2_Trans']\n",
    "df_4=df_4[['location_id','Q2_Sales_YoY','Q2_Trans_YoY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51424"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = '/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/' # usecols=[0,1,5],\n",
    "selected_columns = ['customer_id_hashed','sign_up_location','customer_zip_code','sign_up_date']\n",
    "dfiddetail = pd.read_table(folderpath+\"/MediaStormCustTot-hashed-email.txt\",\n",
    "                       header=None,nrows = samplerows,sep = ',',dtype = str,usecols=[0,2,4,5])\n",
    "dfiddetail.columns=['customer_id','sign_up_location','customer_zip_code','sign_up_date']\n",
    "dfiddetail['customer_id_hashed'] = dfiddetail['customer_id'].apply(lambda x: hashlib.sha256(x.encode('utf-8')).hexdigest())\n",
    "dfiddetail=dfiddetail[selected_columns]\n",
    "dfiddetail=dfiddetail[dfiddetail['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormCustomerTransactionTotals_2018-01-09_2018-03-31.txt',\n",
    "                          nrows = samplerows,sep = ',',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'Existing Reward Member Master as of 2018-06-05.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'New Reward Member Master as of 2018-06-05.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'New Reward Member Master as of 2018-07-03.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180717-132337-377.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180731-130714-098.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180814-130703-491.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "del dfiddetail2\n",
    "#\n",
    "dfiddetail['zip_cd']=dfiddetail['customer_zip_code'].apply(lambda x: str(x).split(\"-\")[0].zfill(5))\n",
    "dfiddetail['zip_cd']=dfiddetail['zip_cd'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "del dfiddetail['customer_zip_code']\n",
    "\n",
    "dfiddetail['sign_up_date']=dfiddetail['sign_up_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "dfiddetail=dfiddetail.sort_values(['sign_up_date'],ascending=False)\n",
    "dfiddetail=dfiddetail[['customer_id_hashed','sign_up_location','zip_cd']].drop_duplicates('customer_id_hashed')\n",
    "logging.info(\"Finished read of singing up data, with rows of \"+str(dfiddetail.shape[0]))\n",
    "\n",
    "dfiddetail=dfiddetail[dfiddetail['zip_cd'].apply(lambda x: len(x)).isin([5,9])]\n",
    "dfiddetail['zip_cd']=dfiddetail['zip_cd'].apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_up_id_by_zip=dfiddetail.groupby(['zip_cd'])['customer_id_hashed'].count().to_frame().reset_index()\n",
    "sign_up_id_by_store=dfiddetail.groupby(['sign_up_location'])['customer_id_hashed'].count().to_frame().reset_index()\n",
    "# del dfiddetail\n",
    "gc.collect()\n",
    "# sign_up_id_by_zip later in zip level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2=sign_up_id_by_store.copy()\n",
    "del sign_up_id_by_store\n",
    "df_2=df_2.rename(columns={\"sign_up_location\":\"location_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ta_by_zip=pd.read_excel(\"/home/jian/Projects/Big_Lots/New_TA/zips_in_new_ta/BL_Zips in new TA (TA level)_JL_20180330.xlsx\",\n",
    "                       dtype=str,usecols=['location_id','zip_cd','revenue_flag','TA_of_zip','TA_of_store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TA_Zips=ta_by_zip[['zip_cd','TA_of_zip']].drop_duplicates()\n",
    "TA_Store=ta_by_zip[['location_id','TA_of_store']].drop_duplicates()\n",
    "TA_Store=TA_Store[TA_Store['location_id'].isin(inclusion_store_list_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores_not_in_TA=[x for x in inclusion_store_list_set if x not in ta_by_zip['location_id'].tolist()]\n",
    "zips_for_new_store=df_1[df_1['location_id'].isin(stores_not_in_TA)]['zip_cd'].unique().tolist()\n",
    "# 8 new stores not in TA, 7 of the 8 zips are found in TA and allocated to the TA\n",
    "# 4675|02719 missing TA info, so no population\n",
    "TA_new_store=TA_Zips[TA_Zips['zip_cd'].isin(zips_for_new_store)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "given_TA_7_New_store=df_1[df_1['location_id'].isin(stores_not_in_TA)]\n",
    "given_TA_7_New_store=pd.merge(given_TA_7_New_store,TA_Zips,on=\"zip_cd\",how=\"left\")\n",
    "given_TA_7_New_store=given_TA_7_New_store[['location_id','TA_of_zip']].rename(columns={\"TA_of_zip\":\"TA_of_store\"})\n",
    "TA_Store=TA_Store.append(given_TA_7_New_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo_F_25_54=pd.read_csv(\"/home/jian/Docs/Household_and_Population/2016/Demo_Dataset_2018EASI.csv\",\n",
    "                         dtype=str,usecols=['ZIP_CODE','Estimate; Female: - 25 to 29 years','Estimate; Female: - 30 to 34 years',\n",
    "                                                    'Estimate; Female: - 35 to 39 years','Estimate; Female: - 40 to 44 years',\n",
    "                                                     'Estimate; Female: - 45 to 49 years','Estimate; Female: - 50 to 54 years'])\n",
    "for col in demo_F_25_54.columns.tolist()[1:]:\n",
    "    demo_F_25_54[col]=demo_F_25_54[col].astype(float)\n",
    "demo_F_25_54['ZIP_CODE']=demo_F_25_54['ZIP_CODE'].apply(lambda x: x.zfill(5))\n",
    "demo_F_25_54['Pop_F_25_54']=demo_F_25_54[demo_F_25_54.columns.tolist()[1:]].sum(axis=1)\n",
    "demo_F_25_54=demo_F_25_54.rename(columns={\"ZIP_CODE\":\"zip_cd\"})\n",
    "demo_F_25_54=demo_F_25_54[['zip_cd','Pop_F_25_54']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TA_Zips_POP=pd.merge(TA_Zips,demo_F_25_54,on=\"zip_cd\",how=\"left\")\n",
    "TA_POP=TA_Zips_POP.groupby(['TA_of_zip'])['Pop_F_25_54'].sum().to_frame().reset_index()\n",
    "TA_POP=TA_POP.rename(columns={\"TA_of_zip\":\"TA\"})\n",
    "TA_Store=TA_Store.rename(columns={\"TA_of_store\":\"TA\"})\n",
    "df_3=pd.merge(TA_Store,TA_POP,on=\"TA\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15146"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_sales_from_SP=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_sales_data/From_Sp/combinedtransactions_0811.csv\",\n",
    "                                 dtype=str,nrows=samplerows,usecols=['customer_id_hashed','transaction_date','transaction_id','location_id','total_transaction_amt'])\n",
    "rewards_sales_from_SP=rewards_sales_from_SP[rewards_sales_from_SP['location_id'].isin(inclusion_store_list_set)]\n",
    "rewards_sales_from_SP['transaction_date']=rewards_sales_from_SP['transaction_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "rewards_sales_from_SP=rewards_sales_from_SP[(rewards_sales_from_SP['transaction_date']>=Q2_Start_week_2018) & (rewards_sales_from_SP['transaction_date']<=Q2_End_week_2018)]\n",
    "rewards_sales_from_SP=rewards_sales_from_SP.drop_duplicates()\n",
    "rewards_sales_from_SP['total_transaction_amt']=rewards_sales_from_SP['total_transaction_amt'].astype(float)\n",
    "del rewards_sales_from_SP['transaction_id']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_week_end_date(x):\n",
    "    weekday_num=x.weekday()\n",
    "    if weekday_num==6:\n",
    "        y=x+datetime.timedelta(days=6)\n",
    "    else:\n",
    "        y=x+datetime.timedelta(days=5-weekday_num)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_by_store_Q2_sales=rewards_sales_from_SP.groupby(['location_id'])['total_transaction_amt'].sum().to_frame().reset_index()\n",
    "rewards_by_store_Q2_sales=rewards_by_store_Q2_sales.rename(columns={\"total_transaction_amt\":\"rewards_sales\"})\n",
    "rewards_by_store_Q2_trans=rewards_sales_from_SP.groupby(['location_id'])['total_transaction_amt'].count().to_frame().reset_index()\n",
    "rewards_by_store_Q2_trans=rewards_by_store_Q2_trans.rename(columns={\"total_transaction_amt\":\"rewards_trans\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>rewards_sales</th>\n",
       "      <th>rewards_trans</th>\n",
       "      <th>Q2_rewards_sales_share</th>\n",
       "      <th>Q2_rewards_trans_share</th>\n",
       "      <th>Rewards_AOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>631157.08</td>\n",
       "      <td>15120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.743193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>283740.16</td>\n",
       "      <td>7309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.820654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id  rewards_sales  rewards_trans  Q2_rewards_sales_share  \\\n",
       "0           1      631157.08          15120                     NaN   \n",
       "1        1001      283740.16           7309                     NaN   \n",
       "\n",
       "   Q2_rewards_trans_share  Rewards_AOV  \n",
       "0                     NaN    41.743193  \n",
       "1                     NaN    38.820654  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5=pd.merge(rewards_by_store_Q2_sales,rewards_by_store_Q2_trans,on=\"location_id\",how=\"outer\")\n",
    "df_5['Q2_rewards_sales_share']=np.nan\n",
    "df_5['Q2_rewards_trans_share']=np.nan\n",
    "df_5['Rewards_AOV']=df_5['rewards_sales']/df_5['rewards_trans']\n",
    "df_5.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df_7=inclusion_stores_sales_data[['location_id']+Q2_2017_Weeks+Q2_2018_Weeks]\n",
    "for col in Q2_2018_Weeks:\n",
    "    week_2018=col\n",
    "    week_2017=str(datetime.datetime.strptime(col,\"%Y-%m-%d\").date()-datetime.timedelta(days=52*7))\n",
    "    df_7[\"YoY_\"+col]=np.round((df_7[week_2018]-df_7[week_2017])/df_7[week_2017],6)\n",
    "df_7=df_7[[\"location_id\"]+[\"YoY_\"+x for x in Q2_2018_Weeks]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_level_output=pd.merge(df_1,df_2,on=\"location_id\",how=\"left\")\n",
    "store_level_output=pd.merge(store_level_output,df_3,on=\"location_id\",how=\"left\")\n",
    "store_level_output=pd.merge(store_level_output,df_4,on=\"location_id\",how=\"left\")\n",
    "store_level_output=pd.merge(store_level_output,df_5,on=\"location_id\",how=\"left\")\n",
    "store_level_output=pd.merge(store_level_output,df_7,on=\"location_id\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_sales_from_SP=pd.merge(rewards_sales_from_SP,dfiddetail,on=\"customer_id_hashed\",how=\"left\")\n",
    "del dfiddetail['sign_up_location']\n",
    "rewards_sales_from_SP=pd.merge(rewards_sales_from_SP,dfiddetail,on=\"customer_id_hashed\",how=\"left\")\n",
    "rewards_sales_from_SP['zip_cd']=rewards_sales_from_SP['zip_cd'].fillna(\"zip_missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Store_level_PST=pd.read_csv(\"/home/jian/Projects/Big_Lots/New_TA/zips_in_new_ta/sales_by_zip (Store level).csv\",dtype=str)\n",
    "Store_level_PST=Store_level_PST[Store_level_PST['location_id'].isin(inclusion_store_list_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Store_level_P_Zips=Store_level_PST[Store_level_PST['revenue_flag']==\"P\"].groupby(['location_id'])['zip'].apply(set).to_frame().reset_index()\n",
    "Store_level_S_Zips=Store_level_PST[Store_level_PST['revenue_flag']==\"S\"].groupby(['location_id'])['zip'].apply(set).to_frame().reset_index()\n",
    "Store_level_T_Zips=Store_level_PST[Store_level_PST['revenue_flag']==\"T\"].groupby(['location_id'])['zip'].apply(set).to_frame().reset_index()\n",
    "\n",
    "Store_level_P_Zips_Dict=Store_level_P_Zips.set_index(['location_id']).to_dict()['zip']\n",
    "Store_level_S_Zips_Dict=Store_level_S_Zips.set_index(['location_id']).to_dict()['zip']\n",
    "Store_level_T_Zips_Dict=Store_level_T_Zips.set_index(['location_id']).to_dict()['zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_list_with_PST=Store_level_PST['location_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20864671, 4)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SP_July_Decile=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/Segment_Movement_analysis/Data_From_Sp/df_crm_finalscore_0714data.csv\",\n",
    "                              dtype=str,usecols=['customer_id_hashed','frmindex','zipcodegroup','customer_zip_code'])\n",
    "df_SP_July_Decile=df_SP_July_Decile.drop_duplicates(['customer_id_hashed'])\n",
    "decile_list=df_SP_July_Decile['frmindex'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2847, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-164-6cf98e57c4fb>\", line 20, in <module>\n",
      "    df_decile=df_SP_July_Decile[(df_SP_July_Decile['frmindex']==D_decile) & (df_SP_July_Decile['customer_zip_code'].isin(zips_store_label))]\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pandas/core/series.py\", line 2555, in isin\n",
      "    result = algorithms.isin(_values_from_object(self), values)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 426, in isin\n",
      "    return f(comps, values)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 406, in <lambda>\n",
      "    f = lambda x, y: np.in1d(x, y)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/numpy/lib/arraysetops.py\", line 468, in in1d\n",
      "    ar1, rev_idx = np.unique(ar1, return_inverse=True)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/numpy/lib/arraysetops.py\", line 210, in unique\n",
      "    return _unique1d(ar, return_index, return_inverse, return_counts)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/numpy/lib/arraysetops.py\", line 274, in _unique1d\n",
      "    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1795, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1092, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 312, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/lib/python3.6/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/lib/python3.6/inspect.py\", line 1415, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 166, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/local/lib/python3.6/inspect.py\", line 656, in getsourcefile\n",
      "    all_bytecode_suffixes += importlib.machinery.OPTIMIZED_BYTECODE_SUFFIXES[:]\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "output_zip_level=pd.DataFrame()\n",
    "k=0\n",
    "for store in store_list_with_PST:\n",
    "    total_rewards_sales_store=rewards_sales_from_SP[rewards_sales_from_SP['location_id']==store]['total_transaction_amt'].sum()\n",
    "    for label in [\"P\",\"S\",\"T\"]:\n",
    "        zips_store_label=locals()[\"Store_level_\"+label+\"_Zips_Dict\"][store]\n",
    "        df_id_store_label=sign_up_id_by_zip[sign_up_id_by_zip['zip_cd'].isin(zips_store_label)]\n",
    "        id_count_store_label=df_id_store_label['customer_id_hashed'].sum()\n",
    "        \n",
    "        sales_store_label=rewards_sales_from_SP[rewards_sales_from_SP['zip_cd'].isin(zips_store_label)]['total_transaction_amt'].sum()\n",
    "        trans_store_label=len(rewards_sales_from_SP[rewards_sales_from_SP['zip_cd'].isin(zips_store_label)])\n",
    "        \n",
    "        AOV_store_label=sales_store_label/trans_store_label\n",
    "        \n",
    "        sales_share_label=sales_store_label/total_rewards_sales_store\n",
    "        \n",
    "        trans_to_id=trans_store_label/id_count_store_label\n",
    "        \n",
    "        for D_decile in decile_list:\n",
    "            df_decile=df_SP_July_Decile[(df_SP_July_Decile['frmindex']==D_decile) & (df_SP_July_Decile['customer_zip_code'].isin(zips_store_label))]\n",
    "            locals()[D_decile+\"_store_label\"]=len(df_decile)\n",
    "        locals()['df_app_'+label]=pd.DataFrame({\"location_id\":store,label+\"_id_cousnt\":id_count_store_label,label+\"_sales_share\":sales_share_label,\n",
    "                             label+\"_AOV\":AOV_store_label,label+\"_trans_per_id_avg\":trans_to_id,\n",
    "                             label+\"_D1\":locals()[\"D01_store_label\"],label+\"_D2\":locals()[\"D02_store_label\"],\n",
    "                             label+\"_D3\":locals()[\"D03_store_label\"],label+\"_D4\":locals()[\"D04_store_label\"],\n",
    "                             label+\"_D5\":locals()[\"D05_store_label\"],label+\"_D6\":locals()[\"D06_store_label\"],\n",
    "                             label+\"_D7\":locals()[\"D07_store_label\"],label+\"_D8\":locals()[\"D08_store_label\"],\n",
    "                             label+\"_D9\":locals()[\"D09_store_label\"],label+\"_D10\":locals()[\"D10_store_label\"],\n",
    "                            },index=[store])\n",
    "    df_app_3_lable=pd.merge(df_app_P,df_app_S,on=\"location_id\",how=\"left\")\n",
    "    df_app_3_lable=pd.merge(df_app_3_lable,df_app_T,on=\"location_id\",how=\"left\")\n",
    "    \n",
    "    output_zip_level=output_zip_level.append(df_app_3_lable)\n",
    "    k+=1\n",
    "    if k %100==1:\n",
    "        print(store,datetime.datetime.now())\n",
    "        logging.info(store+str(datetime.datetime.now()))\n",
    "    if k %100==2:\n",
    "        print(store,datetime.datetime.now())\n",
    "        logging.info(store+str(datetime.datetime.now()))\n",
    "    if k %100==3:\n",
    "        print(store,datetime.datetime.now())\n",
    "        logging.info(store+str(datetime.datetime.now()))\n",
    "    if k %100==23:\n",
    "        print(store,datetime.datetime.now())\n",
    "        logging.info(store+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output=pd.merge(store_level_output,output_zip_level,on=\"location_id\",how=\"left\")\n",
    "final_output.to_csv(\"/home/jian/Projects/Big_Lots/Analysis/Store_Stats_201809/BL_Store_Rewards_Stats_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
