{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import hashlib\n",
    "import logging\n",
    "import gc\n",
    "logging.basicConfig(filename='BL_Store_Rewards_Stats'+str(datetime.datetime.now().date())+'.log', level=logging.INFO)\n",
    "\n",
    "\n",
    "samplerows=None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51424"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_info=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20180901-133640-935.txt\",sep=\"|\",dtype=str)\n",
    "store_info=store_info[['location_id','city_nm','state_nm','zip_cd','open_dt']]\n",
    "\n",
    "store_info_2=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20180801-133641-576.txt\",sep=\"|\",dtype=str)\n",
    "store_info_2=store_info_2[['location_id','city_nm','state_nm','zip_cd','open_dt']]\n",
    "store_info_2=store_info_2[~store_info_2['location_id'].isin(store_info['location_id'].tolist())]\n",
    "store_info=store_info.append(store_info_2)\n",
    "\n",
    "store_info_2=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20180703.txt\",sep=\"|\",dtype=str)\n",
    "store_info_2=store_info_2[['location_id','city_nm','state_nm','zip_cd','open_dt']]\n",
    "store_info_2=store_info_2[~store_info_2['location_id'].isin(store_info['location_id'].tolist())]\n",
    "store_info=store_info.append(store_info_2)\n",
    "\n",
    "store_info_2=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20171115.txt\",sep=\"|\",dtype=str)\n",
    "store_info_2=store_info_2[['location_id','city_nm','state_nm','zip_cd','open_dt']]\n",
    "store_info_2=store_info_2[~store_info_2['location_id'].isin(store_info['location_id'].tolist())]\n",
    "store_info=store_info.append(store_info_2)\n",
    "\n",
    "store_info_2=pd.read_table(\"/home/jian/BigLots/static_files/Store_list/MediaStormStores20170913.txt\",sep=\"|\",dtype=str)\n",
    "store_info_2=store_info_2[['location_id','city_nm','state_nm','zip_cd','open_dt']]\n",
    "store_info_2=store_info_2[~store_info_2['location_id'].isin(store_info['location_id'].tolist())]\n",
    "store_info=store_info.append(store_info_2)\n",
    "store_info['zip_cd']=store_info['zip_cd'].apply(lambda x: x.split(\"-\")[0].zfill(5))\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "inclusion_stores_sales_data=pd.read_excel(\"/home/jian/BiglotsCode/outputs/Output_2018-09-01/wide_sales_date2018-09-01.xlsx\",dtype=str,sheetname=\"sales\")\n",
    "inclusion_stores_trans_data=pd.read_excel(\"/home/jian/BiglotsCode/outputs/Output_2018-09-01/wide_sales_date2018-09-01.xlsx\",dtype=str,sheetname=\"transactions\")\n",
    "\n",
    "inclusions_store_list=inclusion_stores_sales_data[inclusion_stores_sales_data['2018-09-01']!=\"0\"]['location_id'].tolist()\n",
    "\n",
    "inclusion_stores_sales_data=inclusion_stores_sales_data[inclusion_stores_sales_data['location_id'].isin(inclusions_store_list)]\n",
    "inclusion_stores_trans_data=inclusion_stores_trans_data[inclusion_stores_trans_data['location_id'].isin(inclusions_store_list)]\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "Q2_Start_week_2018=datetime.date(2018,5,12)\n",
    "Q2_End_week_2018=datetime.date(2018,8,4)\n",
    "Q2_Start_week_2017=datetime.date(2017,5,13)\n",
    "Q2_End_week_2017=datetime.date(2017,8,5)\n",
    "Q2_2017_Weeks=[str(Q2_Start_week_2017+datetime.timedelta(days=7*i)) for i in range(13)]\n",
    "Q2_2018_Weeks=[str(Q2_Start_week_2018+datetime.timedelta(days=7*i)) for i in range(13)]\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "inclusion_stores_sales_data=inclusion_stores_sales_data[['location_id']+Q2_2017_Weeks+Q2_2018_Weeks]\n",
    "inclusion_stores_trans_data=inclusion_stores_trans_data[['location_id']+Q2_2017_Weeks+Q2_2018_Weeks]\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "for col in Q2_2017_Weeks+Q2_2018_Weeks:\n",
    "    inclusion_stores_sales_data[col]=inclusion_stores_sales_data[col].astype(float)\n",
    "    inclusion_stores_trans_data[col]=inclusion_stores_trans_data[col].astype(float)\n",
    "    \n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "inclusion_stores_trans_data['2017_Q2_Trans']=inclusion_stores_trans_data[Q2_2017_Weeks].sum(axis=1)\n",
    "inclusion_stores_trans_data['2018_Q2_Trans']=inclusion_stores_trans_data[Q2_2018_Weeks].sum(axis=1)\n",
    "inclusion_stores_sales_data['2017_Q2_Sales']=inclusion_stores_sales_data[Q2_2017_Weeks].sum(axis=1)\n",
    "inclusion_stores_sales_data['2018_Q2_Sales']=inclusion_stores_sales_data[Q2_2018_Weeks].sum(axis=1)\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "Q2_Sales_Trans=pd.merge(inclusion_stores_trans_data[['location_id','2017_Q2_Trans','2018_Q2_Trans']],\n",
    "                       inclusion_stores_sales_data[['location_id','2017_Q2_Sales','2018_Q2_Sales']],\n",
    "                       on=\"location_id\",how=\"outer\")\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "DMA_Zip=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",skiprows=1,dtype=str)\n",
    "DMA_Zip=DMA_Zip.iloc[:,[0,2]]\n",
    "DMA_Zip.columns=['zip_cd','DMA']\n",
    "DMA_Zip=DMA_Zip.drop_duplicates(['zip_cd'])\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "store_info=pd.merge(store_info,DMA_Zip,on=\"zip_cd\",how=\"left\")\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "inclusion_store_list_set=set(Q2_Sales_Trans['location_id'].unique().tolist())\n",
    "\n",
    "#\n",
    "\n",
    "df_1=store_info.copy()\n",
    "df_1=df_1[df_1['location_id'].isin(inclusion_store_list_set)]\n",
    "df_4=Q2_Sales_Trans.copy()\n",
    "del store_info\n",
    "df_4['Q2_Sales_YoY']=(df_4['2018_Q2_Sales']-df_4['2017_Q2_Sales'])/df_4['2017_Q2_Sales']\n",
    "df_4['Q2_Trans_YoY']=(df_4['2018_Q2_Trans']-df_4['2017_Q2_Trans'])/df_4['2017_Q2_Trans']\n",
    "df_4=df_4[['location_id','Q2_Sales_YoY','Q2_Trans_YoY','2018_Q2_Sales','2017_Q2_Sales','2018_Q2_Trans','2017_Q2_Trans']]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folderpath = '/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/' # usecols=[0,1,5],\n",
    "selected_columns = ['customer_id_hashed','sign_up_location','customer_zip_code','sign_up_date']\n",
    "dfiddetail = pd.read_table(folderpath+\"/MediaStormCustTot-hashed-email.txt\",\n",
    "                       header=None,nrows = samplerows,sep = ',',dtype = str,usecols=[0,2,4,5])\n",
    "dfiddetail.columns=['customer_id','sign_up_date','sign_up_location','customer_zip_code']\n",
    "dfiddetail['customer_id_hashed'] = dfiddetail['customer_id'].apply(lambda x: hashlib.sha256(x.encode('utf-8')).hexdigest())\n",
    "dfiddetail=dfiddetail[selected_columns]\n",
    "dfiddetail=dfiddetail[dfiddetail['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormCustomerTransactionTotals_2018-01-09_2018-03-31.txt',\n",
    "                          nrows = samplerows,sep = ',',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'Existing Reward Member Master as of 2018-06-05.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'New Reward Member Master as of 2018-06-05.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'New Reward Member Master as of 2018-07-03.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180717-132337-377.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180731-130714-098.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180814-130703-491.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,2,4,5],dtype = str)\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "del dfiddetail2\n",
    "#\n",
    "dfiddetail['customer_zip_code']=dfiddetail['customer_zip_code'].astype(str)\n",
    "dfiddetail['customer_zip_code']=dfiddetail['customer_zip_code'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "dfiddetail['customer_zip_code']=dfiddetail['customer_zip_code'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "dfiddetail['customer_zip_code']=dfiddetail['customer_zip_code'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "dfiddetail['zip_cd']=dfiddetail['customer_zip_code'].apply(lambda x: str(x).split(\"-\")[0].zfill(5))\n",
    "del dfiddetail['customer_zip_code']\n",
    "\n",
    "dfiddetail=dfiddetail[dfiddetail['sign_up_date'].apply(lambda x: len(x))==10]\n",
    "\n",
    "dfiddetail['sign_up_date']=dfiddetail['sign_up_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "dfiddetail=dfiddetail.sort_values(['sign_up_date'],ascending=False)\n",
    "dfiddetail=dfiddetail[['customer_id_hashed','sign_up_location','zip_cd','sign_up_date']].drop_duplicates('customer_id_hashed')\n",
    "logging.info(\"Finished read of singing up data, with rows of \"+str(dfiddetail.shape[0]))\n",
    "\n",
    "dfiddetail=dfiddetail[dfiddetail['zip_cd'].apply(lambda x: len(x)).isin([5,9])]\n",
    "dfiddetail['zip_cd']=dfiddetail['zip_cd'].apply(lambda x: x[:5])\n",
    "\n",
    "#\n",
    "\n",
    "sign_up_id_by_zip=dfiddetail.groupby(['zip_cd'])['customer_id_hashed'].count().to_frame().reset_index()\n",
    "sign_up_id_by_store=dfiddetail.groupby(['sign_up_location'])['customer_id_hashed'].count().to_frame().reset_index()\n",
    "gc.collect()\n",
    "\n",
    "df_2=sign_up_id_by_store.copy()\n",
    "del sign_up_id_by_store\n",
    "df_2=df_2.rename(columns={\"sign_up_location\":\"location_id\",\"customer_id_hashed\":\"id_counts_signed_up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "df_2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15217"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta_by_zip=pd.read_excel(\"/home/jian/Projects/Big_Lots/New_TA/zips_in_new_ta/BL_Zips in new TA (TA level)_JL_20180330.xlsx\",\n",
    "                       dtype=str,usecols=['location_id','zip_cd','revenue_flag','TA_of_zip','TA_of_store'])\n",
    "TA_Zips=ta_by_zip[['zip_cd','TA_of_zip']].drop_duplicates()\n",
    "TA_Store=ta_by_zip[['location_id','TA_of_store']].drop_duplicates()\n",
    "TA_Store=TA_Store[TA_Store['location_id'].isin(inclusion_store_list_set)]\n",
    "\n",
    "stores_not_in_TA=[x for x in inclusion_store_list_set if x not in ta_by_zip['location_id'].tolist()]\n",
    "zips_for_new_store=df_1[df_1['location_id'].isin(stores_not_in_TA)]['zip_cd'].unique().tolist()\n",
    "# 8 new stores not in TA, 7 of the 8 zips are found in TA and allocated to the TA\n",
    "# 4675|02719 missing TA info, so no population\n",
    "TA_new_store=TA_Zips[TA_Zips['zip_cd'].isin(zips_for_new_store)]\n",
    "\n",
    "given_TA_7_New_store=df_1[df_1['location_id'].isin(stores_not_in_TA)]\n",
    "given_TA_7_New_store=pd.merge(given_TA_7_New_store,TA_Zips,on=\"zip_cd\",how=\"left\")\n",
    "given_TA_7_New_store=given_TA_7_New_store[['location_id','TA_of_zip']].rename(columns={\"TA_of_zip\":\"TA_of_store\"})\n",
    "TA_Store=TA_Store.append(given_TA_7_New_store)\n",
    "\n",
    "demo_F_25_54=pd.read_csv(\"/home/jian/Docs/Household_and_Population/2016/Demo_Dataset_2018EASI.csv\",\n",
    "                         dtype=str,usecols=['ZIP_CODE','Estimate; Female: - 25 to 29 years','Estimate; Female: - 30 to 34 years',\n",
    "                                                    'Estimate; Female: - 35 to 39 years','Estimate; Female: - 40 to 44 years',\n",
    "                                                     'Estimate; Female: - 45 to 49 years','Estimate; Female: - 50 to 54 years'])\n",
    "for col in demo_F_25_54.columns.tolist()[1:]:\n",
    "    demo_F_25_54[col]=demo_F_25_54[col].astype(float)\n",
    "demo_F_25_54['ZIP_CODE']=demo_F_25_54['ZIP_CODE'].apply(lambda x: x.zfill(5))\n",
    "demo_F_25_54['Pop_F_25_54']=demo_F_25_54[demo_F_25_54.columns.tolist()[1:]].sum(axis=1)\n",
    "demo_F_25_54=demo_F_25_54.rename(columns={\"ZIP_CODE\":\"zip_cd\"})\n",
    "demo_F_25_54=demo_F_25_54[['zip_cd','Pop_F_25_54']]\n",
    "\n",
    "TA_Zips_POP=pd.merge(TA_Zips,demo_F_25_54,on=\"zip_cd\",how=\"left\")\n",
    "TA_POP=TA_Zips_POP.groupby(['TA_of_zip'])['Pop_F_25_54'].sum().to_frame().reset_index()\n",
    "TA_POP=TA_POP.rename(columns={\"TA_of_zip\":\"TA\"})\n",
    "TA_Store=TA_Store.rename(columns={\"TA_of_store\":\"TA\"})\n",
    "df_3=pd.merge(TA_Store,TA_POP,on=\"TA\",how=\"left\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_sales_from_SP=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_sales_data/From_Sp/combinedtransactions_0811.csv\",\n",
    "                                 dtype=str,nrows=samplerows,usecols=['customer_id_hashed','transaction_date','transaction_id','location_id','total_transaction_amt'])\n",
    "rewards_sales_from_SP=rewards_sales_from_SP[rewards_sales_from_SP['location_id'].isin(inclusion_store_list_set)]\n",
    "rewards_sales_from_SP['transaction_date']=rewards_sales_from_SP['transaction_date'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "rewards_sales_from_SP=rewards_sales_from_SP[(rewards_sales_from_SP['transaction_date']>=Q2_Start_week_2018) & (rewards_sales_from_SP['transaction_date']<=Q2_End_week_2018)]\n",
    "rewards_sales_from_SP=rewards_sales_from_SP.drop_duplicates()\n",
    "rewards_sales_from_SP['total_transaction_amt']=rewards_sales_from_SP['total_transaction_amt'].astype(float)\n",
    "del rewards_sales_from_SP['transaction_id']\n",
    "gc.collect()\n",
    "\n",
    "def add_week_end_date(x):\n",
    "    weekday_num=x.weekday()\n",
    "    if weekday_num==6:\n",
    "        y=x+datetime.timedelta(days=6)\n",
    "    else:\n",
    "        y=x+datetime.timedelta(days=5-weekday_num)\n",
    "    return y\n",
    "\n",
    "\n",
    "rewards_by_store_Q2_sales=rewards_sales_from_SP.groupby(['location_id'])['total_transaction_amt'].sum().to_frame().reset_index()\n",
    "rewards_by_store_Q2_sales=rewards_by_store_Q2_sales.rename(columns={\"total_transaction_amt\":\"Q2_rewards_sales\"})\n",
    "rewards_by_store_Q2_trans=rewards_sales_from_SP.groupby(['location_id'])['total_transaction_amt'].count().to_frame().reset_index()\n",
    "rewards_by_store_Q2_trans=rewards_by_store_Q2_trans.rename(columns={\"total_transaction_amt\":\"Q2_rewards_trans\"})\n",
    "\n",
    "df_5=pd.merge(rewards_by_store_Q2_sales,rewards_by_store_Q2_trans,on=\"location_id\",how=\"outer\")\n",
    "df_5['Q2_rewards_sales_share']=np.nan\n",
    "df_5['Q2_rewards_trans_share']=np.nan\n",
    "df_5['Rewards_AOV']=df_5['Q2_rewards_sales']/df_5['Q2_rewards_trans']\n",
    "df_5.head(2)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df_7=inclusion_stores_sales_data[['location_id']+Q2_2017_Weeks+Q2_2018_Weeks]\n",
    "for col in Q2_2018_Weeks:\n",
    "    week_2018=col\n",
    "    week_2017=str(datetime.datetime.strptime(col,\"%Y-%m-%d\").date()-datetime.timedelta(days=52*7))\n",
    "    df_7[\"YoY_\"+col]=np.round((df_7[week_2018]-df_7[week_2017])/df_7[week_2017],6)\n",
    "df_7=df_7[[\"location_id\"]+[\"YoY_\"+x for x in Q2_2018_Weeks]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_level_output=pd.merge(df_1,df_2,on=\"location_id\",how=\"left\")\n",
    "store_level_output=pd.merge(store_level_output,df_3,on=\"location_id\",how=\"left\")\n",
    "store_level_output=pd.merge(store_level_output,df_4,on=\"location_id\",how=\"left\")\n",
    "store_level_output=pd.merge(store_level_output,df_5,on=\"location_id\",how=\"left\")\n",
    "store_level_output=pd.merge(store_level_output,df_7,on=\"location_id\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_level_output['Q2_rewards_sales_share']=store_level_output['Q2_rewards_sales']/store_level_output['2018_Q2_Sales']\n",
    "store_level_output['Q2_rewards_trans_share']=store_level_output['Q2_rewards_trans']/store_level_output['2018_Q2_Trans']\n",
    "# Stopped here sep 12 13:10 pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20850534"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dfiddetail['sign_up_date']\n",
    "rewards_sales_from_SP=pd.merge(rewards_sales_from_SP,dfiddetail,on=\"customer_id_hashed\",how=\"left\")\n",
    "rewards_sales_from_SP['zip_cd']=rewards_sales_from_SP['zip_cd'].fillna(\"zip_missing\")\n",
    "\n",
    "Store_level_PST=pd.read_csv(\"/home/jian/Projects/Big_Lots/New_TA/zips_in_new_ta/sales_by_zip (Store level).csv\",dtype=str)\n",
    "Store_level_PST=Store_level_PST[Store_level_PST['location_id'].isin(inclusion_store_list_set)]\n",
    "\n",
    "Store_level_P_Zips=Store_level_PST[Store_level_PST['revenue_flag']==\"P\"].groupby(['location_id'])['zip'].apply(set).to_frame().reset_index()\n",
    "Store_level_S_Zips=Store_level_PST[Store_level_PST['revenue_flag']==\"S\"].groupby(['location_id'])['zip'].apply(set).to_frame().reset_index()\n",
    "Store_level_T_Zips=Store_level_PST[Store_level_PST['revenue_flag']==\"T\"].groupby(['location_id'])['zip'].apply(set).to_frame().reset_index()\n",
    "\n",
    "Store_level_P_Zips_Dict=Store_level_P_Zips.set_index(['location_id']).to_dict()['zip']\n",
    "Store_level_S_Zips_Dict=Store_level_S_Zips.set_index(['location_id']).to_dict()['zip']\n",
    "Store_level_T_Zips_Dict=Store_level_T_Zips.set_index(['location_id']).to_dict()['zip']\n",
    "\n",
    "store_list_with_PST=Store_level_PST['location_id'].unique().tolist()\n",
    "\n",
    "\n",
    "df_SP_July_Decile=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/Segment_Movement_analysis/Data_From_Sp/df_crm_finalscore_0714data.csv\",\n",
    "                              dtype=str,usecols=['customer_id_hashed','frmindex','zipcodegroup','customer_zip_code'])\n",
    "df_SP_July_Decile=df_SP_July_Decile.drop_duplicates(['customer_id_hashed'])\n",
    "decile_list=df_SP_July_Decile['frmindex'].unique().tolist()\n",
    "len(df_SP_July_Decile['customer_id_hashed'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfiddetail=pd.merge(dfiddetail,df_SP_July_Decile[['customer_id_hashed','frmindex']],on=\"customer_id_hashed\",how=\"left\")\n",
    "dfiddetail_id_count_by_signup_zip_decile=dfiddetail.groupby(['sign_up_location','zip_cd','frmindex'])['customer_id_hashed'].count().to_frame().reset_index()\n",
    "dfiddetail_id_count_by_signup_zip_decile=dfiddetail_id_count_by_signup_zip_decile.rename(columns={\"customer_id_hashed\":\"id_count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rewards_sales_by_store=rewards_sales_from_SP.groupby('location_id')['total_transaction_amt'].sum().to_frame().reset_index()\n",
    "rewards_sales_by_store_dict=rewards_sales_by_store.set_index(['location_id']).to_dict()['total_transaction_amt']\n",
    "\n",
    "rewards_sales_by_customer_zip_store=rewards_sales_from_SP.groupby(['location_id','zip_cd'])['total_transaction_amt'].sum().to_frame().reset_index()\n",
    "rewards_trans_by_customer_zip_store=rewards_sales_from_SP.groupby(['location_id','zip_cd'])['total_transaction_amt'].count().to_frame().reset_index()\n",
    "\n",
    "sign_up_id_by_store_zip=dfiddetail.groupby(['sign_up_location','zip_cd'])['customer_id_hashed'].count().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2018-09-12 15:38:44.746878\n",
      "1003 2018-09-12 15:38:45.520014\n",
      "1051 2018-09-12 15:38:53.388727\n",
      "1191 2018-09-12 15:39:24.007940\n",
      "1195 2018-09-12 15:39:24.816220\n",
      "1228 2018-09-12 15:39:32.646827\n",
      "1399 2018-09-12 15:40:03.379188\n",
      "1401 2018-09-12 15:40:04.169487\n",
      "1446 2018-09-12 15:40:12.054681\n",
      "1603 2018-09-12 15:40:42.798558\n",
      "1606 2018-09-12 15:40:43.569910\n",
      "1640 2018-09-12 15:40:51.488117\n",
      "1760 2018-09-12 15:41:22.270306\n",
      "1762 2018-09-12 15:41:23.058161\n",
      "1793 2018-09-12 15:41:30.970079\n",
      "1890 2018-09-12 15:42:01.734185\n",
      "1892 2018-09-12 15:42:02.525304\n",
      "1927 2018-09-12 15:42:10.432330\n",
      "254 2018-09-12 15:42:40.825979\n",
      "256 2018-09-12 15:42:41.577825\n",
      "315 2018-09-12 15:42:49.129144\n",
      "4104 2018-09-12 15:43:19.397953\n",
      "4106 2018-09-12 15:43:20.178857\n",
      "4131 2018-09-12 15:43:28.074384\n",
      "4292 2018-09-12 15:43:58.832191\n",
      "4296 2018-09-12 15:43:59.626733\n",
      "4337 2018-09-12 15:44:07.517532\n",
      "4521 2018-09-12 15:44:38.283070\n",
      "4523 2018-09-12 15:44:39.084745\n",
      "4547 2018-09-12 15:44:46.987536\n",
      "463 2018-09-12 15:45:17.804448\n",
      "4631 2018-09-12 15:45:18.600572\n",
      "4651 2018-09-12 15:45:26.461910\n",
      "5129 2018-09-12 15:45:56.879994\n",
      "5130 2018-09-12 15:45:57.659169\n",
      "515 2018-09-12 15:46:05.586352\n",
      "5227 2018-09-12 15:46:36.452278\n",
      "5229 2018-09-12 15:46:37.265401\n",
      "5247 2018-09-12 15:46:45.189190\n",
      "5322 2018-09-12 15:47:15.980589\n",
      "5324 2018-09-12 15:47:16.777634\n",
      "546 2018-09-12 15:47:24.603548\n"
     ]
    }
   ],
   "source": [
    "output_zip_level=pd.DataFrame()\n",
    "k=0\n",
    "for store in store_list_with_PST:\n",
    "    total_rewards_sales_store=rewards_sales_by_store_dict[store]\n",
    "    store_rewards_sales_by_customer_zip_store=rewards_sales_by_customer_zip_store[rewards_sales_by_customer_zip_store['location_id']==store]\n",
    "    store_rewards_trans_by_customer_zip_store=rewards_trans_by_customer_zip_store[rewards_trans_by_customer_zip_store['location_id']==store]\n",
    "    store_dfiddetail_id_count_by_signup_zip_decile=dfiddetail_id_count_by_signup_zip_decile[dfiddetail_id_count_by_signup_zip_decile['sign_up_location']==store]\n",
    "    store_sign_up_id_by_store_zip=sign_up_id_by_store_zip[sign_up_id_by_store_zip['sign_up_location']==store]\n",
    "    \n",
    "    for label in [\"P\",\"S\",\"T\"]:\n",
    "        zips_store_label=locals()[\"Store_level_\"+label+\"_Zips_Dict\"][store]\n",
    "        \n",
    "        id_count_store_label_all_zips=sign_up_id_by_zip[sign_up_id_by_zip['zip_cd'].isin(zips_store_label)]['customer_id_hashed'].sum()\n",
    "        id_count_store_label_store_only=store_sign_up_id_by_store_zip[store_sign_up_id_by_store_zip['zip_cd'].isin(zips_store_label)]['customer_id_hashed'].sum()\n",
    "        \n",
    "        sales_store_label=store_rewards_sales_by_customer_zip_store[store_rewards_sales_by_customer_zip_store['zip_cd'].isin(zips_store_label)]['total_transaction_amt'].sum()\n",
    "        trans_store_label=store_rewards_trans_by_customer_zip_store[store_rewards_trans_by_customer_zip_store['zip_cd'].isin(zips_store_label)]['total_transaction_amt'].sum()\n",
    "        \n",
    "        AOV_store_label=sales_store_label/trans_store_label\n",
    "        sales_share_label=sales_store_label/total_rewards_sales_store\n",
    "        \n",
    "        trans_to_id=trans_store_label/id_count_store_label_store_only\n",
    "        \n",
    "        for D_decile in decile_list:\n",
    "            locals()[D_decile+\"_store_label\"]=store_dfiddetail_id_count_by_signup_zip_decile[(store_dfiddetail_id_count_by_signup_zip_decile['frmindex']==D_decile) &\\\n",
    "                                                                                             (store_dfiddetail_id_count_by_signup_zip_decile['zip_cd'].isin(zips_store_label))]['id_count'].sum()\n",
    "            \n",
    "        locals()['df_app_'+label]=pd.DataFrame({\"location_id\":store,label+\"_id_counts\":id_count_store_label_all_zips,\n",
    "                                                label+\"_id_counts_singed_store\":id_count_store_label_store_only,label+\"_sales_share\":sales_share_label,\n",
    "                                                label+\"_AOV\":AOV_store_label,label+\"_trans_per_id_avg\":trans_to_id,\n",
    "                                                label+\"_D1\":locals()[\"D01_store_label\"],label+\"_D2\":locals()[\"D02_store_label\"],\n",
    "                                                label+\"_D3\":locals()[\"D03_store_label\"],label+\"_D4\":locals()[\"D04_store_label\"],\n",
    "                                                label+\"_D5\":locals()[\"D05_store_label\"],label+\"_D6\":locals()[\"D06_store_label\"],\n",
    "                                                label+\"_D7\":locals()[\"D07_store_label\"],label+\"_D8\":locals()[\"D08_store_label\"],\n",
    "                                                label+\"_D9\":locals()[\"D09_store_label\"],label+\"_D10\":locals()[\"D10_store_label\"],\n",
    "                                               },index=[store])\n",
    "    df_app_3_lable=pd.merge(df_app_P,df_app_S,on=\"location_id\",how=\"left\")\n",
    "    df_app_3_lable=pd.merge(df_app_3_lable,df_app_T,on=\"location_id\",how=\"left\")\n",
    "    df_app_3_lable=df_app_3_lable[['location_id','P_id_counts','P_id_counts_singed_store','P_sales_share','P_AOV','P_trans_per_id_avg','P_D1','P_D2','P_D3','P_D4','P_D5','P_D6','P_D7','P_D8','P_D9','P_D10',\n",
    "                                   'S_id_counts','S_id_counts_singed_store','S_sales_share','S_AOV','S_trans_per_id_avg','S_D1','S_D2','S_D3','S_D4','S_D5','S_D6','S_D7','S_D8','S_D9','S_D10',\n",
    "                                   'T_id_counts','T_id_counts_singed_store','T_sales_share','T_AOV','T_trans_per_id_avg','T_D1','T_D2','T_D3','T_D4','T_D5','T_D6','T_D7','T_D8','T_D9','T_D10']]\n",
    "    output_zip_level=output_zip_level.append(df_app_3_lable)\n",
    "    k+=1\n",
    "    if k %100==1:\n",
    "        print(store,datetime.datetime.now())\n",
    "        logging.info(str(k)+\"|\"+store+\"|\"+str(datetime.datetime.now()))\n",
    "    if k %100==3:\n",
    "        print(store,datetime.datetime.now())\n",
    "        logging.info(str(k)+\"|\"+store+\"|\"+str(datetime.datetime.now()))\n",
    "\n",
    "    if k %100==23:\n",
    "        print(store,datetime.datetime.now())\n",
    "        logging.info(str(k)+\"|\"+store+\"|\"+str(datetime.datetime.now()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All_Rewards_regardless_of_Zips_New_Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_id_count(x):\n",
    "    y=len(set(x))\n",
    "    return y\n",
    "    \n",
    "Sep_12_new_request=rewards_sales_from_SP.groupby(['location_id'])['customer_id_hashed'].apply(unique_id_count).to_frame().reset_index()\n",
    "Sep_12_new_request['Q2_rewards_AOV']=np.nan\n",
    "Sep_12_new_request['Q2_rewards_trans_per_id']=np.nan\n",
    "Sep_12_new_request=Sep_12_new_request.rename(columns={\"customer_id_hashed\":\"Q2_rewards_id_shopped\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rewards_sales_from_SP_Decile=rewards_sales_from_SP[['customer_id_hashed','location_id']].drop_duplicates()\n",
    "sp_decile=df_SP_July_Decile[['customer_id_hashed','frmindex']]\n",
    "rewards_sales_from_SP_Decile=pd.merge(rewards_sales_from_SP_Decile,sp_decile,on=\"customer_id_hashed\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 2018-09-12 16:53:18.450509\n",
      "3 1003 2018-09-12 16:53:18.479578\n",
      "5 1006 2018-09-12 16:53:18.507091\n",
      "23 1051 2018-09-12 16:53:18.772083\n",
      "101 1191 2018-09-12 16:53:19.898692\n",
      "103 1195 2018-09-12 16:53:19.932669\n",
      "105 1198 2018-09-12 16:53:19.960700\n",
      "123 1228 2018-09-12 16:53:20.229916\n",
      "201 1399 2018-09-12 16:53:21.370236\n",
      "203 1401 2018-09-12 16:53:21.401444\n",
      "205 1403 2018-09-12 16:53:21.429040\n",
      "223 1446 2018-09-12 16:53:21.692082\n",
      "301 1603 2018-09-12 16:53:22.867644\n",
      "303 1606 2018-09-12 16:53:22.898169\n",
      "305 1608 2018-09-12 16:53:22.930245\n",
      "323 1640 2018-09-12 16:53:23.193619\n",
      "401 1760 2018-09-12 16:53:24.349499\n",
      "403 1762 2018-09-12 16:53:24.377328\n",
      "405 1765 2018-09-12 16:53:24.407900\n",
      "423 1793 2018-09-12 16:53:24.678987\n",
      "501 1890 2018-09-12 16:53:25.855033\n",
      "503 1892 2018-09-12 16:53:25.883866\n",
      "505 1896 2018-09-12 16:53:25.915474\n",
      "523 1927 2018-09-12 16:53:26.198750\n",
      "601 254 2018-09-12 16:53:27.375595\n",
      "603 256 2018-09-12 16:53:27.404958\n",
      "605 258 2018-09-12 16:53:27.433219\n",
      "623 315 2018-09-12 16:53:27.699116\n",
      "701 4104 2018-09-12 16:53:28.896057\n",
      "703 4106 2018-09-12 16:53:28.922267\n",
      "705 4108 2018-09-12 16:53:28.953159\n",
      "723 4131 2018-09-12 16:53:29.231333\n",
      "801 4292 2018-09-12 16:53:30.466527\n",
      "803 4296 2018-09-12 16:53:30.502136\n",
      "805 43 2018-09-12 16:53:30.535122\n",
      "823 4337 2018-09-12 16:53:30.817186\n",
      "901 4521 2018-09-12 16:53:32.011885\n",
      "903 4523 2018-09-12 16:53:32.042808\n",
      "905 4525 2018-09-12 16:53:32.071988\n",
      "923 4547 2018-09-12 16:53:32.340000\n",
      "1001 463 2018-09-12 16:53:33.477718\n",
      "1003 4631 2018-09-12 16:53:33.508052\n",
      "1005 4633 2018-09-12 16:53:33.535975\n",
      "1023 4651 2018-09-12 16:53:33.799137\n",
      "1101 5120 2018-09-12 16:53:34.985891\n",
      "1103 5122 2018-09-12 16:53:35.020625\n",
      "1105 5125 2018-09-12 16:53:35.055135\n",
      "1123 5143 2018-09-12 16:53:35.334978\n",
      "1201 5220 2018-09-12 16:53:36.534146\n",
      "1203 5222 2018-09-12 16:53:36.567997\n",
      "1205 5224 2018-09-12 16:53:36.599161\n",
      "1223 5240 2018-09-12 16:53:36.880157\n",
      "1301 5314 2018-09-12 16:53:38.065456\n",
      "1303 5316 2018-09-12 16:53:38.096891\n",
      "1305 5319 2018-09-12 16:53:38.126238\n",
      "1323 5338 2018-09-12 16:53:38.413603\n",
      "1401 837 2018-09-12 16:53:39.624321\n",
      "1403 840 2018-09-12 16:53:39.654362\n",
      "1405 849 2018-09-12 16:53:39.684826\n"
     ]
    }
   ],
   "source": [
    "count_k=0\n",
    "Sep_12_new_request_Decile=pd.DataFrame()\n",
    "for store,group in rewards_sales_from_SP_Decile.groupby(['location_id']):\n",
    "    for i in range(10):\n",
    "        frmindex_str=\"D\"+str(i+1).zfill(2)\n",
    "        locals()[frmindex_str]=len(group[group['frmindex']==frmindex_str])\n",
    "    df_app=pd.DataFrame({\"location_id\":store,\"D01_July\":D01,\"D02_July\":D02,\"D03_July\":D03,\"D04_July\":D04,\"D05_July\":D05,\n",
    "                        \"D06_July\":D06,\"D07_July\":D07,\"D08_July\":D08,\"D09_July\":D09,\"D10_July\":D10},index=[store])\n",
    "    Sep_12_new_request_Decile=Sep_12_new_request_Decile.append(df_app)\n",
    "    count_k+=1\n",
    "    if count_k %100==1:\n",
    "        print(count_k,store,datetime.datetime.now())\n",
    "        logging.info(str(count_k)+\"|\"+store+\"|\"+str(datetime.datetime.now()))\n",
    "\n",
    "    if count_k %100==23:\n",
    "        print(count_k,store,datetime.datetime.now())\n",
    "        logging.info(str(count_k)+\"|\"+store+\"|\"+str(datetime.datetime.now()))\n",
    "        \n",
    "    \n",
    "Sep_12_new_request=pd.merge(Sep_12_new_request,Sep_12_new_request_Decile,on=\"location_id\",how=\"left\")\n",
    "\n",
    "logging.info(\"Done of the new request | \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final_Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "final_output=pd.merge(store_level_output,output_zip_level,on=\"location_id\",how=\"left\")\n",
    "logging.info(\"Merge1 | \"+str(datetime.datetime.now()))\n",
    "final_output=pd.merge(final_output,Sep_12_new_request,on=\"location_id\",how=\"left\")\n",
    "logging.info(\"Merge2 | \"+str(datetime.datetime.now()))\n",
    "final_output['Q2_rewards_AOV']=final_output['Q2_rewards_sales']/final_output['Q2_rewards_trans']\n",
    "logging.info(\"3 | \"+str(datetime.datetime.now()))\n",
    "final_output['Q2_rewards_trans_per_id']=final_output['Q2_rewards_trans']/final_output['Q2_rewards_id_shopped']\n",
    "logging.info(\"4 | \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_output.to_csv(\"/home/jian/Projects/Big_Lots/Analysis/Store_Stats_201809/BL_Store_Rewards_Stats_JL_\"+str(datetime.datetime.now().date())+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
