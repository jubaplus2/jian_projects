{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-24 14:21:00.676765\n",
      "/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Planner_Request/JT_non_rewards_sales_so_far_2019Q4_4_weeks\n",
      "ty_start_date: 2019-11-03\n",
      "ty_end_date: 2020-02-01\n",
      "ly_start_date: 2018-11-04\n",
      "ly_end_date: 2019-02-02\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "print(datetime.datetime.now())\n",
    "print(os.getcwd())\n",
    "\n",
    "ty_start_date=datetime.date(2019,11,3)\n",
    "ty_end_date=datetime.date(2020,2,1)\n",
    "\n",
    "ly_start_date=ty_start_date-datetime.timedelta(days=52*7)\n",
    "ly_end_date=ty_end_date-datetime.timedelta(days=52*7)\n",
    "\n",
    "\n",
    "print(\"ty_start_date:\",ty_start_date)\n",
    "print(\"ty_end_date:\",ty_end_date)\n",
    "\n",
    "print(\"ly_start_date:\",ly_start_date)\n",
    "print(\"ly_end_date:\",ly_end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "def recursive_file_gen(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root,file)\n",
    "list_files_ly=glob.glob(\"/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/*.txt\")\n",
    "list_files_ly=[x for x in list_files_ly if x.split(\"/MediaStormDailySalesHistory\")[1][:8]>=str(ly_start_date).replace(\"-\",\"\")]\n",
    "list_files_ly=[x for x in list_files_ly if x.split(\"/MediaStormDailySalesHistory\")[1][:8]<=str(ly_end_date).replace(\"-\",\"\")]\n",
    "list_files_ly.sort()\n",
    "print(len(list_files_ly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "list_file_ty=recursive_file_gen(\"/home/jian/BigLots/\")\n",
    "list_file_ty=[x for x in list_file_ty if \"dailysales\" in x.lower()]\n",
    "list_file_ty=[x for x in list_file_ty if \"/MediaStorm_\" in x]\n",
    "list_file_ty=[x for x in list_file_ty if x.split(\"/MediaStorm_\")[1][:10]>=str(ty_start_date)]\n",
    "list_file_ty=[x for x in list_file_ty if x.split(\"/MediaStorm_\")[1][:10]<=str(ty_end_date)]\n",
    "list_file_ty.sort()\n",
    "print(len(list_file_ty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>division_id</th>\n",
       "      <th>class_code_id</th>\n",
       "      <th>subclass_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   division_id class_code_id subclass_id\n",
       "0            1         11001           2\n",
       "1            1         11001           4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_taxo=pd.read_table(\"/home/jian/BigLots/static_files/ProductTaxonomy/MediaStormProductTaxonomy20200101-135600-916.txt\",\n",
    "                              dtype=str,sep=\"|\")\n",
    "df_product_taxo=df_product_taxo[['division_id','class_code_id','subclass_id']].drop_duplicates()\n",
    "df_product_taxo['division_id']=df_product_taxo['division_id'].astype(int)\n",
    "df_division_name=pd.read_table(\"/home/jian/BigLots/static_files/MediaStorm Data Extract - Division Names.txt\",sep=\"|\")\n",
    "df_product_taxo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-24 15:06:42.105754 1 done\n",
      "2020-01-24 15:08:29.194437 2 done\n",
      "2020-01-24 15:17:37.610658 3 done\n",
      "2020-01-24 15:30:57.417063 4 done\n",
      "2020-01-24 15:42:05.186632 5 done\n",
      "2020-01-24 15:50:11.881793 6 done\n",
      "2020-01-24 16:00:44.082409 7 done\n",
      "2020-01-24 16:03:10.884726 8 done\n",
      "2020-01-24 16:05:05.400245 9 done\n",
      "2020-01-24 16:09:44.328774 10 done\n",
      "2020-01-24 16:15:14.390447 11 done\n",
      "2020-01-24 16:20:34.663750 12 done\n",
      "2020-01-24 16:24:59.687547 13 done\n"
     ]
    }
   ],
   "source": [
    "df_summary_InWeek_ly=pd.DataFrame()\n",
    "df_summary_CumQ_ly=pd.DataFrame()\n",
    "\n",
    "df_rewards_ids_ly=pd.DataFrame()\n",
    "\n",
    "cum_R_sales=0\n",
    "cum_R_trans=0\n",
    "\n",
    "cum_N_sales=0\n",
    "cum_N_trans=0\n",
    "\n",
    "week_num=0\n",
    "for file in list_files_ly:\n",
    "    week_num+=1\n",
    "    df=pd.read_table(file,dtype=str,sep=\"|\",\n",
    "                    usecols=['location_id','transaction_dt','transaction_id','customer_id_hashed','class_code_id','subclass_id','item_transaction_amt'])\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    df=pd.merge(df,df_product_taxo,on=['class_code_id','subclass_id'],how=\"left\")\n",
    "    date_min=df['transaction_dt'].min()\n",
    "    date_max=df['transaction_dt'].max()\n",
    "    \n",
    "    df['rewards_label']=np.where(pd.notnull(df['customer_id_hashed']),\"Rewards\",\"Non_Rewards\")\n",
    "    df_division=df.groupby(['rewards_label','division_id'])['item_transaction_amt'].sum().to_frame().reset_index()\n",
    "    df_division_R=df_division[df_division['rewards_label']==\"Rewards\"].T\n",
    "    df_division_N=df_division[df_division['rewards_label']==\"Non_Rewards\"].T\n",
    "    \n",
    "    df_division_R_2=df_division_R.loc[df_division_R.index==\"item_transaction_amt\"]\n",
    "    df_division_R_2.columns=[\"Rewards_Div_\"+str(x) for x in df_division_R.loc[df_division_R.index==\"division_id\"].values.tolist()[0]]\n",
    "    df_division_R=df_division_R_2.reset_index()\n",
    "    df_division_R['week_num']=week_num\n",
    "\n",
    "    df_division_N_2=df_division_N.loc[df_division_N.index==\"item_transaction_amt\"]\n",
    "    df_division_N_2.columns=[\"NonRew_Div_\"+str(x) for x in df_division_N.loc[df_division_N.index==\"division_id\"].values.tolist()[0]]\n",
    "    df_division_N=df_division_N_2.reset_index()\n",
    "    df_division_N['week_num']=week_num\n",
    "\n",
    "    del df_division_R['index']\n",
    "    del df_division_N['index']\n",
    "    \n",
    "    df_rewards=df[pd.notnull(df['customer_id_hashed'])]\n",
    "    df_nonrewards=df[pd.isnull(df['customer_id_hashed'])]\n",
    "    \n",
    "    num_R_sales=df_rewards['item_transaction_amt'].sum()\n",
    "    num_R_trans=df_rewards[['location_id','transaction_dt','transaction_id','customer_id_hashed']].drop_duplicates().shape[0]\n",
    "    num_R_shoppers=df_rewards['customer_id_hashed'].nunique()\n",
    "    \n",
    "    num_N_sales=df_nonrewards['item_transaction_amt'].sum()\n",
    "    num_N_trans=df_nonrewards[['location_id','transaction_dt','transaction_id']].drop_duplicates().shape[0]\n",
    "    \n",
    "    df_rewards_shoppers=df_rewards[['customer_id_hashed']].drop_duplicates()\n",
    "    df_rewards_shoppers['week_start']=date_min\n",
    "    df_rewards_shoppers['week_end']=date_max\n",
    "    df_rewards_ids_ly=df_rewards_ids_ly.append(df_rewards_shoppers)\n",
    "    \n",
    "    cum_R_sales+=num_R_sales\n",
    "    cum_R_trans+=num_R_trans\n",
    "    cum_N_sales+=num_N_sales\n",
    "    cum_N_trans+=num_N_trans\n",
    "    cum_R_shoppers=df_rewards_ids_ly['customer_id_hashed'].nunique()\n",
    "    \n",
    "    df_in_week=pd.DataFrame({\"week_num\":week_num,\"week_start\":date_min,\"week_end\":date_max,\n",
    "                             \"Rewards_sales\":num_R_sales,\"Rewards_trans\":num_R_trans,\"Rewards_shoppers\":num_R_shoppers,\n",
    "                             'NonRewards_sales':num_N_sales,\"NonRewards_trans\":num_N_trans,\n",
    "                            },index=[0])\n",
    "    \n",
    "    df_cum_week=pd.DataFrame({\"week_num\":week_num,\"week_start\":date_min,\"week_end\":date_max,\n",
    "                             \"Rewards_sales\":cum_R_sales,\"Rewards_trans\":cum_R_trans,\"Rewards_shoppers\":cum_R_shoppers,\n",
    "                             'NonRewards_sales':cum_N_sales,\"NonRewards_trans\":cum_N_trans,\n",
    "                            },index=[0])\n",
    "    df_in_week=pd.merge(df_in_week,df_division_R,on=\"week_num\",how=\"outer\")\n",
    "    df_in_week=pd.merge(df_in_week,df_division_N,on=\"week_num\",how=\"outer\")\n",
    "    \n",
    "    df_summary_InWeek_ly=df_summary_InWeek_ly.append(df_in_week)\n",
    "    df_summary_CumQ_ly=df_summary_CumQ_ly.append(df_cum_week)\n",
    "    print(datetime.datetime.now(),week_num,\"done\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-24 16:26:15.835299 1 done\n",
      "2020-01-24 16:28:51.552242 2 done\n",
      "2020-01-24 16:33:05.378557 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-24 16:37:14.087468 4 done\n",
      "2020-01-24 16:42:19.043969 5 done\n",
      "2020-01-24 16:47:32.045603 6 done\n",
      "2020-01-24 16:53:00.314159 7 done\n",
      "2020-01-24 16:57:37.596783 8 done\n",
      "2020-01-24 17:01:31.320648 9 done\n",
      "2020-01-24 17:04:41.164403 10 done\n",
      "2020-01-24 17:06:54.317776 11 done\n"
     ]
    }
   ],
   "source": [
    "df_summary_InWeek_ty=pd.DataFrame()\n",
    "df_summary_CumQ_ty=pd.DataFrame()\n",
    "\n",
    "df_rewards_ids_ty=pd.DataFrame()\n",
    "\n",
    "cum_R_sales=0\n",
    "cum_R_trans=0\n",
    "\n",
    "cum_N_sales=0\n",
    "cum_N_trans=0\n",
    "\n",
    "week_num=0\n",
    "for file in list_file_ty:\n",
    "    week_num+=1\n",
    "    df=pd.read_table(file,dtype=str,sep=\"|\",\n",
    "                    usecols=['location_id','transaction_dt','transaction_id','customer_id_hashed','class_code_id','subclass_id','item_transaction_amt'])\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    df=pd.merge(df,df_product_taxo,on=['class_code_id','subclass_id'],how=\"left\")\n",
    "    date_min=df['transaction_dt'].min()\n",
    "    date_max=df['transaction_dt'].max()\n",
    "    \n",
    "    df['rewards_label']=np.where(pd.notnull(df['customer_id_hashed']),\"Rewards\",\"Non_Rewards\")\n",
    "    df_division=df.groupby(['rewards_label','division_id'])['item_transaction_amt'].sum().to_frame().reset_index()\n",
    "    df_division_R=df_division[df_division['rewards_label']==\"Rewards\"].T\n",
    "    df_division_N=df_division[df_division['rewards_label']==\"Non_Rewards\"].T\n",
    "    \n",
    "    df_division_R_2=df_division_R.loc[df_division_R.index==\"item_transaction_amt\"]\n",
    "    df_division_R_2.columns=[\"Rewards_Div_\"+str(x) for x in df_division_R.loc[df_division_R.index==\"division_id\"].values.tolist()[0]]\n",
    "    df_division_R=df_division_R_2.reset_index()\n",
    "    df_division_R['week_num']=week_num\n",
    "\n",
    "    df_division_N_2=df_division_N.loc[df_division_N.index==\"item_transaction_amt\"]\n",
    "    df_division_N_2.columns=[\"NonRew_Div_\"+str(x) for x in df_division_N.loc[df_division_N.index==\"division_id\"].values.tolist()[0]]\n",
    "    df_division_N=df_division_N_2.reset_index()\n",
    "    df_division_N['week_num']=week_num\n",
    "\n",
    "    del df_division_R['index']\n",
    "    del df_division_N['index']\n",
    "    \n",
    "    df_rewards=df[pd.notnull(df['customer_id_hashed'])]\n",
    "    df_nonrewards=df[pd.isnull(df['customer_id_hashed'])]\n",
    "    \n",
    "    num_R_sales=df_rewards['item_transaction_amt'].sum()\n",
    "    num_R_trans=df_rewards[['location_id','transaction_dt','transaction_id','customer_id_hashed']].drop_duplicates().shape[0]\n",
    "    num_R_shoppers=df_rewards['customer_id_hashed'].nunique()\n",
    "    \n",
    "    num_N_sales=df_nonrewards['item_transaction_amt'].sum()\n",
    "    num_N_trans=df_nonrewards[['location_id','transaction_dt','transaction_id']].drop_duplicates().shape[0]\n",
    "    \n",
    "    df_rewards_shoppers=df_rewards[['customer_id_hashed']].drop_duplicates()\n",
    "    df_rewards_shoppers['week_start']=date_min\n",
    "    df_rewards_shoppers['week_end']=date_max\n",
    "    df_rewards_ids_ty=df_rewards_ids_ty.append(df_rewards_shoppers)\n",
    "    \n",
    "    cum_R_sales+=num_R_sales\n",
    "    cum_R_trans+=num_R_trans\n",
    "    cum_N_sales+=num_N_sales\n",
    "    cum_N_trans+=num_N_trans\n",
    "    cum_R_shoppers=df_rewards_ids_ty['customer_id_hashed'].nunique()\n",
    "    \n",
    "    df_in_week=pd.DataFrame({\"week_num\":week_num,\"week_start\":date_min,\"week_end\":date_max,\n",
    "                             \"Rewards_sales\":num_R_sales,\"Rewards_trans\":num_R_trans,\"Rewards_shoppers\":num_R_shoppers,\n",
    "                             'NonRewards_sales':num_N_sales,\"NonRewards_trans\":num_N_trans,\n",
    "                            },index=[0])\n",
    "    \n",
    "    df_cum_week=pd.DataFrame({\"week_num\":week_num,\"week_start\":date_min,\"week_end\":date_max,\n",
    "                             \"Rewards_sales\":cum_R_sales,\"Rewards_trans\":cum_R_trans,\"Rewards_shoppers\":cum_R_shoppers,\n",
    "                             'NonRewards_sales':cum_N_sales,\"NonRewards_trans\":cum_N_trans,\n",
    "                            },index=[0])\n",
    "    df_in_week=pd.merge(df_in_week,df_division_R,on=\"week_num\",how=\"outer\")\n",
    "    df_in_week=pd.merge(df_in_week,df_division_N,on=\"week_num\",how=\"outer\")\n",
    "    \n",
    "    df_summary_InWeek_ty=df_summary_InWeek_ty.append(df_in_week)\n",
    "    df_summary_CumQ_ty=df_summary_CumQ_ty.append(df_cum_week)\n",
    "    print(datetime.datetime.now(),week_num,\"done\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_InWeek_ty=df_summary_InWeek_ty[df_summary_InWeek_ly.columns.tolist()]\n",
    "\n",
    "writer=pd.ExcelWriter(\"./BL_projection_in_quarter_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_summary_InWeek_ty.to_excel(writer,\"df_summary_InWeek_ty\",index=False)\n",
    "df_summary_CumQ_ty.to_excel(writer,\"df_summary_CumQ_ty\",index=False)\n",
    "\n",
    "df_summary_InWeek_ly.to_excel(writer,\"df_summary_InWeek_ly\",index=False)\n",
    "df_summary_CumQ_ly.to_excel(writer,\"df_summary_CumQ_ly\",index=False)\n",
    "\n",
    "df_division_name.to_excel(writer,\"df_division_name\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rewards_ids_ty.to_csv(\"./df_rewards_ids_ty.csv\",index=False)\n",
    "df_rewards_ids_ly.to_csv(\"./df_rewards_ids_ly.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>week_start</th>\n",
       "      <th>week_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b445597aeb04ea0afe60321876a7580f52abaa8e4ef5b0...</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>2019-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23b14d85798fd5580f20d79e32824ad4cd6df31f5effe5...</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>2019-11-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed  week_start    week_end\n",
       "0  b445597aeb04ea0afe60321876a7580f52abaa8e4ef5b0...  2019-11-03  2019-11-09\n",
       "1  23b14d85798fd5580f20d79e32824ad4cd6df31f5effe5...  2019-11-03  2019-11-09"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rewards_ids_ty.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>week_start</th>\n",
       "      <th>week_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34e22ad0c4e216b4983bc2978770b3dbd7301213f8ebfd...</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>2018-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>049f7c29a72fd252a880b32912fa49adc5dc55f3047193...</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>2018-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5216dbc5abd3e8d9057ef64926cc52ea99704484ee80b3...</td>\n",
       "      <td>2018-11-04</td>\n",
       "      <td>2018-11-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed  week_start    week_end\n",
       "0  34e22ad0c4e216b4983bc2978770b3dbd7301213f8ebfd...  2018-11-04  2018-11-10\n",
       "2  049f7c29a72fd252a880b32912fa49adc5dc55f3047193...  2018-11-04  2018-11-10\n",
       "4  5216dbc5abd3e8d9057ef64926cc52ea99704484ee80b3...  2018-11-04  2018-11-10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rewards_ids_ly.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rewards_ids_ty['week_start'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
