{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-31 16:20:44.871224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Planner_Request/BR_audience_furniture_browser'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "print(datetime.datetime.now())\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489861, 5) (54430, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>customersummary_mastercustomerid</th>\n",
       "      <th>Email</th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>execution_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>KFK_0_8017815</td>\n",
       "      <td>ad5f11c041c89839c09204f9ce34f5d97ea8ddaa81f1f0...</td>\n",
       "      <td>83228bfe2f6d62bb0218751ceb63aa8551e9fd89a999f1...</td>\n",
       "      <td>1578944138509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>KFK_0_37564566</td>\n",
       "      <td>c612188e441b8fef2e5eed0c918fec1d12e23f801b9e69...</td>\n",
       "      <td>94245ca46539f480c2490a5e3373f237dbc455094f85b7...</td>\n",
       "      <td>1578944138509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index customersummary_mastercustomerid  \\\n",
       "0     0                    KFK_0_8017815   \n",
       "1     2                   KFK_0_37564566   \n",
       "\n",
       "                                               Email  \\\n",
       "0  ad5f11c041c89839c09204f9ce34f5d97ea8ddaa81f1f0...   \n",
       "1  c612188e441b8fef2e5eed0c918fec1d12e23f801b9e69...   \n",
       "\n",
       "                                  customer_id_hashed   execution_id  \n",
       "0  83228bfe2f6d62bb0218751ceb63aa8551e9fd89a999f1...  1578944138509  \n",
       "1  94245ca46539f480c2490a5e3373f237dbc455094f85b7...  1578944138509  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=pd.read_csv(\"./BL_furniture_browser_test_group_JL_+str(datetime.datetime.now().date()).csv\",dtype=str)\n",
    "df_control=pd.read_csv(\"./BL_furniture_browser_control_group_JL_+str(datetime.datetime.now().date()).csv\",dtype=str)\n",
    "\n",
    "print(df_test.shape,df_control.shape)\n",
    "\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(544291, 2) 544291\n"
     ]
    }
   ],
   "source": [
    "df_group_1=df_test[['customer_id_hashed']].drop_duplicates()\n",
    "df_group_1['group']='test'\n",
    "df_group_2=df_control[['customer_id_hashed']].drop_duplicates()\n",
    "df_group_2['group']='control'\n",
    "\n",
    "df_group=df_group_1.append(df_group_2)\n",
    "print(df_group.shape,df_group['customer_id_hashed'].nunique())\n",
    "\n",
    "df_total_id=df_group.groupby(['group'])['customer_id_hashed'].count().to_frame().reset_index().rename(columns={\"customer_id_hashed\":\"total_ids\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>total_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>control</td>\n",
       "      <td>54430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>489861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     group  total_ids\n",
       "0  control      54430\n",
       "1     test     489861"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_by_day_1=pd.read_table(\"/home/jian/BigLots/2020_by_weeks/MediaStorm_2020-01-18/MediaStormDailySales20200121-111749-649.txt\",\n",
    "                                sep=\"|\",dtype=str)\n",
    "df_sales_by_day_2=pd.read_table(\"/home/jian/BigLots/2020_by_weeks/MediaStorm_2020-01-25/MediaStormDailySales20200128-111758-074.txt\",\n",
    "                                sep=\"|\",dtype=str)\n",
    "df_sales_by_day=df_sales_by_day_1.append(df_sales_by_day_2)\n",
    "\n",
    "del df_sales_by_day_1\n",
    "del df_sales_by_day_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_by_day['item_transaction_amt']=df_sales_by_day['item_transaction_amt'].astype(float)\n",
    "df_sales_by_day=df_sales_by_day[pd.notnull(df_sales_by_day['customer_id_hashed'])]\n",
    "df_sales_by_day=pd.merge(df_sales_by_day,df_group,on=\"customer_id_hashed\",how=\"left\")\n",
    "df_sales_by_day['group']=df_sales_by_day['group'].fillna('others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxonomy_div=pd.read_table(\"/home/jian/BigLots/static_files/ProductTaxonomy/MediaStormProductTaxonomy20200101-135600-916.txt\",dtype=str,sep=\"|\")\n",
    "df_taxonomy_div=df_taxonomy_div[['division_id','class_code_id','subclass_id']].drop_duplicates()\n",
    "\n",
    "df_sales_by_day=pd.merge(df_sales_by_day,df_taxonomy_div,on=['class_code_id','subclass_id'],how=\"left\")\n",
    "# df_sales_by_day['store_type']=np.where(df_sales_by_day['location_id']==\"6990\",\"online\",\"instore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Store Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_fun={\"customer_id_hashed\":\"nunique\",\"item_transaction_amt\":\"sum\"}\n",
    "df_total_sales=df_sales_by_day.groupby(['transaction_dt','group'])['customer_id_hashed','item_transaction_amt'].agg(agg_fun).reset_index()\n",
    "df_total_trans=df_sales_by_day[['group','location_id','transaction_dt','transaction_id','customer_id_hashed']].drop_duplicates()\n",
    "df_total_trans['trans']=1\n",
    "df_total_trans=df_total_trans.groupby(['transaction_dt','group'])['trans'].sum().to_frame().reset_index()\n",
    "df_total=pd.merge(df_total_sales,df_total_trans,on=['transaction_dt','group'],how=\"outer\")\n",
    "df_total=df_total.rename(columns={\"customer_id_hashed\":\"total_shoppers\",\"item_transaction_amt\":\"total_sales\",\"trans\":\"total_trans\"})\n",
    "df_total['total_AOV']=df_total['total_sales']/df_total['total_trans']\n",
    "\n",
    "df_division_sales=df_sales_by_day.groupby(['transaction_dt','group','division_id'])['customer_id_hashed','item_transaction_amt'].agg(agg_fun).reset_index()\n",
    "df_division_trans=df_sales_by_day[['group','location_id','transaction_dt','transaction_id','customer_id_hashed','division_id']].drop_duplicates()\n",
    "df_division_trans['trans']=1\n",
    "df_division_trans=df_division_trans.groupby(['transaction_dt','group','division_id'])['trans'].sum().to_frame().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_division=pd.merge(df_division_sales,df_division_trans,on=['transaction_dt','group','division_id'],how=\"outer\")\n",
    "df_division['AOV']=df_division['item_transaction_amt']/df_division['trans']\n",
    "df_division=df_division.rename(columns={\"customer_id_hashed\":\"division_shoppers\",\"item_transaction_amt\":\"division_sales\",\"trans\":\"division_trans\",\"AOV\":\"division_AOV\"})\n",
    "\n",
    "df_division=df_division.pivot_table(index=['transaction_dt','group'],columns='division_id',values=['division_shoppers','division_sales','division_trans',\"division_AOV\"]).reset_index()\n",
    "\n",
    "new_cols=[]\n",
    "for col in df_division.columns.tolist():\n",
    "    if not col[1]:\n",
    "        new_cols.append(col[0])\n",
    "    else:\n",
    "        new_cols.append(\"division_\"+col[1]+\"_\"+col[0].split(\"_\")[1])\n",
    "df_division.columns=new_cols\n",
    "\n",
    "new_cols=['transaction_dt','group']\n",
    "for i in range(10):\n",
    "    new_cols.append(\"division_\"+str(i)+\"_shoppers\")\n",
    "    new_cols.append(\"division_\"+str(i)+\"_sales\")\n",
    "    new_cols.append(\"division_\"+str(i)+\"_trans\")\n",
    "    new_cols.append(\"division_\"+str(i)+\"_AOV\")\n",
    "new_cols=[x for x in new_cols if x in df_division.columns.tolist()]    \n",
    "df_division=df_division[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=99\n",
    "\n",
    "df_output=pd.merge(df_total,df_division,on=['transaction_dt','group'],how=\"outer\")\n",
    "\n",
    "df_output=pd.merge(df_total_id,df_output,on=\"group\",how=\"outer\")\n",
    "df_output=df_output.sort_values([\"transaction_dt\",\"group\"])\n",
    "# df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 days overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_3_campaign_days=df_sales_by_day[df_sales_by_day['transaction_dt'].isin(['2020-01-18','2020-01-19','2020-01-20'])]\n",
    "df_sales_3_campaign_days=df_sales_3_campaign_days.rename(columns={\"transaction_dt\":\"date_kept_to_dedup\"})\n",
    "\n",
    "df_sales_3_campaign_days['transaction_dt']='total_3_days_Jan_18-20'\n",
    "\n",
    "df_total_sales=df_sales_3_campaign_days.groupby(['transaction_dt','group'])['customer_id_hashed','item_transaction_amt'].agg(agg_fun).reset_index()\n",
    "df_total_trans=df_sales_3_campaign_days[['group','location_id','transaction_dt','transaction_id','customer_id_hashed','date_kept_to_dedup']].drop_duplicates()\n",
    "df_total_trans['trans']=1\n",
    "df_total_trans=df_total_trans.groupby(['transaction_dt','group'])['trans'].sum().to_frame().reset_index()\n",
    "df_total=pd.merge(df_total_sales,df_total_trans,on=['transaction_dt','group'],how=\"outer\")\n",
    "df_total=df_total.rename(columns={\"customer_id_hashed\":\"total_shoppers\",\"item_transaction_amt\":\"total_sales\",\"trans\":\"total_trans\"})\n",
    "df_total['total_AOV']=df_total['total_sales']/df_total['total_trans']\n",
    "\n",
    "df_division_sales=df_sales_3_campaign_days.groupby(['transaction_dt','group','division_id'])['customer_id_hashed','item_transaction_amt'].agg(agg_fun).reset_index()\n",
    "df_division_trans=df_sales_3_campaign_days[['group','location_id','transaction_dt','transaction_id','customer_id_hashed','division_id','date_kept_to_dedup']].drop_duplicates()\n",
    "df_division_trans['trans']=1\n",
    "df_division_trans=df_division_trans.groupby(['transaction_dt','group','division_id'])['trans'].sum().to_frame().reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 days overall\n",
    "\n",
    "df_division=pd.merge(df_division_sales,df_division_trans,on=['transaction_dt','group','division_id'],how=\"outer\")\n",
    "df_division['AOV']=df_division['item_transaction_amt']/df_division['trans']\n",
    "df_division=df_division.rename(columns={\"customer_id_hashed\":\"division_shoppers\",\"item_transaction_amt\":\"division_sales\",\"trans\":\"division_trans\",\"AOV\":\"division_AOV\"})\n",
    "\n",
    "df_division=df_division.pivot_table(index=['transaction_dt','group'],columns='division_id',values=['division_shoppers','division_sales','division_trans',\"division_AOV\"]).reset_index()\n",
    "\n",
    "new_cols=[]\n",
    "for col in df_division.columns.tolist():\n",
    "    if not col[1]:\n",
    "        new_cols.append(col[0])\n",
    "    else:\n",
    "        new_cols.append(\"division_\"+col[1]+\"_\"+col[0].split(\"_\")[1])\n",
    "df_division.columns=new_cols\n",
    "\n",
    "new_cols=['transaction_dt','group']\n",
    "for i in range(10):\n",
    "    new_cols.append(\"division_\"+str(i)+\"_shoppers\")\n",
    "    new_cols.append(\"division_\"+str(i)+\"_sales\")\n",
    "    new_cols.append(\"division_\"+str(i)+\"_trans\")\n",
    "    new_cols.append(\"division_\"+str(i)+\"_AOV\")\n",
    "new_cols=[x for x in new_cols if x in df_division.columns.tolist()]    \n",
    "df_division=df_division[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_division=pd.merge(df_division_sales,df_division_trans,on=['transaction_dt','group','division_id'],how=\"outer\")\n",
    "df_division['AOV']=df_division['item_transaction_amt']/df_division['trans']\n",
    "df_division=df_division.rename(columns={\"customer_id_hashed\":\"division_shoppers\",\"item_transaction_amt\":\"division_sales\",\"trans\":\"division_trans\",\"AOV\":\"division_AOV\"})\n",
    "\n",
    "df_division=df_division.pivot_table(index=['transaction_dt','group'],columns='division_id',values=['division_shoppers','division_sales','division_trans',\"division_AOV\"]).reset_index()\n",
    "\n",
    "new_cols=[]\n",
    "for col in df_division.columns.tolist():\n",
    "    if not col[1]:\n",
    "        new_cols.append(col[0])\n",
    "    else:\n",
    "        new_cols.append(\"division_\"+col[1]+\"_\"+col[0].split(\"_\")[1])\n",
    "df_division.columns=new_cols\n",
    "\n",
    "new_cols=['transaction_dt','group']\n",
    "for i in range(10):\n",
    "    new_cols.append(\"division_\"+str(i)+\"_shoppers\")\n",
    "    new_cols.append(\"division_\"+str(i)+\"_sales\")\n",
    "    new_cols.append(\"division_\"+str(i)+\"_trans\")\n",
    "    new_cols.append(\"division_\"+str(i)+\"_AOV\")\n",
    "new_cols=[x for x in new_cols if x in df_division.columns.tolist()]    \n",
    "df_division=df_division[new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_2=pd.merge(df_total,df_division,on=['transaction_dt','group'],how=\"outer\")\n",
    "\n",
    "df_output_2=pd.merge(df_total_id,df_output_2,on=\"group\",how=\"outer\")\n",
    "df_output_2=df_output_2.sort_values([\"transaction_dt\",\"group\"])\n",
    "\n",
    "df_output=df_output.append(df_output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_division_name=pd.read_table(\"/home/jian/BigLots/static_files/MediaStorm Data Extract - Division Names.txt\",sep=\"|\")\n",
    "\n",
    "writer=pd.ExcelWriter(\"./BL_performance_of_furniture_browser_groups_updated_3_Campaign_days_JL_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "df_output.to_excel(writer,\"view_no_store_type\",index=False)\n",
    "df_division_name.to_excel(writer,\"divison_name\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
