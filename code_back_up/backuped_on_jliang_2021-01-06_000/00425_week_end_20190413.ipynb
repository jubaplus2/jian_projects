{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2020-05-07 23:22:37.763702\n"
     ]
    }
   ],
   "source": [
    "# email: Migration Tracker for the week 4/25\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import gc\n",
    "import logging\n",
    "import glob\n",
    "# Change the print content to all of strings for the log writing\n",
    "print(\"Start: \"+str(datetime.datetime.now()))\n",
    "\n",
    "samplerows=None\n",
    "\n",
    "\n",
    "last_sturday = datetime.date(2019,4,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_file_gen(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root,file)\n",
    "\n",
    "            \n",
    "def get_current_week_quarter_week(input_saturday):\n",
    "    weeks_since_19Q1= int((input_saturday-last_day_of_2018Q4).days/7)\n",
    "\n",
    " \n",
    "\n",
    "    year_integer=2018+int(np.ceil(weeks_since_19Q1/52))\n",
    "    quarter_integer=int(np.ceil(weeks_since_19Q1/13))%4\n",
    "    if quarter_integer==0:\n",
    "        quarter_integer=4\n",
    "        \n",
    "    week_integer=int(np.ceil(weeks_since_19Q1%13))\n",
    "\n",
    " \n",
    "\n",
    "    if week_integer==0:\n",
    "        week_integer=13\n",
    "        \n",
    "    return str(year_integer)+\"_Q\"+str(quarter_integer),week_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2019, 1, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_day_of_2018Q4=datetime.date(2019,2,2)\n",
    "\n",
    "year_of_quarter=int(get_current_week_quarter_week(last_sturday)[0][:4])\n",
    "quarter_of_quarter=int(get_current_week_quarter_week(last_sturday)[0][-1])\n",
    "current_week=int(get_current_week_quarter_week(last_sturday)[1])\n",
    "year_of_quarter,quarter_of_quarter,current_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 2, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_quarter_beginning=last_day_of_2018Q4+datetime.timedelta(days=(int(year_of_quarter)-2019)*52*7+(int(quarter_of_quarter)-1)*13*7+1)\n",
    "current_quarter_beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2018, 11, 4), datetime.date(2019, 2, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_complete_quarter_End=current_quarter_beginning-datetime.timedelta(days=1)\n",
    "recent_complete_quarter_Start=recent_complete_quarter_End-datetime.timedelta(days=13*7-1)\n",
    "recent_complete_quarter_Start,recent_complete_quarter_End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lapsed_date_begin 2014-10-28\n",
      "1 read chunk 2020-05-07 14:26:40.587086\n",
      "2 read chunk 2020-05-07 14:27:11.624885\n",
      "3 read chunk 2020-05-07 14:27:38.500331\n",
      "4 read chunk 2020-05-07 14:28:11.350875\n",
      "5 read chunk 2020-05-07 14:28:46.552005\n",
      "6 read chunk 2020-05-07 14:29:24.113180\n",
      "7 read chunk 2020-05-07 14:29:59.931921\n",
      "8 read chunk 2020-05-07 14:30:42.147732\n",
      "9 read chunk 2020-05-07 14:31:24.296071\n",
      "10 read chunk 2020-05-07 14:32:04.943560\n",
      "11 read chunk 2020-05-07 14:32:54.072661\n",
      "12 read chunk 2020-05-07 14:35:42.563358\n",
      "13 read chunk 2020-05-07 14:38:41.910371\n",
      "14 read chunk 2020-05-07 14:39:34.393292\n",
      "15 read chunk 2020-05-07 14:40:27.150724\n"
     ]
    }
   ],
   "source": [
    "# force_run==1:\n",
    "# run the part in the if condition\n",
    "\n",
    "lapsed_date_begin=recent_complete_quarter_Start-datetime.timedelta(days=1)-datetime.timedelta(days=(4*365+1+6)) # Prior quarter back 4years\n",
    "print(\"lapsed_date_begin\",lapsed_date_begin)\n",
    "lapsed=pd.read_table(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_sales_data/lapsed20140826_20170226/MediaStormLapsedCustDtl.txt\",\n",
    "                 sep=\",\",nrows=samplerows,usecols=['customer_id_hashed','transaction_date'],dtype=str).drop_duplicates()\n",
    "lapsed=lapsed[lapsed['transaction_date']>=str(lapsed_date_begin)]\n",
    "\n",
    "chunksize_num = 10**7\n",
    "filename='/home/jian/Projects/Big_Lots/Live_Ramp/Quarterly_Update_2019Q1/crm_newscore_0922/combinedtransactions_0922.csv'\n",
    "dftrans_before_20180922=pd.DataFrame()\n",
    "count_i=0\n",
    "\n",
    "for chunk in pd.read_csv(filename, chunksize=chunksize_num,dtype=str,nrows=samplerows,\n",
    "                         usecols=['customer_id_hashed','transaction_date']):\n",
    "    chunk = chunk.drop_duplicates()\n",
    "    chunk=chunk[chunk['transaction_date']>=str(lapsed_date_begin)]\n",
    "    dftrans_before_20180922=dftrans_before_20180922.append(chunk)\n",
    "    count_i+=1\n",
    "    print(str(count_i)+\" read chunk \"+str(datetime.datetime.now()))\n",
    "dftrans_before_20180922=dftrans_before_20180922.drop_duplicates()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_rewards_most_recent.shape: (23141367, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards_most_recent=dftrans_before_20180922.append(lapsed)\n",
    "all_rewards_most_recent=all_rewards_most_recent.sort_values([\"customer_id_hashed\",\"transaction_date\"],ascending=[True,False])\n",
    "all_rewards_most_recent=all_rewards_most_recent.drop_duplicates(['customer_id_hashed'])\n",
    "print(\"all_rewards_most_recent.shape: \"+str(all_rewards_most_recent.shape))\n",
    "\n",
    "del chunk\n",
    "del dftrans_before_20180922\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74861588</th>\n",
       "      <td>00000135f48c68690ad3d5fc9ada41bb5cd687452007e8...</td>\n",
       "      <td>2017-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148150940</th>\n",
       "      <td>000001dadc0265bf9d250566d74e0006323f18b5826641...</td>\n",
       "      <td>2018-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          customer_id_hashed transaction_date\n",
       "74861588   00000135f48c68690ad3d5fc9ada41bb5cd687452007e8...       2017-01-19\n",
       "148150940  000001dadc0265bf9d250566d74e0006323f18b5826641...       2018-09-22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards_most_recent.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "historical_daily_df.shape(20, 2)\n",
      "2018-09-29 2019-02-09\n"
     ]
    }
   ],
   "source": [
    "# Before the end of 2019Q1, up to 2019-02-09\n",
    "historical_daily_data_folder=\"/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/\"\n",
    "historical_daily_data_list=list(recursive_file_gen(historical_daily_data_folder))\n",
    "historical_daily_data_list=[x for x in historical_daily_data_list if (\".txt\" in x) & (\"DailySales\" in x)]\n",
    "historical_daily_df=pd.DataFrame({\"file_path\":historical_daily_data_list})\n",
    "historical_daily_df['week_end_dt']=historical_daily_df['file_path'].apply(lambda x: datetime.datetime.strptime(x.split(\".\")[0].split(\"MediaStormDailySalesHistory\")[1],\"%Y%m%d\").date())\n",
    "historical_daily_df=historical_daily_df[(historical_daily_df['week_end_dt']<=datetime.date(2019,5,4)) & (historical_daily_df['week_end_dt']>datetime.date(2018,9,22))] # hard-code due to the 1st week of daily in item available\n",
    "historical_daily_df=historical_daily_df.sort_values(\"week_end_dt\")\n",
    "print(\"historical_daily_df.shape\"+str(historical_daily_df.shape))\n",
    "\n",
    "print(historical_daily_df['week_end_dt'].min(),historical_daily_df['week_end_dt'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekly_daily_df.shape: (64, 2)\n"
     ]
    }
   ],
   "source": [
    "# All daily files since 2019\n",
    "weekly_daily_df=list(recursive_file_gen(\"/home/jian/BigLots/\"))\n",
    "weekly_daily_df=[x for x in weekly_daily_df if (\"2018\" not in x) & (\"2017\" not in x) & (\"2016\" not in x) & (\"hist\" not in x.lower())]\n",
    "weekly_daily_df=[x for x in weekly_daily_df if (\".txt\" in x) & (\"aily\" in x)]\n",
    "\n",
    "weekly_daily_df=pd.DataFrame({\"file_path\":weekly_daily_df})\n",
    "weekly_daily_df['week_end_dt']=weekly_daily_df['file_path'].apply(lambda x: datetime.datetime.strptime(x.split(\"/MediaStorm_\")[1][:10],\"%Y-%m-%d\").date())\n",
    "weekly_daily_df=weekly_daily_df[weekly_daily_df['week_end_dt']>historical_daily_df['week_end_dt'].max()]\n",
    "print(\"weekly_daily_df.shape: \"+ str(weekly_daily_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekly_daily_df_in_recent_Q.shape: (13, 2)\n"
     ]
    }
   ],
   "source": [
    "# here from the historical_daily_df since it's old\n",
    "\n",
    "weekly_daily_df_in_recent_Q=historical_daily_df[(historical_daily_df['week_end_dt']>=recent_complete_quarter_Start) & (historical_daily_df['week_end_dt']<=recent_complete_quarter_End)]\n",
    "# For later use to read last quarter sales\n",
    "print(\"weekly_daily_df_in_recent_Q.shape: \"+ str(weekly_daily_df_in_recent_Q.shape))\n",
    "\n",
    "weekly_daily_df_upto_pri_quarter_end=historical_daily_df[historical_daily_df['week_end_dt']<recent_complete_quarter_Start]\n",
    "# weekly_daily_df_upto_pri_quarter_end=weekly_daily_df_upto_pri_quarter_end.append(historical_daily_df).sort_values(\"week_end_dt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jian/.local/lib/python3.6/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "rew_df_after_20180929_before_pri_quarter=pd.DataFrame()\n",
    "rew_df_last_quarter_only=pd.DataFrame()\n",
    "\n",
    "for file in weekly_daily_df_upto_pri_quarter_end['file_path'].tolist():\n",
    "    df=pd.read_table(file,sep=\"|\",dtype=str,nrows=samplerows,\n",
    "                     usecols=[\"customer_id_hashed\",\"transaction_dt\"]).drop_duplicates().rename(columns={\"transaction_dt\":\"transaction_date\"})\n",
    "    df=df[~pd.isnull(df['customer_id_hashed'])]\n",
    "    rew_df_after_20180929_before_pri_quarter=rew_df_after_20180929_before_pri_quarter.append(df)\n",
    "\n",
    "for file in weekly_daily_df_in_recent_Q['file_path'].tolist():\n",
    "    df=pd.read_table(file,sep=\"|\",dtype=str,nrows=samplerows,\n",
    "                     usecols=[\"customer_id_hashed\",\"transaction_dt\"]).drop_duplicates().rename(columns={\"transaction_dt\":\"transaction_date\"})\n",
    "    df=df[~pd.isnull(df['customer_id_hashed'])]\n",
    "    rew_df_last_quarter_only=rew_df_last_quarter_only.append(df)\n",
    "\n",
    "all_rewards_most_recent=all_rewards_most_recent.append(rew_df_after_20180929_before_pri_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30754328, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards_most_recent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2014-10-28', '2018-11-03')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards_most_recent['transaction_date'].min(),all_rewards_most_recent['transaction_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del rew_df_after_20180929_before_pri_quarter\n",
    "all_rewards_most_recent=all_rewards_most_recent.sort_values([\"customer_id_hashed\",\"transaction_date\"],ascending=[True,False])\n",
    "all_rewards_most_recent=all_rewards_most_recent.drop_duplicates(['customer_id_hashed'])\n",
    "all_rewards_most_recent['transaction_date_before_the_Quarter']=all_rewards_most_recent['transaction_date']\n",
    "\n",
    "all_rewards_most_recent_After=all_rewards_most_recent[['customer_id_hashed','transaction_date']].append(rew_df_last_quarter_only)\n",
    "del rew_df_last_quarter_only\n",
    "\n",
    "all_rewards_most_recent_After=all_rewards_most_recent_After.sort_values([\"customer_id_hashed\",\"transaction_date\"],ascending=[True,False])\n",
    "all_rewards_most_recent_After=all_rewards_most_recent_After.drop_duplicates(['customer_id_hashed']).rename(columns={\"transaction_date\":\"transaction_date_after_the_Quarter\"})\n",
    "\n",
    "all_rewards_most_recent=pd.merge(all_rewards_most_recent,all_rewards_most_recent_After,on=\"customer_id_hashed\",how=\"outer\")\n",
    "del all_rewards_most_recent_After\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Active', 'Lapsed_13_48', 'WD_48+', 'NotAvailable_Before_Quarter']\n",
      "['Active' 'WD_48+' 'Lapsed_13_48']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filled the na before with a later date 2099-12-31\n",
    "all_rewards_most_recent['transaction_date_before_the_Quarter']=all_rewards_most_recent['transaction_date_before_the_Quarter'].fillna(\"2099-12-31\")\n",
    "# Change here to use unique dates and merge\n",
    "all_rewards_most_recent_date=all_rewards_most_recent[['transaction_date_before_the_Quarter']].drop_duplicates()\n",
    "all_rewards_most_recent_date['date']=pd.to_datetime(all_rewards_most_recent_date['transaction_date_before_the_Quarter'],format=\"%Y-%m-%d\").dt.date\n",
    "all_rewards_most_recent_date['Days_to_pre_Quarter_End']=recent_complete_quarter_Start-datetime.timedelta(days=1)-all_rewards_most_recent_date['date']\n",
    "all_rewards_most_recent_date['Month_to_pre_Quarter_End']=all_rewards_most_recent_date['Days_to_pre_Quarter_End'].apply(lambda x: x.days/(365.25/12))\n",
    "all_rewards_most_recent_date['Group_before_the_Quarter']=np.where((all_rewards_most_recent_date['Month_to_pre_Quarter_End']>12) & (all_rewards_most_recent_date['Month_to_pre_Quarter_End']<=48),\"Lapsed_13_48\",\n",
    "                                                       np.where(all_rewards_most_recent_date['Month_to_pre_Quarter_End']>48,\"WD_48+\",\n",
    "                                                                np.where((all_rewards_most_recent_date['Month_to_pre_Quarter_End']>=0) & (all_rewards_most_recent_date['Month_to_pre_Quarter_End']<=12),\"Active\",\n",
    "                                                                        np.where(all_rewards_most_recent_date['Month_to_pre_Quarter_End']<0,\"NotAvailable_Before_Quarter\",\"NaN\")\n",
    "                                                                        )\n",
    "                                                               )\n",
    "                                                       )\n",
    "\n",
    "all_rewards_most_recent=pd.merge(all_rewards_most_recent,all_rewards_most_recent_date,on=\"transaction_date_before_the_Quarter\",how=\"left\")\n",
    "del all_rewards_most_recent_date\n",
    "del all_rewards_most_recent['transaction_date_before_the_Quarter']\n",
    "all_rewards_most_recent=all_rewards_most_recent.rename(columns={\"date\":\"transaction_date_before_the_Quarter\"})\n",
    "\n",
    "\n",
    "#######\n",
    "all_rewards_most_recent_date=all_rewards_most_recent[['transaction_date_after_the_Quarter']].drop_duplicates()\n",
    "all_rewards_most_recent_date['date']=pd.to_datetime(all_rewards_most_recent_date['transaction_date_after_the_Quarter'],format=\"%Y-%m-%d\").dt.date\n",
    "all_rewards_most_recent_date['Days_to_recentt_Quarter_End']=recent_complete_quarter_End-all_rewards_most_recent_date['date']\n",
    "all_rewards_most_recent_date['Month_to_recent_Quarter_End']=all_rewards_most_recent_date['Days_to_recentt_Quarter_End'].apply(lambda x: x.days/(365.25/12))\n",
    "all_rewards_most_recent_date['Group_after_the_Quarter']=np.where((all_rewards_most_recent_date['Month_to_recent_Quarter_End']>12) & (all_rewards_most_recent_date['Month_to_recent_Quarter_End']<=48),\"Lapsed_13_48\",\n",
    "                                                       np.where(all_rewards_most_recent_date['Month_to_recent_Quarter_End']>48,\"WD_48+\",\n",
    "                                                                np.where((all_rewards_most_recent_date['Month_to_recent_Quarter_End']>=0) & (all_rewards_most_recent_date['Month_to_recent_Quarter_End']<=12),\"Active\",\n",
    "                                                                        np.where(all_rewards_most_recent_date['Month_to_recent_Quarter_End']<0,\"NotAvailable_Before_Q4\",\"NaN\")\n",
    "                                                                        )\n",
    "                                                               )\n",
    "                                                       )\n",
    "\n",
    "\n",
    "all_rewards_most_recent=pd.merge(all_rewards_most_recent,all_rewards_most_recent_date,on=\"transaction_date_after_the_Quarter\",how=\"left\")\n",
    "del all_rewards_most_recent_date\n",
    "del all_rewards_most_recent['transaction_date_after_the_Quarter']\n",
    "all_rewards_most_recent=all_rewards_most_recent.rename(columns={\"date\":\"transaction_date_after_the_Quarter\"})\n",
    "\n",
    "print(str(all_rewards_most_recent['Group_before_the_Quarter'].unique().tolist()))\n",
    "print(str(all_rewards_most_recent['Group_after_the_Quarter'].unique()))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "RecentQuarter_sales_by_id=pd.DataFrame()\n",
    "\n",
    "for file in weekly_daily_df_in_recent_Q['file_path'].tolist():\n",
    "    df=pd.read_table(file,sep=\"|\",dtype=str,nrows=samplerows,\n",
    "                     usecols=['location_id','transaction_dt','transaction_id','customer_id_hashed','item_transaction_amt'])\n",
    "    df=df[~pd.isnull(df['customer_id_hashed'])]\n",
    "    df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "    df_sales=df.groupby(['customer_id_hashed'])['item_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"item_transaction_amt\":\"sales_recent_Quarter\"})\n",
    "\n",
    "    df_trans=df[['location_id','transaction_dt','transaction_id','customer_id_hashed']].drop_duplicates()\n",
    "    df_trans=df_trans.groupby([\"customer_id_hashed\"])['transaction_id'].count().to_frame().reset_index().rename(columns={\"transaction_id\":\"trans_recent_Quarter\"})\n",
    "\n",
    "    df=pd.merge(df_sales,df_trans,on=\"customer_id_hashed\",how=\"outer\")\n",
    "\n",
    "    RecentQuarter_sales_by_id=RecentQuarter_sales_by_id.append(df)\n",
    "    # print(file,datetime.datetime.now())\n",
    "RecentQuarter_sales_by_id=RecentQuarter_sales_by_id.groupby(\"customer_id_hashed\")['sales_recent_Quarter','trans_recent_Quarter'].sum().reset_index()\n",
    "RecentQuarter_sales_by_id['Recent_Quarter_Shopping_Group']=\"Recent_Quarter_Shopped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards_most_recent=pd.merge(all_rewards_most_recent,RecentQuarter_sales_by_id,on=\"customer_id_hashed\",how=\"outer\")\n",
    "del RecentQuarter_sales_by_id\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"'2018-11-04'\", \"'2019-02-02'\")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )\n",
    "\n",
    "str_date_recent_complete_quarter_Start=\"'\"+str(recent_complete_quarter_Start)+\"'\"\n",
    "str_date_recent_complete_quarter_End=\"'\"+str(recent_complete_quarter_End)+\"'\"\n",
    "str_date_recent_complete_quarter_Start,str_date_recent_complete_quarter_End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-04 2019-02-02\n",
      "recent_new_sign_ups.shape: (2202974, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_new_sign_ups=pd.read_sql(\"select customer_id_hashed,sign_up_date from BL_Rewards_Master where sign_up_date between %s and %s\"%(str_date_recent_complete_quarter_Start,str_date_recent_complete_quarter_End),\n",
    "                               con=BL_engine)\n",
    "print(recent_new_sign_ups['sign_up_date'].min(),recent_new_sign_ups['sign_up_date'].max())\n",
    "\n",
    "recent_new_sign_ups=recent_new_sign_ups.sort_values(['customer_id_hashed','sign_up_date']).drop_duplicates(\"customer_id_hashed\")\n",
    "recent_new_sign_ups['NewRewards_RecentQuarter']=\"Recent_Quarter_New_Sign_Ups\"\n",
    "print(\"recent_new_sign_ups.shape: \"+str(recent_new_sign_ups.shape))\n",
    "del recent_new_sign_ups['sign_up_date']\n",
    "\n",
    "all_rewards_most_recent=pd.merge(all_rewards_most_recent,recent_new_sign_ups,on=\"customer_id_hashed\",how=\"outer\")\n",
    "all_rewards_most_recent['NewRewards_RecentQuarter']=all_rewards_most_recent['NewRewards_RecentQuarter'].fillna(\"Old_Rewards_Members\")\n",
    "del recent_new_sign_ups\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rewards_most_recent['sales_recent_Quarter']=all_rewards_most_recent['sales_recent_Quarter'].fillna(0)\n",
    "all_rewards_most_recent['trans_recent_Quarter']=all_rewards_most_recent['trans_recent_Quarter'].fillna(0)\n",
    "\n",
    "all_rewards_most_recent['Recent_Quarter_Shopping_Group']=all_rewards_most_recent['Recent_Quarter_Shopping_Group'].fillna(\"Recent_Quarter_No_Shop\")\n",
    "all_rewards_most_recent['Group_before_the_Quarter']=all_rewards_most_recent['Group_before_the_Quarter'].fillna(\"nan\")\n",
    "all_rewards_most_recent['Group_after_the_Quarter']=all_rewards_most_recent['Group_after_the_Quarter'].fillna(\"nan\")\n",
    "\n",
    "output_id_recentquarter_count=all_rewards_most_recent.groupby(['Group_before_the_Quarter','Group_after_the_Quarter','NewRewards_RecentQuarter','Recent_Quarter_Shopping_Group'])['customer_id_hashed'].count().to_frame().reset_index().rename(columns={\"customer_id_hashed\":\"id_count\"})\n",
    "output_id_recentquarter_sales=all_rewards_most_recent.groupby(['Group_before_the_Quarter','Group_after_the_Quarter','NewRewards_RecentQuarter','Recent_Quarter_Shopping_Group'])['sales_recent_Quarter','trans_recent_Quarter'].sum().reset_index()\n",
    "\n",
    "output_recentquarter=pd.merge(output_id_recentquarter_count,output_id_recentquarter_sales,on=['Group_before_the_Quarter','Group_after_the_Quarter','NewRewards_RecentQuarter','Recent_Quarter_Shopping_Group'],how=\"outer\")\n",
    "all_rewards_most_recent.to_csv('/home/jian/celery/Migration_Performance/quarterly_report/migration_group_for_recent_quarter_before_'+str(year_of_quarter)+\"Q\"+str(quarter_of_quarter)+\".csv\",index=False)\n",
    "output_recentquarter.to_csv('/home/jian/celery/Migration_Performance/quarterly_report/summary/summary_migration_group_for_recent_quarter_before_'+ str(year_of_quarter)+\"Q\"+str(quarter_of_quarter)+\".csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2014, 10, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lapsed_date_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>week_end_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-02-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>/home/jian/BigLots/2019_by_weeks/MediaStorm_20...</td>\n",
       "      <td>2019-04-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file_path week_end_dt\n",
       "23  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-02-09\n",
       "24  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-02-16\n",
       "25  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-02-23\n",
       "26  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-02\n",
       "27  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-09\n",
       "28  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-16\n",
       "29  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-23\n",
       "30  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-03-30\n",
       "31  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-04-06\n",
       "32  /home/jian/BigLots/2019_by_weeks/MediaStorm_20...  2019-04-13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[7]:\n",
    "\n",
    "all_rewards_most_recent=glob.glob(\"/home/jian/celery/Migration_Performance/quarterly_report/*.csv\")\n",
    "all_rewards_most_recent=[x for x in all_rewards_most_recent if str(year_of_quarter)+\"Q\"+str(quarter_of_quarter) in x]\n",
    "if len(all_rewards_most_recent)!=1:\n",
    "    print(\"Error: multiple files about id by group at the begining of the quarter are saved, please check\")\n",
    "else:\n",
    "    df_all_rewards_most_recent=pd.read_csv(all_rewards_most_recent[0],dtype=str)\n",
    "    df_all_rewards_most_recent['sales_recent_Quarter']=df_all_rewards_most_recent['sales_recent_Quarter'].astype(float)\n",
    "    df_all_rewards_most_recent['trans_recent_Quarter']=df_all_rewards_most_recent['trans_recent_Quarter'].astype(float).astype(int)\n",
    "if 'sign_up_date' in df_all_rewards_most_recent.columns.tolist():\n",
    "    del df_all_rewards_most_recent['sign_up_date']\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "# Read this onging quarter performance\n",
    "weekly_daily_df=list(recursive_file_gen(\"/home/jian/BigLots/\"))\n",
    "weekly_daily_df=[x for x in weekly_daily_df if (\"2018\" not in x) & (\"2017\" not in x) & (\"2016\" not in x) & (\"hist\" not in x.lower())]\n",
    "weekly_daily_df=[x for x in weekly_daily_df if (\".txt\" in x) & (\"aily\" in x)]\n",
    "\n",
    "weekly_daily_df=pd.DataFrame({\"file_path\":weekly_daily_df})\n",
    "weekly_daily_df['week_end_dt']=weekly_daily_df['file_path'].apply(lambda x: datetime.datetime.strptime(x.split(\"/MediaStorm_\")[1][:10],\"%Y-%m-%d\").date())\n",
    "weekly_daily_df=weekly_daily_df[weekly_daily_df['week_end_dt']>current_quarter_beginning]\n",
    "weekly_daily_df=weekly_daily_df[weekly_daily_df['week_end_dt']<=last_sturday]\n",
    "\n",
    "weekly_daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"'2019-02-03'\", \"'2019-04-13'\")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import sqlalchemy\n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )\n",
    "\n",
    "str_date_ongoing_quarter_Start=\"'\"+str(recent_complete_quarter_Start+datetime.timedelta(days=7*13))+\"'\"\n",
    "str_date_last_sturday=\"'\"+str(last_sturday)+\"'\"\n",
    "str_date_ongoing_quarter_Start,str_date_last_sturday\n",
    "'''\n",
    "# inacurate above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-03 2019-04-13\n",
      "ongoing_new_sign_ups.shape: (1271097, 3)\n"
     ]
    }
   ],
   "source": [
    "ongoing_new_sign_ups=pd.read_sql(\"select customer_id_hashed,sign_up_date from BL_Rewards_Master where sign_up_date between %s and %s\"%(str_date_ongoing_quarter_Start,str_date_last_sturday),\n",
    "                               con=BL_engine)\n",
    "print(ongoing_new_sign_ups['sign_up_date'].min(),ongoing_new_sign_ups['sign_up_date'].max())\n",
    "\n",
    "ongoing_new_sign_ups=ongoing_new_sign_ups.sort_values(['customer_id_hashed','sign_up_date']).drop_duplicates(\"customer_id_hashed\")\n",
    "ongoing_new_sign_ups['NewRewards_OngoingQuarter']=\"Ongoing_Quarter_New_Sign_Ups\"\n",
    "print(\"ongoing_new_sign_ups.shape: \"+str(ongoing_new_sign_ups.shape))\n",
    "del ongoing_new_sign_ups['sign_up_date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if weekly_daily_df.shape[0]!=current_week:\n",
    "    print(\"Error: ongoing quarter daily file count doesn't match\")\n",
    "else:\n",
    "    current_quarter_file_list=weekly_daily_df['file_path'].tolist()\n",
    "    current_quarter_sales=pd.DataFrame()\n",
    "    for file in current_quarter_file_list:\n",
    "        try:\n",
    "            df=pd.read_table(file,sep=\"|\",dtype=str,nrows=samplerows,\n",
    "                         usecols=['location_id','transaction_dt','transaction_id','customer_id_hashed','item_transaction_amt'])\n",
    "        \n",
    "        except:\n",
    "            df=pd.read_table(file,sep=\"|\",dtype=str,nrows=samplerows,\n",
    "                         usecols=['location_id','transaction_dt','transaction_id','customer_id_hashed','subclass_transaction_amt'])\n",
    "            df=df.rename(columns={\"subclass_transaction_amt\":\"item_transaction_amt\"})\n",
    "        \n",
    "        df=df[~pd.isnull(df['customer_id_hashed'])]\n",
    "        df['item_transaction_amt']=df['item_transaction_amt'].astype(float)\n",
    "        df_sales=df.groupby(['customer_id_hashed'])['item_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"item_transaction_amt\":\"sales_ongoing_Quarter\"})\n",
    "\n",
    "        df_trans=df[['location_id','transaction_dt','transaction_id','customer_id_hashed']].drop_duplicates()\n",
    "        df_trans=df_trans.groupby([\"customer_id_hashed\"])['transaction_id'].count().to_frame().reset_index().rename(columns={\"transaction_id\":\"trans_ongoing_Quarter\"})\n",
    "\n",
    "        df=pd.merge(df_sales,df_trans,on=\"customer_id_hashed\",how=\"outer\")\n",
    "\n",
    "        current_quarter_sales=current_quarter_sales.append(df)\n",
    "    del df\n",
    "    current_quarter_sales=current_quarter_sales.groupby('customer_id_hashed')['sales_ongoing_Quarter','trans_ongoing_Quarter'].sum().reset_index()\n",
    "    current_quarter_sales['Ongoing_Quarter_Shopping_Group']=\"Ongoing_Quarter_Shopped\"\n",
    "\n",
    "    \n",
    "    df_all_rewards_most_recent=pd.merge(df_all_rewards_most_recent,current_quarter_sales,on=\"customer_id_hashed\",how=\"outer\")\n",
    "    del current_quarter_sales\n",
    "    df_all_rewards_most_recent['Ongoing_Quarter_Shopping_Group']=df_all_rewards_most_recent['Ongoing_Quarter_Shopping_Group'].fillna(\"Ongoing_Quarter_No_Shop\")\n",
    "    gc.collect()\n",
    "    \n",
    "    df_all_rewards_most_recent=pd.merge(df_all_rewards_most_recent,ongoing_new_sign_ups,on=\"customer_id_hashed\",how=\"outer\")\n",
    "    del ongoing_new_sign_ups\n",
    "    df_all_rewards_most_recent['NewRewards_OngoingQuarter']=df_all_rewards_most_recent['NewRewards_OngoingQuarter'].fillna(\"Old_Rewards_Members\")\n",
    "    \n",
    "    df_all_rewards_most_recent['sales_recent_Quarter']=df_all_rewards_most_recent['sales_recent_Quarter'].fillna(0)\n",
    "    df_all_rewards_most_recent['trans_recent_Quarter']=df_all_rewards_most_recent['trans_recent_Quarter'].fillna(0)\n",
    "    df_all_rewards_most_recent['sales_ongoing_Quarter']=df_all_rewards_most_recent['sales_ongoing_Quarter'].fillna(0)\n",
    "    df_all_rewards_most_recent['trans_ongoing_Quarter']=df_all_rewards_most_recent['trans_ongoing_Quarter'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_hashed</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>transaction_date_before_the_Quarter</th>\n",
       "      <th>Days_to_pre_Quarter_End</th>\n",
       "      <th>Month_to_pre_Quarter_End</th>\n",
       "      <th>Group_before_the_Quarter</th>\n",
       "      <th>transaction_date_after_the_Quarter</th>\n",
       "      <th>Days_to_recentt_Quarter_End</th>\n",
       "      <th>Month_to_recent_Quarter_End</th>\n",
       "      <th>Group_after_the_Quarter</th>\n",
       "      <th>sales_recent_Quarter</th>\n",
       "      <th>trans_recent_Quarter</th>\n",
       "      <th>Recent_Quarter_Shopping_Group</th>\n",
       "      <th>NewRewards_RecentQuarter</th>\n",
       "      <th>sales_ongoing_Quarter</th>\n",
       "      <th>trans_ongoing_Quarter</th>\n",
       "      <th>Ongoing_Quarter_Shopping_Group</th>\n",
       "      <th>NewRewards_OngoingQuarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000135f48c68690ad3d5fc9ada41bb5cd687452007e8...</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>4 days 00:00:00.000000000</td>\n",
       "      <td>0.13141683778234087</td>\n",
       "      <td>Active</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>95 days 00:00:00.000000000</td>\n",
       "      <td>3.1211498973305956</td>\n",
       "      <td>Active</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Recent_Quarter_No_Shop</td>\n",
       "      <td>Old_Rewards_Members</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ongoing_Quarter_No_Shop</td>\n",
       "      <td>Old_Rewards_Members</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001dadc0265bf9d250566d74e0006323f18b5826641...</td>\n",
       "      <td>2018-10-27</td>\n",
       "      <td>2018-10-27</td>\n",
       "      <td>7 days 00:00:00.000000000</td>\n",
       "      <td>0.2299794661190965</td>\n",
       "      <td>Active</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>43 days 00:00:00.000000000</td>\n",
       "      <td>1.4127310061601643</td>\n",
       "      <td>Active</td>\n",
       "      <td>42.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Recent_Quarter_Shopped</td>\n",
       "      <td>Old_Rewards_Members</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ongoing_Quarter_No_Shop</td>\n",
       "      <td>Old_Rewards_Members</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  customer_id_hashed transaction_date  \\\n",
       "0  00000135f48c68690ad3d5fc9ada41bb5cd687452007e8...       2018-10-30   \n",
       "1  000001dadc0265bf9d250566d74e0006323f18b5826641...       2018-10-27   \n",
       "\n",
       "  transaction_date_before_the_Quarter    Days_to_pre_Quarter_End  \\\n",
       "0                          2018-10-30  4 days 00:00:00.000000000   \n",
       "1                          2018-10-27  7 days 00:00:00.000000000   \n",
       "\n",
       "  Month_to_pre_Quarter_End Group_before_the_Quarter  \\\n",
       "0      0.13141683778234087                   Active   \n",
       "1       0.2299794661190965                   Active   \n",
       "\n",
       "  transaction_date_after_the_Quarter Days_to_recentt_Quarter_End  \\\n",
       "0                         2018-10-30  95 days 00:00:00.000000000   \n",
       "1                         2018-12-21  43 days 00:00:00.000000000   \n",
       "\n",
       "  Month_to_recent_Quarter_End Group_after_the_Quarter  sales_recent_Quarter  \\\n",
       "0          3.1211498973305956                  Active                   0.0   \n",
       "1          1.4127310061601643                  Active                  42.2   \n",
       "\n",
       "   trans_recent_Quarter Recent_Quarter_Shopping_Group  \\\n",
       "0                   0.0        Recent_Quarter_No_Shop   \n",
       "1                   1.0        Recent_Quarter_Shopped   \n",
       "\n",
       "  NewRewards_RecentQuarter  sales_ongoing_Quarter  trans_ongoing_Quarter  \\\n",
       "0      Old_Rewards_Members                    0.0                    0.0   \n",
       "1      Old_Rewards_Members                    0.0                    0.0   \n",
       "\n",
       "  Ongoing_Quarter_Shopping_Group NewRewards_OngoingQuarter  \n",
       "0        Ongoing_Quarter_No_Shop       Old_Rewards_Members  \n",
       "1        Ongoing_Quarter_No_Shop       Old_Rewards_Members  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_rewards_most_recent.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-07 21:29:49.111344Group_before_the_Quarter\n",
      "2020-05-07 21:29:50.922707Group_after_the_Quarter\n",
      "2020-05-07 21:29:52.802846NewRewards_RecentQuarter\n",
      "2020-05-07 21:29:54.549503Recent_Quarter_Shopping_Group\n",
      "2020-05-07 21:29:56.434385NewRewards_OngoingQuarter\n",
      "2020-05-07 21:29:58.244418Ongoing_Quarter_Shopping_Group\n"
     ]
    }
   ],
   "source": [
    "deminsion_cols=['Group_before_the_Quarter','Group_after_the_Quarter','NewRewards_RecentQuarter','Recent_Quarter_Shopping_Group','NewRewards_OngoingQuarter','Ongoing_Quarter_Shopping_Group']\n",
    "for col in deminsion_cols:\n",
    "    df_all_rewards_most_recent[col]=df_all_rewards_most_recent[col].fillna('nan')\n",
    "    print(str(datetime.datetime.now())+col)\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "output_id_count_everygroup=df_all_rewards_most_recent.groupby(deminsion_cols)['customer_id_hashed'].count().to_frame().reset_index().rename(columns={\"customer_id_hashed\":\"id_count\"})\n",
    "output_id_sales_everygroup=df_all_rewards_most_recent.groupby(deminsion_cols)['sales_recent_Quarter','trans_recent_Quarter','sales_ongoing_Quarter','trans_ongoing_Quarter'].sum().reset_index()\n",
    "\n",
    "output_everygroup=pd.merge(output_id_count_everygroup,output_id_sales_everygroup,on=deminsion_cols,how=\"outer\")\n",
    "\n",
    "\n",
    "output_everygroup['Recent_Quarteer_Sale_per_ID']=output_everygroup['sales_recent_Quarter']/output_everygroup['id_count']\n",
    "output_everygroup['Recent_Quarteer_Sale_per_ID']=output_everygroup['Recent_Quarteer_Sale_per_ID'].apply(lambda x: np.round(x,2))\n",
    "output_everygroup['Recent_Quarteer_Trans_per_ID']=output_everygroup['trans_recent_Quarter']/output_everygroup['id_count']\n",
    "output_everygroup['Recent_Quarteer_Trans_per_ID']=output_everygroup['Recent_Quarteer_Trans_per_ID'].apply(lambda x: np.round(x,2))\n",
    "\n",
    "output_everygroup['ongoing_Quarteer_Sale_per_ID']=output_everygroup['sales_ongoing_Quarter']/output_everygroup['id_count']\n",
    "output_everygroup['ongoing_Quarteer_Sale_per_ID']=output_everygroup['ongoing_Quarteer_Sale_per_ID'].apply(lambda x: np.round(x,2))\n",
    "output_everygroup['ongoing_Quarteer_Trans_per_ID']=output_everygroup['trans_ongoing_Quarter']/output_everygroup['id_count']\n",
    "output_everygroup['ongoing_Quarteer_Trans_per_ID']=output_everygroup['ongoing_Quarteer_Trans_per_ID'].apply(lambda x: np.round(x,2))\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "output_everygroup['before_ongoing_quarter_label']=np.where(output_everygroup['Group_after_the_Quarter']==\"Active\",\"Active\",\n",
    "                                                          np.where(output_everygroup['Group_after_the_Quarter']==\"Lapsed_13_48\",\"Lapsed\",\n",
    "                                                                  np.where(((output_everygroup['Group_after_the_Quarter']==\"nan\") &\\\n",
    "                                                                            (output_everygroup['NewRewards_RecentQuarter']==\"Recent_Quarter_New_Sign_Ups\") &\\\n",
    "                                                                            (output_everygroup['Recent_Quarter_Shopping_Group']==\"Recent_Quarter_No_Shop\")),\" Sign Up No Purchase (Previous Quarter)\",\"nan\")\n",
    "                                                                  )\n",
    "                                                          )\n",
    "count_pre=output_everygroup.groupby(\"before_ongoing_quarter_label\")['id_count'].sum().to_frame().reset_index()\n",
    "count_pre=count_pre[count_pre['before_ongoing_quarter_label']!=\"nan\"]\n",
    "\n",
    "output_everygroup['in_quarter_label']=np.where(((output_everygroup['Group_after_the_Quarter']==\"Active\") &                                                (output_everygroup['Ongoing_Quarter_Shopping_Group']==\"Ongoing_Quarter_Shopped\")),\"Active Shopper\",\n",
    "                                               np.where(((output_everygroup['Group_after_the_Quarter']==\"Lapsed_13_48\") &\\\n",
    "                                                         (output_everygroup['Ongoing_Quarter_Shopping_Group']==\"Ongoing_Quarter_Shopped\")),\"Activated Lapsed\",\n",
    "                                                        np.where(((output_everygroup['NewRewards_RecentQuarter']==\"Recent_Quarter_New_Sign_Ups\") &\\\n",
    "                                                                 (output_everygroup['Recent_Quarter_Shopping_Group']==\"Recent_Quarter_No_Shop\") &\\\n",
    "                                                                 (output_everygroup['Ongoing_Quarter_Shopping_Group']==\"Ongoing_Quarter_Shopped\") &\\\n",
    "                                                                 (output_everygroup['Group_before_the_Quarter']==\"nan\") &\\\n",
    "                                                                 (output_everygroup['Group_after_the_Quarter']==\"nan\")),\"Activated Recent Sign Up No Purchase\",\n",
    "                                                                 np.where(((output_everygroup['Group_after_the_Quarter'].isin(['WD_48+','nan'])) &\\\n",
    "                                                                            (output_everygroup['Ongoing_Quarter_Shopping_Group']==\"Ongoing_Quarter_Shopped\") &\\\n",
    "                                                                            (output_everygroup['NewRewards_OngoingQuarter']==\"Old_Rewards_Members\") &\\\n",
    "                                                                            (output_everygroup['NewRewards_RecentQuarter']!=\"Recent_Quarter_New_Sign_Ups\")),\"Resurrected Lapsed\",\n",
    "                                                                           np.where(((output_everygroup['NewRewards_OngoingQuarter']==\"Ongoing_Quarter_New_Sign_Ups\") &\\\n",
    "                                                                                     (output_everygroup['Ongoing_Quarter_Shopping_Group']==\"Ongoing_Quarter_Shopped\") &\\\n",
    "                                                                                     (output_everygroup['Group_after_the_Quarter']==\"nan\")),\"New Rewards Purchaser\",\n",
    "                                                                                    \"nan\")\n",
    "                                                                          )\n",
    "                                                                )\n",
    "                                                       )\n",
    "                                              )\n",
    "count_in_ongoing=output_everygroup.groupby(\"in_quarter_label\")['id_count'].sum().to_frame().reset_index()\n",
    "count_in_ongoing=count_in_ongoing[count_in_ongoing['in_quarter_label']!=\"nan\"]\n",
    "\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "writer_my=pd.ExcelWriter(\"./BL_tracking_migration_status_as_week_of_\"+str(last_sturday)+\"_\"+str(datetime.datetime.now().date())+\".xlsx\",engine=\"xlsxwriter\")\n",
    "output_everygroup.to_excel(writer_my,\"pivot\",index=False)\n",
    "count_pre.to_excel(writer_my,\"count_pre\",index=False)\n",
    "count_in_ongoing.to_excel(writer_my,\"count_in_ongoing\",index=False)\n",
    "writer_my.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/Projects/Big_Lots/Analysis/2020_Q1/plannder_requests/JT_both_year_April_migration_table_20200507'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
