{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/BigLots/static_files/store_list_from_Dom/Store List Report 07.10.20 425PM.xlsx'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_store_Dom=\"/home/jian/BigLots/static_files/store_list_from_Dom/\"\n",
    "file_store_Dom=glob.glob(folder_store_Dom+\"*.xlsx\")\n",
    "file_store_Dom=sorted(file_store_Dom,key=lambda x: os.stat(x).st_mtime)\n",
    "file_store_Dom=file_store_Dom[-1]\n",
    "file_store_Dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file=pd.ExcelFile(file_store_Dom)\n",
    "df_store_type=excel_file.parse(\"Store List\")\n",
    "df_store_type=df_store_type[['Store','Furniture Type']].drop_duplicates()\n",
    "df_store_type=df_store_type.rename(columns={\"Store\":\"location_id\"})\n",
    "df_store_type=df_store_type[pd.notnull(df_store_type['location_id'])]\n",
    "df_store_type['location_id']=df_store_type['location_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1479, 2), 1479)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store_type.shape,df_store_type['location_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_file_gen(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "list_store_sales_files=list(recursive_file_gen(\"/home/jian/BigLots/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_store_sales_files=[x for x in list_store_sales_files if \"MediaStormSalesWeekly\" in x]\n",
    "list_store_sales_files=[x for x in list_store_sales_files if \"_by_weeks/MediaStorm_\" in x]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_end_dt_2020Q2=[datetime.date(2020,8,1)-datetime.timedelta(days=7*i) for i in range(13)]\n",
    "week_end_dt_2020Q1=[datetime.date(2020,5,2)-datetime.timedelta(days=7*i) for i in range(13)]\n",
    "\n",
    "week_end_dt_2019Q2=[x-datetime.timedelta(days=7*52) for x in week_end_dt_2020Q2]\n",
    "week_end_dt_2019Q1=[x-datetime.timedelta(days=7*52) for x in week_end_dt_2020Q1]\n",
    "\n",
    "week_end_dt_2020Q2=[str(x) for x in week_end_dt_2020Q2]\n",
    "week_end_dt_2020Q1=[str(x) for x in week_end_dt_2020Q1]\n",
    "week_end_dt_2019Q2=[str(x) for x in week_end_dt_2019Q2]\n",
    "week_end_dt_2019Q1=[str(x) for x in week_end_dt_2019Q1]\n",
    "\n",
    "list_store_sales_files_2020Q2=[x for x in list_store_sales_files if x.split(\"_by_weeks/MediaStorm_\")[1][:10] in week_end_dt_2020Q2]\n",
    "list_store_sales_files_2020Q1=[x for x in list_store_sales_files if x.split(\"_by_weeks/MediaStorm_\")[1][:10] in week_end_dt_2020Q1]\n",
    "list_store_sales_files_2019Q2=[x for x in list_store_sales_files if x.split(\"_by_weeks/MediaStorm_\")[1][:10] in week_end_dt_2019Q2]\n",
    "list_store_sales_files_2019Q1=[x for x in list_store_sales_files if x.split(\"_by_weeks/MediaStorm_\")[1][:10] in week_end_dt_2019Q1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_by_store=pd.DataFrame()\n",
    "for file in list_store_sales_files_2020Q2:\n",
    "    df=pd.read_csv(file,dtype=str,sep=\"|\",usecols=['location_id','week_end_dt','gross_sales_amt']).drop_duplicates()\n",
    "    df['year']=\"2020\"\n",
    "    df['quarter']=\"Q2\"\n",
    "    df_sales_by_store=df_sales_by_store.append(df)\n",
    "for file in list_store_sales_files_2020Q1:\n",
    "    df=pd.read_csv(file,dtype=str,sep=\"|\",usecols=['location_id','week_end_dt','gross_sales_amt']).drop_duplicates()\n",
    "    df['year']=\"2020\"\n",
    "    df['quarter']=\"Q1\"\n",
    "    df_sales_by_store=df_sales_by_store.append(df)\n",
    "for file in list_store_sales_files_2019Q2:\n",
    "    df=pd.read_csv(file,dtype=str,sep=\"|\",usecols=['location_id','week_end_dt','gross_sales_amt']).drop_duplicates()\n",
    "    df['year']=\"2019\"\n",
    "    df['quarter']=\"Q2\"\n",
    "    df_sales_by_store=df_sales_by_store.append(df)\n",
    "for file in list_store_sales_files_2019Q1:\n",
    "    df=pd.read_csv(file,dtype=str,sep=\"|\",usecols=['location_id','week_end_dt','gross_sales_amt']).drop_duplicates()\n",
    "    df['year']=\"2019\"\n",
    "    df['quarter']=\"Q1\"\n",
    "    df_sales_by_store=df_sales_by_store.append(df)\n",
    "df_sales_by_store['gross_sales_amt']=df_sales_by_store['gross_sales_amt'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"./BL_sales_by_furtype_JL_%s.xlsx\"%str(datetime.datetime.now().date()),engine=\"xlsxwriter\")\n",
    "\n",
    "for quarter, df_group in df_sales_by_store.groupby(\"quarter\"):\n",
    "    df_week_count=df_group.groupby([\"location_id\"])['week_end_dt'].count().to_frame().reset_index()\n",
    "    df_week_count_inclusion=df_week_count[df_week_count['week_end_dt']==26]\n",
    "    list_store_inclusion=df_week_count_inclusion['location_id'].tolist()\n",
    "    \n",
    "    df_location_id_exclusion=df_week_count[~df_week_count['location_id'].isin(list_store_inclusion)]\n",
    "    df_exclusion=df_group[~df_group['location_id'].isin(list_store_inclusion)]\n",
    "    df_inclusion=df_group[df_group['location_id'].isin(list_store_inclusion)]\n",
    "\n",
    "    df_output=pd.merge(df_inclusion,df_store_type,on=\"location_id\",how=\"left\")\n",
    "    df_inclusion_stores=df_output[['location_id','Furniture Type','quarter']].drop_duplicates()\n",
    "    df_output['Furniture Type']=df_output['Furniture Type'].fillna(\"nan\")\n",
    "    df_output['Furniture Type']=np.where(df_output['location_id']==\"6990\",\"Online\",df_output['Furniture Type'])\n",
    "    agg_func={'location_id':\"nunique\",\"gross_sales_amt\":\"sum\"}\n",
    "    df_output=df_output.groupby(['Furniture Type','year','quarter'])['location_id','gross_sales_amt'].agg(agg_func).reset_index()\n",
    "    df_output=df_output.rename(columns={\"gross_sales_amt\":\"sales\"})\n",
    "    df_output=df_output.pivot_table(index=['quarter','Furniture Type','location_id'],columns=\"year\",values=\"sales\")\n",
    "    \n",
    "    #### \n",
    "    df_output.to_excel(writer,\"sales_%s_summary\"%quarter,index=True)\n",
    "    df_inclusion_stores.to_excel(writer,\"IncludeStores_%s\"%quarter,index=False)\n",
    "    df_exclusion.to_excel(writer,\"ExcludeStores_%s\"%quarter,index=False)\n",
    "    \n",
    "writer.save()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
