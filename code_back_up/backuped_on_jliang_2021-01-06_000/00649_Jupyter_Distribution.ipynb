{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 9, 7, 14, 4, 55, 603259)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "import hashlib\n",
    "import gc\n",
    "logging.basicConfig(filename='rewards_py_20180831.log', level=logging.INFO)\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samplerows = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_list_cols=['location_id','address_line_1','address_line_2','city_nm','state_nm','zip_cd']\n",
    "store_list=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStores20180801-133641-576.txt\",dtype=str,sep=\"|\")\n",
    "store_list=store_list[store_list_cols]\n",
    "\n",
    "store_list_2=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStores_20180703.txt\",dtype=str,sep=\"|\")\n",
    "store_list_2=store_list_2[~store_list_2['location_id'].isin(store_list['location_id'].unique().tolist())]\n",
    "store_list_2=store_list_2[store_list_cols]\n",
    "store_list=store_list.append(store_list_2)\n",
    "\n",
    "store_list_2=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStoreList_Nov15.txt\",dtype=str,sep=\"|\")\n",
    "store_list_2=store_list_2[~store_list_2['location_id'].isin(store_list['location_id'].unique().tolist())]\n",
    "store_list_2=store_list_2[store_list_cols]\n",
    "store_list=store_list.append(store_list_2)\n",
    "\n",
    "store_list_2=pd.read_table(\"/home/jian/BigLots/static_files/MediaStormStoresList_0913.txt\",dtype=str,sep=\"|\")\n",
    "store_list_2=store_list_2[~store_list_2['location_id'].isin(store_list['location_id'].unique().tolist())]\n",
    "store_list_2=store_list_2[store_list_cols]\n",
    "store_list=store_list.append(store_list_2)\n",
    "\n",
    "store_list['zip_cd']=store_list['zip_cd'].apply(lambda x: x.split(\"-\")[0].zfill(5))\n",
    "store_list=store_list.rename(columns={\"location_id\":\"store\"})\n",
    "store_list['store']=store_list['store'].astype(str)\n",
    "store_list=store_list[~store_list['store'].isin([\"145\",\"6990\"])]\n",
    "inclusion_store_list_set=set(store_list['store'].unique().tolist())\n",
    "del store_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_from_SP=pd.read_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/loyalty_sales_data/From_Sp/combinedtransactions_0811.csv\",dtype=str,nrows=samplerows,usecols=['customer_id_hashed','transaction_date','transaction_id','location_id','total_transaction_amt'])\n",
    "\n",
    "sales_from_SP['total_transaction_amt']=sales_from_SP['total_transaction_amt'].astype(float)\n",
    "sales_from_SP=sales_from_SP[sales_from_SP['total_transaction_amt']>0]\n",
    "del sales_from_SP['total_transaction_amt']\n",
    "\n",
    "sales_from_SP=sales_from_SP.drop_duplicates()\n",
    "\n",
    "sales_from_SP=sales_from_SP[['customer_id_hashed','transaction_date','location_id']]\n",
    "\n",
    "\n",
    "sales_from_SP=sales_from_SP[sales_from_SP['location_id'].isin(inclusion_store_list_set)]\n",
    "id_list_sales_set=set(sales_from_SP['customer_id_hashed'].unique().tolist())\n",
    "\n",
    "logging.info(\"Finished read of transaction data from spencer, with rows of \"+str(sales_from_SP.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = '/home/jian/Projects/Big_Lots/Loyal_members/loyalty_register_data/' # usecols=[0,1,5],\n",
    "selected_columns = ['customer_id_hashed', 'email_address_hash','sign_up_location','customer_zip_code']\n",
    "dfiddetail = pd.read_table(folderpath+\"/MediaStormCustTot-hashed-email.txt\",\n",
    "                       header=None,nrows = samplerows,sep = ',',dtype = 'str',usecols=[0,1,4,5])\n",
    "dfiddetail.columns=['customer_id', 'email_address_hash','sign_up_location','customer_zip_code']\n",
    "dfiddetail['customer_id_hashed'] = dfiddetail['customer_id'].apply(lambda x: hashlib.sha256(x.encode('utf-8')).hexdigest())\n",
    "dfiddetail=dfiddetail[selected_columns]\n",
    "dfiddetail=dfiddetail[dfiddetail['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormCustomerTransactionTotals_2018-01-09_2018-03-31.txt',\n",
    "                          nrows = samplerows,sep = ',',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'Existing Reward Member Master as of 2018-06-05.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'New Reward Member Master as of 2018-06-05.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'New Reward Member Master as of 2018-07-03.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180717-132337-377.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180731-130714-098.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail2 = pd.read_csv(folderpath+'MediaStormMasterBiWeekly20180814-130703-491.txt',\n",
    "                          nrows = samplerows,sep = '|',usecols=[0,1,4,5],dtype = 'str')\n",
    "dfiddetail2=dfiddetail2[selected_columns]\n",
    "dfiddetail2['sign_up_location']=dfiddetail2['sign_up_location'].fillna(\"nan\")\n",
    "dfiddetail2=dfiddetail2[dfiddetail2['sign_up_location'].isin(inclusion_store_list_set)]\n",
    "dfiddetail = dfiddetail.append(dfiddetail2)\n",
    "\n",
    "#\n",
    "dfiddetail=dfiddetail[['customer_id_hashed','sign_up_location','customer_zip_code']].drop_duplicates()\n",
    "logging.info(\"Finished read of singing up data, with rows of \"+str(dfiddetail.shape[0]))\n",
    "del dfiddetail2\n",
    "\n",
    "\n",
    "unique_id_master_list_set=set(dfiddetail['customer_id_hashed'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_list_len(x):\n",
    "    y=len(set(x))\n",
    "    return y\n",
    "\n",
    "output_master=dfiddetail.groupby(['sign_up_location'])['customer_id_hashed'].agg(unique_list_len).to_frame().reset_index()\n",
    "\n",
    "# output_master.to_csv(folderpath+\"output/unique_id_signed_up_per_store_\"+str(datetime.datetime.now().date())+\".csv\",index=False)\n",
    "output_master=output_master.sort_values(['sign_up_location'])\n",
    "\n",
    "\n",
    "del dfiddetail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_date=sorted(sales_from_SP['transaction_date'].unique().tolist())\n",
    "purchase_dates_df=pd.DataFrame({\"Date\":transaction_date},index=range(len(transaction_date)))\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "del sales_from_SP['transaction_date']\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Start of 1st task\"+str(datetime.datetime.now()))\n",
    "no_signingup_df=sales_from_SP[~sales_from_SP['customer_id_hashed'].isin(unique_id_master_list_set)]\n",
    "sales_from_SP=sales_from_SP[sales_from_SP['customer_id_hashed'].isin(unique_id_master_list_set)]\n",
    "\n",
    "output1_trans_group=sales_from_SP.groupby(['customer_id_hashed'])['location_id'].count().to_frame().reset_index()\n",
    "logging.info(\"Done of groupby sales_from_SP \"+str(datetime.datetime.now()))\n",
    "rewards_set_1=set(output1_trans_group[output1_trans_group['location_id']==1]['customer_id_hashed'].tolist())\n",
    "logging.info(\"Done of set 1 \"+str(datetime.datetime.now()))\n",
    "rewards_set_2=set(output1_trans_group[output1_trans_group['location_id']==2]['customer_id_hashed'].tolist())\n",
    "rewards_set_3=set(output1_trans_group[output1_trans_group['location_id']==3]['customer_id_hashed'].tolist())\n",
    "rewards_set_4=set(output1_trans_group[output1_trans_group['location_id']==4]['customer_id_hashed'].tolist())\n",
    "rewards_set_5=set(output1_trans_group[output1_trans_group['location_id']==5]['customer_id_hashed'].tolist())\n",
    "rewards_set_6=set(output1_trans_group[output1_trans_group['location_id']==6]['customer_id_hashed'].tolist())\n",
    "rewards_set_7=set(output1_trans_group[output1_trans_group['location_id']==7]['customer_id_hashed'].tolist())\n",
    "rewards_set_8=set(output1_trans_group[output1_trans_group['location_id']==8]['customer_id_hashed'].tolist())\n",
    "rewards_set_9=set(output1_trans_group[output1_trans_group['location_id']==9]['customer_id_hashed'].tolist())\n",
    "rewards_set_10=set(output1_trans_group[output1_trans_group['location_id']==10]['customer_id_hashed'].tolist())\n",
    "rewards_set_10_Plus=set(output1_trans_group[output1_trans_group['location_id']>10]['customer_id_hashed'].tolist())\n",
    "rewards_set_0=set([x for x in unique_id_master_list_set if x not in id_list_sales_set])\n",
    "logging.info(\"Done of set all \"+str(datetime.datetime.now()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output1_trans_group=output1_trans_group.rename(columns={\"location_id\":\"transaction_count\"})\n",
    "output1_trans_group['transaction_count']=np.where(output1_trans_group['transaction_count']>10,\"10+\",output1_trans_group['transaction_count'])\n",
    "output1_trans_group=output1_trans_group.groupby(['transaction_count'])['customer_id_hashed'].agg(unique_list_len).to_frame().reset_index()\n",
    "logging.info(\"Done of groupby unique id\")\n",
    "\n",
    "output1_trans_group=output1_trans_group.rename(columns={\"transaction_count\":\"transaction_group\",\"customer_id_hashed\":\"count_unique_ids\"})\n",
    "output1_trans_group['transaction_group']=output1_trans_group['transaction_group'].astype(str)\n",
    "output1_trans_group=pd.DataFrame({\"transaction_group\":\"0\",\"count_unique_ids\":len(rewards_set_0)},index=[0]).append(output1_trans_group)\n",
    "\n",
    "logging.info(\"Done of 1st task\"+str(datetime.datetime.now()))\n",
    "output1_trans_group=output1_trans_group[['transaction_group','count_unique_ids']]\n",
    "output1_trans_group.to_csv(\"/home/jian/Projects/Big_Lots/Loyal_members/Rewards_Members_Distritbution_Analysis/output1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "# output2_unique_id_by_store=pd.DataFrame({\"store\":list(inclusion_store_list_set)},index=list(inclusion_store_list_set))\n",
    "output2_unique_id_by_store=pd.DataFrame()\n",
    "for location,group in sales_from_SP.groupby(['location_id']):\n",
    "    group_trans_freq=group.groupby(['customer_id_hashed'])['location_id'].count().to_frame().reset_index()\n",
    "    group_trans_freq=group_trans_freq.rename(columns={\"location_id\":\"trans_group\"})\n",
    "    group_trans_freq['trans_group']=np.where(group_trans_freq['trans_group']>10,\"10+\",group_trans_freq['trans_group'])\n",
    "    group_trans_freq['trans_group']=group_trans_freq['trans_group'].astype(str)\n",
    "    df_1_store_output=group_trans_freq.groupby(['trans_group'])['customer_id_hashed'].count().to_frame().reset_index()\n",
    "    df_1_store_output['trans_group']=df_1_store_output['trans_group'].apply(lambda x: \"unique_id_counts_tranced_\"+x)\n",
    "    dict_df_1_store=df_1_store_output.set_index(['trans_group']).to_dict()['customer_id_hashed']\n",
    "    df_1_store_output=pd.DataFrame(dict_df_1_store,index=[location]).reset_index()\n",
    "    output2_unique_id_by_store=output2_unique_id_by_store.append(df_1_store_output)\n",
    "output2_unique_id_by_store=output2_unique_id_by_store.rename(columns={\"index\":\"location_id\"})\n",
    "cols_list=['location_id']+[\"unique_id_counts_tranced_\"+str(i+1) for i in range(10)]+['unique_id_counts_tranced_10+']\n",
    "output2_unique_id_by_store=output2_unique_id_by_store[cols_list]\n",
    "output2_unique_id_by_store['location_id']=output2_unique_id_by_store['location_id'].astype(int)\n",
    "output2_unique_id_by_store=output2_unique_id_by_store.sort_values(['location_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Start of taks3 \"+str(datetime.datetime.now()))\n",
    "def id_set(x):\n",
    "    y=set(x)\n",
    "    return y\n",
    "output3_unique_id_by_store=sales_from_SP.groupby(['customer_id_hashed'])['location_id'].agg(unique_list_len).to_frame().reset_index()\n",
    "output3_unique_id_by_store['location_id']=np.where(output3_unique_id_by_store['location_id']>10,\"10+\",output3_unique_id_by_store['location_id'])\n",
    "output3_unique_id_by_store['location_id']=output3_unique_id_by_store['location_id'].astype(str)\n",
    "\n",
    "output3_unique_id_by_store=output3_unique_id_by_store.groupby(['location_id'])['customer_id_hashed'].agg(id_set).to_frame().reset_index()\n",
    "output3_unique_id_by_store=output3_unique_id_by_store.rename(columns={\"location_id\":\"went_uniq_store_group\",\"customer_id_hashed\":\"id_list\"})\n",
    "output3_unique_id_by_store['ID_counts']=output3_unique_id_by_store['id_list'].apply(lambda x: len(x))\n",
    "\n",
    "transaction_id=pd.DataFrame()\n",
    "for i in range(len(output3_unique_id_by_store)):\n",
    "    store_group=output3_unique_id_by_store['went_uniq_store_group'][i]\n",
    "    id_set=output3_unique_id_by_store['id_list'][i]\n",
    "    len_trans=len(sales_from_SP[sales_from_SP['customer_id_hashed'].isin(id_set)])\n",
    "    df=pd.DataFrame({\"went_uniq_store_group\":store_group,\"trnasactions_count\":len_trans},index=[0])\n",
    "    transaction_id=transaction_id.append(df)\n",
    "    \n",
    "del output3_unique_id_by_store['id_list']\n",
    "\n",
    "output3_unique_id_by_store=pd.merge(output3_unique_id_by_store,transaction_id,on=\"went_uniq_store_group\",how=\"left\")\n",
    "logging.info(\"Done of taks3 \"+str(datetime.datetime.now()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id_counts_tranced_1</th>\n",
       "      <th>unique_id_counts_tranced_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id_counts_tranced_1  unique_id_counts_tranced_2\n",
       "1                           1                           2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumption_output=sales_from_SP.groupby(['location_id'])['customer_id_hashed'].agg(unique_list_len).to_frame().reset_index()\n",
    "consumption_output=consumption_output.sort_values(['location_id'])\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "output_master=output_master.rename(columns={\"sign_up_location\":\"store\",\"customer_id_hashed\":\"signup_id count\"})\n",
    "consumption_output=consumption_output.rename(columns={\"location_id\":\"store\",\"customer_id_hashed\":\"consumption_id count\"})\n",
    "Merge_by_store=pd.merge(output_master,consumption_output,on=\"store\",how=\"left\")\n",
    "Merge_by_store['store']=Merge_by_store['store'].astype(int)\n",
    "Merge_by_store=Merge_by_store.sort_values('store')\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "DMA=pd.read_excel(\"/home/jian/Docs/Geo_mapping/Zips by DMA by County16-17 nielsen.xlsx\",dtype=str,skiprows=1,usecols=[0,2])\n",
    "DMA.columns=['zip_cd','DMA']\n",
    "DMA=DMA.drop_duplicates(\"zip_cd\")\n",
    "store_list['store']=store_list['store'].astype(int)\n",
    "Merge_by_store=pd.merge(Merge_by_store,store_list,on=\"store\",how=\"outer\")\n",
    "Merge_by_store=pd.merge(Merge_by_store,DMA,on=\"zip_cd\",how=\"left\")\n",
    "Merge_by_store=Merge_by_store[['store','address_line_1','address_line_2','city_nm','state_nm','zip_cd','DMA','signup_id count','consumption_id count']]\n",
    "\n",
    "\n",
    "# # Write to Excel\n",
    "\n",
    "# In[16]:\n",
    "no_signingup_df_purchase=no_signingup_df.groupby(['location_id'])['customer_id_hashed'].count().to_frame().reset_index()\n",
    "no_signingup_df_purchase=no_signingup_df_purchase.rename(columns={\"customer_id_hashed\":\"transactions\"})\n",
    "\n",
    "\n",
    "outputfolder=\"/home/jian/Projects/Big_Lots/Loyal_members/Rewards_Members_Distritbution_Analysis/output/\"\n",
    "writer=pd.ExcelWriter(outputfolder+\"BL_unique_id_by_store_\"+str(datetime.datetime.now().date())+\".xlsx\",engine='xlsxwriter')\n",
    "output1_trans_group.to_excel(writer,\"output1_trans_group\",index=False)\n",
    "output2_unique_id_by_store.to_excel(writer,\"output2_unique_id_by_store\",index=False)\n",
    "output3_unique_id_by_store.to_excel(writer,\"output3_id_transactions\",index=False)\n",
    "Merge_by_store.to_excel(writer,\"distribution_table\",index=False)\n",
    "output_master.to_excel(writer,\"register_id_by_location\",index=False)\n",
    "consumption_output.to_excel(writer,\"purchase_id_by_location\",index=False)\n",
    "purchase_dates_df.to_excel(writer,\"purchase_date_range\",index=False)\n",
    "no_signingup_df_purchase.to_excel(writer,\"no_signingup_purchase\",index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
