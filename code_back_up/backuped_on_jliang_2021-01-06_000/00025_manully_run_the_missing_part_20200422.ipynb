{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thismonday 2020-04-20\n",
      "Good to load\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import gc\n",
    "import logging\n",
    "import sqlalchemy\n",
    "import glob\n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )\n",
    "\n",
    "logging.basicConfig(filename=\"/home/jian/BL_weekly_crontab/cron_2_Google_Bing_LR/log_BL_Weekly_Google_and_Bing_LR_uploading.log\", level=logging.INFO)\n",
    "logging.info(\"Started: \"+str(datetime.datetime.now()))\n",
    "def recursive_file_gen(my_root_dir):\n",
    "    for root, dirs, files in os.walk(my_root_dir):\n",
    "        for file in files:\n",
    "            yield os.path.join(root, file)\n",
    "\n",
    "thismonday=datetime.datetime.now().date()-datetime.timedelta(days=datetime.datetime.now().date().weekday())\n",
    "# thismonday=datetime.date(2019,3,25)\n",
    "print(\"thismonday\", thismonday)\n",
    "logging.info(\"thismonday: \"+str(thismonday))\n",
    "\n",
    "last_week_end_saturday=thismonday-datetime.timedelta(days=2)\n",
    "\n",
    "writer_pather=\"/home/jian/celery/Bing_LiveRamp/output/\"\n",
    "\n",
    "posibble_recent_folder=\"/home/jian/BigLots/2020_by_weeks/MediaStorm_\"+str(last_week_end_saturday)+\"/\"\n",
    "daily_files_recent=[x for x in list(recursive_file_gen(posibble_recent_folder)) if \"Daily\" in x]\n",
    "\n",
    "if len(daily_files_recent)==1:\n",
    "    daily_file_last_week=daily_files_recent[0]\n",
    "    print(\"Good to load\")\n",
    "    logging.info(str(datetime.datetime.now())+\": Good to load\")\n",
    "else:\n",
    "    daily_file_last_week=np.nan\n",
    "    print(str(datetime.datetime.now())+\": Last week daily data not avaiable\")\n",
    "    logging.info(str(datetime.datetime.now())+\": Last week daily data not avaiable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/BigLots/2020_by_weeks/MediaStorm_2020-04-18/MediaStormDailySales20200421-111910-356.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_file_last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last weekly file not only 1\n",
      "1% store sales variances: 5\n",
      "4% store trans variances: 3\n"
     ]
    }
   ],
   "source": [
    "df_daily_sales_last_week=pd.read_table(daily_file_last_week,sep=\"|\",dtype=str)\n",
    "df_daily_sales_last_week=df_daily_sales_last_week[df_daily_sales_last_week['location_id']!=\"6990\"]\n",
    "df_daily_sales_last_week['item_transaction_amt']=df_daily_sales_last_week['item_transaction_amt'].astype(float)\n",
    "qc_weekly_sales=df_daily_sales_last_week.groupby(['location_id'])['item_transaction_amt'].sum().to_frame().reset_index().rename(columns={\"item_transaction_amt\":\"sales_from_Daily\"})\n",
    "qc_weekly_trans=df_daily_sales_last_week[['location_id','transaction_dt','transaction_id','customer_id_hashed']].drop_duplicates()\n",
    "qc_weekly_trans=qc_weekly_trans.groupby(['location_id'])['transaction_id'].count().to_frame().reset_index().rename(columns={\"transaction_id\":\"trans_from_Daily\"})\n",
    "df_daily_sales_last_week=pd.merge(qc_weekly_sales,qc_weekly_trans,on=\"location_id\",how=\"outer\")\n",
    "\n",
    "weekly_data_path=glob.glob(\"/home/jian/BigLots/MediaStorm_\"+str(last_week_end_saturday)+\"/*\")\n",
    "weekly_data_path=[x for x in weekly_data_path if \"SalesWeekly\" in x]\n",
    "if len(weekly_data_path)!=1:\n",
    "\tprint(\"Last weekly file not only 1\")\n",
    "\tlogging.info(\"Last weekly file not only 1\")\n",
    "\n",
    "else :\n",
    "\tprint(\"Last weekly file good as 1\")\n",
    "\tlogging.info(\"Last weekly file good as 1\")\n",
    "\n",
    "\n",
    "weekly_data_path=glob.glob(\"/home/jian/BigLots/2020_by_weeks/MediaStorm_\"+str(last_week_end_saturday)+\"/*\")\n",
    "weekly_data_path=[x for x in weekly_data_path if \"SalesWeekly\" in x]\n",
    "if len(weekly_data_path)==0:    \n",
    "    weekly_data_path=glob.glob(\"/home/jian/BigLots/MediaStorm_\"+str(last_week_end_saturday)+\"/*\")\n",
    "    weekly_data_path=[x for x in weekly_data_path if \"SalesWeekly\" in x]\n",
    "\n",
    "if len(weekly_data_path)==1:\n",
    "    weekly_data_path=weekly_data_path[0]\n",
    "\n",
    "else:\n",
    "    print(\"Checking the new weekly data\")\n",
    "\n",
    "\n",
    "Weekly_Data=pd.read_table(weekly_data_path,dtype=str,sep=\"|\",usecols=[\"location_id\",'week_end_dt','gross_sales_amt','gross_transaction_cnt'])\n",
    "Weekly_Data=Weekly_Data[Weekly_Data['location_id']!=\"6990\"]\n",
    "Weekly_Data=Weekly_Data.drop_duplicates()\n",
    "Weekly_Data['gross_sales_amt']=Weekly_Data['gross_sales_amt'].astype(float)\n",
    "Weekly_Data['gross_transaction_cnt']=Weekly_Data['gross_transaction_cnt'].astype(int)\n",
    "\n",
    "\n",
    "QC_df=pd.merge(Weekly_Data,df_daily_sales_last_week,on=\"location_id\",how=\"outer\")\n",
    "\n",
    "\n",
    "QC_df['Sales_Diff']=(QC_df['gross_sales_amt']-QC_df['sales_from_Daily'])/QC_df['sales_from_Daily']\n",
    "QC_df['Trans_Diff']=(QC_df['gross_transaction_cnt']-QC_df['trans_from_Daily'])/QC_df['gross_transaction_cnt']\n",
    "\n",
    "print(\"1% store sales variances: \"+str(QC_df[(QC_df['Sales_Diff'].apply(lambda x: np.abs(x)>0.01))].shape[0]))\n",
    "print(\"4% store trans variances: \"+str(QC_df[(QC_df['Trans_Diff'].apply(lambda x: np.abs(x)>0.04))].shape[0]))\n",
    "logging.info(\"1% store sales variances: \"+str(QC_df[(QC_df['Sales_Diff'].apply(lambda x: np.abs(x)>0.01))].shape[0]))\n",
    "logging.info(\"4% store trans variances: \"+str(QC_df[(QC_df['Trans_Diff'].apply(lambda x: np.abs(x)>0.04))].shape[0]))\n",
    "\n",
    "# Above is the QC df, below is the update df\n",
    "\n",
    "\n",
    "sales_daily_lastweek=pd.read_table(daily_file_last_week,sep=\"|\",dtype=str,usecols=['location_id','customer_id_hashed','transaction_dt','item_transaction_amt'])\n",
    "sales_daily_lastweek=sales_daily_lastweek[~pd.isnull(sales_daily_lastweek['customer_id_hashed'])]\n",
    "sales_daily_lastweek=sales_daily_lastweek[sales_daily_lastweek['location_id']!=\"6990\"]\n",
    "sales_daily_lastweek['item_transaction_amt']=sales_daily_lastweek['item_transaction_amt'].astype(float)\n",
    "sales_daily_lastweek_agg=sales_daily_lastweek.groupby(['customer_id_hashed','transaction_dt'])['item_transaction_amt'].sum().to_frame().reset_index()\n",
    "sales_daily_lastweek_agg=sales_daily_lastweek_agg.rename(columns={\"transaction_dt\":\"Timestamp\",\"item_transaction_amt\":\"Conversion_Amount\"})\n",
    "sales_daily_lastweek_agg['Timestamp']=sales_daily_lastweek_agg['Timestamp'].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").date())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86097624.98999998"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_daily_lastweek['item_transaction_amt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217445, 4)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# all_master_file=pd.read_sql(\"select customer_id_hashed, email_address_hash, customer_zip_code from BL_Rewards_Master;\",con=BL_engine)\n",
    "new_master_file=pd.read_sql(\"select customer_id_hashed, email_address_hash, customer_zip_code,sign_up_date from BL_Rewards_Master where sign_up_date>='2020-04-12';\",con=BL_engine)\n",
    "print(new_master_file.shape)\n",
    "print(new_master_file['sign_up_date'].nunique())\n",
    "del new_master_file['sign_up_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217445, 3)\n",
      "217439\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# all_master_file=pd.read_sql(\"select customer_id_hashed, email_address_hash, customer_zip_code from BL_Rewards_Master;\",con=BL_engine)\n",
    "\n",
    "print(new_master_file.shape)\n",
    "print(len(new_master_file['customer_id_hashed'].unique()))\n",
    "logging.info(\"new_master_file.shape: \"+str(new_master_file.shape))\n",
    "logging.info(\"len(new_master_file['customer_id_hashed'].unique()): \"+str(len(new_master_file['customer_id_hashed'].unique())))\n",
    "\n",
    "new_master_file=new_master_file.drop_duplicates('customer_id_hashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Email rows excluded: 1156902\n",
      "1.063780683238511\n"
     ]
    }
   ],
   "source": [
    "sales_daily_lastweek_agg=pd.merge(sales_daily_lastweek_agg,new_master_file,on=\"customer_id_hashed\",how=\"left\").rename(columns={\"email_address_hash\":\"Email_1\",\"customer_zip_code\":\"Zip\"})\n",
    "\n",
    "print(\"Null Email rows excluded: \"+str(sales_daily_lastweek_agg[pd.isnull(sales_daily_lastweek_agg['Email_1'])].shape[0]))\n",
    "print(sales_daily_lastweek_agg.shape[0]/sales_daily_lastweek_agg[pd.isnull(sales_daily_lastweek_agg['Email_1'])].shape[0])\n",
    "\n",
    "logging.info(\"Null Email rows excluded: \"+str(sales_daily_lastweek_agg[pd.isnull(sales_daily_lastweek_agg['Email_1'])].shape[0]))\n",
    "logging.info(str(sales_daily_lastweek_agg.shape[0]/sales_daily_lastweek_agg[pd.isnull(sales_daily_lastweek_agg['Email_1'])].shape[0]))\n",
    "\n",
    "sales_daily_lastweek_agg=sales_daily_lastweek_agg[~pd.isnull(sales_daily_lastweek_agg['Email_1'])]\n",
    "del sales_daily_lastweek_agg['customer_id_hashed']\n",
    "\n",
    "sales_daily_lastweek_agg=sales_daily_lastweek_agg[[\"Email_1\",\"Zip\",\"Timestamp\", \"Conversion_Amount\"]]\n",
    "sales_daily_lastweek_agg['Conversion_Amount']=sales_daily_lastweek_agg['Conversion_Amount'].apply(lambda x: np.round(x,2)).astype(str)\n",
    "sales_daily_lastweek_agg['Conversion_Amount']=sales_daily_lastweek_agg['Conversion_Amount'].apply(lambda x: x.split(\".\")[0]+\".\"+x.split(\".\")[1].ljust(2,\"0\"))\n",
    "sales_daily_lastweek_agg['Product_Group']=\"In_Store\"\n",
    "\n",
    "sales_daily_lastweek_agg['Zip']=\"00000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2020, 4, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_max_date=sales_daily_lastweek_agg['Timestamp'].max()\n",
    "data_max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2020, 4, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_min_date=sales_daily_lastweek_agg['Timestamp'].min()\n",
    "data_min_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_pather=\"/home/jian/celery/Bing_LiveRamp/output/\"\n",
    "\n",
    "local_path=writer_pather+\"/BL_LR_BingStoreSalesSupplement_\"+str(data_min_date)+\"_\"+str(data_max_date)+\"_JL_\"+str(datetime.datetime.now().date())+\".txt\"\n",
    "\n",
    "sales_daily_lastweek_agg.to_csv(local_path,index=False,sep=\"|\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10909764.190000001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_daily_lastweek_agg['Conversion_Amount'].astype(float).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69400333.40000004"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"/home/jian/celery/Bing_LiveRamp/output/BL_LR_BingStoreSales_2020-04-13_2020-04-18_JL_2020-04-21.txt\",sep=\"|\")\n",
    "df['Conversion_Amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80310097.59000003"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10909764.190000001+69400333.40000004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jian/celery/Bing_LiveRamp/output//BL_LR_BingStoreSalesSupplement_2020-04-13_2020-04-18_JL_2020-04-23.txt'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "\n",
    "host = \"files.liveramp.com\" #hard-coded\n",
    "port = 22\n",
    "transport = paramiko.Transport((host, port))\n",
    "\n",
    "password = \"Jubaplus2019!\" #hard-coded\n",
    "username = \"bing-big-lots\" #hard-coded\n",
    "transport.connect(username = username, password = password)\n",
    "sftp = paramiko.SFTPClient.from_transport(transport)\n",
    "\n",
    "# local_path defined above before saving the local txt\n",
    "remote_path=\"/uploads/\"+os.path.basename(local_path)\n",
    "sftp.put(local_path,remote_path)\n",
    "sftp.close()\n",
    "transport.close()\n",
    "\n",
    "\n",
    "logging.info(\"Done of Bing: \"+str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google below from the output of Bing\n",
    "df_google=sales_daily_lastweek_agg.rename(columns={\"Zip\":\"Zip_Code\",\n",
    "  \"Timestamp\":\"transaction_timestamp\",\n",
    "  \"Product_Group\":\"transaction_category\",\n",
    "  \"Conversion_Amount\":\"transaction_amount\"})\n",
    "\n",
    "df_google=df_google[['Zip_Code','Email_1','transaction_category','transaction_timestamp','transaction_amount']]\n",
    "\n",
    "local_path_google=\"/home/jian/celery/Google_LiveRamp/output/BL_LR_GoogleStoreSalesSupplement__\"+str(data_min_date)+\"_\"+str(data_max_date)+\"_JL_\"+str(datetime.datetime.now().date())+\".txt\"\n",
    "df_google.to_csv(local_path_google,index=False,sep=\"|\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "\n",
    "host = \"files.liveramp.com\" #hard-coded\n",
    "port = 22\n",
    "transport = paramiko.Transport((host, port))\n",
    "\n",
    "password = \"Jubaplus2019!\" #hard-coded\n",
    "username = \"big-lots-ga-aw\" #hard-coded\n",
    "transport.connect(username = username, password = password)\n",
    "sftp = paramiko.SFTPClient.from_transport(transport)\n",
    "\n",
    "remote_path=\"/uploads/\"+os.path.basename(local_path_google)\n",
    "sftp.put(local_path_google,remote_path)\n",
    "sftp.close()\n",
    "transport.close()\n",
    "logging.info(\"Done of Google: \"+str(datetime.datetime.now()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "message = \"\"\"From: Juba <jubapluscc@gmail.com>\n",
    "To: Jian <jian@jubaplus.com>, Mike Mahler <mmahler@mediastorm.biz>, Maggie Chiu <mchiu@mediastorm.biz>, Naja Aldefri <naldefri@mediastorm.biz>, Daniela Balboni <dbalboni@mediastorm.biz>, Zhenya Brisker <zbrisker@mediastorm.biz>, John Thomas <jthomas@mediastorm.biz>, Simeng Sun <ssun@mediastorm.biz>, Mohammed Uddin <muddin@mediastorm.biz>\n",
    "MIME-Version: 1.0\n",
    "Content-type: text\n",
    "Subject: Big Lots Rewards Sales in Store uploaded to LiveRamp \n",
    "\n",
    "Hi Mike,\n",
    "\n",
    "The last week Big Lots Rewards Sales in Store uploaded to LiveRamp Bing & Google.\n",
    "\n",
    "Thanks,\n",
    "Jian\n",
    "\"\"\"\n",
    "smtpObj = smtplib.SMTP('smtp.gmail.com',587)\n",
    "smtpObj.ehlo()\n",
    "smtpObj.starttls()\n",
    "smtpObj.login('jubapluscc@gmail.com','mfppxsfikqmazbqj')\n",
    "\n",
    "\n",
    "sender=\"jubapluscc@gmail.com\"\n",
    "receivers=['jian@jubaplus.com','mmahler@mediastorm.biz','mchiu@mediastorm.biz', 'naldefri@mediastorm.biz', 'dbalboni@mediastorm.biz', 'zbrisker@mediastorm.biz', 'jthomas@mediastorm.biz', 'ssun@mediastorm.biz', 'muddin@mediastorm.biz','GAbouJaoude@mediastorm.biz']\n",
    "try:\n",
    "    smtpObj.sendmail(sender, receivers, message)         \n",
    "    print(\"Successfully sent email\")\n",
    "    logging.info(\"Successfully sent email\")\n",
    "except:\n",
    "    print(\"Error: unable to send email\")\n",
    "    logging.info(\"Error: unable to send email\")\n",
    "print(\"done celery: \"+ str(datetime.datetime.now()))\n",
    "logging.info(\"done celery: \"+ str(datetime.datetime.now()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
