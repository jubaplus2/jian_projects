{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2 -- POS by department\n",
    "# All id, trans since 2018-02-04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-10 17:45:58.994176\n",
      "/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building\n"
     ]
    }
   ],
   "source": [
    "# ID Level spec from Yoram, modified on 20191115\n",
    "# Email 20191115 6:30 p.m.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import paramiko\n",
    "import sqlalchemy\n",
    "import logging\n",
    "import glob\n",
    "import gc\n",
    "logging.basicConfig(filename='/home/jian/Projects/Big_Lots/Analysis/2019_Q4/Predictive_Model_Building/predictive_dataset_building_T2_POS_by_id_department.log',level=\"INFO\")\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "print(os.getcwd())\n",
    "\n",
    "logging.info(\"start now: \"+str(datetime.datetime.now()))\n",
    "# IDs to include since 2018Q1\n",
    "\n",
    "BL_SQL_CONNECTION= 'mysql+pymysql://jian:JubaPlus-2017@localhost/BigLots' \n",
    "BL_engine = sqlalchemy.create_engine(\n",
    "        BL_SQL_CONNECTION, \n",
    "        pool_recycle=1800\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pymysql/cursors.py:166: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tables_in_BigLots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BL_POS_Item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BL_POS_Subclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BL_Rewards_Master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pred_CRM_table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pred_POS_Department</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tables_in_BigLots\n",
       "0          BL_POS_Item\n",
       "1      BL_POS_Subclass\n",
       "2    BL_Rewards_Master\n",
       "3       Pred_CRM_table\n",
       "4  Pred_POS_Department"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"show tables;\",con=BL_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field</th>\n",
       "      <th>Type</th>\n",
       "      <th>Null</th>\n",
       "      <th>Key</th>\n",
       "      <th>Default</th>\n",
       "      <th>Extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customer_id_hashed</td>\n",
       "      <td>varchar(64)</td>\n",
       "      <td>YES</td>\n",
       "      <td>MUL</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>email_address_hash</td>\n",
       "      <td>varchar(64)</td>\n",
       "      <td>YES</td>\n",
       "      <td>MUL</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sign_up_date</td>\n",
       "      <td>date</td>\n",
       "      <td>YES</td>\n",
       "      <td>MUL</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sign_up_channel</td>\n",
       "      <td>varchar(64)</td>\n",
       "      <td>YES</td>\n",
       "      <td>MUL</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sign_up_location</td>\n",
       "      <td>int(11)</td>\n",
       "      <td>YES</td>\n",
       "      <td>MUL</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>customer_zip_code</td>\n",
       "      <td>varchar(16)</td>\n",
       "      <td>YES</td>\n",
       "      <td>MUL</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>transaction_count</td>\n",
       "      <td>int(11)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>transaction_amount</td>\n",
       "      <td>decimal(10,2)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>experian_multi_cluster</td>\n",
       "      <td>varchar(32)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>experian_demo_cluster</td>\n",
       "      <td>varchar(32)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>purchase_channel</td>\n",
       "      <td>varchar(32)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>email_unsubscribe_indicator</td>\n",
       "      <td>varchar(2)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>email_undeliverable_indicator</td>\n",
       "      <td>varchar(2)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>file_path</td>\n",
       "      <td>varchar(256)</td>\n",
       "      <td>YES</td>\n",
       "      <td>MUL</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Field           Type Null  Key Default Extra\n",
       "0              customer_id_hashed    varchar(64)  YES  MUL    None      \n",
       "1              email_address_hash    varchar(64)  YES  MUL    None      \n",
       "2                    sign_up_date           date  YES  MUL    None      \n",
       "3                 sign_up_channel    varchar(64)  YES  MUL    None      \n",
       "4                sign_up_location        int(11)  YES  MUL    None      \n",
       "5               customer_zip_code    varchar(16)  YES  MUL    None      \n",
       "6               transaction_count        int(11)  YES         None      \n",
       "7              transaction_amount  decimal(10,2)  YES         None      \n",
       "8          experian_multi_cluster    varchar(32)  YES         None      \n",
       "9           experian_demo_cluster    varchar(32)  YES         None      \n",
       "10               purchase_channel    varchar(32)  YES         None      \n",
       "11    email_unsubscribe_indicator     varchar(2)  YES         None      \n",
       "12  email_undeliverable_indicator     varchar(2)  YES         None      \n",
       "13                      file_path   varchar(256)  YES  MUL    None      "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"desc BL_Rewards_Master;\",con=BL_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Product Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/drv5/biglots_data/Monthly_Taxonomy/MediaStormProductTaxonomy20200101-135600-916.txt\n"
     ]
    }
   ],
   "source": [
    "# Use last one\n",
    "host = \"64.237.51.251\" #hard-coded\n",
    "port = 22\n",
    "transport = paramiko.Transport((host, port))\n",
    "\n",
    "password = \"bwRi3V6fgZsfJrMl\" #hard-coded\n",
    "username = \"client\" #hard-coded\n",
    "transport.connect(username = username, password = password)\n",
    "sftp = paramiko.SFTPClient.from_transport(transport)\n",
    "# list_taxonomy=[]\n",
    "part_1=sftp.listdir(\"/mnt/drv5/biglots_data/\")\n",
    "part_1=[\"/mnt/drv5/biglots_data/\"+x for x in part_1 if \"ProductTaxonomy\" in x]\n",
    "\n",
    "part_2=sftp.listdir(\"/mnt/drv5/biglots_data/Monthly_Taxonomy/\")\n",
    "part_2=[\"/mnt/drv5/biglots_data/Monthly_Taxonomy/\"+x for x in part_2 if \"ProductTaxonomy\" in x]\n",
    "list_taxonomy=part_1+part_2\n",
    "\n",
    "\n",
    "last_prod_taxonomy=sorted(list_taxonomy,key=lambda x: x.split(\"/MediaStormProductTaxonomy\")[1][:8])[-1]\n",
    "print(last_prod_taxonomy)\n",
    "logging.info(\"last_prod_taxonomy: \"+str(last_prod_taxonomy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_prod_taxo=\"/home/jian/BigLots/static_files/ProductTaxonomy/\"+os.path.basename(last_prod_taxonomy)\n",
    "\n",
    "if not os.path.exists(local_prod_taxo):\n",
    "    \n",
    "    sftp.get(last_prod_taxonomy,local_prod_taxo)\n",
    "sftp.close()\n",
    "transport.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_taxo=pd.read_csv(local_prod_taxo,dtype=str,sep=\"|\")\n",
    "df_prod_taxo_dep=df_prod_taxo[['department_id','class_code_id','subclass_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department_id</th>\n",
       "      <th>class_code_id</th>\n",
       "      <th>subclass_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>11001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>11001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>11001</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>11001</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>11001</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>710</td>\n",
       "      <td>71010</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>710</td>\n",
       "      <td>71010</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>710</td>\n",
       "      <td>71010</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>710</td>\n",
       "      <td>71020</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>710</td>\n",
       "      <td>71099</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2875 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     department_id class_code_id subclass_id\n",
       "0              108         11001           2\n",
       "1              108         11001           4\n",
       "2              108         11001           6\n",
       "3              108         11001           8\n",
       "4              108         11001          10\n",
       "...            ...           ...         ...\n",
       "2870           710         71010         752\n",
       "2871           710         71010         801\n",
       "2872           710         71010         998\n",
       "2873           710         71020         999\n",
       "2874           710         71099         999\n",
       "\n",
       "[2875 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prod_taxo_dep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS_data_from_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_file_gen(root_path):\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            yield os.path.join(root,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jian/BigLots/hist_daily_data_subclasslevel/MediaStormDailySales_week_ending_2018-02-10.txt\n",
      "/home/jian/BigLots/hist_daily_data_subclasslevel/MediaStormDailySales_week_ending_2018-06-09.txt\n"
     ]
    }
   ],
   "source": [
    "# Read from each file\n",
    "\n",
    "list_file_subclass=glob.glob(\"/home/jian/BigLots/hist_daily_data_subclasslevel/*.txt\")\n",
    "list_file_subclass=[x for x in list_file_subclass if x.split(\"_ending_\")[1][:10]>=\"2018-02-04\"]\n",
    "list_file_subclass.sort()\n",
    "print(list_file_subclass[0])\n",
    "print(list_file_subclass[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-06-16/MediaStormDailySales.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-06-23/MediaStormDailySales.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-06-30/MediaStormDailySales.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-07-07/MediaStormDailySales.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-07-14/MediaStormDailySales20180717-113630-767.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-07-21/MediaStormDailySales20180724-113327-741.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-07-28/MediaStormDailySales20180731-111804-489.txt',\n",
       " '/home/jian/BigLots/2018_by_weeks/MediaStorm_2018-08-04/MediaStormDailySales20180807-111637-702.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_file_subclass_weekly=list(recursive_file_gen(\"/home/jian/BigLots/2018_by_weeks/\"))\n",
    "list_file_subclass_weekly=[x for x in list_file_subclass_weekly if \"dailysales\" in x.lower()]\n",
    "list_file_subclass_weekly=[x for x in list_file_subclass_weekly if x[-4:]==\".txt\"]\n",
    "list_file_subclass_weekly=[x for x in list_file_subclass_weekly if x.split(\"s/MediaStorm_\")[1][:10]<=\"2018-08-04\"]\n",
    "list_file_subclass_weekly.sort()\n",
    "list_file_subclass_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/MediaStormDailySalesHistory20180811.txt\n",
      "/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/MediaStormDailySalesHistory20190209.txt\n"
     ]
    }
   ],
   "source": [
    "list_file_item=glob.glob(\"/home/jian/BigLots/hist_daily_data_itemlevel_decompressed/*.txt\")\n",
    "list_file_item.sort()\n",
    "print(list_file_item[0])\n",
    "print(list_file_item[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jian/BigLots/2019_by_weeks/MediaStorm_2019-02-16/MediaStormDailySales20190219-113605-481.txt\n",
      "/home/jian/BigLots/2019_by_weeks/MediaStorm_2019-12-28/MediaStormDailySales20191231-112945-515.txt\n"
     ]
    }
   ],
   "source": [
    "list_file_item_weekly=list(recursive_file_gen(\"/home/jian/BigLots/2019_by_weeks/\"))\n",
    "list_file_item_weekly=[x for x in list_file_item_weekly if \"dailysales\" in x.lower()]\n",
    "list_file_item_weekly=[x for x in list_file_item_weekly if x[-4:]==\".txt\"]\n",
    "list_file_item_weekly=[x for x in list_file_item_weekly if x.split(\"/MediaStorm_\")[1][:10]>=\"2019-02-16\"]\n",
    "list_file_item_weekly.sort()\n",
    "print(list_file_item_weekly[0])\n",
    "print(list_file_item_weekly[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "list_all_weekly_data=list_file_subclass+list_file_subclass_weekly+list_file_item+list_file_item_weekly\n",
    "print(len(list_all_weekly_data))\n",
    "\n",
    "logging.info(\"len(list_all_weekly_data): \"+str(len(list_all_weekly_data)))\n",
    "logging.info(\"list_all_weekly_data[0]: \"+str(list_all_weekly_data[0]))\n",
    "logging.info(\"list_all_weekly_data[-1]: \"+str(list_all_weekly_data[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:An empty TABLE Pred_POS_Department has been created. 2020-01-10 17:46:01.605346\n"
     ]
    }
   ],
   "source": [
    "import pymysql.cursors\n",
    "engine_pymysql_db_BL = pymysql.connect(host='localhost',user='jian',\n",
    "                         password='JubaPlus-2017',db='BigLots',\n",
    "                         charset='utf8mb4',cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "def create_BL_Pred_POS_department_table():\n",
    "    with engine_pymysql_db_BL.cursor() as cur:\n",
    "        cur.execute(\"DROP TABLE IF EXISTS Pred_POS_Department\")\n",
    "        cur.execute(\"CREATE TABLE Pred_POS_Department \\\n",
    "        (\\\n",
    "        location_id int, \\\n",
    "        transaction_dt Date, \\\n",
    "        transaction_id varchar(16), \\\n",
    "        customer_id_hashed char(64), \\\n",
    "        department_id varchar(16), \\\n",
    "        sales decimal(10,2), \\\n",
    "        units int, \\\n",
    "        trans_order_since_18Q1 int \\\n",
    "        );\"\n",
    "                   )\n",
    "    print(\"1:An empty TABLE Pred_POS_Department has been created.\",datetime.datetime.now())\n",
    "    logging.info(\"1:An empty TABLE Pred_POS_Department has been created.\"+str(datetime.datetime.now()))\n",
    " \n",
    " \n",
    "create_BL_Pred_POS_department_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-04 2018-02-10 2020-01-10 17:47:59.462549\n",
      "done of file:  1 /home/jian/BigLots/hist_daily_data_subclasslevel/MediaStormDailySales_week_ending_2018-02-10.txt\n",
      "2018-02-11 2018-02-17 2020-01-10 17:55:18.065220\n",
      "done of file:  2 /home/jian/BigLots/hist_daily_data_subclasslevel/MediaStormDailySales_week_ending_2018-02-17.txt\n",
      "2018-02-18 2018-02-24 2020-01-10 18:03:27.005440\n",
      "done of file:  3 /home/jian/BigLots/hist_daily_data_subclasslevel/MediaStormDailySales_week_ending_2018-02-24.txt\n",
      "2018-02-25 2018-03-03 2020-01-10 18:12:13.851682\n",
      "done of file:  4 /home/jian/BigLots/hist_daily_data_subclasslevel/MediaStormDailySales_week_ending_2018-03-03.txt\n",
      "2018-03-04 2018-03-10 2020-01-10 18:21:26.176368\n",
      "done of file:  5 /home/jian/BigLots/hist_daily_data_subclasslevel/MediaStormDailySales_week_ending_2018-03-10.txt\n"
     ]
    }
   ],
   "source": [
    "list_df_by_week_day_summary=[]\n",
    "total_sales=0\n",
    "i_counter=0\n",
    "\n",
    "df_id_order_count=pd.DataFrame(columns=['customer_id_hashed','trans_order_since_18Q1'])\n",
    "\n",
    "for file in list_all_weekly_data:\n",
    "    df=pd.read_csv(file,dtype=str,nrows=None,sep=\"|\")\n",
    "    df=df.rename(columns={\"subclass_transaction_amt\":\"sales\"})\n",
    "    df=df.rename(columns={\"item_transaction_amt\":\"sales\"})\n",
    "    \n",
    "    df=df.rename(columns={\"subclass_transaction_units\":\"units\"})\n",
    "    df=df.rename(columns={\"item_transaction_units\":\"units\"})\n",
    "    \n",
    "    df['sales']=df['sales'].astype(float)\n",
    "    df['units']=df['units'].astype(int)\n",
    "    \n",
    "    \n",
    "    df=pd.merge(df,df_prod_taxo_dep,on=['class_code_id','subclass_id'],how=\"left\")\n",
    "    df['department_id']=df['department_id'].fillna(\"-1\")\n",
    "    df['customer_id_hashed']=df['customer_id_hashed'].fillna(\"non_rewards\")\n",
    "    \n",
    "    df=df.groupby(['location_id','transaction_dt','transaction_id','customer_id_hashed','department_id'])['sales','units'].sum().reset_index()\n",
    "    df=df.sort_values(['customer_id_hashed','transaction_dt','location_id','transaction_id','department_id'])\n",
    "    \n",
    "    # add the transaction_order\n",
    "    df_order_this_week_rewards=df[df['customer_id_hashed']!=\"non_rewards\"]\n",
    "    df_order_this_week_rewards=df_order_this_week_rewards[['customer_id_hashed','transaction_dt','location_id','transaction_id']].drop_duplicates()\n",
    "    df_order_this_week_rewards=df_order_this_week_rewards.sort_values(['customer_id_hashed','transaction_dt','location_id','transaction_id'])\n",
    "    df_order_this_week_rewards['trans_order_in_week']=pd.Categorical(df_order_this_week_rewards['customer_id_hashed']+ '_'+\\\n",
    "                                                                     df_order_this_week_rewards['transaction_dt']+ '_'+\\\n",
    "                                                                     df_order_this_week_rewards['location_id']+ '_'+\\\n",
    "                                                                     df_order_this_week_rewards['transaction_id']\n",
    "                                                                    ).codes\n",
    "\n",
    "    df_min_index_per_id=df_order_this_week_rewards[['customer_id_hashed','trans_order_in_week']].sort_values(['customer_id_hashed','trans_order_in_week'],ascending=[True,True]).drop_duplicates(\"customer_id_hashed\")\n",
    "    df_min_index_per_id=df_min_index_per_id.rename(columns={\"trans_order_in_week\":\"min_order\"})\n",
    "    df_order_this_week_rewards=pd.merge(df_order_this_week_rewards,df_min_index_per_id,on=\"customer_id_hashed\",how=\"left\")\n",
    "    df_order_this_week_rewards['trans_order_in_week']=df_order_this_week_rewards['trans_order_in_week']-df_order_this_week_rewards['min_order']+1\n",
    "    \n",
    "    df_order_this_week_rewards=pd.merge(df_order_this_week_rewards,df_id_order_count,on='customer_id_hashed',how=\"left\")\n",
    "    df_order_this_week_rewards['trans_order_since_18Q1']=df_order_this_week_rewards['trans_order_since_18Q1'].fillna(0)\n",
    "    df_order_this_week_rewards['trans_order_since_18Q1']=df_order_this_week_rewards['trans_order_since_18Q1']+df_order_this_week_rewards['trans_order_in_week']\n",
    "    df_order_this_week_rewards=df_order_this_week_rewards[['customer_id_hashed','transaction_dt','location_id','transaction_id','trans_order_since_18Q1']]\n",
    "    df=pd.merge(df,df_order_this_week_rewards,on=['customer_id_hashed','transaction_dt','location_id','transaction_id'],how=\"left\")\n",
    "\n",
    "    #\n",
    "    df_order_this_week_rewards=df_order_this_week_rewards[['customer_id_hashed','trans_order_since_18Q1']].sort_values([\"customer_id_hashed\",\"trans_order_since_18Q1\"],ascending=[True,False]).drop_duplicates(\"customer_id_hashed\")\n",
    "    df_id_order_count=df_order_this_week_rewards.append(df_id_order_count).drop_duplicates(\"customer_id_hashed\")\n",
    "    \n",
    "    # format\n",
    "    df['location_id']=df['location_id'].astype(int)\n",
    "    df['transaction_dt']=pd.to_datetime(df['transaction_dt'],format=\"%Y-%m-%d\").dt.date\n",
    "    df['customer_id_hashed']=df['customer_id_hashed'].replace(\"non_rewards\",np.nan)\n",
    "    df=df.round({'sales': 2})\n",
    "    \n",
    "    print(df['transaction_dt'].min(),df['transaction_dt'].max(),datetime.datetime.now())\n",
    "    logging.info(str(df['transaction_dt'].min())+\" | \"+str(df['transaction_dt'].max())+\" | \"+str(datetime.datetime.now()))\n",
    "    \n",
    "\n",
    "    df.to_sql(\"Pred_POS_Department\",if_exists='append', con=BL_engine, index=False,chunksize=300000,\n",
    "                    dtype={\n",
    "                        'location_id':sqlalchemy.types.INTEGER(),\n",
    "                        'transaction_dt':sqlalchemy.Date(), \n",
    "                        'transaction_id':sqlalchemy.types.VARCHAR(length=16),\n",
    "                        'customer_id_hashed':sqlalchemy.types.VARCHAR(length=64),\n",
    "                        'department_id':sqlalchemy.types.VARCHAR(length=16),\n",
    "                        'sales':sqlalchemy.types.DECIMAL(precision=10,scale=2,asdecimal=True),\n",
    "                        'units':sqlalchemy.types.INTEGER()\n",
    "                    })\n",
    "\n",
    "    \n",
    "    i_counter+=1\n",
    "    print(\"done of file: \",i_counter,file)\n",
    "    logging.info(\"done of file: \"+str(i_counter)+\" | \"+file)\n",
    "\n",
    "    total_sales+=df['sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done of write to sql: 2020-01-10 18:27:42.701197\n",
      "total_sales 474663603.8099999\n"
     ]
    }
   ],
   "source": [
    "print(\"done of write to sql: \"+str(datetime.datetime.now()))\n",
    "logging.info(\"done of write to sql: \"+str(datetime.datetime.now()))\n",
    "print('total_sales',total_sales)\n",
    "logging.info('total_sales'+str(total_sales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done of indexing 2020-01-10 18:33:35.631022\n"
     ]
    }
   ],
   "source": [
    "with engine_pymysql_db_BL.cursor() as cur:\n",
    "    cur.execute(\"create index location_id on Pred_POS_Department(location_id);\")\n",
    "    cur.execute(\"create index transaction_dt on Pred_POS_Department(transaction_dt);\")\n",
    "    cur.execute(\"create index customer_id_hashed on Pred_POS_Department(customer_id_hashed);\")\n",
    "    cur.execute(\"create index department_id on Pred_POS_Department(department_id);\")\n",
    "    cur.execute(\"create index trans_order_since_18Q1 on Pred_POS_Department(trans_order_since_18Q1);\")\n",
    "print('Done of indexing',datetime.datetime.now())\n",
    "logging.info('total_sales'+str(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
